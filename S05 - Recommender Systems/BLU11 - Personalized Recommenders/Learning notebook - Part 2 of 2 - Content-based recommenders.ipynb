{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLU11 - Learning Notebook - Part 2 of 2 - Content-based recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix, load_npz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative recommenders use previous interactions to predict the interest of a given user in a particular item. However, due to the cold-start problem, this approach may be limited in the face of a developing community that is onboarding new players and games (that will have a low number of ratings to start with).\n",
    "\n",
    "In this notebook, we'll extend our system to include item metadata and explore an alternative approach where the recommendations are based on the identification of item properties that each user likes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Content-based recommenders\n",
    "\n",
    "Content-based recommenders extract item features from the available metadata and learn which of the features each user prefers.\n",
    "\n",
    "It's time to get back to the whiteboard üñäÔ∏è and time to delve into the `metadata.json` file. We import the item metadata into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoGameID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007 Legends</td>\n",
       "      <td>[Action, Shooter]</td>\n",
       "      <td>Gamers and Bond aficionados alike will become ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0RBITALIS</td>\n",
       "      <td>[Simulation, Indie]</td>\n",
       "      <td>0RBITALIS is a satellite launching simulator w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1... 2... 3... KICK IT! (Drop That Beat Like a...</td>\n",
       "      <td>[Action, Indie]</td>\n",
       "      <td>&lt;p&gt;Battle your favorite drum &amp;#39;n&amp;#39; bass ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Second Ninja</td>\n",
       "      <td>[Action, Indie]</td>\n",
       "      <td>Ninjas are cool, this is an established fact o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10,000,000</td>\n",
       "      <td>[Action, RPG, Casual, Indie, Puzzle]</td>\n",
       "      <td>&lt;p&gt;10000000 is a Dungeon Crawling RPG Matching...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Name  \\\n",
       "VideoGameID                                                      \n",
       "0                                                  007 Legends   \n",
       "1                                                    0RBITALIS   \n",
       "2            1... 2... 3... KICK IT! (Drop That Beat Like a...   \n",
       "3                                              10 Second Ninja   \n",
       "4                                                   10,000,000   \n",
       "\n",
       "                                           Genres  \\\n",
       "VideoGameID                                         \n",
       "0                               [Action, Shooter]   \n",
       "1                             [Simulation, Indie]   \n",
       "2                                 [Action, Indie]   \n",
       "3                                 [Action, Indie]   \n",
       "4            [Action, RPG, Casual, Indie, Puzzle]   \n",
       "\n",
       "                                                   Description  \n",
       "VideoGameID                                                     \n",
       "0            Gamers and Bond aficionados alike will become ...  \n",
       "1            0RBITALIS is a satellite launching simulator w...  \n",
       "2            <p>Battle your favorite drum &#39;n&#39; bass ...  \n",
       "3            Ninjas are cool, this is an established fact o...  \n",
       "4            <p>10000000 is a Dungeon Crawling RPG Matching...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_content():\n",
    "    df = pd.read_json(os.path.join(os.path.join('data', 'metadata.json')), orient='index')\n",
    "    df = (df.rename(columns={\"ID\": \"VideoGameID\"})\n",
    "            .set_index('VideoGameID')\n",
    "            .sort_index())\n",
    "    return df[['Name', 'Genres', 'Description']]\n",
    "\n",
    "\n",
    "item_content = read_content()\n",
    "item_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the `Genres` and `Description` columns in the form of text. Let's see how we can incorporate this information into our recommender."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Building item profiles\n",
    "\n",
    "We will start with the genre information. We will construct an item profile matrix $P_{IG}$, a matrix where rows are items and columns are genres $g$ from the set of all possible genres $G$. Assume that there are $n$ items and $w$ genres.\n",
    "\n",
    "$$P_{IG} = \\begin{bmatrix}p_{1, 1} & p_{1, 2} & \\dots & p_{1, w}\\\\ p_{2, 1} & p_{2, 2} & \\dots & p_{2, w}\\\\ \\dots & \\dots & \\dots & \\dots \\\\ p_{n, 1} & p_{n, 2} & \\dots & p_{n, w}\\end{bmatrix}$$\n",
    "\n",
    "The matrix values $p_{ig}$ represent whether, or how much, a given genre $g$ is present in the item $i$. What kind of values can we use for $p_{ig}$?\n",
    "\n",
    "We could use a one-hot encoding to simply represent the presence or absence of the given genre in each item. Or, as you just finished the NLP specialization and are a text processing pro, we can use a tfidf vectorization. üìÑ\n",
    "\n",
    "In this case, the term frequency is the occurence of genre $g$ in item $i$. For this data, a genre can occur at most once per item (boolean frequency), but things can be different if for instance the users could assign genres to games. The inverse document frequency weighting adjusts the term frequencies for the rarity of the genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Item profiles from the genres\n",
    "\n",
    "To build the item profiles, we use your old friend the [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer). Since the transformer is prepared to receive strings (and not lists), we need to do some Pandas magic to convert the lists to strings and reduce multi-word genres to a single string, e.g. \"Massively Multiplayer\" to \"MassivelyMultiplayer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genres = item_content['Genres'].apply(\";\".join).str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the transformer. We verify that it returns a sparse matrix, which is excellent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 12469 stored elements and shape (5155, 19)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of genres is not that long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['action', 'adventure', 'arcade', 'boardgames', 'card', 'casual',\n",
       "       'educational', 'family', 'fighting', 'indie',\n",
       "       'massivelymultiplayer', 'platformer', 'puzzle', 'racing', 'rpg',\n",
       "       'shooter', 'simulation', 'sports', 'strategy'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Item profiles from the item description\n",
    "\n",
    "Transforming the genre information to item features was easy-peasy. We can apply the same strategy to the item description and simply vectorize the description text. We can in fact join the `Genres` and `Description` text into one string and vectorize it at once. This will give another set of features, we'll call them tags, $t \\in T$. We can store them in the item profile matrix $P_{IT}$ with rows for all the items and columns for all the tags:\n",
    "\n",
    "$$P_{IT} = \\begin{bmatrix}p_{1, 1} & p_{1, 2} & \\dots & p_{1, z}\\\\ p_{2, 1} & p_{2, 2} & \\dots & p_{2, z}\\\\ \\dots & \\dots & \\dots & \\dots \\\\ p_{n, 1} & p_{n, 2} & \\dots & p_{n, z}\\end{bmatrix}$$\n",
    "\n",
    "Below we concatenate the descriptions with the genres and fit the transformer on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_content = item_content['Description'] + genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 688709 stored elements and shape (5155, 33710)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_profiles = vectorizer.fit_transform(all_content)\n",
    "item_profiles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a much larger and richer matrix with, hopefully, more descriptive power.\n",
    "\n",
    "Another approach would be to vectorize the genres and descriptions separately and then horizontally concatenate the two item profile matrices. We'd get a matrix with n rows (for each items) and with columns representing the genres and other features extracted from the item descriptions. The code would be the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "genre_profile = vectorizer.fit_transform(genres)\n",
    "description_profile = vectorizer.fit_transform(item_content['Description'])\n",
    "item_profiles_ = np.hstack([genre_profile.toarray(), description_profile.toarray()])\n",
    "item_profiles_ = csr_matrix(item_profiles_)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, there is always room for applying any feature selection or dimension reduction techniques to this item feature set, but we won't go into that here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Connecting users with items\n",
    "\n",
    "Item profiles are not enough to provide personalized recommendations as they do not consider the taste of the user.\n",
    "\n",
    "So far, we have the ratings matrix $R$ which represents user interactions with items and the item profiles matrix $P_{IT}$ which represents the item attributes. Is there a way to connect the item profiles to the user preferences?\n",
    "\n",
    "Yes, there is! We can project the ratings matrix into the space of item attributes by multiplying the two matrices and construct a user profiles matrix $P_{UT}$, an $m \\times z$ matrix which connects the item atributes to the users. This will be our user representation in the item attribute space. The matrix has a row for each user and a column for each item attribute or tag.\n",
    "\n",
    "$$P_{UT} = R \\times P_{IT}$$\n",
    "\n",
    "$$P_{UT} = \\begin{bmatrix}p_{1, 1} & p_{1, 2} & \\dots & p_{1, z}\\\\ p_{2, 1} & p_{2, 2} & \\dots & p_{2, z}\\\\ \\dots & \\dots & \\dots & \\dots \\\\ p_{m, 1} & p_{m, 2} & \\dots & p_{m, z}\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of the matrix is a dot-product of user ratings by item attributes:\n",
    "\n",
    "$$p_{u, t} = r_u \\cdot p_t = \\sum\\limits_{i=1}^n r_{u, i}p_{i, t}$$\n",
    "\n",
    "The $r_u$ stands for a row of the ratings matrix, i.e. a user, and $p_t$ stands for a column of the items profile matrix, i.e. an attribute. Basically, we weigh each attribute vector (which represents the strength of the given attribute for each item) by the user ratings for each item to get an estimate of how much this particular user likes that attribute. A good rating for item $i$ is a good rating to all attributes of $i$, i.e. if the user likes $i$ we assume they like the attributes of $i$. Effectively, we have transformed the user vector from a representation in the space of items (row in the ratings matrix) to a space of item attributes (row in the user profiles matrix).\n",
    "\n",
    "Armed with this knowledge, we can now build the user profiles matrix from our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Building the $P_U$ matrix\n",
    "\n",
    "The first step is to load the ratings matrix $R$ created in the first notebook and saved for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 128804 stored elements and shape (12393, 5155)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = load_npz(os.path.join('data', 'ratings_matrix.npz'))\n",
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we compute the dot product between the ratings matrix and the item profiles matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 6539426 stored elements and shape (12393, 33710)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_profiles = np.dot(R, item_profiles)\n",
    "user_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Making predictions\n",
    "\n",
    "The prediction step in content-based filtering is different from the collaborative filtering. First, recap. What do we have?\n",
    "\n",
    "* $R$, the ratings matrix.\n",
    "* $P_{IT}$, a matrix with item profiles.\n",
    "* $P_{UT}$, a matrix with user preferences represented in the space of item attributes.\n",
    "\n",
    "What do we want? To know what items best match each user's taste.\n",
    "\n",
    "Therefore, given that items and users are represented in the same space (same features/columns), we can use the cosine similarity to identify which items are closest to each user. Take $p^T_i$ and $p^T_u$ to represent a row of the $P_{IT}$ and $P_{UT}$ matrices, respectively. The cosine similarity between these vectors is:\n",
    "\n",
    "$$sim(p^T_u, p^T_i) = cos(\\theta) = \\frac{p^T_u \\cdot p^T_i}{||p^T_u||\\ ||p^T_i||}$$\n",
    "\n",
    "Again, we can compute the similarities for all the item-user pairs at once using matrix calculations:\n",
    "\n",
    "$$sim(P_{UT}, P_{IT}) = \\frac{P_{UT} \\times P_{IT}}{||P_{UT}||\\ ||P_{IT}||}$$\n",
    "\n",
    "The similarity values will be used for the predictions matrix and we will then select the items with the highest similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 60252254 stored elements and shape (12393, 5155)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_predictions(R, item_profiles, user_profiles):\n",
    "    \n",
    "    preds = cosine_similarity(user_profiles, item_profiles)\n",
    "    \n",
    "    # Exclude previously rated items.\n",
    "    preds[R.nonzero()] = 0\n",
    "    \n",
    "    return csr_matrix(preds)\n",
    "\n",
    "\n",
    "content_preds = make_predictions(R, item_profiles, user_profiles)\n",
    "content_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have a little less predictions using content-based recommendations, but usually it's the opposite. It just happens that we have a very populated ratings matrix in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05687734142964063"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sparsity(matrix):\n",
    "    return 1 - matrix.nnz / (matrix.shape[0] * matrix.shape[1])\n",
    "\n",
    "\n",
    "sparsity(content_preds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filtering\n",
    "\n",
    "We can now apply the filtering techniques (best-item, top-$N$) from the first notebook to generate content-based recommendations. To exemplify, we test the same best-item implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 857],\n",
       "       [  29],\n",
       "       [3872],\n",
       "       ...,\n",
       "       [ 983],\n",
       "       [1338],\n",
       "       [1338]], shape=(12393, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_best_item(pred):\n",
    "    return np.negative(pred).toarray().argsort()[:, :1]\n",
    "\n",
    "\n",
    "get_best_item(content_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of curiosity, let's check what is the game corresponding to the first prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoGameName    Cities XL Platinum\n",
       "Name: 857, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_games = pd.read_csv(os.path.join('data', 'video_games.csv'), index_col='VideoGameID')\n",
    "video_games.loc[857]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the gist, content-based recommenders will allow us to make recommendations even in the face of the cold-start problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Further reading\n",
    "We have looked at collaborative recommender systems which use only user-item interactions and at content-based recommender systems which also include item metadata. Another type of recommender systems are hybrid systems which use both user and item metadata. We did not have such data in our case and usually they are also more difficult to obtain than item metadata.\n",
    "\n",
    "You can read more about recommender systems in this [presentation](https://www.slideshare.net/slideshow/boston-ml-architecting-recommender-systems/111756663#20) from James Kirk.\n",
    "\n",
    "Now off to the exercise notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
