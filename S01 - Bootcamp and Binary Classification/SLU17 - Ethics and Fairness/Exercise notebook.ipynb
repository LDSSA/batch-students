{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7eefba202588b76c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## SLU17 - Ethics & Fairness - Exercise notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-91014708c09c3dd3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-dark')\n",
    "plt.rcParams[\"figure.figsize\"]=(3.5,3.5)\n",
    "\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "from utils.utils import make_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b49e97248f79ffb3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Criminal justice bias\n",
    "\n",
    "Exercise adaptated from the book [Fairness and Machine Learning by Solon Barocas, Moritz Hardt, and Arvind Narayanan](https://fairmlbook.org/pdf/fairmlbook.pdf).\n",
    "\n",
    "Based on the ProPublica's article [Machine Bias](https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing) about a proprietary risk score algorithm, called COMPAS, used in the US.\n",
    "\n",
    "This is the problem setting:\n",
    "\n",
    "> Risk assessment is an important component of the criminal justice system. In the United States, judges set bail and decide pre-trial detention based on their assessment of the risk that a released defendant would fail to appear at trial or cause harm to the public.\n",
    "\n",
    "These scores are intended to assess the risk that a defendant will re-offend, a task often called **recidivism prediction**.\n",
    "\n",
    "Weâ€™ll use data obtained and released by ProPublica. The data shows demographic and crim-related characteristics of convicted defendants. It also shows if they reoffended within a two-year period after release from jail (the `is_recid` column). The `decile_score` and `score_text` columns show the recidivism risk prediction of the COMPAS algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-451332a48de708b5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data = make_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-45e19c89bf364d74",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 1 - Score distribution for Black and White defendants\n",
    "\n",
    "In this exercise, we will compare the predicted `decile_score` distributions for different races. This is the score predicted by the COMPAS algorithm. High score means a high risk of reoffending. \n",
    "\n",
    "In the three cells below, plot the histograms of the `decile_score` for all defendants, for the Black defendants - `African-American` race, and for White defendants - `Caucasian` race. Use the `histtype='step'` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1214438aeb6fb1fb",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot here the decile_score histogram for all defendants.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c0db9a1ce9d279ff",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot here the decile_score histogram for the Black defendants.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e73a94d85986910b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot here the decile_score histogram for the White defendants.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-46558ca26fbf767c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Interpretation\n",
    "\n",
    "Based on these plots, what can you conclude from the distributions? Uncomment the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5a21d6a873bee7f1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# hypothesis_1 = 'The distributions of the scores are similar for the Black and White populations.'\n",
    "# hypothesis_1 = 'Scores for White defendants are skewed toward lower-risk categories.'\n",
    "# hypothesis_1 = 'Scores for Black defendants are skewed toward lower-risk categories.'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c7d5b413b2522590",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert hashlib.sha256(json.dumps(hypothesis_1).encode()).hexdigest() == \\\n",
    "'06e140a33dbeaa1e33267a84dde10c3edebbc01c64206f7cf30cd89839768209', 'Not correct.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76dada44dc86e56f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 2 - Error rates\n",
    "\n",
    "In this exercise, we will compare the predicted `decile_score` of people who have reoffended within a two-year period across the races. The reoffension is indicated in the column `is_recid`, 1 means reoffension.\n",
    "\n",
    "In the three cells below, plot the histograms of the `decile_score` for all reoffenders, for the Black reoffenders - `African-American` race, and for White reoffenders - `Caucasian` race. Use the `histtype='step'` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0d47432f9e15cc0b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot here the decile_score histogram for all reoffenders.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c75dac65af59a0ac",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot here the decile_score histogram for Black reoffenders.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c58fb419278988c1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot here the decile_score histogram for White reoffenders.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d33bdc3d3fed7431",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Interpretation\n",
    "\n",
    "Overall, the risk score doesn't appear to be particularly good at separating recidivists. The resulting histogram for all reoffenders resembles a uniform distribution.\n",
    "\n",
    "Based on these plots, uncomment the correct answer. (Remember, these histograms refer to **actual recidivists**.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-60a69c870b9bd3ca",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# hypothesis_2 = 'The distribution of recidivists scores is similar for both races groups.'\n",
    "# hypothesis_2 = 'Scores for White recidivists are skewed toward lower-risk categories.'\n",
    "# hypothesis_2 = 'Scores for Black recidivists are skewed toward lower-risk categories.'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ab17b0f1269533b3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert hashlib.sha256(json.dumps(hypothesis_2).encode()).hexdigest() == \\\n",
    "'b7ba150ca7b49b520bedee10410e7a92817a98aa4513e682769f618780f1489a', 'Not correct.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b4475f800084fc1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 3 - When predictions fail differently\n",
    "\n",
    "Defendants with `decile_score` higher than 4 are classified as being at high-risk of recidivism. In this exercise, we will compare the predictions for high-risk of recidivism across the races.\n",
    "\n",
    "In the cells below, calculate the false positive rate (FPR) for predictions of high-risk of recidivism for all people, for Black people - `African-American` race, and for White people - `Caucasian` race.\n",
    "\n",
    "Recall that the false positive rate, also known as the probability of false alarm, is given by:\n",
    "\n",
    "$$FPR = \\frac{FP}{FP + TN} = \\frac{FP}{N}$$\n",
    "\n",
    "Where $FP$ is the number of false positives, $TN$ is the number of true negatives, and $N$ the total number of negatives. You can use the `confusion_matrix` function to calculate the true/false positives/negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e4b38dad2d0bc97d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculate here the FPR for all people predicted at high-risk of recidivism.\n",
    "# fpr = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2c45aed7cea89b5d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate here the FPR for Black people predicted at high-risk of recidivism.\n",
    "# fpr_b = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f311ec4dff1d2d26",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate here the FPR for all White predicted at high-risk of recidivism.\n",
    "# fpr_w = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9f195b34ea5e7d27",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(fpr, 0.293, decimal=3, err_msg='Calculated fpr is not correct.')\n",
    "np.testing.assert_almost_equal(fpr_b, 0.414, decimal=3, err_msg='Calculated fpr_b is not correct.')\n",
    "np.testing.assert_almost_equal(fpr_w, 0.216, decimal=3, err_msg='Calculated fpr_w is not correct.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3e4536a4d58c9576",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(f'Overall FPR is {round(fpr,2)}, FPR for Black people is {round(fpr_b,2)}, and FPR for White people is {round(fpr_w,2)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bb87e47ad2cc67c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Clearly, Black people are disproportionately more often falsely predicted to be at high-risk of recidivism than White people."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
