{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad1289a5a69aed06",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# SLU11 - Tree-based models: Exercises\n",
    "\n",
    "⚠️  You will need graphviz for some of the exercises. Please follow the installation instructions in the README if you did not install it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0de77c0206c013f9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-23191391573685f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We will use the hiking weather data from the learning notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-26ece027fa34fb82",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = utils.make_data()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5bd781fc92eff09b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 1 - Decision Trees\n",
    "\n",
    "### 1.1 Gini impurity\n",
    "\n",
    "Used by the CART algorithm for classification, Gini impurity is an alternative to entropy.\n",
    "\n",
    "Similarly to entropy, it is a way to measure node homogeneity. As such, it can be used to identify promising splits.\n",
    "\n",
    "Take $p$ as the probability of the positive class, i.e., the proportion of positive cases in the set. The Gini impurity is given by:\n",
    "\n",
    "$$I_G(p)= 1 - p^2 - (1-p)^2$$\n",
    "\n",
    "It measures how often a randomly chosen element from the set would be incorrectly labeled.\n",
    "\n",
    "Implement it in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-096c9f233958084b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gini(p):\n",
    "    \"\"\" \n",
    "    Returns the Gini impurity for the given probability\n",
    "    \n",
    "    Args:\n",
    "        p (float): probability of the positive class\n",
    "        \n",
    "    Returns:\n",
    "        (float): Gini impurity for the given probability\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cd65813e62272b59",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(gini(p=0),float), 'The output should be a float.'\n",
    "assert  hashlib.sha256(json.dumps(str(gini(p=0))).encode()).hexdigest() == \\\n",
    "'16522468b17d5af6df90b05f6f6b8a1258ecb7b824dab04bfc63e1ed623558c7', 'The calculated gini impurity is not correct.'\n",
    "assert  hashlib.sha256(json.dumps(str(gini(p=1/6))).encode()).hexdigest() == \\\n",
    "'75116388ece71b50aaaaf8abb686c87975d70a06fce6b74ced563f768b4762c4', 'The calculated gini impurity is not correct.'\n",
    "assert  hashlib.sha256(json.dumps(str(gini(p=1/3))).encode()).hexdigest() == \\\n",
    "'9c33f8289cfa4048673daafd4e8fe1290e79d77f0cec5378b80f8b7c36b3d3fc', 'The calculated gini impurity is not correct.'\n",
    "assert  hashlib.sha256(json.dumps(str(gini(p=1/2))).encode()).hexdigest() == \\\n",
    "'55a1a301b2e39a34ca61eee36a76e8c97ad7c2d71a91906baad643dcfc1f2928', 'The calculated gini impurity is not correct.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04b84fddb28c08cc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1.2 Applying the Gini impurity\n",
    "\n",
    "#### 1.2.1 Single node\n",
    "\n",
    "Compute the Gini impurity of a node with all samples with normal humidity.\n",
    "\n",
    "In the first step, define a function that computes the probability of the positive class at the given node.\n",
    "\n",
    "Then use the function to calculate the probability and the Gini impurity for a node that includes all instances where $x_i^{Humidity}$ is `'normal'`.\n",
    "\n",
    "Note that `'normal'` is a string, not a boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1eb99a6c8f5fd94d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_probability(node):\n",
    "    \"\"\" \n",
    "    Returns the probability of the positive class at the given node.\n",
    "    \n",
    "    Args:\n",
    "        node (pd.DataFrame): samples belonging to the node,\n",
    "                             a subset of the data dataframe\n",
    "        \n",
    "    Returns:\n",
    "        (float): probability of the positive class at the given node\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "# Now \n",
    "# single_node_gini = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f847f2e82a8bd209",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert hashlib.sha256(json.dumps(str(single_node_gini)).encode()).hexdigest() == \\\n",
    "'e240cf038f4b3a3b865762f0420828c390f8d90b0e7de9aa8550b4bd9105063f', \"Are you computing the probability for the right node? \\\n",
    "Are you checking all instances where Class is TRUE?\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-be5197a0bc4535d5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### 1.2.2 Single feature\n",
    "\n",
    "Write a function to compute the mean Gini impurity of branching the given data on the given feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ca4c34be595ebcb3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def mean_impurity(data, feature_name):\n",
    "    \"\"\" \n",
    "    Returns the mean Gini impurity of branching the given data on the given feature\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): samples dataframe\n",
    "        feature_name (string): feature on which the node should branch\n",
    "        \n",
    "    Returns:\n",
    "        (float): mean impurity of branching the given data on the given feature\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-92d7465bbb671305",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(mean_impurity(data, 'Outlook'),float), 'The output should be a float.'\n",
    "assert hashlib.sha256(json.dumps(str(round(mean_impurity(data, 'Outlook'),4))).encode()).hexdigest() == \\\n",
    "'5830db5516c4425f35f1e07c77099a86a9f9ac935da32df698db4a6790b1e544', 'The mean impurity for the Outlook feature is not correct.'\n",
    "assert hashlib.sha256(json.dumps(str(round(mean_impurity(data, 'Humidity'),4))).encode()).hexdigest() == \\\n",
    "'27d59dff61e8ae2b23d553db74d8be2ef5d343f8dcb41cb88a0523eeba8e20e2', 'The mean impurity for the Humidity feature is not correct.'\n",
    "assert hashlib.sha256(json.dumps(str(round(mean_impurity(data, 'Temperature'),4))).encode()).hexdigest() == \\\n",
    "'3157bf686408d38a62a06be8ed1c460ac1565d6613ce0e792665a5a82fe4f99d', 'The mean impurity for the Temperature feature is not correct.'\n",
    "assert hashlib.sha256(json.dumps(str(round(mean_impurity(data, 'Windy'),4))).encode()).hexdigest() == \\\n",
    "'9e6b44d567ead782bf355adea0554cba7dbf36286397d3d995ac26023e47f9f8', 'The mean impurity for the Windy feature is not correct.'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-64e25603766a0f61",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1.3 Analyzing a decision tree\n",
    "\n",
    "#### 1.3.1 DecisionTreeClassifier\n",
    "\n",
    "Import and train a DecisionTreeClassifier using the provided features X and target y.\n",
    "\n",
    "* Set `random_state = 101`\n",
    "* use the `entropy`criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3589b3ae147946e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# we will use this data in this exercise\n",
    "exercise_data = utils.make_exercise_data()\n",
    "X, y = utils.separate_target_variable(exercise_data)\n",
    "X = utils.process_categorical_features(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1adca6f8556b71f2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Import the model\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Instantiate the model with random_state=101, and assign it to the variable \"model\". Then fit it to the data\n",
    "# model = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2b25486151a99ff4",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert hashlib.sha256(json.dumps(str(model.get_params())).encode()).hexdigest() == \\\n",
    "'a506fbdfc7b7fe53a0ef12218f267be76af167861b7df9d19dee8d865c995a7e', \"Did you set up the model as required?\"\n",
    "assert len(model.predict(X))==len(y), 'Did you fit the model correctly?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2b16bb4342d9273f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.3.2 Analyze the resulting tree\n",
    "The fitted decision tree `model` from the previous exercise is shown here. Examine it and answer questions about it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-305f6ceccf83d72f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tree = utils.visualize_tree(model, X.columns, [\"negative_class\", \"positive_class\"])\n",
    "Image(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6071b6c8ab8707a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "a) A new instance of data has the following features: \n",
    "\n",
    "* `fruit` is not equal to `papaya`;\n",
    "* `Region` is not equal to `Central America`;\n",
    "* `sweet` is not equal to `y`.\n",
    "\n",
    "To which class will this decision tree assign this new instance? ('positive_class' or 'negative_class'). Assign the answer to variable `a_answer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3121ada0143f47eb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# a_answer = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b5731dacae1388ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "b)  One of the four statements below is **false**. Assign its number to variable `b_answer`.\n",
    "\n",
    "1. When building a decision tree using the ID3 algorithm,  at each split, we select the attribute test that leads to the highest information gain.\n",
    "2. Decision trees aren't extremely robust to overfitting.\n",
    "3. We can use a decision tree to represent a set of complex rules.\n",
    "4. Entropy can be seen as a measure of homogeneity in a set of values. The more entropy, the more homogeneous it will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8dc20adf21b9b42a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# b_answer = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62ffd43b55d81c25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "c) What is the name of the most important feature of this decision tree, `model`? Assign it to variable `c_answer`. Feel free to use any functions/methods needed to obtain this answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d69772097f40e125",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# feature_importances = ...\n",
    "# c_answer = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9f9ede8eb23ecb90",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "final_answer = str(b_answer) + a_answer + c_answer\n",
    "assert hashlib.sha256(json.dumps(final_answer).encode()).hexdigest() == \\\n",
    "'f8113e64e76abb4a42a94fdf6d07de8ec4fc3ddb36e855e0c185d17a26270c38', \"Some answers are wrong!\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fd2ce5a9573d00ff",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 2 - Ensemble models\n",
    "\n",
    "### 2.1 Bagging\n",
    "\n",
    "Assign the lowercase letter of the **incorrect statement** to the variable `bagging_answer`:\n",
    "\n",
    "a) Bagging is an ensemble method in which the predictions of several weak learners are combined to generate a final prediction.\n",
    "\n",
    "b) Bagging involves creating multiple data sets by sampling columns.\n",
    "\n",
    "c) Bootstrapping, often used when bagging, is the creation of several datasets through row sampling of a main dataset.\n",
    "\n",
    "d) Bagging helps to deal with overfitting, which is a big risk when using Decision Trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c734638ada0323ab",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# bagging_answer = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashlib.sha256(json.dumps(bagging_answer).encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f0ee1005cf77cd42",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert hashlib.sha256(json.dumps(bagging_answer).encode()).hexdigest() == \\\n",
    "'c100f95c1913f9c72fc1f4ef0847e1e723ffe0bde0b36e5f36c13f81fe8c26ed', 'Not correct.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0eaa70d393975c48",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.2 Random forests\n",
    "\n",
    "Assign the lowercase letter of the **incorrect statement** to the variable `forest_answer`:\n",
    "\n",
    "a) We use random feature selection with random forests to force our models to be \"creative\" and adapt to not having access to the full information, thus increasing diversity inside the ensemble.\n",
    "\n",
    "b) Random forests aggregate the predictions of multiple models running in parallel.\n",
    "\n",
    "c) Random forests aggregate the predictions of multiple models running sequentially.\n",
    "\n",
    "d) Random forests rely on random feature selection before each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7841ec3e8a3d8ab4",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# forest_answer = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d7e4db2d6899e82f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert hashlib.sha256(json.dumps(forest_answer).encode()).hexdigest() == \\\n",
    "'879923da020d1533f4d8e921ea7bac61e8ba41d3c89d17a4d14e3a89c6780d5d', 'Not correct.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d81f6f19292ecf56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.3 - Gradient boosting\n",
    "\n",
    "Assign the lowercase letter of the **incorrect statement** to the variable `boosting_answer`:\n",
    "\n",
    "a) Gradient boosting fits individual trees sequentially, to the negative gradients of the previous tree.\n",
    "\n",
    "b) Gradient boosting is fairly robust to over-fitting so a large number of estimators usually results in worse performance.\n",
    "\n",
    "c) Gradient boosting can only be used to optimize the squared error loss function.\n",
    "\n",
    "d) Gradient boosting fits individual trees on the residuals of the previous tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-19d101619190adb0",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# boosting_answer = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2aa78ad9cfadcba8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert hashlib.sha256(json.dumps(boosting_answer).encode()).hexdigest() == \\\n",
    "'879923da020d1533f4d8e921ea7bac61e8ba41d3c89d17a4d14e3a89c6780d5d', 'Not correct.'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
