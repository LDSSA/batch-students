{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4779b21",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96cd08680b07fd21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import io\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp\n",
    "from plotchecker import LinePlotChecker, ScatterPlotChecker, BarPlotChecker\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "plt.rcParams['figure.figsize']=(4.8, 3.6)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cba64a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8649ce0b822858ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the previous BLU, we worked with the \"Velho Banco\" data set, with the goal to design a system that predicts if a given individual earns more than 50K a year. \n",
    "\n",
    "As a reminder, each row in the dataset is about a client, and here's the attribute information:\n",
    "\n",
    "    1) age - client's age\n",
    "    2) workclass - type of work performed by the client (eg. `Private`)\n",
    "    3) fnlwgt - final weight assigned by the Census Bureau: if two samples have the same (or similar) fnlwgt they have similar characteristics, demographically speaking\n",
    "    4) education - level of education of client (eg. `Bachelors`)\n",
    "    5) education-num - numerically encoded level of education\n",
    "    6) marital-status - client's marital status (eg `Widowed`)\n",
    "    7) occupation - type of job held by the client (eg. `Craft-repair`)\n",
    "    8) relationship - family position of the client\n",
    "    9) race - client's race\n",
    "    10) sex - \"male\"/\"female\"\n",
    "    11) capital-gain - total capital gain in the previous year\n",
    "    12) capital-loss - total capital loss in previous year\n",
    "    13) hours-per-week - number of hours the the client works per week\n",
    "    14) native-country - client's original nationality (eg. `Portugal`)\n",
    "\n",
    "The original data set is located in `data/bank.csv`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0340f23-b802-4f3b-9885-eb6d44ef42c1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f86e818301e9e0fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Recently your client has provided you with a new set of observations, located in `data/bank_new_observations.csv`. This is your goal:\n",
    "\n",
    "- Assess how your model performs with the new dataset\n",
    "- Assess if there have been any changes to the data \n",
    "- Deploy a new model\n",
    "\n",
    "Start by loading the old and new data and have a quick look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd645b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5a5d9ea7d542b8b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    df = pd.read_csv(os.path.join(\"data\", file))\n",
    "    return df\n",
    "df_original = load_data(\"bank.csv\")\n",
    "df_new = load_data(\"bank_new_observations.csv\")\n",
    "target='salary'\n",
    "df_new.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1eb0eafa-5111-45e2-b134-7b3bf873685c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-137881b8963bcb30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1 - Data drift\n",
    "\n",
    "One of the most important things is to check if the data has changed over time. This data is not timestamped, so the approach will be to check if the distribution has changed from one data set to the other. Let's begin!\n",
    "\n",
    "**Important note about the grading**: Grading plots is difficult! We are using [`plotchecker`](https://github.com/jhamrick/plotchecker) to grade the plots with `nbgrader`. For `plotchecker` to work with nbgrader, we need to have the following line in the solution cell, after the code required to do the plot:\n",
    "\n",
    "```\n",
    "axis = plt.gca();\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c72aa1c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7230e5aeecd1dab4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.1 - Feature distributions\n",
    "\n",
    "Start by building a function to plot the histogram of the given feature and data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89005ff",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d38810c26a6f6b3f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_distribution_histogram(dataframe, \n",
    "                                    column_name, \n",
    "                                    title, x_axis_label, y_axis_label,\n",
    "                                    label_name,\n",
    "                                    number_bins = 15):\n",
    "    \"\"\"\n",
    "    This function generates a histogram for the column_name feature from the dataframe.\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): Input dataframe\n",
    "        column_name (str): Name of the column to plot\n",
    "        title (str): Title of the histogram\n",
    "        x_axis_label (str): X-axis label\n",
    "        y_axis_label (str): Y-axis label\n",
    "        label_name (str): plot label in the legend\n",
    "        number_bins (str): number of bins of the histogram\n",
    "    Returns:\n",
    "        Histogram of the column_name column from dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    plt.legend(loc='upper right')\n",
    "    axis = plt.gca();\n",
    "    return axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e387f8-2f75-48cc-a4c5-2b5feb49966c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8b9ecb359e8afde4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Plot the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c488b89-600d-4b90-8bed-51d2713472cf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7555c5f9a3094575",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "axis = generate_distribution_histogram(df_new, 'age',\n",
    "                                title = 'Age Distribution: Velho Banco',\n",
    "                                x_axis_label = 'Age (years)',\n",
    "                                y_axis_label = 'Frequency',\n",
    "                                label_name = 'Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e04b7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2a86e98ad84f32e7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pc = BarPlotChecker(axis)\n",
    "l = [pc.xlabel] + [pc.ylabel]\n",
    "\n",
    "assert hashlib.sha256(json.dumps(''.join(l)).encode()).hexdigest() == \\\n",
    "'96587ec8128cfd651ee75e3659b87264b9140ed983af5982a367780577004501', 'Did you set the correct axis labels?'\n",
    "assert hashlib.sha256(json.dumps(pc.title).encode()).hexdigest() == \\\n",
    "'6f3ef4e639562eaec813bcbe1260e2a0d059446a7dc0f852eb996f48bfe6c0d1', 'Did you set the correct plot title?'\n",
    "try:\n",
    "    pc.assert_num_bars(15)\n",
    "except:\n",
    "    \"Did you set the right number of bins?\"\n",
    "assert hashlib.sha256(json.dumps(' '.join([str(i) for i in pc.heights])).encode()).hexdigest() == \\\n",
    "'b274d2f78fd524e2123991f138d515ad7a6ee24f9317eaa935625b0a7121a75e', 'Did choose the correct variable and plot type?'\n",
    "assert hashlib.sha256(json.dumps(' '.join([str(round(i,2)) for i in pc.centers])).encode()).hexdigest() == \\\n",
    "'3fcabfacf502b2c70af55c6cd38ca0dd7e108e0772f782ece147a502540f8abc', 'Did choose the correct variable and plot type?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6d8ddf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c700286f49dcbaa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.2 - Old and new age\n",
    "Let's use your function to look at the \"Age\" variable of the original and new data. Examine the plot and answer the question below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b5f59",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-16ad1e9b7eb15d73",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "axis = generate_distribution_histogram(df_original, 'age',\n",
    "                                title = 'Age Distribution: Velho Banco',\n",
    "                                x_axis_label = 'Age (years)',\n",
    "                                y_axis_label = 'Frequency',\n",
    "                                label_name = 'Original data')\n",
    "axis = generate_distribution_histogram(df_new, 'age',\n",
    "                                title = 'Age Distribution: Velho Banco',\n",
    "                                x_axis_label = 'Age (years)',\n",
    "                                y_axis_label = 'Frequency',\n",
    "                                label_name = 'New data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76af75f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05177050f00f7e93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Do you think there was a change in the distribution? Answer with `\"yes\"` or `\"no\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166d349",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6bce97fde5dcd36b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer_1_2 = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326961f9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-221bb1b584d9dd11",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert hashlib.sha256(json.dumps(answer_1_2).encode()).hexdigest() == \\\n",
    "'04a06452677210a3cdaec376fd5ebbca1714cb7af9e62bf5cce1644310a9086a', \"Look again!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1f9ed6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b2dadef9a85dc3be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.3 K-S statistic\n",
    "\n",
    "How sure are you about your answer to the previous question? That's what statistics is for! \n",
    "\n",
    "As we covered in the learning notebook, the [K-S statistic](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ks_2samp.html) is a useful tool to check if the new data belongs to the same distribution as the original data. Let's use it to corroborate our hypothesis. Our null hypothesis is that the distributions are the same. We want to know with confidence level of 95%. If the p-value<0.05, we'll have to reject the null hypothesis, otherwise we keep it.\n",
    "\n",
    "Implement the function below to return the p-value of the K-S statistic for the distribution of the selected feature from the new and original data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6522bddb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1fe5c5c130ff4717",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_ks_test(feature, training_df, new_df):\n",
    "    \"\"\"\n",
    "    Returns the k-s statistic for the distribution of the same feature in two datasets.\n",
    "    Args:\n",
    "        feature (str): feature name\n",
    "        training_df (pd.DataFrame): dataframe used to train the model\n",
    "        new_df (pd.DataFrame): dataframe with the new data\n",
    "    Returns:\n",
    "        p-value of the K-S statistic for feature in training_df and new_df\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6f83a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7b69f4b8e2335fbe",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pvalue = get_ks_test('age', df_original, df_new)\n",
    "assert isinstance(pvalue, float), \"Are you returning just the p-value?\"\n",
    "np.testing.assert_almost_equal(pvalue, 0.9331, decimal=3, \n",
    "                err_msg=\"The p-value is not correct.\")\n",
    "print(f'p-value: {pvalue}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc84a9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a2685fbad657f66f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "With a p-value as high as this, it's pretty safe to say that for the age, there is no difference in the distribution of values. What about the other features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70444d33",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-30d76e50782846f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.4 - Statistics for all features\n",
    "\n",
    "Using the function above, check if there is any significant change in any feature distribution for the new and training data sets.\n",
    "\n",
    "Calculate the p-values for all the features in the data sets. Save the results in a dictionary called `ks_test_dict` and don't forget to exclude the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bdf1ae",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f479320b89643340",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ks_test_dict = {}\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97d294",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-65521b9fd493215c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(ks_test_dict, dict), 'The result should be a dictionary.'\n",
    "assert hashlib.sha256(json.dumps(' '.join(sorted(ks_test_dict.keys()))).encode()).hexdigest() == \\\n",
    "'5af9f4d5e6510a7564b1938b29cf39e500c237e2477f3d9025f4e93dd3578c57', \"Have you excluded the target variable?\"\n",
    "np.testing.assert_almost_equal(sum(ks_test_dict.values()), 11.41, decimal=2,\n",
    "            err_msg=\"The p-values are not correct?\")\n",
    "ks_test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a112e9-368f-44c7-9ccb-ea076bb0d563",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-682718de3a7bffa1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's check if any of the features has changed significantly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de57462",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4a8e06e7b86c52f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for k,v in ks_test_dict.items():\n",
    "    if v < 0.005:\n",
    "        print(\"Feature {k} has changed significantly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae7d22b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c27e3ccb061f166",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we can safely say that we do not have a case of data drift on our hands. At least with the very basic tests that we've done. Knowing this, we can combine all the data we have and see if the model improves!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f364908-d14f-4729-9b20-387904d1d38d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1c36118f42aa77e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2 - Prepare data\n",
    "We know that the data is the same, so we'll merge the old and new data and prepare the train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8ab289-2483-49a8-8d69-00045166ca8d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b6116c5fc9874a98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.1 - Combine data sets\n",
    "\n",
    "Combine the two datasets into one. Add a new column called `is_new` that is going to have `False` values for the old data and `True` values for the new observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5dd4c3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-905f1ad95e11cc3c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# df_combined = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c4928a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-59f405baf8725c0d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_combined.shape == (32561, 16), 'The shape of the combined dataframe is wrong.'\n",
    "assert 'is_new' in df_combined.columns, 'Did you add the is_new column?'\n",
    "assert sum(df_combined['is_new']) == 14561, 'The is_new column has a wrong number of True values.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec0e735",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4979ebd01837370a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In total we now have 32561 observations. This dataset is still small enough so that we do not have to do any data selection to retrain our model, but the same might not be true for future iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8dc832",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ac2bb3e0f273242b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.2 - Prepare the train and test sets\n",
    "\n",
    "Split the combined data into train and test sets in the following way:\n",
    "- Create train and test dataframes. Call them `df_train` and `df_test`. We'll need them in the following exercises.\n",
    "    - Test set should be 25% of `df_combined`.\n",
    "    - Make sure to have 25% of new values in the test sample.\n",
    "    - Use random state 42 while splitting the data sets.\n",
    "- Binarize the target into `True` and `False` values:\n",
    "    - `False`: client has a salary of less or equal than 50K\n",
    "    - `True`: client has a salary higher than 50K\n",
    "- Separate the train and test dataframes into features and target - `X_train`, `X_test`, `y_train` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23bc1d6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4598367d0a6061d7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b9a85",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cd33090db78fc4ca",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_train.shape == (24420, 16), 'The shape of df_train shape is wrong.?'\n",
    "assert df_train[target].dtype == 'bool', \"Have you changed the target variable to binary?\"\n",
    "assert df_test.shape == (8141, 16), 'The shape of df_test is wrong.?'\n",
    "assert df_test[target].dtype == 'bool', \"Have you changed the target variable to binary?\"\n",
    "assert sum(X_train['is_new']) == 10920, 'The is_new column in the training dataset set has a wrong number of True values.'\n",
    "assert sum(X_test['is_new']) == 3641, 'The is_new column in test dataframe has a wrong number of True values.'\n",
    "assert X_train.shape == (24420, 15), 'The shape of X_train is wrong.'\n",
    "assert X_test.shape == (8141, 15), 'The shape of X_test is wrong.'\n",
    "assert y_train.shape == (24420,), 'The shape of X_train is wrong.'\n",
    "assert y_test.shape == (8141,), 'The shape of X_train is wrong.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed936045",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-950b3692c2accef4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 3 - Retrain the original model with all data\n",
    "Now we need to retrain the model. Load the original model pipeline provided by the client from the `pipeline_blu14.pickle` file in the `data` directory. Train the pipeline with the training data created in ex. 2.2 and calculate the probabilities for the positive class and the predictions on the test set. Calculate the precision and recall for the predictions. Calculate also the the retrieval rates for male and female clients which were the important parameters for the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5b0dd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7530d8bc1189fb35",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# pipeline = ...\n",
    "# proba_pos = \n",
    "# preds = \n",
    "# precision_baseline = \n",
    "# recall_baseline = \n",
    "# retrieval_male_baseline = \n",
    "# retrieval_female_baseline = \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f674067",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8d3bed017ca3c9fd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(pipeline, Pipeline)\n",
    "assert len(preds)==8141, 'The predictions are not correct.'\n",
    "np.testing.assert_almost_equal(sum(preds), 3542, decimal=0, err_msg='The predictions are not correct.')\n",
    "assert proba_pos.shape==(8141,), 'The probabilities are not correct.'\n",
    "assert preds[0] == (proba_pos[0]>0.5), 'The probabilities should be of the positive class.'\n",
    "np.testing.assert_almost_equal(sum(proba_pos), 3609.23, decimal=2, err_msg='The probabilities are not correct.')\n",
    "assert isinstance(precision_baseline, float), 'The precision should be a float.'\n",
    "np.testing.assert_almost_equal(precision_baseline, 0.47, decimal=2, err_msg='The precision is not correct.')\n",
    "assert isinstance(recall_baseline, float), 'The recall should be a float.'\n",
    "np.testing.assert_almost_equal(recall_baseline, 0.86, decimal=2, err_msg='The recall is not correct.')\n",
    "assert isinstance(retrieval_male_baseline, float), 'The male retrieval rate should be a float.'\n",
    "np.testing.assert_almost_equal(retrieval_male_baseline, 0.91, decimal=2, err_msg='The male retrieval rate is not correct.')\n",
    "assert isinstance(retrieval_female_baseline, float), 'The female retrieval rate should be a float.'\n",
    "np.testing.assert_almost_equal(retrieval_female_baseline, 0.55, decimal=2, err_msg='The female retrieval rate is not correct.')\n",
    "print(f'Precision: {precision_baseline}, recall: {recall_baseline}')\n",
    "print(f'Male retrieval rate {retrieval_male_baseline}, female retrieval rate {retrieval_female_baseline}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73603ec3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b4fec662e1b35676",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 4 - Probability threshold\n",
    "Our recall is pretty good, but the precision is not even 50%. The difference between the male and female retrieval rates is also quite large. \n",
    "\n",
    "Let's try to improve the precision to at least 50% by selecting another threshold for the probabilities `proba_pos` calculated in ex. 3. Use the precision-recall curve to find the threshold where the precision is at least 0.5. Calculate the corresponding recall and the male and female retrieval rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce566acc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8daf046ccb24741e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# threshold = ...\n",
    "# precision_threshold = \n",
    "# recall_threshold =\n",
    "# retrieval_male_threshold = \n",
    "# retrieval_female_threshold = \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e130e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1169c2176dcd94b3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(threshold, float), 'Threshold should be a float.'\n",
    "assert isinstance(precision_threshold, float), 'The precision should be a float.'\n",
    "assert isinstance(recall_threshold, float), 'The recall should be a float.'\n",
    "assert isinstance(retrieval_male_threshold, float), 'The male retrieval rate should be a float.'\n",
    "assert isinstance(retrieval_female_threshold, float), 'The female retrieval rate should be a float.'\n",
    "np.testing.assert_almost_equal(threshold + precision_threshold + recall_threshold + retrieval_male_threshold + retrieval_female_threshold,\n",
    "                               2.946778566399038, decimal=3, err_msg='The calculated values are not correct.')\n",
    "np.testing.assert_almost_equal(np.var([threshold,precision_threshold,recall_threshold,retrieval_male_threshold,retrieval_female_threshold]),\n",
    "                               0.0, decimal=1, err_msg='The calculated values are not correct.')\n",
    "print(f'Precision: {precision_threshold}, recall: {recall_threshold}')\n",
    "print(f'Male retrieval rate {retrieval_male_threshold}, female retrieval rate {retrieval_female_threshold}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6548b1a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-895fde939e211975",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 5 - Remove rare values\n",
    "\n",
    "The female retrieval rate is much worse for just a small gain in precision, so that is not the way to go. Let's see if we can work on the data set. We will try to remove rare values for some of the features.\n",
    "\n",
    "Filter rare values for the following features in `df_train`:\n",
    "- Remove rows with `education` that appear <= 150 times.\n",
    "- Remove rows with `marital-status` that appear <= 30 times.\n",
    "\n",
    "The filtered data should be stored in a new dataframe `df_filtered`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3ba6a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-464a40e1e6037a35",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_filtered = df_train.copy()\n",
    "# train_filtered = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c3fdc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1a2d374b946aa3e3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert train_filtered.shape == (24236, 16), 'The shape of the filtered dataframe is not correct.'\n",
    "assert hashlib.sha256(json.dumps(' '.join(sorted(train_filtered.education.unique()))).encode()).hexdigest() == \\\n",
    "'48405cefe80fabb9e11337caa0b8e770f6bc76d131259ffd4edfd378791fcb96'\n",
    ", 'The education feature is not filtered correctly.'\n",
    "assert hashlib.sha256(json.dumps(' '.join(sorted(train_filtered['marital-status'].unique()))).encode()).hexdigest() == \\\n",
    "'2d65f0c31a2d8bfde9f97d036ac0b46a0f32b52538ec0ac1af013e6c84fe6c69', 'The marital-status column is not filtered correctly.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e8188",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-74cb193c45b9470c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 6 - Merge similar values\n",
    "\n",
    "The `workclass` feature has several values that represent the same information. It might be beneficial to merge them.\n",
    "\n",
    "Implement the function below that merges the `?`, `Without-pay`, and `Never-worked` values in the `workclass` column into a single `No-salary` category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c9b56",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b57ecbc07311aa67",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def merge_workclass_values(df):\n",
    "    \"\"\"\n",
    "    Merges the ?, Without-pay, and Never-worked values in the workclass column of df into a single No-salary category.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe with a workclass column\n",
    "    Returns:\n",
    "        df_merged_workclass (pd.DataFrame): dataframe with merged values in the workclass column\n",
    "    \"\"\"\n",
    "    df_merged_workclass = df.copy()\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return df_merged_workclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c120c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ad7f12498232f88c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_filtered = merge_workclass_values(train_filtered)\n",
    "assert train_filtered.shape == (24236, 16), 'The shape of the filtered dataframe is not correct.'\n",
    "assert sum(train_filtered.workclass=='No-salary') == 1411, 'Did you merge the categories correctly?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2933e94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-12c3ce1eb7fb939c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 7 - Predict on the filtered data\n",
    "\n",
    "Let's split `train_filtered` into `X` and `Y` parts and do the same thing once again:\n",
    "- Fit the pipeline.\n",
    "- Merge the workclass values in the test set.\n",
    "- Calculate predictions on the processed test set.\n",
    "- Calculate precision and recall.\n",
    "- Calculate male and female retrieval rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c9d89",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6dcd4961cd62a260",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# preds_filtered = \n",
    "# precision_filtered = \n",
    "# recall_filtered = \n",
    "# retrieval_male_filtered = \n",
    "# retrieval_female_filtered = \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3a0d9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-db39a36ffa243bdc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(preds_filtered)==8141, 'The predictions are not correct.'\n",
    "np.testing.assert_almost_equal(sum(preds_filtered), 3649, decimal=0, err_msg='The predictions are not correct.')\n",
    "assert isinstance(precision_filtered, float), 'The precision should be a float.'\n",
    "np.testing.assert_almost_equal(precision_filtered, 0.46, decimal=2, err_msg='The precision is not correct.')\n",
    "assert isinstance(recall_filtered, float), 'The recall should be a float.'\n",
    "np.testing.assert_almost_equal(recall_filtered, 0.87, decimal=2, err_msg='The recall is not correct.')\n",
    "assert isinstance(retrieval_male_filtered, float), 'The male retrieval rate should be a float.'\n",
    "np.testing.assert_almost_equal(retrieval_male_filtered, 0.92, decimal=2, err_msg='The male retrieval rate is not correct.')\n",
    "assert isinstance(retrieval_female_filtered, float), 'The female retrieval rate should be a float.'\n",
    "np.testing.assert_almost_equal(retrieval_female_filtered, 0.56, decimal=2, err_msg='The female retrieval rate is not correct.')\n",
    "print(f'Precision: {precision_filtered}, recall: {recall_filtered}')\n",
    "print(f'Male retrieval rate {retrieval_male_filtered}, female retrieval rate {retrieval_female_filtered}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733fc799",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f83dae43b3828639",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 8 - Retrain the model on all data\n",
    "Our retrained model has a slightly worse precision and better recall, but still a large difference in the male and female retrieval rates. It's usually a good idea to retrain the model on the whole dataset, so now I want you to:\n",
    "- Apply the filters from exercise 5 ` to `df_combined`\n",
    "- Apply the transformation of the `workclass` column from exercise 6 to `df_combined`\n",
    "- Train the pipeline on the combined data\n",
    "- Export the trained pipeline, columns names, and data types to the `/tmp` directory to the files `new_pipeline.pickle`, `new_dtypes.pickle`, and `new_columns.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcbb094",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fb28e12d8a8a4577",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97683298",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cf52c8c09d0bd55c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('/tmp', 'new_columns.json')) as fh:\n",
    "    columns = json.load(fh)\n",
    "\n",
    "with open(os.path.join('/tmp', 'new_pipeline.pickle'), 'rb') as fh:\n",
    "    pipeline = joblib.load(fh)\n",
    "\n",
    "with open(os.path.join('/tmp', 'new_dtypes.pickle'), 'rb') as fh:\n",
    "    dtypes = pickle.load(fh)\n",
    "\n",
    "assert isinstance(columns, list), 'The columns should be a list of training features.'\n",
    "assert 'salary' not in columns, 'There should be only training features in columns. You got target there.'\n",
    "assert 'is_new' in columns, \"Your columns don't contain the is_new feature.\"\n",
    "assert isinstance(pipeline, Pipeline), 'new_pipeline.pickle does not seem to be an instance of the Pipeline class.'\n",
    "assert isinstance(dtypes, pd.core.series.Series), 'new_dtypes.pickle is not pickled well'\n",
    "assert all([column in dtypes.index for column in columns]), 'Some columns from new_columns file are not in the new_dtypes file.'\n",
    "assert all([dtype in columns for dtype in dtypes.index]), 'Some dtypes from new_dtypes file are not in the new_columns file.'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f47c5d3c-7aeb-4ebb-94a9-a1852a86d828",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-23b7f5e0911f976b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "And now it's time to change the server! I know you missed this part :)\n",
    "\n",
    "Before we do it, I want to remind you that in this exercise notebook we didn't cover the ethics topic. Our model is trained on sensitive features like race and sex. In a real situation you'd need to make sure that your model is not discriminating anyone. Maybe the bad female vs. male retrieval rates are due to this or maybe to the imbalance of the classes.\n",
    "\n",
    "Now go and create a copy of the `protected_server.py` file. Call it `new_server.py`.\n",
    "\n",
    "In that file:\n",
    "- Change the `check_valid_column` function to have the new added columns. You can also automate it by reading the columns file, it's even better!\n",
    "- Change the `check_categorical_values` function: make sure the values there still make sense!\n",
    "- We also added one more categorical feature to the dataframe, `is_new`. Go and add possible values to the check.\n",
    "\n",
    "As soon as it's done, go ahead and start the server and play with the predictions. Make sure that the server checks the `is_new` feature values. Try to send requests without `is_new` or with a different value (not True or False).\n",
    "\n",
    "There's much more we can do with this dataset to train a better model, and more importantly, a model that doesn't descriminate. So if you're willing, go crazy! Make the best model you can! It's great preparation for the hackathon! ;) See you there!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3397af-5817-4032-afe9-fb56a418f5ce",
   "metadata": {},
   "source": [
    "And now take a moment to be very proud of you! You have mastered all the exercise notebooks in the course.\n",
    "\n",
    "<img src=\"media/proud_girl.png\" width=\"300\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
