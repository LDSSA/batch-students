{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c8eb4b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fe6ee765726b9073",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# SLU32 - Training for the hackathon, part 1\n",
    "In the hackathon, you will receive a dataset and a metric and you will have to set up and optimize a model for the given metric. You will have learned all the necessary bits and pieces to accomplish this task by then, nevertheless, it can still seem a daunting task. Solving a hackathon is a multistep task with multiple possible solutions and so a much bigger problem than any of the exercises in the exercise notebooks.\n",
    "\n",
    "This SLU is meant to help you prepare for it. You can practice all that you learned in the first part of the S01 specialization, in SLUs 01-10. You should first get to know your dataset (exploratory data analysis - EDA) and then set up the first model.\n",
    "\n",
    "We are providing hints to guide you through the workflow. It's on you to fill in all the code. This workflow is just a proposal to get you started, you will design your own workflow that suits your needs once you're more experienced.\n",
    "\n",
    "The second part of the training is SLU64 where you can practice feature engineering, model optimization, and dealing with imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all you need in this cell - we already did some imports for you\n",
    "# basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "#sklearn libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,roc_curve,classification_report,auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557ceab9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e319a174835d907",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. Read the problem statement\n",
    "We will use the problem from the first hackathon from the previous batch of LDSSA. You can read the problem statement [here](https://docs.google.com/document/d/1mONeQMAyYW2cJvinYHGAQ2W_04P1HHU68dcUj-iosow/edit#heading=h.640xl1uqp9un). The topic might be from an area completely unfamiliar to you, but this is normal in data science. Data scientists often work on very different problems and each time have to learn a bit about the background to deliver a good solution. Of course, in a hackathon, you'll have little time to explore the topic, but you can always ask the instructors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30037655",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8a2c0317ea21724e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2. Import the dataset\n",
    "There are two datasets in the `data` folder - train and test. You should train your model with the train dataset. The test dataset should be used only at the end to calculate the predictions, never in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and preview the dataset (you can first look at the datafile directly)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b066e84c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7097a22865e686ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3. Exploratory data analysis (EDA) and data cleaning\n",
    "Use Pandas tools from SLUs 01 - 06 and plots to get to know your dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651bf892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the size of the dataset and the variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a34ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is your data tidy - variables in columns and data points in rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the datatypes.\n",
    "# Do they make sense or do you need to correct them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f95a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many unique values does each column have?\n",
    "# Identify the categorical and numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80abe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the ranges of the numerical values.\n",
    "# Are there outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a79d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if the dataset is balanced - how many datapoints for each class do you have?\n",
    "# you don't have tools to do with this yet, but it's good to know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See where you have missing values.\n",
    "# Think about how to deal with them - fill in (different strategies) or drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b583a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you have duplicated data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334fd73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the variables independent?\n",
    "# Check out the correlations between variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9474b37f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef5d5e954409e874",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4. Model - baseline\n",
    "This is clearly a classification problem, so you can apply the classification model you already know to get the first result (baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef4c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the variables that you want to feed into the model.\n",
    "# By SLU10, you don't yet know the tools for dealing with categorical variables, \n",
    "# so you can ignore them or use some simple strategy.\n",
    "# Do the variables need to be scaled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520cd259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc2f2cf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05403a72454a58c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 5. Calculate the predictions\n",
    "Calculate the predictions for both the train and the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a58ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the predictions for the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24327f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the prediction for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the prediction to a csv file.\n",
    "# Uncomment the code and run it.\n",
    "# It is expected that the prediction is in the variable test_prediction.\n",
    "#submission = pd.Series(test_prediction,index=test.index, name='id')\n",
    "#submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae81ffa4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9447088a54b1ed54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 6. Model evaluation with the training data\n",
    "Use the prediction for the training data to evaluate your model. In a real hackathon, you will have access to the labels of the training data, but not of the test data, so you will have to use the train data prediction to evaluate your model during the development.\n",
    "\n",
    "As per the problem setting, you should be using the roc-auc-score to evaluate the model. Just for the sake of training, you can also look at other metrics and think if they make sense in this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ad838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the first place, calculate the roc-auc-score for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now check how the model does on the other metrics you learned about.\n",
    "# Which of them are relevant for this situation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428cbd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can calculate the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67189094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot here the roc curve and calculate the auroc score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e481eec4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6d886d52117f2ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 7. Calculate the score with the test data\n",
    "In this section, we will test the model predictions for the test data. In a real hackathon, you will generate these predictions, then submit them to the portal. The portal will compare your prediction with the real labels and give you a score.\n",
    "\n",
    "Here, you have the test predictions in the `portal` directory, together with the code to calculate the score. Run the following cells to calculate your score (you need to uncomment some parts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd89c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the code to calculate the score.\n",
    "from portal.score import load, validate, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the true labels and your prediction.\n",
    "# Uncomment and run the code.\n",
    "#y_true = load(\"portal/data\")\n",
    "#y_pred = load(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f79f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function just validates if the prediction has the correct format.\n",
    "# Uncomment and run it.\n",
    "#validate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e150642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the auc-roc score for your test prediction.\n",
    "# Uncomment and run the code.\n",
    "#score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3137c19c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee01e5cc4f5de757",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 8. Feature selection\n",
    "This is something we looked at only briefly in the Exercise notebook of SLU09. You will learn about it in depth in SLU14. You can look at how important are the features for the model outcome and then retrain the model with just the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d158a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coefficients of the model and see which ones have the most weight in the model \n",
    "# (the highest numbers in absolute terms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94184d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the model with the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c750eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you like, tweak other model parameters.\n",
    "# Again, this is something that you will learn about in later SLUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a4816",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f280ee0ade08e13c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 9. Presentation\n",
    "The final part of the hackathon is to present your solution to the other teams. The presentation should contain all the steps in the analysis, with justification of the decisions you made. You will need to use tables or visualizations to support your claims. You can think how you'd present the EDA part of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8522dd7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-96f8b599abd52e9f",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('I have completed the hackathon training!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
