{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c8eb4b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fe6ee765726b9073",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# SLU64 - Training for the hackathon, part 2\n",
    "Welcome to part 2 of hackathon training. Hopefully, after going through part 1, you're well acquainted with your dataset and have successfully constructed your first model.\n",
    "\n",
    "In this SLU, you'll deal with imbalance, try out other models, engineer new features, and finally optimize your model and its hyperparameters. We're providing hints to guide you through the workflow, but it's on you to fill in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all you need in this cell - we already did some imports for you\n",
    "# basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "#sklearn libraries\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, RobustScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer, Binarizer, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,roc_curve,classification_report,auc\n",
    "# imbalanced datasets\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler\n",
    "from imblearn.under_sampling import TomekLinks,RandomUnderSampler\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, SelectFromModel\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# pipelines\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "\n",
    "#other libraries\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30037655",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8a2c0317ea21724e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. Import the dataset and do the train-test split\n",
    "Let's start by taking a step back and divide our dataset into `train` and `test` datasets. Hide your test dataset in a _virtual drawer_ and take it out when it's time for testing. Prepare your preprocessing workflow with the `train` dataset.\n",
    "\n",
    "Use the `train.csv` for the split, but don't touch the `test.csv` file for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset and do the train-test split.\n",
    "# Take into account the imbalance of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00ce1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your preprocessing pipeline using the train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7300e8f2",
   "metadata": {},
   "source": [
    "### 2. Feature engineering\n",
    "Datasets contain numerical and categorical features. Basic feature engineering, such as dealing with the categorical features, is an obligatory part of preprocessing. Engineering new features is an optional step that can be done as part of model optimization.\n",
    "\n",
    "Can you encode the categorical features in a form that is more advantageous for the model? Can you engineer new features from the existing one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98095f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the categorical features and see if you can encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff92416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, explore the anonymous column and see if you can extract more information from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02de966e",
   "metadata": {},
   "source": [
    "### 3. Preprocess the test data\n",
    "Repeat the same preprocessing you did earlier with the train data. Apply the previous transformations, but don't fit the transformers again!\n",
    "\n",
    "The easiest way to do this is with a pipeline. Of course, you can also try it initally without a pipeline, which means setting up a pipeline later, but do try using a pipeline at some point. It'll make your life easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1145a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformation that you used on the train dataset to the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9474b37f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef5d5e954409e874",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4. Test more models\n",
    "Here you can test all the models that you know and see which one performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef4c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all the models you know.\n",
    "# Use the default model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the predictions for the train and test data and choose your best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc2f2cf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05403a72454a58c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 5. Feature selection\n",
    "Feature selection is part of model optimization. Use common sense first and then automatic tools, but always check if their output makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a58ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Think about which features are likely to influence the model outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24327f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at feature importance for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are automatic feature selection tools helpful? Critically evaluate their output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae81ffa4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9447088a54b1ed54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 6. Model optimization\n",
    "You can further refine your best performing models with hyperparameter optimization. Keep in mind that this can take time to run. If you don't have much computing power, consider running your notebooks on [Kaggle](https://www.kaggle.com/)\n",
    "or [Google Colab](https://colab.research.google.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ad838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation to test models or model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca2d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the hyperparameter search schemes to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e371c4",
   "metadata": {},
   "source": [
    "### 7. Pipeline\n",
    "If you didn't use a pipeline yet, now is your chance! Nomally, you'd start your process with a pipeline, because pipelines make things easier, but you're practicing now for the hackaton. Using a pipeline later in your process might a way to experiment with and understand your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your pipeline.\n",
    "# Run your train data through it first and then your test data next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e481eec4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6d886d52117f2ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 8. Calculate the score with the test data\n",
    "In this section, we'll test model predictions for the test data (the one with the unknown labels, not the data from your train-test split). In a real hackathon, you'll generate these predictions and then submit them to the portal. The portal will compare your prediction with the real labels and give you a score.\n",
    "\n",
    "For this SLU, you have the test predictions in the `portal` directory, together with the code to calculate the score. Run the following cells to calculate your score. You'll need to uncomment some parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd89c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the code to calculate the score.\n",
    "from portal.score import load, validate, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the true labels and your prediction.\n",
    "# Uncomment and run the code.\n",
    "#y_true = load(\"portal/data\")\n",
    "#y_pred = load(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f79f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function just validates if the prediction has the correct format.\n",
    "# Uncomment and run it.\n",
    "#validate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e150642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the auc-roc score for your test prediction.\n",
    "# Uncomment and run the code.\n",
    "#score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a4816",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f280ee0ade08e13c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 9. Presentation\n",
    "Add the model optimization part to your presentation. Remember to justify the decisions you made. You'll need to use tables or visualizations to support your claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8522dd7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-96f8b599abd52e9f",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"I have completed the hackathon training part 2. I'm a star!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
