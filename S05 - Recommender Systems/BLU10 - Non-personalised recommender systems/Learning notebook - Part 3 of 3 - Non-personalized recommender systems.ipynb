{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLU10 - Part 3 of 3 - Non-personalized recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is finally time to implement our first basic recommender system! We will use a data set of user ratings of movies.\n",
    "\n",
    "## 1. Non-personalized RS\n",
    "\n",
    "The core function of any RS is to identify useful items for the user. Going back to our framework, non-personalized RS are typically built on the base model, exploiting just the interactions between users and items - the ratings.\n",
    "\n",
    "![Recommender Sytems Framework](./media/recommender_systems_framework_base.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider users, however, only as providers of the ratings, ignoring user preferences shown by the ratings they give. **The rationale is that a generic user also likes something that is liked by many users.**\n",
    "\n",
    "This approach is particularly relevant in the absence of information about user preferences, like for users that didn't provide any ratings, new users, or if we simply did not collect any user information. If we are unable to predict the utility of an item for a particular user, then we recommend an item with high utility for many users.\n",
    "\n",
    "We will use the non-personalized algorithm example here to give you an idea of building an RS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the data\n",
    "\n",
    "First, we read the movie ratings data into into a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \"\"\" Read ratings data from a text file to a NumPy array.\"\"\"   \n",
    "    path = os.path.join('data', 'ml-latest-small', 'ratings.csv')\n",
    "    data = np.genfromtxt(path, delimiter=',',skip_header=1, usecols=[0, 1, 2])\n",
    "    return data\n",
    "\n",
    "\n",
    "data = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data. To make the visualization easier, we show the data in a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1061.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1172.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0       1    2\n",
       "0  1.0    31.0  2.5\n",
       "1  1.0  1029.0  3.0\n",
       "2  1.0  1061.0  3.0\n",
       "3  1.0  1129.0  2.0\n",
       "4  1.0  1172.0  4.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have here is:\n",
    "* User identification (userId) in the first column\n",
    "* Item identification (movieId) in the second column\n",
    "* Rating in the third column.\n",
    "\n",
    "This is a memory effective way to store the data, but it's not convenient to build an RS. The next step is to use this data to construct a ratings matrix.\n",
    "\n",
    "The dataset also contains a timestamp that we don't need at the moment. We are not using the column names to make further array manipulation easier.\n",
    "\n",
    "We have 100004 movie ratings from 671 users and 9066 movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100004, 671, 9066)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0], pd.DataFrame(data)[0].nunique(), pd.DataFrame(data)[1].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the ratings matrix\n",
    "\n",
    "The second step is to transform this data representation into a ratings matrix, with:\n",
    "* Users as rows\n",
    "* Items as columns\n",
    "* Ratings as values.\n",
    "\n",
    "We have 671 user ids (1-671) and 9066 movies ids (1-163949). As the ids are not necessarily consecutive, we will store the mapping of the ids to the matrix indices so that we can reconstruct the original array. \n",
    "\n",
    "Then we create a matrix filled with zeros with the size we want:\n",
    "* The number of unique users is the number of rows\n",
    "* The number of unique items is the number of columns.\n",
    "\n",
    "Finally, we fill in the rating values using the stored indexes. We'll do this in a vectorized way which is the great advantage of using NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Building the ratings matrix with Numpy\n",
    "We're going to use the [unique](https://numpy.org/doc/stable/reference/generated/numpy.unique.html#numpy.unique) function to obtain the unique elements from the user and item id input arrays. This is to remember the relation of the ratings matrix indices to the user/item ids.\n",
    "\n",
    "Then we construct an empty matrix and fill in the ratings values using the previously obtained indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [5., 0., 0., ..., 0., 0., 0.]], shape=(671, 9066))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_ratings(data):\n",
    "    \n",
    "    users, user_pos = np.unique(data[:, 0], return_inverse=True)\n",
    "    items, item_pos = np.unique(data[:, 1], return_inverse=True)\n",
    "    \n",
    "    R = np.zeros((len(users), len(items)))\n",
    "    R[user_pos, item_pos] = data[:, 2]\n",
    "    \n",
    "    return R\n",
    "\n",
    "\n",
    "R = make_ratings(data)\n",
    "R"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many values do you think will be non-zero in this matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100004"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(R[R>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly the number of rows we had in our tabular format!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Building the ratings matrix with Pandas \n",
    "\n",
    "Another beautiful constructor that we can use is the Pandas pivot function (that you've already met when learning about tidy data). It can be convenient to retain indexes for our products and users in a dataframe instead of having a numpy array and Pandas rescues us on that.\n",
    "\n",
    "The dataframe pivot method takes as arguments: \n",
    "- index: The row index (the user id)\n",
    "- columns: The column names (the item id)\n",
    "- values: The values of the matrix (the ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>...</th>\n",
       "      <th>161084.0</th>\n",
       "      <th>161155.0</th>\n",
       "      <th>161594.0</th>\n",
       "      <th>161830.0</th>\n",
       "      <th>161918.0</th>\n",
       "      <th>161944.0</th>\n",
       "      <th>162376.0</th>\n",
       "      <th>162542.0</th>\n",
       "      <th>162672.0</th>\n",
       "      <th>163949.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9066 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "1    1.0       2.0       3.0       4.0       5.0       6.0       7.0       \\\n",
       "0                                                                           \n",
       "1.0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2.0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3.0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4.0       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "5.0       NaN       NaN       4.0       NaN       NaN       NaN       NaN   \n",
       "\n",
       "1    8.0       9.0       10.0      ...  161084.0  161155.0  161594.0  \\\n",
       "0                                  ...                                 \n",
       "1.0       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "2.0       NaN       NaN       4.0  ...       NaN       NaN       NaN   \n",
       "3.0       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "4.0       NaN       NaN       4.0  ...       NaN       NaN       NaN   \n",
       "5.0       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "\n",
       "1    161830.0  161918.0  161944.0  162376.0  162542.0  162672.0  163949.0  \n",
       "0                                                                          \n",
       "1.0       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "2.0       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "3.0       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "4.0       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "5.0       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 9066 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data).pivot(index=0, columns=1, values=2).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We can power this up with `fillna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>...</th>\n",
       "      <th>161084.0</th>\n",
       "      <th>161155.0</th>\n",
       "      <th>161594.0</th>\n",
       "      <th>161830.0</th>\n",
       "      <th>161918.0</th>\n",
       "      <th>161944.0</th>\n",
       "      <th>162376.0</th>\n",
       "      <th>162542.0</th>\n",
       "      <th>162672.0</th>\n",
       "      <th>163949.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9066 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "1    1.0       2.0       3.0       4.0       5.0       6.0       7.0       \\\n",
       "0                                                                           \n",
       "1.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "5.0       0.0       0.0       4.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "1    8.0       9.0       10.0      ...  161084.0  161155.0  161594.0  \\\n",
       "0                                  ...                                 \n",
       "1.0       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "2.0       0.0       0.0       4.0  ...       0.0       0.0       0.0   \n",
       "3.0       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "4.0       0.0       0.0       4.0  ...       0.0       0.0       0.0   \n",
       "5.0       0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "\n",
       "1    161830.0  161918.0  161944.0  162376.0  162542.0  162672.0  163949.0  \n",
       "0                                                                          \n",
       "1.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "3.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "4.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "5.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 9066 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data).pivot(index=0, columns=1, values=2).fillna(0).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A thing of beauty. One-line of code! But remember that with great power comes great responsibility - this matrix is really hungry and eats a lot of space! (That's why we won't save it.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Density and sparsity scores\n",
    "\n",
    "Density and sparsity scores tell us how sparse is our sparse matrix.\n",
    "\n",
    "### 4.1 Density \n",
    "\n",
    "Density is the fraction of the non-zero elements of the matrix. We will use the [nonzero](https://numpy.org/doc/stable/reference/generated/numpy.nonzero.html#numpy-nonzero) method to return a mask of the elements that are non-zero. \n",
    "\n",
    "This is another way to get the elements that are not zero in a matrix. If the matrix has negative elements, it's more efficient to use this method instead of doing `R[R>0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   0,   0, ..., 670, 670, 670], shape=(100004,)),\n",
       " array([  30,  833,  859, ..., 4597, 4610, 4696], shape=(100004,)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the density score as\n",
    "\n",
    "$$Density = \\frac{|R'|}{|R|}$$\n",
    "\n",
    "Where $|R'|$ is equal to the number of matrix elements that are not zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016439141608663475"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R[R.nonzero()].size / R.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holy moly, at least now we know what we are up against! Only 1.6% of the matrix has values that are not zero."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Sparsity\n",
    "\n",
    "Sparsity is the opposite of density - the fraction of matrix elements that are zero. Simply put\n",
    "\n",
    "$$Sparsity = 1- \\frac{|R'|}{|R|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9835608583913366"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - R[R.nonzero()].size / R.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two attributes complement each other and they are important when dealing with ratings matrixes. In this case, **our ratings matrix is ~2% dense and ~98% sparse!** Here we are with our sparse ratings matrix ready to set up the first non-personalized recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Aggregated opinion\n",
    "\n",
    "The most important aspect of non-personalized recommenders is that we predict the utility of an item for any user. We'll be doing that by looking at the opinions of all the users in the community.\n",
    "\n",
    "Perhaps the oldest RS is aggregated opinion, i.e. most popular/most hated (think Billboard or [IMDb Bottom 100](https://www.imdb.com/chart/bottom)). Another simple option is the most rated items. Most rated items tend to be those that get most interaction from the users or those that elicit the strongest opinions.\n",
    "\n",
    "### 5.1 Most-rated\n",
    "\n",
    "One way to find the most popular items is to select the ones with most ratings.\n",
    "\n",
    "We start by selecting the elements of the ratings matrix that are not zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False]], shape=(671, 9066))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_rating(R):\n",
    "    return np.greater(R, 0)\n",
    "\n",
    "is_rating(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that each row corresponds to a user and each column to an item, so we can sum each column to know how many times each item was rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([247, 107,  59, ...,   1,   1,   1], shape=(9066,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_ratings(R):\n",
    "    R_ = is_rating(R)\n",
    "    return R_.sum(axis=0)\n",
    "\n",
    "count_ratings(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write a function that retrieves the N most-rated items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([321, 266, 284])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_rated(R, n):\n",
    "    R_ = count_ratings(R)\n",
    "    return np.negative(R_).argsort()[:n]\n",
    "\n",
    "\n",
    "most_rated(R, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Yeah, but what if most ratings are negative?\n",
    "\n",
    "The most-rated items are certainly the most interesting or maybe most controversial, but are they also good? We can extend the function above to mimic another popular algorithm, \"Highest % of Top Ratings\", which counts only the positive ratings.\n",
    "\n",
    "Let's say a positive rating is anything above the value of 3 (e.g. 3 stars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([182,  51,  24, ...,   1,   0,   1], shape=(9066,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_positive_ratings(R, threshold):\n",
    "    R_ = is_above_threshold(R, threshold)\n",
    "    return R_.sum(axis=0)\n",
    "\n",
    "\n",
    "def is_above_threshold(R, threshold):\n",
    "    return np.greater(R, threshold)\n",
    "\n",
    "\n",
    "count_positive_ratings(R, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we just need to count the number of positive ratings and sort the resulting array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([284, 321, 266])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_positive_ratings(R, threshold, n):\n",
    "    R_ = count_positive_ratings(R, threshold)\n",
    "    return np.negative(R_).argsort()[:n]\n",
    "\n",
    "\n",
    "most_positive_ratings(R, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Powering up with summary statistics\n",
    "\n",
    "Until now we have used only the counts of the ratings as measures of popularity. But we can rely on good old statistics to help us out here for better recommendations.\n",
    "\n",
    "Probably the most popular non-personalized algorithm is the average rating. Popularized at first by Amazon and Ebay and then IMDB and Netflix, this is a basic yet widely used algorithm.\n",
    "\n",
    "The first step is to remove the zeros so that they don't affect our average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [ 4., nan, nan, ..., nan, nan, nan],\n",
       "       [ 5., nan, nan, ..., nan, nan, nan]], shape=(671, 9066))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_zeros(R):\n",
    "    R_ = R.copy()\n",
    "    R_[R_ == 0] = np.nan\n",
    "    \n",
    "    return R_\n",
    "\n",
    "\n",
    "remove_zeros(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can safely compute the average rating per item and sort the array. We are using the [np.nanmean](https://numpy.org/doc/stable/reference/generated/numpy.nanmean.html#numpy-nanmean) function which ignores the NaNs when computing the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.87246964, 3.40186916, 3.16101695, ..., 5.        , 3.        ,\n",
       "       5.        ], shape=(9066,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mean_ratings(R):\n",
    "    R_ = remove_zeros(R)\n",
    "    return np.nanmean(R_, axis=0)\n",
    "\n",
    "\n",
    "mean_ratings(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9065, 8119, 8125])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def best_mean_rating(R, n):\n",
    "    R_ = mean_ratings(R)\n",
    "    return np.negative(R_).argsort()[:n]\n",
    "\n",
    "\n",
    "best_mean_rating(R, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to average rating is computing the mean rating only for users that liked the item, so basically ignoring the less good ratings.\n",
    "\n",
    "It's also increasingly popular to show a histogram alongside mean ratings to give an idea of the distribution of the ratings. Or to normalize the mean by the number of ratings so that items with a low number of ratings do not get an advantage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Association rules\n",
    "\n",
    "Perhaps one of the most interesting (and also very popular) non-personalized algorithms is \"people who buy X also buy Y\".\n",
    "\n",
    "These kinds of algorithms are called **association rules**. The [mlxtend](http://rasbt.github.io/mlxtend/) library has the implementation of some of them.\n",
    "\n",
    "Before looking at the association rules, we need to define a helper concept, **support**, and look at different metrics that measure the strength of the association rules.\n",
    "\n",
    "### 7.1 Support\n",
    "\n",
    "Support measures the frequency of a set of items in a database of transactions. Let's say we have a database of purchases in a supermarket - a table where rows are purchases and columns are items. The support of a set of purchased items is the fraction of purchases that contains that specific item set. For instance, in a pandemic, everybody buys toilet paper - the support of toilet paper is 1 because it is contained in every purchase made in the supermarket. If every tenth purchase contains toilet paper and bananas, the support of the item set {toilet paper, bananas} is 0.1.\n",
    "\n",
    "Now onto the association rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Apriori\n",
    "\n",
    "[Apriori](http://rasbt.github.io/mlxtend/api_subpackages/mlxtend.frequent_patterns/#apriori) is a function used to identify common item sets, i.e. stuff that usually goes together. Usually, we are interested only in item sets that are frequent, i.e. that have some minimal support (occurence threshold). This is is how the algorithm goes:\n",
    "\n",
    "* We identify individual items that satisfy a minimum occurrence threshold (minimum support)\n",
    "* We extend the item sets, adding one item at a time\n",
    "* Every time we check if the resulting item set satisfies the specified threshold\n",
    "* The algorithm stops when there are no more items to add that meet the threshold.\n",
    "\n",
    "Clearly, if a certain set meets the minimum occurence threshold, all its subsets also meet it.\n",
    "\n",
    "For our database of purchases (rows are purchases, columns are items), `mlxtend` expects a one-hot input, so 0/1 or True/False to indicate which items belong to which purchase. The `min_support` parameter indicates the minimum occurrence threshold (fraction of purchases containing the given item set).\n",
    "\n",
    "Unfortunately, `mlxtend` only supports dataframes at this point. The items in the selected item sets are returned as respective column indices. Let's write a function that takes the ratings matrix and gets us item sets with the given minimal support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.368107</td>\n",
       "      <td>(0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.339791</td>\n",
       "      <td>(100)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.433681</td>\n",
       "      <td>(232)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.482861</td>\n",
       "      <td>(266)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.463487</td>\n",
       "      <td>(284)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.508197</td>\n",
       "      <td>(321)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.317437</td>\n",
       "      <td>(406)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.408346</td>\n",
       "      <td>(427)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>(472)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.320417</td>\n",
       "      <td>(521)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.353204</td>\n",
       "      <td>(522)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.301043</td>\n",
       "      <td>(523)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.453055</td>\n",
       "      <td>(525)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.333830</td>\n",
       "      <td>(535)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.324888</td>\n",
       "      <td>(644)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.348733</td>\n",
       "      <td>(953)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.327869</td>\n",
       "      <td>(955)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.323398</td>\n",
       "      <td>(966)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.336811</td>\n",
       "      <td>(1024)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.385991</td>\n",
       "      <td>(2062)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.327869</td>\n",
       "      <td>(2288)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.301043</td>\n",
       "      <td>(2374)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.302534</td>\n",
       "      <td>(232, 953)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.326379</td>\n",
       "      <td>(266, 284)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.344262</td>\n",
       "      <td>(321, 266)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.333830</td>\n",
       "      <td>(266, 525)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.321908</td>\n",
       "      <td>(321, 284)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.308495</td>\n",
       "      <td>(284, 525)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.329359</td>\n",
       "      <td>(321, 427)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.338301</td>\n",
       "      <td>(321, 525)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     support    itemsets\n",
       "0   0.368107         (0)\n",
       "1   0.339791       (100)\n",
       "2   0.433681       (232)\n",
       "3   0.482861       (266)\n",
       "4   0.463487       (284)\n",
       "5   0.508197       (321)\n",
       "6   0.317437       (406)\n",
       "7   0.408346       (427)\n",
       "8   0.363636       (472)\n",
       "9   0.320417       (521)\n",
       "10  0.353204       (522)\n",
       "11  0.301043       (523)\n",
       "12  0.453055       (525)\n",
       "13  0.333830       (535)\n",
       "14  0.324888       (644)\n",
       "15  0.348733       (953)\n",
       "16  0.327869       (955)\n",
       "17  0.323398       (966)\n",
       "18  0.336811      (1024)\n",
       "19  0.385991      (2062)\n",
       "20  0.327869      (2288)\n",
       "21  0.301043      (2374)\n",
       "22  0.302534  (232, 953)\n",
       "23  0.326379  (266, 284)\n",
       "24  0.344262  (321, 266)\n",
       "25  0.333830  (266, 525)\n",
       "26  0.321908  (321, 284)\n",
       "27  0.308495  (284, 525)\n",
       "28  0.329359  (321, 427)\n",
       "29  0.338301  (321, 525)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_apriori_itemsets(R, min_support=0.3):\n",
    "    R_ = pd.DataFrame(R > 0)\n",
    "    return apriori(R_, min_support)\n",
    "\n",
    "\n",
    "get_apriori_itemsets(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After identiying the item sets with the `apriori` function, we can use the `association_rules` function to find out how strong is the association between the items in the item sets.\n",
    "\n",
    "The strength of the association rules is measured with different metrics, we will look at two of them. Notice that association rules can have a direction because we may be interested in looking at implications. Do people who buy toilet paper also buy bananas? Do people who buy bananas also buy toilet paper? That's why we talk about antecedent and consequent items or item sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Confidence\n",
    "\n",
    "Given two item sets $i$, called *antecendent*, and $j$, called *consequent*, the confidence refers to how frequently the item set $j$ is purchased given that the item set $i$ was purchased (how many people who buy toilet paper also buy bananas?):\n",
    "\n",
    "$$Confidence\\{i \\to j \\} = \\frac{Support\\{i, j\\}}{Support\\{i\\}}$$\n",
    "\n",
    "Or, in a more familiar way, confidence is the conditional probability of $j$ given $i$:\n",
    "\n",
    "$$P(j|i) = \\frac{P(i \\cap j)}{P(i)}$$\n",
    "\n",
    "However, do $i$ and $j$ occur for the same users for a reason, or is it random? What if $j$ is a trendy item?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Lift\n",
    "\n",
    "Meet the toilet paper trap: just because people buy toilet paper all the time, it doesn't mean toilet paper goes well with bananas. Fortunately, there is a better way. \n",
    "\n",
    "The lift algorithm takes into consideration the popularity of the items and normalizes the confidence to the support of $j$.\n",
    "\n",
    "$$Lift\\{i \\to j\\}\\ =\\ \\frac{Confidence\\{i \\to j \\}}{Support\\{j\\}}\\ =\\ \\frac{Support\\{i, j\\}}{Support\\{i\\} * Support\\{j\\}}$$\n",
    "\n",
    "The denominator is the likelihood that $i$ and $j$ appear together by chance, so lift questions whether $i$ makes $j$ more probable or not.\n",
    "\n",
    "Mlxtend implements two more metrics measuring the independence of the item sets, *leverage* and *conviction*. Check out the definitions [here](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/#metrics)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Association rules\n",
    "Let's look at the association rules between two-item item sets from our ratings matrix (antecendent and consequent). \n",
    "\n",
    "The [association_rules](http://rasbt.github.io/mlxtend/api_subpackages/mlxtend.frequent_patterns/#association_rules) method returns a table where each row is an association rule with its strength indicated by different metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>representativity</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>certainty</th>\n",
       "      <th>kulczynski</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(232)</td>\n",
       "      <td>(953)</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>0.348733</td>\n",
       "      <td>0.302534</td>\n",
       "      <td>0.697595</td>\n",
       "      <td>2.000367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151295</td>\n",
       "      <td>2.153621</td>\n",
       "      <td>0.883057</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.535666</td>\n",
       "      <td>0.782558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(953)</td>\n",
       "      <td>(232)</td>\n",
       "      <td>0.348733</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>0.302534</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>2.000367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151295</td>\n",
       "      <td>4.274794</td>\n",
       "      <td>0.767875</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.766071</td>\n",
       "      <td>0.782558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(266)</td>\n",
       "      <td>(284)</td>\n",
       "      <td>0.482861</td>\n",
       "      <td>0.463487</td>\n",
       "      <td>0.326379</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>1.458348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102578</td>\n",
       "      <td>1.655525</td>\n",
       "      <td>0.607753</td>\n",
       "      <td>0.526442</td>\n",
       "      <td>0.395962</td>\n",
       "      <td>0.690053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(284)</td>\n",
       "      <td>(266)</td>\n",
       "      <td>0.463487</td>\n",
       "      <td>0.482861</td>\n",
       "      <td>0.326379</td>\n",
       "      <td>0.704180</td>\n",
       "      <td>1.458348</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.102578</td>\n",
       "      <td>1.748153</td>\n",
       "      <td>0.585807</td>\n",
       "      <td>0.526442</td>\n",
       "      <td>0.427968</td>\n",
       "      <td>0.690053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(321)</td>\n",
       "      <td>(266)</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.482861</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>1.402927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.098874</td>\n",
       "      <td>1.603130</td>\n",
       "      <td>0.583983</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>0.376220</td>\n",
       "      <td>0.695191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(266)</td>\n",
       "      <td>(321)</td>\n",
       "      <td>0.482861</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>1.402927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.098874</td>\n",
       "      <td>1.713379</td>\n",
       "      <td>0.555373</td>\n",
       "      <td>0.532258</td>\n",
       "      <td>0.416358</td>\n",
       "      <td>0.695191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(266)</td>\n",
       "      <td>(525)</td>\n",
       "      <td>0.482861</td>\n",
       "      <td>0.453055</td>\n",
       "      <td>0.333830</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>1.525991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.115067</td>\n",
       "      <td>1.772101</td>\n",
       "      <td>0.666529</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.435698</td>\n",
       "      <td>0.714100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(525)</td>\n",
       "      <td>(266)</td>\n",
       "      <td>0.453055</td>\n",
       "      <td>0.482861</td>\n",
       "      <td>0.333830</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>1.525991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.115067</td>\n",
       "      <td>1.965127</td>\n",
       "      <td>0.630206</td>\n",
       "      <td>0.554455</td>\n",
       "      <td>0.491127</td>\n",
       "      <td>0.714100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(321)</td>\n",
       "      <td>(284)</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.463487</td>\n",
       "      <td>0.321908</td>\n",
       "      <td>0.633431</td>\n",
       "      <td>1.366663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.086365</td>\n",
       "      <td>1.463607</td>\n",
       "      <td>0.545525</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.316756</td>\n",
       "      <td>0.663982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(284)</td>\n",
       "      <td>(321)</td>\n",
       "      <td>0.463487</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.321908</td>\n",
       "      <td>0.694534</td>\n",
       "      <td>1.366663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.086365</td>\n",
       "      <td>1.610009</td>\n",
       "      <td>0.500064</td>\n",
       "      <td>0.495413</td>\n",
       "      <td>0.378885</td>\n",
       "      <td>0.663982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(284)</td>\n",
       "      <td>(525)</td>\n",
       "      <td>0.463487</td>\n",
       "      <td>0.453055</td>\n",
       "      <td>0.308495</td>\n",
       "      <td>0.665595</td>\n",
       "      <td>1.469125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.098509</td>\n",
       "      <td>1.635575</td>\n",
       "      <td>0.595183</td>\n",
       "      <td>0.507353</td>\n",
       "      <td>0.388594</td>\n",
       "      <td>0.673258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(525)</td>\n",
       "      <td>(284)</td>\n",
       "      <td>0.453055</td>\n",
       "      <td>0.463487</td>\n",
       "      <td>0.308495</td>\n",
       "      <td>0.680921</td>\n",
       "      <td>1.469125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.098509</td>\n",
       "      <td>1.681442</td>\n",
       "      <td>0.583830</td>\n",
       "      <td>0.507353</td>\n",
       "      <td>0.405272</td>\n",
       "      <td>0.673258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(321)</td>\n",
       "      <td>(427)</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.408346</td>\n",
       "      <td>0.329359</td>\n",
       "      <td>0.648094</td>\n",
       "      <td>1.587120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121839</td>\n",
       "      <td>1.681284</td>\n",
       "      <td>0.752187</td>\n",
       "      <td>0.560914</td>\n",
       "      <td>0.405217</td>\n",
       "      <td>0.727332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(427)</td>\n",
       "      <td>(321)</td>\n",
       "      <td>0.408346</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.329359</td>\n",
       "      <td>0.806569</td>\n",
       "      <td>1.587120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.121839</td>\n",
       "      <td>2.542530</td>\n",
       "      <td>0.625244</td>\n",
       "      <td>0.560914</td>\n",
       "      <td>0.606691</td>\n",
       "      <td>0.727332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(321)</td>\n",
       "      <td>(525)</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.453055</td>\n",
       "      <td>0.338301</td>\n",
       "      <td>0.665689</td>\n",
       "      <td>1.469334</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.108060</td>\n",
       "      <td>1.636037</td>\n",
       "      <td>0.649486</td>\n",
       "      <td>0.543062</td>\n",
       "      <td>0.388767</td>\n",
       "      <td>0.706200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(525)</td>\n",
       "      <td>(321)</td>\n",
       "      <td>0.453055</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.338301</td>\n",
       "      <td>0.746711</td>\n",
       "      <td>1.469334</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.108060</td>\n",
       "      <td>1.941665</td>\n",
       "      <td>0.584007</td>\n",
       "      <td>0.543062</td>\n",
       "      <td>0.484978</td>\n",
       "      <td>0.706200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   antecedents consequents  antecedent support  consequent support   support  \\\n",
       "0        (232)       (953)            0.433681            0.348733  0.302534   \n",
       "1        (953)       (232)            0.348733            0.433681  0.302534   \n",
       "2        (266)       (284)            0.482861            0.463487  0.326379   \n",
       "3        (284)       (266)            0.463487            0.482861  0.326379   \n",
       "4        (321)       (266)            0.508197            0.482861  0.344262   \n",
       "5        (266)       (321)            0.482861            0.508197  0.344262   \n",
       "6        (266)       (525)            0.482861            0.453055  0.333830   \n",
       "7        (525)       (266)            0.453055            0.482861  0.333830   \n",
       "8        (321)       (284)            0.508197            0.463487  0.321908   \n",
       "9        (284)       (321)            0.463487            0.508197  0.321908   \n",
       "10       (284)       (525)            0.463487            0.453055  0.308495   \n",
       "11       (525)       (284)            0.453055            0.463487  0.308495   \n",
       "12       (321)       (427)            0.508197            0.408346  0.329359   \n",
       "13       (427)       (321)            0.408346            0.508197  0.329359   \n",
       "14       (321)       (525)            0.508197            0.453055  0.338301   \n",
       "15       (525)       (321)            0.453055            0.508197  0.338301   \n",
       "\n",
       "    confidence      lift  representativity  leverage  conviction  \\\n",
       "0     0.697595  2.000367               1.0  0.151295    2.153621   \n",
       "1     0.867521  2.000367               1.0  0.151295    4.274794   \n",
       "2     0.675926  1.458348               1.0  0.102578    1.655525   \n",
       "3     0.704180  1.458348               1.0  0.102578    1.748153   \n",
       "4     0.677419  1.402927               1.0  0.098874    1.603130   \n",
       "5     0.712963  1.402927               1.0  0.098874    1.713379   \n",
       "6     0.691358  1.525991               1.0  0.115067    1.772101   \n",
       "7     0.736842  1.525991               1.0  0.115067    1.965127   \n",
       "8     0.633431  1.366663               1.0  0.086365    1.463607   \n",
       "9     0.694534  1.366663               1.0  0.086365    1.610009   \n",
       "10    0.665595  1.469125               1.0  0.098509    1.635575   \n",
       "11    0.680921  1.469125               1.0  0.098509    1.681442   \n",
       "12    0.648094  1.587120               1.0  0.121839    1.681284   \n",
       "13    0.806569  1.587120               1.0  0.121839    2.542530   \n",
       "14    0.665689  1.469334               1.0  0.108060    1.636037   \n",
       "15    0.746711  1.469334               1.0  0.108060    1.941665   \n",
       "\n",
       "    zhangs_metric   jaccard  certainty  kulczynski  \n",
       "0        0.883057  0.630435   0.535666    0.782558  \n",
       "1        0.767875  0.630435   0.766071    0.782558  \n",
       "2        0.607753  0.526442   0.395962    0.690053  \n",
       "3        0.585807  0.526442   0.427968    0.690053  \n",
       "4        0.583983  0.532258   0.376220    0.695191  \n",
       "5        0.555373  0.532258   0.416358    0.695191  \n",
       "6        0.666529  0.554455   0.435698    0.714100  \n",
       "7        0.630206  0.554455   0.491127    0.714100  \n",
       "8        0.545525  0.495413   0.316756    0.663982  \n",
       "9        0.500064  0.495413   0.378885    0.663982  \n",
       "10       0.595183  0.507353   0.388594    0.673258  \n",
       "11       0.583830  0.507353   0.405272    0.673258  \n",
       "12       0.752187  0.560914   0.405217    0.727332  \n",
       "13       0.625244  0.560914   0.606691    0.727332  \n",
       "14       0.649486  0.543062   0.388767    0.706200  \n",
       "15       0.584007  0.543062   0.484978    0.706200  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_rules(R, min_support=.3, min_threshold=1.2):\n",
    "    itemsets = get_apriori_itemsets(R, min_support=0.3)\n",
    "    return association_rules(itemsets, metric=\"lift\", min_threshold=min_threshold, num_itemsets=itemsets.shape[0])\n",
    "\n",
    "get_rules(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping up: \n",
    "- Non-personalized recommenders do not take into account specific user preferences or characteristics.\n",
    "- Non-personalized recommenders approaches are the simplest way to design recommendation engines.\n",
    "- It's really important to know how to handle matrix sparsity as it will impact your workflow until the end.\n",
    "\n",
    "Now we have the foundations to tackle more complex recommendation approaches, coming up in the next BLUs.\n",
    "\n",
    "Time to practice!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
