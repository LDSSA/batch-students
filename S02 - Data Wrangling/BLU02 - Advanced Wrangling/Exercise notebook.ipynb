{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b66f2958",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3bf24e7ba2c45b1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# BLU02 - Exercises Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd525da6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bebba7f87f4f151b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import hashlib # for grading\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b2b87c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a23783765364606a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1 Read the Oscars data (graded)\n",
    "\n",
    "In this first exercise, we aim to create a single dataframe, combining all Oscar nominees from all ceremonies.\n",
    "\n",
    "With a caveat though: **we want to include seasons from the year 1960 onwards**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e539f29e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e16abeb47fc4ea37",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_year(folder_path, file_name):\n",
    "    path = os.path.join(folder_path, file_name)\n",
    "    return pd.read_csv(path, index_col = 0)\n",
    "\n",
    "def read_nominees(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    # Create a list with the name of all files containing annual nominees from\n",
    "    # 1960 inclusive and onwards (just the filename, no complete path.)\n",
    "    # files_from_1960: List[str] = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # Create a list with the dataframes\n",
    "    # nominees_year: List[pd.DataFrame] = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # Use pd.concat to create a single dataframe.\n",
    "    # nominees: pd.DataFrame = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # Drop the column 'ceremony'.\n",
    "    # nominees = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    ## Remove missing values.\n",
    "    # nominees = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return nominees\n",
    "\n",
    "nominees = read_nominees(os.path.join('data', 'oscars'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b3ffb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2656708135a5a5e4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert nominees['year_ceremony'].min() == 1960\n",
    "assert nominees['year_ceremony'].max() == 2023\n",
    "assert nominees.isna().sum().sum() == 0\n",
    "assert nominees.shape == (7116, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31920670",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3383047fa18f453e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2 Read the IMDB Ratings data (graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f86c9d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e228c2d82463c6b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_ratings(file_path): \n",
    "    # Read the ratings data and drop the 'director', 'star1', 'star2', 'star3', and 'star4' columns.\n",
    "    # top_rated: pd.DataFrame = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # Please make the necessary changes and convert the 'runtime' column to int\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    ## Remove the lines with no metascore info.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return top_rated\n",
    "\n",
    "top_rated = read_ratings(os.path.join('data','imdb_top_1000.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e0b5f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3d21007e725ab889",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert top_rated.shape == (843, 5)\n",
    "assert top_rated.runtime.min() == 64\n",
    "assert top_rated.runtime.max() == 321\n",
    "assert top_rated.metascore.isna().sum() == 0\n",
    "assert set(top_rated.columns) == set([\n",
    "    'film', 'metascore', 'no_votes', 'rating', 'runtime'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d6c904",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2ae195e6dd100fc5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3 Combine Oscars and Ratings data (graded)\n",
    "\n",
    "Let's combine both dataframes into a single dataset, using an inner join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a56101",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a65f1464b4525a8b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember that you want use a column of both dataframes to combine them.\n",
    "# Join only the nominees of films present on the ratings list\n",
    "# best_rated_nominees = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26483891",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ac9aef3d5251e36c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert best_rated_nominees.shape == (1919, 10)\n",
    "assert set(best_rated_nominees.columns) == set(['year_film', 'year_ceremony', 'category', 'name', 'film', 'winner',\n",
    "       'runtime', 'rating', 'metascore', 'no_votes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71271ecf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1fd4cd11d5139889",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4 Read top grossing and budget films data (graded)\n",
    "\n",
    "We will read the two remaining pieces of data. \n",
    "\n",
    "Again, albeit the step-by-step description, we encourage you to use method chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb533fb6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-503e208490ff38e0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_gross(file_path):\n",
    "    # Read the works data.\n",
    "    # top_grossing: pd.DataFrame = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    # Remove the year column.\n",
    "    # gross: pd.DataFrame = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    ## Ensure that the gross data is read as int.\n",
    "     # top_grossing: pd.DataFrame = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return top_grossing\n",
    "\n",
    "\n",
    "def read_budget(file_path):\n",
    "    # Read the top budget data and drop the 'runtime', 'theaters', and 'year' Columns\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    ## Please make the necessary changes and convert the 'budget_rank' column to int\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return top_budget\n",
    "\n",
    "\n",
    "top_grossing = read_gross('data/gross_top_200.csv')\n",
    "top_budget = read_budget('data/budget_top_500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f60f07",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b8389314995f18ea",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert top_grossing.shape == (200, 3)\n",
    "assert set(top_grossing.columns) == set([\n",
    "    'gross_rank', 'film', 'gross'\n",
    "])\n",
    "\n",
    "assert top_budget.shape == (500, 3)\n",
    "assert set(top_budget.columns) == set([\n",
    "   'budget_rank', 'film', 'production_cost'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839081fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c16e4e26e68cd019",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 5 Combine the top grossing and budget films\n",
    "\n",
    "Like we did for Oscar nominees and top rated films, now we combine the top budget and grossing films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae5297",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-08d9a086cc5646cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Combine both dataframes, again using an inner type of join\n",
    "# top_grossing_budget : pd.DataFrame = ....\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184d4cd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4d9f103dfffd311b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert top_grossing_budget.shape == (129, 5)\n",
    "assert set(top_grossing_budget.columns) == set(\n",
    "    [\n",
    "        'budget_rank', 'film', 'production_cost', 'gross_rank', 'gross'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cddd282",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab79800d6e447f1e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 6 Combine everything (graded)\n",
    "\n",
    "The final goal here is to create a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4eee72",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce1f05022e8cd63a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Combine best_rated_nominees and nyp into a single dataframe.\n",
    "# You need to figure out the common column shared between the two dataframes\n",
    "# top_films = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c7dc60",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ce29fa3aec1c244e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert top_films.shape == (184, 14)\n",
    "assert set(top_films.columns) == set(\n",
    "    [\n",
    "       'year_film', 'year_ceremony', 'category', 'name', 'film', 'winner',\n",
    "       'runtime', 'rating', 'metascore', 'no_votes', 'budget_rank',\n",
    "       'production_cost', 'gross_rank', 'gross'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c7125",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4407d9518b0d6e2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 7 Final transformations (graded)\n",
    "\n",
    "Now, we perform the train-test split.\n",
    "\n",
    "We also perform some final transformations on both datasets:\n",
    "\n",
    "* Tranform \"winner\" into a binary feature\n",
    "* Create a new feature, rating_rank, from the rating column. \n",
    "* Filter out the movies that appear less than 10 times in the DataFrame.\n",
    "* Keep only 'film', 'winner', 'category', 'runtime', 'rating', 'metascore', 'no_votes', 'budget_rank', 'production_cost', 'gross_rank', 'rating_rank' and 'gross' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5094ff",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1c1ab0d912e615ca",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def transform_winner(df):\n",
    "    df = df.copy()\n",
    "    # df = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return df\n",
    "\n",
    "def create_rating_rank(df):\n",
    "    df = df.copy()\n",
    "    # df['rating_rank'] = \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # You should follow these exact steps:\n",
    "    #   1 - Binarize 'winner'\n",
    "    #   2 - Filter out rows that have a film that appear is less than 10 times in the DataFrame.\n",
    "    #   3 - Keep only the 'film', 'winner', category', 'runtime', 'rating', 'metascore', 'no_votes', \n",
    "    #      'budget_rank', 'production_cost', 'gross_rank', 'rating_rank' and 'gross' columns\n",
    "    #   5 - Create a new feature, rating_rank, from the ranking column. \n",
    "    #   6 - Sort the DataFrame by 'rating' in ascending order\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return df\n",
    "\n",
    "\n",
    "top_films_preprocessed = preprocess_data(top_films)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21e1d5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9d9c75c48e4eaf63",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert top_films_preprocessed.shape == (59, 12)\n",
    "assert set(top_films_preprocessed.columns) == {\n",
    "       'category', 'film', 'runtime', 'rating', 'metascore', 'no_votes',\n",
    "       'budget_rank', 'production_cost', 'gross_rank', 'gross', 'rating_rank','winner'\n",
    "}\n",
    "assert top_films_preprocessed.budget_rank.min() == 49\n",
    "assert top_films_preprocessed.gross_rank.max() == 180\n",
    "assert top_films_preprocessed.iloc[0].no_votes == 769145"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4918d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4557c57da6142038",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# The house prices dataset\n",
    "\n",
    "A dataset containing several characteristics of several houses and their selling price \n",
    "\n",
    "* LotFrontage: Linear feet of street connected to property\n",
    "* LotArea: Lot size in square feet\n",
    "* OverallQual: Rates the overall material and finish of the house\n",
    "       10  Very Excellent\n",
    "       9\tExcellent\n",
    "       8\tVery Good\n",
    "       7\tGood\n",
    "       6\tAbove Average\n",
    "       5\tAverage\n",
    "       4\tBelow Average\n",
    "       3\tFair\n",
    "       2\tPoor\n",
    "       1\tVery Poor\n",
    "* OverallCond: Rates the overall condition of the house\n",
    "\n",
    "       10\tVery Excellent\n",
    "       9\tExcellent\n",
    "       8\tVery Good\n",
    "       7\tGood\n",
    "       6\tAbove Average\t\n",
    "       5\tAverage\n",
    "       4\tBelow Average\t\n",
    "       3\tFair\n",
    "       2\tPoor\n",
    "       1\tVery Poor\n",
    "* MasVnrArea: Masonry veneer area in square feet\n",
    "* BsmtFinSF1: Type 1 finished square feet\n",
    "* BsmtUnfSF: Unfinished square feet of basement area\n",
    "* TotalBsmtSF: Total square feet of basement area\n",
    "* 1stFlrSF: First Floor square feet\n",
    "* 2ndFlrSF: Second floor square feet\n",
    "* LowQualFinSF: Low quality finished square feet (all floors)\n",
    "* GrLivArea: Above grade (ground) living area square feet\n",
    "* BsmtFullBath: Basement full bathrooms\n",
    "* BsmtHalfBath: Basement half bathrooms\n",
    "* FullBath: Full bathrooms above grade\n",
    "* HalfBath: Half baths above grade\n",
    "* BedroomAbvGr: Bedrooms above grade (does NOT include basement bedrooms)\n",
    "* KitchenAbvGr: Kitchens above grade\n",
    "* TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
    "* Fireplaces: Number of fireplaces\n",
    "* GarageCars: Size of garage in car capacity\n",
    "* GarageArea: Size of garage in square feet\n",
    "* WoodDeckSF: Wood deck area in square feet\n",
    "* OpenPorchSF: Open porch area in square feet\n",
    "* EnclosedPorch: Enclosed porch area in square feet\n",
    "* 3SsnPorch: Three season porch area in square feet\n",
    "* ScreenPorch: Screen porch area in square feet\n",
    "* PoolArea: Pool area in square feet\n",
    "* MiscVal: $Value of miscellaneous feature \n",
    "* SellingDate: Date when the house was sold\n",
    "* BuildingDate: Date when the house was built\n",
    "* RemodAddDate: Remodel date (same as construction date if no remodeling or additions)\n",
    "* SalePrice: The house price at the selling date (our target variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efd8c63",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2f274d778f5887e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's read the csv and create our train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049fd662",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7582e93ac7adb85f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def house_price_dataset():\n",
    "    return pd.read_csv(\n",
    "    'data/housePrices.csv', \n",
    "        parse_dates=[\n",
    "            'SellingDate',\n",
    "            'BuildingDate',\n",
    "            'RemodAddDate'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "dataset = house_price_dataset()\n",
    "dataset_train, dataset_test = train_test_split(dataset, random_state=0)\n",
    "X_train = dataset_train.drop(columns='SalePrice')\n",
    "y_train = dataset_train.SalePrice\n",
    "X_test = dataset_test.drop(columns='SalePrice')\n",
    "y_test = dataset_test.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fa1fe4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-425695b0c9d45ae9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 8 Build a DateTransformer transformer (graded)\n",
    "\n",
    "A simple transformer that transforms dates into timedeltas can be useful, from times to times, when modeling. Usually when you have features that are Dates you compute a time delta between the feature and a given refence date.\n",
    "\n",
    "e.g Imagine that your clients have a loyalty period that ends at a given date. When your model is doing some predictions, one of the features that you can use is the number of days until the end of the loyalty period. i.e the date when the loyalty ends minus the date when your model is running. \n",
    "\n",
    "In the house prices dataset, the selling date will be the reference data, since we want to predict the house price at the selling date. For instance, two houses with the exact same features can vary in prices if the construction year is different. So we should input this information and feed into the model. Then we need to convert the other dates using our transformer\n",
    "\n",
    "Hint: Result should be integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b78c45",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d9538038181ba578",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class DateTransformer(BaseEstimator, TransformerMixin):\n",
    "    # Implement the __init__ method.\n",
    "    # Our DateTransformer must be able to receive two parameters: \n",
    "    # datetime_cols: a list, that contains the datetime cols that should be converted\n",
    "    # ref_date_col: indicates the name of the column that should be used as reference date,\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "        \n",
    "    # There's no need for a fit method in this case, it does nothing.\n",
    "    # We should be able to call fit without any explicit parameters.\n",
    "    # Meaning: we should be able to call fit() on the transformer.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Transform should transform all datetime columns into the difference in days to the reference date.\n",
    "    # The reference date column should be dropped. \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab1d26c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b64b26753ecd8561",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_transformed = DateTransformer(\n",
    "    datetime_cols=['BuildingDate', 'RemodAddDate'], \n",
    "    ref_date_col='SellingDate'\n",
    ").fit_transform(X_train)\n",
    "assert X_train_transformed.BuildingDate.min() == -49008\n",
    "assert X_train_transformed.BuildingDate.max() == -1\n",
    "assert 'SellingDate' not in X_train_transformed.columns\n",
    "assert X_train_transformed.dtypes.BuildingDate == np.dtype('int64')\n",
    "assert X_train_transformed.dtypes.RemodAddDate == np.dtype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dc7b15",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5989c2b51d38b449",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You might be wondering why we have to implement it as a Transformer Class, and not using functions.\n",
    "You'll understand the reason in the next section, we're we can tie them all together in a `Pipeline`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714780de",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-46fe8c71f80d2717",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 9 Building the pipeline (graded)\n",
    "\n",
    "Finally, we want to use the two transformers together and run a linear regression on top. We want to:\n",
    "\n",
    "* Convert the dates to time deltas relative to the Selling Date.\n",
    "\n",
    "* Scale all features to the same range, using `sklearn.preprocessing.RobustScaler()`.\n",
    "\n",
    "* Estimate the SellingPrice using a Linear Regression.\n",
    "\n",
    "Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data (i.e., Gaussian with zero mean and unit variance).\n",
    "\n",
    "In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.\n",
    "\n",
    "For instance, many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the l1 and l2 regularizers of linear models) assume that all features are centered around zero and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697faf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0afe11",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6bc09de5e71383d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a pipeline including:\n",
    "#   1 - 'date_converter', DateTransformer(['BuildingDate', 'RemodAddDate'], ref_date_col='SellingDate')\n",
    "#   2 - 'robust_scaler', RobustScaler() with the default parameters\n",
    "#   3 - 'model', LinearRegression\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('MAE: {}'.format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01715551",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5d21dcdd34a13d24",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(pipeline) == Pipeline\n",
    "assert type(pipeline.named_steps['date_converter']) == DateTransformer\n",
    "assert type(pipeline.named_steps['robust_scaler']) == RobustScaler\n",
    "assert pipeline.named_steps['date_converter'].get_params()['ref_date_col'] == 'SellingDate'\n",
    "assert set(\n",
    "    pipeline.named_steps['date_converter'].get_params()['datetime_cols']\n",
    ") == {'BuildingDate', 'RemodAddDate'}\n",
    "assert type(pipeline.named_steps['model']) == LinearRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97367e2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-154280375c499868",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 10. Access the cofficients from the pipeline (ungraded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0f0738",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a913e812dcb37ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we would want to obtain the coefficients from the model to understand features with the most predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404b9be",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-58083ef8ab8d97c7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#coefs = ....\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810e2d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f42cbedb988b6aa8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert coefs.shape == (30,), 'Wrong number of coefficients. Did you select the features correctly?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3facfa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57f2ca220627e218",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Exercises complete, congratulations! You are about to become a certified data wrangler."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
