{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLU12 - Learning Notebook 2 - Workflow\n",
    "\n",
    "In this notebook, we will create non-personalized and personalized recommendations for a model dataset following a workflow like in a hackathon. After doing everything by hand in the previous BLUs, we will use get to use two RS libraries, [lightFM](https://making.lyst.com/lightfm/docs/index.html) and [surprise](https://surpriselib.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary dependencies\n",
    "\n",
    "# Operating System\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Numpy, Pandas and Scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# LightFM\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset as lfmDataset\n",
    "from lightfm import evaluation as lfmEvaluation\n",
    "\n",
    "# Surprise\n",
    "from surprise import SVD\n",
    "from surprise import Dataset as sDataset\n",
    "from surprise import Reader\n",
    "\n",
    "# Model Evaluation\n",
    "from evaluation import evaluate_solution, precision_k, average_precision_k\n",
    "\n",
    "# RAM control\n",
    "from ramcontrol import check_memory_limit, memory_circuit_breaker\n",
    "\n",
    "plt.rcParams['figure.figsize']=(4.8, 3.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    " This notebook is quite memory intensive, it uses over 3GB RAM. To prevent your PC from turning into a bonfire if you don't have enough memory, there are some steps that can be taken:\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./media/burning_pc.gif\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - In cells that consume a lot of RAM, stop execution if RAM usage is too high. This can be done with the function `memory_circuit_breaker`. This function checks if the total computer RAM usage percentage is above a threshold and if it can't be lowered, the execution is stopped. You can control the percentage with `memory_limit_perc` below.\n",
    " - Frequently delete useless objects along the notebook. If a dataframe or matrix is not going to be used further on, then we can delete that object and let the garbage collector `gc` clear some RAM.\n",
    " - Change the data types to lighter alternatives: integer IDs can be converted to strings, numerical values can have smaller \"bitness\", for example use `np.float32` instead of `np.float64` (but be on the lookout for [overflow errors](https://numpy.org/doc/stable/user/basics.types.html#overflow-errors)), remove unused features early, etc.\n",
    " - If RAM is still an issue at this point, you can subset the original dataset to work with a smaller fraction of the data.\n",
    " - When you execute cells multiple times, it might happen that the memory usage increases at each execution, even if no new objects or data is generated. If that's the case, you should restart the kernel and re-execute the cells.\n",
    " - Ultimately, you may need more RAM. ¯\\\\_(ツ)_/¯ or try to run this notebook on public platforms like Kaggle or Google Collab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit of total memory percentage that be used [0.,100.]\n",
    "memory_limit_perc = 70."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "In this notebook, we are going to simulate the real-life environment of the Hackathon! We will provide you with a dataset and some tips and you are going to train, validate, and predict with a recommender system using all the knowledge acquired throughout this specialization.\n",
    "\n",
    "### 1.1 Context\n",
    "You have finished the Academy and you are hired as a data scientist in Recommenu. Recommenu is a disruptive crowdsourcing peer-to-peer mobile app experience developed to deliver a unique environment especially designed for maximum enjoyment by empowering users to engage in recipe sharing and reviewing in a paradigm shift block-chain powered AI platform.\n",
    "\n",
    "<img src=\"./media/recommenu_logo.png\" width=\"350\"/>\n",
    "\n",
    "First week on the job and the CEO of the next-unicorn-startup that hired you pitches your first task: build a recommender system to suggest users what they should prepare for their next meals. Your recommendations should be based on user reviews. She doesn't care how you do it or how it works, just that you use fancy trendy eye-catching mind-blowing AI *stuff* to promote Recommenu's name in the data science industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Technical task\n",
    "After the pitch from the CEO, you talk with your lead data scientist and plan the tasks needed to fulfill the job. The company collected some data about the users and the recipes and you will need to create the recommender system that is effective enough so that your users will always know what to cook. The main task is to find the best recommendations for each user.\n",
    "\n",
    "### 1.3 Evaluation\n",
    "\n",
    "Your lead DS will keep some of the data as a test dataset (in which you will estimate production performance) and gives you the remaining data.\n",
    "\n",
    "The expected output is 50 recommendations for each user. The recommendations are compared with the validation data set and evaluated using map@50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "\n",
    "### 2.1 Step -1: Inspect the data\n",
    "The data is in the `data` folder. As a good data scientist, your first step is to validate that the data you have will be good enough to proceed.\n",
    "\n",
    "The files we have available for the training stage are:\n",
    "* `RAW_interactions_train.csv` with the user reviews\n",
    "* `RAW_recipes.csv` with the recipe metadata\n",
    "\n",
    "We also have an example output file:\n",
    "* `example_output.csv` is an example of the output, the first column is the user id and the remaining 50 columns are the recommended recipe ids\n",
    "\n",
    "The best approach is to look at the raw files and print out the first rows of each file just to get an overall sense of what we have. Remember what you've learned in the data wrangling specialization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_interactions_train.csv \n",
      "\n",
      "user_id,recipe_id,review_date,rating,comment\n",
      "2133146,40767,2012-01-03,0,\"i'm yet to try this recipe but my dad makes one very similar. it's definitely sweetened condensed milk (because its thick and sugary), and the sugar has to be simmered until its melted completely. my father also used golden syrup on top of the ingredients listed here. you can also add a small portion of water once the ingredients are thoroughly combined and sugar melted and place back on low heat to thicken up again\"\n",
      "1619510,169999,2011-06-18,5,\"Made this many times, absolutly love it. Like my corn on the raw side took kpfen advise and only cooked it for 15 minutes....\"\n"
     ]
    }
   ],
   "source": [
    "print(\"RAW_interactions_train.csv \\n\")\n",
    "!head -3 data/RAW_interactions_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_recipes.csv\n",
      "\n",
      "name,id,minutes,contributor_id,submitted,tags,nutrition,n_steps,steps,description,ingredients,n_ingredients\n",
      "bananas 4 ice cream  pie,70971,180,102353,2003-09-10,\"['weeknight', 'time-to-make', 'course', 'main-ingredient', 'preparation', 'pies-and-tarts', 'desserts', 'lunch', 'snacks', 'no-cook', 'refrigerator', 'kid-friendly', 'frozen-desserts', 'pies', 'chocolate', 'dietary', 'inexpensive', 'equipment', 'number-of-servings', 'technique', '4-hours-or-less']\",\"[4270.8, 254.0, 1306.0, 111.0, 127.0, 431.0, 220.0]\",8,\"['crumble cookies into a 9-inch pie plate , or cake pan', 'pat down to form an even layer', 'drizzle 1 cup of chocolate topping evenly over the cookies with a small spoon', 'scoop the vanilla ice cream on top of the chocolate and smooth down', 'cover with half of the sliced bananas', 'top with strawberry ice cream', 'cover and freeze until firm', 'before serving , top with 1 / 4 cup chocolate topping , whipped cream , and sliced bananas']\",,\"['chocolate sandwich style cookies', 'chocolate syrup', 'vanilla ice cream', 'bananas', 'strawberry ice cream', 'whipped cream']\",6\n"
     ]
    }
   ],
   "source": [
    "print(\"RAW_recipes.csv\\n\")\n",
    "!head -2 data/RAW_recipes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_output.csv \n",
      "\n",
      "4470,12985,304842,293304,414,25150,314086,68212,217471,14397,177172,54386,315812,319911,243769,302247,86545,2078,16220,310418,302369,289658,221730,333259,311604,52478,307202,329834,25323,337625,277126,87433,170541,212702,24825,212017,348629,127365,241705,183796,341456,170222,207916,384072,132813,107193,188549,362714,138672,21771,339689,38941,177486,244143,285387,157386,307140,126831,302031,181854,192716,334187,57500,165401,305991,207935,351764,105434,45592,187097,311262,266750,109807,90822,311702,208383,52176,243307,97972,19682,353035,30292,72314,105694,108137,335634,55364,84395,147076,261596,49469,39842,245936,69165,202995,49781,142602,223714,122591,333064,149655,11147,69227,252967,8402,180413,291341,321987,79814,167248,168430,30643,36589,362643,165753,247135,378274,172483,353700,93787,177574,150116,250930,245012,129495,307414,315425,340072,334240,114624,39401,183790,348308,47391,242558,186377,100897,248603,142745,261901,162388,345265,263933,130077,368393,57225,3525,383719,225153,211334,16174,123457,25706,290375,18659,144822,11011,106583,281075,212852,65358,357810,80219,234609,180961,286585,384867,173528,86689,147248,233124,295289,354625,200290,141858,62467,262242,142093,106938,339376,108845,170852,342771,299538,269885,302901,379370,2242,50740,95103,233632,344876,19159,12554,37096,242151,154559,204174,26935,118989,258876,104967,359476,67850,115162,103524,294932,107099,113267,285117,384804,37133,251150,144511,273894,374773,364125,363499,237680,197733,327413,103466,100771,18535,360529,21336,70955,30040,26705,89877,366619,206251,212432,82048,2923,71432,369493,224243,151129,10974,160878,46393,58821,232052,2607,7530,175099,236352,82113,341506,329869,116648,28070,34845,98159,273650,163838,26673,327320,201980,225108,373821,43768,97877,91536,282116,516,195088,289238,204165,147082,183572,330392,198718,228908,188333,315546,170645,148050,90974,8201,40311,251101,275435,145229,190270,384923,262794,45265,249112,191205,123113,24400,373947,269572,57565,351817,137197,305804,378161,374972,365793,9655,374902,140654,49724,92515,121349,268231,321930,48688,279862,309384,157562,60866,278084,137338,350805,190006,188700,327086,165972,171320,320656,149980,183682,280035,189538,227404,37046,78964,101204,10208,70949,359966,248927,104805,235145,336461,115734,237672,205666,339774,127276,74558,348491,301690,148041,209788,198994,362652,149371,207699,115107,289108,158075,371705,35067,6276,319788,98418,9402,197451,314143,189553,287391,305496,76417,182917,66327,290073,67219,77729,37214,280827,196087,74321,252262,178028,284507,1590,225531,153623,133887,189905,271406,54368,99940,46039,96041,142382,221812,331326,98924,168493,288347,346138,48323,115101,171653,352818,6982,275256,251735,155424,206288,277036,380381,205438,52844,191270,62960,243516,49770,296742,190479,198665,359613,380489,229935,166796,25890,278229,226501,121402,271676,70628,15847,201050,26812,17994,198218,283925,224988,253868,89424,70839,107825,172688,381931,128469,130182,105213,142493,69983,45620,35266,78404,190591,126648,157291,186533,322169,84673,12305,329813,254647,312175,191170,373418,104505,312338,265175,41131,59866,252886,315974,318496,59631,59916,110402,235155,356911,195772,239031,128723,226526,281007,306779,28977,335254,190305,256158,384538,61211,131840,355207,118681,86191,300627,105749,176395,372451,99587,348454,349220,105937,140694,363559,257947,94236\n"
     ]
    }
   ],
   "source": [
    "print(\"example_output.csv \\n\")\n",
    "!head -1 data/example_output.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Step 0: Load the data\n",
    "After validating that the data is good enough, we start building the ratings matrix. Our strategy is to get a non-personalized recommender system as a baseline. This avoids the cold start problem and allows us to predict both for existing and new users.\n",
    "\n",
    "We will load the rating data and the recipe metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2133146</td>\n",
       "      <td>40767</td>\n",
       "      <td>2012-01-03</td>\n",
       "      <td>0</td>\n",
       "      <td>i'm yet to try this recipe but my dad makes on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1619510</td>\n",
       "      <td>169999</td>\n",
       "      <td>2011-06-18</td>\n",
       "      <td>5</td>\n",
       "      <td>Made this many times, absolutly love it. Like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1072593</td>\n",
       "      <td>111434</td>\n",
       "      <td>2014-08-07</td>\n",
       "      <td>5</td>\n",
       "      <td>The family&amp;#039;s divided on this one.  The ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72489</td>\n",
       "      <td>15059</td>\n",
       "      <td>2004-12-20</td>\n",
       "      <td>5</td>\n",
       "      <td>C'est si bon!  These are delicious and delecta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109110</td>\n",
       "      <td>336205</td>\n",
       "      <td>2013-06-10</td>\n",
       "      <td>0</td>\n",
       "      <td>This wasn&amp;#039;t to our taste.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  recipe_id review_date  rating  \\\n",
       "0  2133146      40767  2012-01-03       0   \n",
       "1  1619510     169999  2011-06-18       5   \n",
       "2  1072593     111434  2014-08-07       5   \n",
       "3    72489      15059  2004-12-20       5   \n",
       "4   109110     336205  2013-06-10       0   \n",
       "\n",
       "                                             comment  \n",
       "0  i'm yet to try this recipe but my dad makes on...  \n",
       "1  Made this many times, absolutly love it. Like ...  \n",
       "2  The family&#039;s divided on this one.  The ra...  \n",
       "3  C'est si bon!  These are delicious and delecta...  \n",
       "4                     This wasn&#039;t to our taste.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = os.path.join('data', 'RAW_interactions_train.csv')\n",
    "data = pd.read_csv(train_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bananas 4 ice cream  pie</td>\n",
       "      <td>70971</td>\n",
       "      <td>180</td>\n",
       "      <td>102353</td>\n",
       "      <td>2003-09-10</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[4270.8, 254.0, 1306.0, 111.0, 127.0, 431.0, 2...</td>\n",
       "      <td>8</td>\n",
       "      <td>['crumble cookies into a 9-inch pie plate , or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['chocolate sandwich style cookies', 'chocolat...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beat this  banana bread</td>\n",
       "      <td>75452</td>\n",
       "      <td>70</td>\n",
       "      <td>15892</td>\n",
       "      <td>2003-11-04</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[2669.3, 160.0, 976.0, 107.0, 62.0, 310.0, 138.0]</td>\n",
       "      <td>12</td>\n",
       "      <td>['preheat oven to 350 degrees', 'butter two 9x...</td>\n",
       "      <td>from ann hodgman's</td>\n",
       "      <td>['sugar', 'unsalted butter', 'bananas', 'eggs'...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>better than sex  strawberries</td>\n",
       "      <td>42198</td>\n",
       "      <td>1460</td>\n",
       "      <td>41531</td>\n",
       "      <td>2002-10-03</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[734.1, 66.0, 199.0, 10.0, 10.0, 117.0, 28.0]</td>\n",
       "      <td>8</td>\n",
       "      <td>['crush vanilla wafers into fine crumbs and li...</td>\n",
       "      <td>simple but sexy. this was in my local newspape...</td>\n",
       "      <td>['vanilla wafers', 'butter', 'powdered sugar',...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>better then bush s  baked beans</td>\n",
       "      <td>67547</td>\n",
       "      <td>2970</td>\n",
       "      <td>85627</td>\n",
       "      <td>2003-07-26</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[462.4, 28.0, 214.0, 69.0, 14.0, 29.0, 23.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['in a very large sauce pan cover the beans an...</td>\n",
       "      <td>i'd have to say that this is a labor of love d...</td>\n",
       "      <td>['great northern bean', 'chicken bouillon cube...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chinese  candy</td>\n",
       "      <td>23933</td>\n",
       "      <td>15</td>\n",
       "      <td>35268</td>\n",
       "      <td>2002-03-29</td>\n",
       "      <td>['15-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[232.7, 21.0, 77.0, 4.0, 6.0, 38.0, 8.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>['melt butterscotch chips in heavy saucepan ov...</td>\n",
       "      <td>a little different, and oh so good. i include ...</td>\n",
       "      <td>['butterscotch chips', 'chinese noodles', 'sal...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name     id  minutes  contributor_id  \\\n",
       "0         bananas 4 ice cream  pie  70971      180          102353   \n",
       "1          beat this  banana bread  75452       70           15892   \n",
       "2    better than sex  strawberries  42198     1460           41531   \n",
       "3  better then bush s  baked beans  67547     2970           85627   \n",
       "4                   chinese  candy  23933       15           35268   \n",
       "\n",
       "    submitted                                               tags  \\\n",
       "0  2003-09-10  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "1  2003-11-04  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "2  2002-10-03  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "3  2003-07-26  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "4  2002-03-29  ['15-minutes-or-less', 'time-to-make', 'course...   \n",
       "\n",
       "                                           nutrition  n_steps  \\\n",
       "0  [4270.8, 254.0, 1306.0, 111.0, 127.0, 431.0, 2...        8   \n",
       "1  [2669.3, 160.0, 976.0, 107.0, 62.0, 310.0, 138.0]       12   \n",
       "2      [734.1, 66.0, 199.0, 10.0, 10.0, 117.0, 28.0]        8   \n",
       "3       [462.4, 28.0, 214.0, 69.0, 14.0, 29.0, 23.0]        9   \n",
       "4           [232.7, 21.0, 77.0, 4.0, 6.0, 38.0, 8.0]        4   \n",
       "\n",
       "                                               steps  \\\n",
       "0  ['crumble cookies into a 9-inch pie plate , or...   \n",
       "1  ['preheat oven to 350 degrees', 'butter two 9x...   \n",
       "2  ['crush vanilla wafers into fine crumbs and li...   \n",
       "3  ['in a very large sauce pan cover the beans an...   \n",
       "4  ['melt butterscotch chips in heavy saucepan ov...   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                NaN   \n",
       "1                                from ann hodgman's    \n",
       "2  simple but sexy. this was in my local newspape...   \n",
       "3  i'd have to say that this is a labor of love d...   \n",
       "4  a little different, and oh so good. i include ...   \n",
       "\n",
       "                                         ingredients  n_ingredients  \n",
       "0  ['chocolate sandwich style cookies', 'chocolat...              6  \n",
       "1  ['sugar', 'unsalted butter', 'bananas', 'eggs'...              9  \n",
       "2  ['vanilla wafers', 'butter', 'powdered sugar',...              7  \n",
       "3  ['great northern bean', 'chicken bouillon cube...             13  \n",
       "4  ['butterscotch chips', 'chinese noodles', 'sal...              3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_meta_path = os.path.join('data', 'RAW_recipes.csv')\n",
    "recipes = pd.read_csv(recipe_meta_path)\n",
    "recipes.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Step 1: Interaction data exploration\n",
    "\n",
    "Let's explore the interaction data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 163,065 ratings in total.\n"
     ]
    }
   ],
   "source": [
    "# How many ratings do we have in total?\n",
    "# Tip: The \":,\" at the end of the f-string adds the thousand separator.\n",
    "print(f\"We have {len(data):,} ratings in total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We have 30,695 recipes rated.\n"
     ]
    }
   ],
   "source": [
    "# How many recipes were rated?\n",
    "print(f\" We have {data['recipe_id'].unique().size:,} recipes rated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We have 58,884 users that rated at least one recipe.\n"
     ]
    }
   ],
   "source": [
    "# How many users rated at least one recipe?\n",
    "print(f\" We have {data['user_id'].unique().size:,} users that rated at least one recipe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the rating distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the rating distribution.\n",
    "data[\"rating\"].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are expecting ratings between 1 and 5, but we have some 0 values. Let's check these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>2002194880</td>\n",
       "      <td>36431</td>\n",
       "      <td>2018-06-22</td>\n",
       "      <td>0</td>\n",
       "      <td>How do you store them after they are done? Wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>2002171413</td>\n",
       "      <td>449747</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>0</td>\n",
       "      <td>Cook uncovered and in a low pan (use a good qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>162285</td>\n",
       "      <td>103281</td>\n",
       "      <td>2005-02-21</td>\n",
       "      <td>0</td>\n",
       "      <td>I am from Bavaria and my mom used to make it a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>2164272</td>\n",
       "      <td>411501</td>\n",
       "      <td>2017-03-06</td>\n",
       "      <td>0</td>\n",
       "      <td>I am so excited!!! Shawn can't wait for me to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>1759082</td>\n",
       "      <td>15411</td>\n",
       "      <td>2010-12-15</td>\n",
       "      <td>0</td>\n",
       "      <td>Quick, Easy, &amp; using ingredients that you ALWA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>2001467157</td>\n",
       "      <td>48635</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>0</td>\n",
       "      <td>Do I have to use the baking soda???</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>111336</td>\n",
       "      <td>693</td>\n",
       "      <td>2005-08-24</td>\n",
       "      <td>0</td>\n",
       "      <td>Easy, quick \"hot dish\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>261899</td>\n",
       "      <td>211710</td>\n",
       "      <td>2012-10-14</td>\n",
       "      <td>0</td>\n",
       "      <td>My family loved this..So tonight I'm trying wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>2206320</td>\n",
       "      <td>475041</td>\n",
       "      <td>2012-03-12</td>\n",
       "      <td>0</td>\n",
       "      <td>That sounds yummy!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>159782</td>\n",
       "      <td>334688</td>\n",
       "      <td>2011-01-18</td>\n",
       "      <td>0</td>\n",
       "      <td>Well, it doesn't get much easier than this. Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>2000079955</td>\n",
       "      <td>60350</td>\n",
       "      <td>2015-03-22</td>\n",
       "      <td>0</td>\n",
       "      <td>Seriously? The worst recipe ever!! Made it yes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>443407</td>\n",
       "      <td>269449</td>\n",
       "      <td>2014-07-18</td>\n",
       "      <td>0</td>\n",
       "      <td>This is a great recipe, I doubled it and used ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>139381</td>\n",
       "      <td>39618</td>\n",
       "      <td>2007-03-28</td>\n",
       "      <td>0</td>\n",
       "      <td>I have to agree with the previous poster...and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>1802485902</td>\n",
       "      <td>451534</td>\n",
       "      <td>2014-02-13</td>\n",
       "      <td>0</td>\n",
       "      <td>How much water should I add?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>2856176</td>\n",
       "      <td>48760</td>\n",
       "      <td>2016-02-04</td>\n",
       "      <td>0</td>\n",
       "      <td>We enjoyed this recipe.  Unique flavor.  Very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>599450</td>\n",
       "      <td>322299</td>\n",
       "      <td>2009-11-24</td>\n",
       "      <td>0</td>\n",
       "      <td>I made these as directed with one exception: I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>278639</td>\n",
       "      <td>29386</td>\n",
       "      <td>2008-09-04</td>\n",
       "      <td>0</td>\n",
       "      <td>I made this last night and it was a hit with b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>26399</td>\n",
       "      <td>50454</td>\n",
       "      <td>2003-03-04</td>\n",
       "      <td>0</td>\n",
       "      <td>Hi,I'm glad you liked it!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>908675</td>\n",
       "      <td>416234</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>My cousin gave us a bunch of turnips from a fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>2001680577</td>\n",
       "      <td>495292</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>0</td>\n",
       "      <td>I will do this with the organic egg noodles. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>2541860</td>\n",
       "      <td>129926</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>WOW...This was incredible, I wish I could give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>1803121000</td>\n",
       "      <td>215370</td>\n",
       "      <td>2014-09-10</td>\n",
       "      <td>0</td>\n",
       "      <td>First things first. THE SOUP- How does it real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>782743</td>\n",
       "      <td>94991</td>\n",
       "      <td>2008-04-02</td>\n",
       "      <td>0</td>\n",
       "      <td>I never would have thought to put these ingred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>119385</td>\n",
       "      <td>70755</td>\n",
       "      <td>2008-05-20</td>\n",
       "      <td>0</td>\n",
       "      <td>I've been making this for a while now and my l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>2419652</td>\n",
       "      <td>99476</td>\n",
       "      <td>2012-09-25</td>\n",
       "      <td>0</td>\n",
       "      <td>Great recipe!!! Super easy &amp; quick &amp; DELICIOUS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>1458727</td>\n",
       "      <td>367227</td>\n",
       "      <td>2010-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>I found this recipe on a bag of Al Dente Fettu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>340312</td>\n",
       "      <td>235590</td>\n",
       "      <td>2009-07-30</td>\n",
       "      <td>0</td>\n",
       "      <td>This is a great idea, and sooo cute! I will be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>2002096619</td>\n",
       "      <td>205890</td>\n",
       "      <td>2018-04-05</td>\n",
       "      <td>0</td>\n",
       "      <td>I used Crisco instead of butter and added a ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>290578</td>\n",
       "      <td>84956</td>\n",
       "      <td>2009-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>This bread has a really nice flavor and I  sme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2001246873</td>\n",
       "      <td>411045</td>\n",
       "      <td>2016-11-15</td>\n",
       "      <td>0</td>\n",
       "      <td>Living in Colorado, also, I have been searchin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>274065</td>\n",
       "      <td>84330</td>\n",
       "      <td>2006-11-29</td>\n",
       "      <td>0</td>\n",
       "      <td>I wish that I could say we loved this soup but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>926427</td>\n",
       "      <td>317259</td>\n",
       "      <td>2008-10-19</td>\n",
       "      <td>0</td>\n",
       "      <td>I can't rate this yet.  Unfortunately, my croc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>62264</td>\n",
       "      <td>195433</td>\n",
       "      <td>2006-11-14</td>\n",
       "      <td>0</td>\n",
       "      <td>this is scrapple! great stuff!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>837429</td>\n",
       "      <td>260781</td>\n",
       "      <td>2008-05-11</td>\n",
       "      <td>0</td>\n",
       "      <td>I had DH make this for me for mother's day. We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>2001250426</td>\n",
       "      <td>27735</td>\n",
       "      <td>2018-02-03</td>\n",
       "      <td>0</td>\n",
       "      <td>I love this it's so good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>402172</td>\n",
       "      <td>389516</td>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>I used sour cream instead of yogurt to lazy an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>2774770</td>\n",
       "      <td>132008</td>\n",
       "      <td>2013-04-07</td>\n",
       "      <td>0</td>\n",
       "      <td>Wonderful recipe.  Would also be great with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>2325224</td>\n",
       "      <td>123630</td>\n",
       "      <td>2012-08-20</td>\n",
       "      <td>0</td>\n",
       "      <td>These muffins taste like they are from a bed a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>1460501</td>\n",
       "      <td>265711</td>\n",
       "      <td>2012-02-09</td>\n",
       "      <td>0</td>\n",
       "      <td>ANOTHER OPTION - Grandma Tomasini always serve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>724631</td>\n",
       "      <td>512748</td>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>I am not comfortable giving any stars because ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  recipe_id review_date  rating  \\\n",
       "1560  2002194880      36431  2018-06-22       0   \n",
       "1584  2002171413     449747  2018-05-31       0   \n",
       "1600      162285     103281  2005-02-21       0   \n",
       "1670     2164272     411501  2017-03-06       0   \n",
       "1674     1759082      15411  2010-12-15       0   \n",
       "1676  2001467157      48635  2017-04-01       0   \n",
       "1678      111336        693  2005-08-24       0   \n",
       "1683      261899     211710  2012-10-14       0   \n",
       "1698     2206320     475041  2012-03-12       0   \n",
       "1701      159782     334688  2011-01-18       0   \n",
       "1732  2000079955      60350  2015-03-22       0   \n",
       "1757      443407     269449  2014-07-18       0   \n",
       "1763      139381      39618  2007-03-28       0   \n",
       "1768  1802485902     451534  2014-02-13       0   \n",
       "1772     2856176      48760  2016-02-04       0   \n",
       "1806      599450     322299  2009-11-24       0   \n",
       "1826      278639      29386  2008-09-04       0   \n",
       "1833       26399      50454  2003-03-04       0   \n",
       "1840      908675     416234  2010-03-31       0   \n",
       "1871  2001680577     495292  2017-08-20       0   \n",
       "1917     2541860     129926  2013-01-02       0   \n",
       "1954  1803121000     215370  2014-09-10       0   \n",
       "1964      782743      94991  2008-04-02       0   \n",
       "1967      119385      70755  2008-05-20       0   \n",
       "2054     2419652      99476  2012-09-25       0   \n",
       "2086     1458727     367227  2010-02-02       0   \n",
       "2095      340312     235590  2009-07-30       0   \n",
       "2139  2002096619     205890  2018-04-05       0   \n",
       "2141      290578      84956  2009-01-16       0   \n",
       "2150  2001246873     411045  2016-11-15       0   \n",
       "2170      274065      84330  2006-11-29       0   \n",
       "2192      926427     317259  2008-10-19       0   \n",
       "2194       62264     195433  2006-11-14       0   \n",
       "2212      837429     260781  2008-05-11       0   \n",
       "2219  2001250426      27735  2018-02-03       0   \n",
       "2224      402172     389516  2011-06-01       0   \n",
       "2227     2774770     132008  2013-04-07       0   \n",
       "2232     2325224     123630  2012-08-20       0   \n",
       "2236     1460501     265711  2012-02-09       0   \n",
       "2249      724631     512748  2014-05-01       0   \n",
       "\n",
       "                                                comment  \n",
       "1560  How do you store them after they are done? Wha...  \n",
       "1584  Cook uncovered and in a low pan (use a good qu...  \n",
       "1600  I am from Bavaria and my mom used to make it a...  \n",
       "1670  I am so excited!!! Shawn can't wait for me to ...  \n",
       "1674  Quick, Easy, & using ingredients that you ALWA...  \n",
       "1676                Do I have to use the baking soda???  \n",
       "1678                            Easy, quick \"hot dish\".  \n",
       "1683  My family loved this..So tonight I'm trying wi...  \n",
       "1698                               That sounds yummy!!!  \n",
       "1701  Well, it doesn't get much easier than this. Ad...  \n",
       "1732  Seriously? The worst recipe ever!! Made it yes...  \n",
       "1757  This is a great recipe, I doubled it and used ...  \n",
       "1763  I have to agree with the previous poster...and...  \n",
       "1768                       How much water should I add?  \n",
       "1772  We enjoyed this recipe.  Unique flavor.  Very ...  \n",
       "1806  I made these as directed with one exception: I...  \n",
       "1826  I made this last night and it was a hit with b...  \n",
       "1833                          Hi,I'm glad you liked it!  \n",
       "1840  My cousin gave us a bunch of turnips from a fi...  \n",
       "1871  I will do this with the organic egg noodles. T...  \n",
       "1917  WOW...This was incredible, I wish I could give...  \n",
       "1954  First things first. THE SOUP- How does it real...  \n",
       "1964  I never would have thought to put these ingred...  \n",
       "1967  I've been making this for a while now and my l...  \n",
       "2054  Great recipe!!! Super easy & quick & DELICIOUS...  \n",
       "2086  I found this recipe on a bag of Al Dente Fettu...  \n",
       "2095  This is a great idea, and sooo cute! I will be...  \n",
       "2139  I used Crisco instead of butter and added a ta...  \n",
       "2141  This bread has a really nice flavor and I  sme...  \n",
       "2150  Living in Colorado, also, I have been searchin...  \n",
       "2170  I wish that I could say we loved this soup but...  \n",
       "2192  I can't rate this yet.  Unfortunately, my croc...  \n",
       "2194                     this is scrapple! great stuff!  \n",
       "2212  I had DH make this for me for mother's day. We...  \n",
       "2219                           I love this it's so good  \n",
       "2224  I used sour cream instead of yogurt to lazy an...  \n",
       "2227  Wonderful recipe.  Would also be great with a ...  \n",
       "2232  These muffins taste like they are from a bed a...  \n",
       "2236  ANOTHER OPTION - Grandma Tomasini always serve...  \n",
       "2249  I am not comfortable giving any stars because ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data[\"rating\"] == 0][80:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the rating is 0, some comments are negative but most are positive. Let's read some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WOW...This was incredible, I wish I could give a hundred stars. My Boyfriend said we would never eat out Mexican again. So five stars from him and five from me...my daughter even ate every bite! This is a great recipe. I of course added just a little spice, 1 Tbsp of cumin to the chicken and onions. Perfect recipe, the sauce is beautiful when it comes together, Everything was perfect. Thank you for sharing!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data[\"rating\"] == 0, \"comment\"][1917]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seriously? The worst recipe ever!! Made it yesterday. Never ever experienced such a worse mac n cheese sauce:-(\\nTotal flour taste! Like sb else already noticed: your family will hate you for that.\\nGoing to find me another recipe now or have to stick to the craft company.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data[\"rating\"] == 0, \"comment\"][1732]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Great recipe!!! Super easy & quick & DELICIOUS!!! My family loved it!!!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data[\"rating\"] == 0, \"comment\"][2054]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How much water should I add?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data[\"rating\"] == 0, \"comment\"][1768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I can't rate this yet.  Unfortunately, my crock pot died while making and by the time I found out I had to dump the whole thing for safety reasons.  I did try remaking but having less wine (using 1/2 wine, half homemade beef broth) it wouldn't be fair to rate.  I'm so sorry, Chohettz.  \\r\\nMade for PAC, 2008.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data[\"rating\"] == 0, \"comment\"][2192]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While some comments are positive, others are negative. One user even commented that they didn't rate the recipe. Let's see if there are more cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>441655</td>\n",
       "      <td>443523</td>\n",
       "      <td>2010-12-07</td>\n",
       "      <td>0</td>\n",
       "      <td>Delicious!! I added a hint of peppermint extra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>386585</td>\n",
       "      <td>345396</td>\n",
       "      <td>2009-02-23</td>\n",
       "      <td>0</td>\n",
       "      <td>I will not give any stars, because I messed th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>31803</td>\n",
       "      <td>56621</td>\n",
       "      <td>2005-09-11</td>\n",
       "      <td>0</td>\n",
       "      <td>These turned out great! We can't buy Grape Nut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>136997</td>\n",
       "      <td>229960</td>\n",
       "      <td>2007-06-29</td>\n",
       "      <td>0</td>\n",
       "      <td>I was intrigued by this, but I don't think it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>1584953</td>\n",
       "      <td>236448</td>\n",
       "      <td>2011-02-22</td>\n",
       "      <td>0</td>\n",
       "      <td>I didn't rate this because I realized I had th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  recipe_id review_date  rating  \\\n",
       "58     441655     443523  2010-12-07       0   \n",
       "335    386585     345396  2009-02-23       0   \n",
       "471     31803      56621  2005-09-11       0   \n",
       "883    136997     229960  2007-06-29       0   \n",
       "1435  1584953     236448  2011-02-22       0   \n",
       "\n",
       "                                                comment  \n",
       "58    Delicious!! I added a hint of peppermint extra...  \n",
       "335   I will not give any stars, because I messed th...  \n",
       "471   These turned out great! We can't buy Grape Nut...  \n",
       "883   I was intrigued by this, but I don't think it ...  \n",
       "1435  I didn't rate this because I realized I had th...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[(data[\"rating\"] == 0) & (data[\"comment\"].str.contains(\"rate\"))].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I didn't rate this because I realized I had the same recipe already saved on another recipe site, going back to 2006. Anyway, it's really good\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## A particular case\n",
    "data.loc[data[\"rating\"] == 0, \"comment\"][1435]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these comments lead us to believe that zero rating means that the user purposely did not rate the recipe (maybe they didn't follow the recipe and feel that they shouldn't rate it) or forgot to rate it regardless of liking the recipe.\n",
    "\n",
    "There doesn't seem to be a consistent meaning behind zero ratings. Recipes with rating 0 can be excellent, horrible or something in between. For this reason, reviews with zero rating should be removed from our data.\n",
    "\n",
    "Note: In a more advanced approach, you might try to use sentiment analysis (or other techniques) to predict the rating when a user does not rate a recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8,984 reviews with rating 0 where removed from training data.\n"
     ]
    }
   ],
   "source": [
    "# Removing 0 ratings\n",
    "nr_reviews_orig = data.shape[0]\n",
    "data = data.copy().loc[(data[\"rating\"] != 0)]\n",
    "nr_reviews_new = data.shape[0]\n",
    "print(f\"{nr_reviews_orig - nr_reviews_new:,} reviews with rating 0 where removed from training data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed that the review date goes from from January 2000 to December 2018. This is a huge time interval! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The earliest review was written on 2000-03-13.\n",
      "The lastest review was written on 2018-12-19.\n"
     ]
    }
   ],
   "source": [
    "## Training data interval range\n",
    "print(f\"The earliest review was written on {data['review_date'].min()}.\")\n",
    "print(f\"The lastest review was written on {data['review_date'].max()}.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most cases, using old data is a risk. Old data might not accurately reflect the current relationship between features and target. We say that we have **[concept drift](https://machinelearningmastery.com/gentle-introduction-concept-drift-machine-learning/)** when the relationship between inputs and outputs changes over time. \n",
    "\n",
    "In our case, we are going to assume that the user taste does not change significantly over time. In a professional setting, we should back this assumption with data or deal with concept drift.\n",
    "\n",
    "We also remove the comment column, it won't be necessary for the construction of the ratings matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"review_date\", \"comment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Train/validation split\n",
    "\n",
    "We are splitting the available data into training and validation data. The validation data can be used to compare models before submitting the recommendations to the portal. Note that the data points that we are predicting are given by a user-item pair. The user-item pairs between the train and validation sets will be different, but a given user or item can appear in both sets.\n",
    "\n",
    "A smarter way to do the split would be make sure that we have all items and users in both sets. That would also be more similar to a real life situation where we're predicting non-existing ratings for existing users. For now, we're just going to deal with items or users missing from the train set later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val = train_test_split(data, test_size=0.4, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Training set\n",
    "Let's look at basic stats for the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 92,448 ratings in total.\n"
     ]
    }
   ],
   "source": [
    "# How many ratings do we have in total?\n",
    "# Tip: The \":,\" at the end of the f-string adds the thousand separator.\n",
    "print(f\"We have {len(data_train):,} ratings in total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We have 21,358 recipes rated.\n"
     ]
    }
   ],
   "source": [
    "# How many recipes were rated?\n",
    "print(f\" We have {data_train['recipe_id'].unique().size:,} recipes rated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We have 36,431 users that rated at least one recipe.\n"
     ]
    }
   ],
   "source": [
    "# How many users rated at least one recipe?\n",
    "print(f\" We have {data_train['user_id'].unique().size:,} users that rated at least one recipe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Validation set\n",
    "And the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 61,633 ratings in total.\n"
     ]
    }
   ],
   "source": [
    "# How many ratings do we have in total?\n",
    "# Tip: The \":,\" at the end of the f-string adds the thousand separator.\n",
    "print(f\"We have {len(data_val):,} ratings in total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We have 16,662 recipes rated.\n"
     ]
    }
   ],
   "source": [
    "# How many recipes were rated?\n",
    "print(f\" We have {data_val['recipe_id'].unique().size:,} recipes rated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We have 27,073 users that rated at least one recipe.\n"
     ]
    }
   ],
   "source": [
    "# How many users rated at least one recipe?\n",
    "print(f\" We have {data_val['user_id'].unique().size:,} users that rated at least one recipe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many recipes were rated by each user?\n",
    "data_val.groupby('user_id').rating.apply(len).plot.hist(bins=50,log=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most users rated just a few recipes, in fact about half the ratings in the validation are from users who rated just one recipe. If we want to use metrics like `map@k`, our test users must have at least k positive ratings. In our case, it's k=50, as we're using map@50.\n",
    "\n",
    "One might argue that by selecting such users for testing, we'll have selection bias because we are specifically ignoring users with fewer ratings. This is a consideration that you should take into account especially if you want to evaluate the performance of recommendations to new users. \n",
    "\n",
    "This functions selects positive ratings from users with at least 50 positive reviews from the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128079</th>\n",
       "      <td>560491</td>\n",
       "      <td>33671</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10492</th>\n",
       "      <td>169430</td>\n",
       "      <td>436201</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154262</th>\n",
       "      <td>107583</td>\n",
       "      <td>335113</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92987</th>\n",
       "      <td>133174</td>\n",
       "      <td>141443</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23908</th>\n",
       "      <td>160974</td>\n",
       "      <td>43104</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  recipe_id  rating\n",
       "128079   560491      33671       5\n",
       "10492    169430     436201       5\n",
       "154262   107583     335113       5\n",
       "92987    133174     141443       5\n",
       "23908    160974      43104       5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_frequent_reviewers(df: pd.DataFrame, min_nr_reviews: int = 50, min_rating: int = 3):\n",
    "    \"\"\"\n",
    "    Select users with at least min_nr_reviews reviews with a rating larger than min_rating.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select only positive reviews\n",
    "    df_positive = df.copy().loc[df[\"rating\"] >= min_rating]\n",
    "\n",
    "    # Select users with more than min_nr_reviews positive reviews\n",
    "    user_review_count = df_positive.groupby(by=[\"user_id\"])[\"recipe_id\"].count()\n",
    "    test_users_list = list(user_review_count[user_review_count > min_nr_reviews].index)\n",
    "\n",
    "    # Select ratings from users specified above\n",
    "    df_restrict = df_positive.loc[df_positive[\"user_id\"].isin(test_users_list)]\n",
    "    \n",
    "    return df_restrict\n",
    "\n",
    "data_val_final = select_frequent_reviewers(data_val)\n",
    "data_val_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a list of validation data user ids for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are validating recommendations with 73 users.\n",
      "user_ids: [4470, 5060, 8688, 9869, 17803, 29782, 37449, 37779, 39835, 41578, 47559, 50969, 52543, 53932, 58104, 80353, 88099, 89831, 95743, 101823, 104295, 107135, 107583, 126440, 128473, 131126, 133174, 136997, 140132, 145352, 149363, 157425, 158086, 160974, 166642, 169430, 169969, 173579, 174096, 176615, 179133, 197023, 198154, 199848, 204024, 222564, 226066, 226863, 280271, 286566, 296809, 305531, 324390, 369715, 383346, 386585, 400708, 424680, 428885, 452355, 452940, 461834, 482376, 486725, 498271, 542159, 560491, 632249, 653438, 679953, 844554, 1072593, 1179225]\n"
     ]
    }
   ],
   "source": [
    "users_val = sorted(data_val_final[\"user_id\"].unique())\n",
    "print(f\"We are validating recommendations with {len(users_val)} users.\")\n",
    "print('user_ids:', users_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that even though we selected 40% of the data to be used for validation, are left with a tiny number of users to validate our results. The validation data is too small to have an accurate evaluation of the models. With more data and a more robust cross-validation method this shouldn't be a problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Create the validation \n",
    "\n",
    "We will now find the 50 best rated recipes for each of the 73 selected users. This will be our ground truth for comparing the predictions. The result is a dataframe with a row for each user where the recipe ids are ordered according to the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4470</td>\n",
       "      <td>65020</td>\n",
       "      <td>76661</td>\n",
       "      <td>17326</td>\n",
       "      <td>336760</td>\n",
       "      <td>30004</td>\n",
       "      <td>231677</td>\n",
       "      <td>66191</td>\n",
       "      <td>146160</td>\n",
       "      <td>79353</td>\n",
       "      <td>...</td>\n",
       "      <td>26942</td>\n",
       "      <td>33570</td>\n",
       "      <td>22267</td>\n",
       "      <td>252288</td>\n",
       "      <td>64698</td>\n",
       "      <td>25800</td>\n",
       "      <td>68491</td>\n",
       "      <td>52275</td>\n",
       "      <td>31713</td>\n",
       "      <td>180609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5060</td>\n",
       "      <td>93190</td>\n",
       "      <td>189415</td>\n",
       "      <td>83770</td>\n",
       "      <td>211506</td>\n",
       "      <td>103345</td>\n",
       "      <td>208092</td>\n",
       "      <td>16761</td>\n",
       "      <td>43588</td>\n",
       "      <td>11357</td>\n",
       "      <td>...</td>\n",
       "      <td>256418</td>\n",
       "      <td>86936</td>\n",
       "      <td>316609</td>\n",
       "      <td>22739</td>\n",
       "      <td>65077</td>\n",
       "      <td>127858</td>\n",
       "      <td>57177</td>\n",
       "      <td>23034</td>\n",
       "      <td>27760</td>\n",
       "      <td>12794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8688</td>\n",
       "      <td>133548</td>\n",
       "      <td>107636</td>\n",
       "      <td>218341</td>\n",
       "      <td>226188</td>\n",
       "      <td>15509</td>\n",
       "      <td>25806</td>\n",
       "      <td>247633</td>\n",
       "      <td>51757</td>\n",
       "      <td>214533</td>\n",
       "      <td>...</td>\n",
       "      <td>17566</td>\n",
       "      <td>185498</td>\n",
       "      <td>55768</td>\n",
       "      <td>29210</td>\n",
       "      <td>29544</td>\n",
       "      <td>166111</td>\n",
       "      <td>39072</td>\n",
       "      <td>52646</td>\n",
       "      <td>50022</td>\n",
       "      <td>49942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9869</td>\n",
       "      <td>34853</td>\n",
       "      <td>21349</td>\n",
       "      <td>13982</td>\n",
       "      <td>194664</td>\n",
       "      <td>28440</td>\n",
       "      <td>95007</td>\n",
       "      <td>47616</td>\n",
       "      <td>152072</td>\n",
       "      <td>12787</td>\n",
       "      <td>...</td>\n",
       "      <td>48217</td>\n",
       "      <td>44572</td>\n",
       "      <td>12354</td>\n",
       "      <td>31482</td>\n",
       "      <td>31710</td>\n",
       "      <td>25519</td>\n",
       "      <td>189655</td>\n",
       "      <td>10367</td>\n",
       "      <td>59510</td>\n",
       "      <td>24019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17803</td>\n",
       "      <td>272643</td>\n",
       "      <td>304533</td>\n",
       "      <td>181004</td>\n",
       "      <td>3370</td>\n",
       "      <td>142253</td>\n",
       "      <td>430357</td>\n",
       "      <td>268736</td>\n",
       "      <td>153885</td>\n",
       "      <td>441222</td>\n",
       "      <td>...</td>\n",
       "      <td>107498</td>\n",
       "      <td>251389</td>\n",
       "      <td>112282</td>\n",
       "      <td>192869</td>\n",
       "      <td>211485</td>\n",
       "      <td>256044</td>\n",
       "      <td>305634</td>\n",
       "      <td>16961</td>\n",
       "      <td>121271</td>\n",
       "      <td>25556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0       1       2       3       4       5       6       7       8   \\\n",
       "0   4470   65020   76661   17326  336760   30004  231677   66191  146160   \n",
       "1   5060   93190  189415   83770  211506  103345  208092   16761   43588   \n",
       "2   8688  133548  107636  218341  226188   15509   25806  247633   51757   \n",
       "3   9869   34853   21349   13982  194664   28440   95007   47616  152072   \n",
       "4  17803  272643  304533  181004    3370  142253  430357  268736  153885   \n",
       "\n",
       "       9   ...      41      42      43      44      45      46      47     48  \\\n",
       "0   79353  ...   26942   33570   22267  252288   64698   25800   68491  52275   \n",
       "1   11357  ...  256418   86936  316609   22739   65077  127858   57177  23034   \n",
       "2  214533  ...   17566  185498   55768   29210   29544  166111   39072  52646   \n",
       "3   12787  ...   48217   44572   12354   31482   31710   25519  189655  10367   \n",
       "4  441222  ...  107498  251389  112282  192869  211485  256044  305634  16961   \n",
       "\n",
       "       49      50  \n",
       "0   31713  180609  \n",
       "1   27760   12794  \n",
       "2   50022   49942  \n",
       "3   59510   24019  \n",
       "4  121271   25556  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nr of recommendations per user\n",
    "k_top = 50\n",
    "\n",
    "def top_items_per_user(df: pd.DataFrame, user_col: str, rating_col:str, k_top: int = 50):\n",
    "    \"\"\"\n",
    "    Creates a ranking of k_top recipes according to rating for each user.\n",
    "    Does not take into account equal ratings.\n",
    "\n",
    "    Returns:\n",
    "        df_recommendations (pd.DataFrame): each row is a user, the first value is the user id,\n",
    "                                           followed by recipe ids sorted by rank\n",
    "    \"\"\"\n",
    "    df_sorted=df.copy().sort_values([user_col,rating_col],ascending=False)\n",
    "    df_k_top=df_sorted.groupby(user_col).tail(k_top)\n",
    "    df_k_top.loc[:,['rank']]=pd.Series(list(range(50,0,-1))*len(df_k_top[user_col].unique()),\n",
    "                                       index=df_k_top.index)\n",
    "\n",
    "    df_recommendations = df_k_top.pivot(index=user_col, columns=\"rank\", values=\"recipe_id\")\n",
    "    df_recommendations = df_recommendations.reset_index()\n",
    "    df_recommendations.columns = np.arange(len(df_recommendations.columns))\n",
    "    return df_recommendations\n",
    "\n",
    "val_recommendations = top_items_per_user(data_val_final, \"user_id\", \"rating\", k_top=k_top)\n",
    "val_recommendations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Save the validation\n",
    "\n",
    "Here we create a function to store recommendations into a `.csv` file and store our validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations were saved in file validation_recommendations.csv.\n"
     ]
    }
   ],
   "source": [
    "def save_recommendations(df: pd.DataFrame, file_name: str):\n",
    "    \"\"\"\n",
    "    Save recommendation dataframe as .csv.\n",
    "    \"\"\"\n",
    "    \n",
    "    file_path = os.path.join(\"data\", f\"{file_name}.csv\")\n",
    "    df.to_csv(file_path, index=False, header=False)\n",
    "    print(f\"Recommendations were saved in file {file_name}.csv.\")\n",
    "    \n",
    "save_recommendations(val_recommendations, \"validation_recommendations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the validation for comparing the results from any RS we will create, we can proceed to design the RS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Non-personalized recommendations\n",
    "\n",
    "For our non-personalized baseline, we'll select the most popular recipes from all the rated recipes. Our definition of most popular in this case will be the recipes that have the best score but are also rated more often. We will calculate the average score and the number of times a recipe was rated, sort the recipes, and select the 50 with the highest rating ordered by the number of times they were rated. We can directly find the most popular recipes without creating a rating matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154351, 515167, 55309, 487111, 18446, 24768, 69051, 104292, 153877, 20233, 87047, 497261, 29184, 36041, 110397, 114956, 495202, 61040, 61514, 57549, 474694, 11548, 50498, 51058, 98846, 112299, 496573, 109287, 157841, 191225, 55634, 66990, 82102, 105545, 190733, 269611, 272181, 284630, 518145, 37758, 73825, 100450, 146563, 163220, 209670, 228909, 13275, 50958, 74182, 94087]\n"
     ]
    }
   ],
   "source": [
    "def non_pers_reco_order(data: pd.DataFrame,\n",
    "                        item_col: str,\n",
    "                        rating_col:str,\n",
    "                        k_top: int = 50,\n",
    "                        aggregation: list() = [\"mean\", \"count\"]):\n",
    "    \"\"\"\n",
    "    Create an ordered list of non-personalized recommendations, from best rated to worst rated.\n",
    "    \"\"\"\n",
    "    non_pers_ratings = data.groupby(by=[item_col])[rating_col].agg(aggregation)\n",
    "    \n",
    "    #The resulting column names might be different than the specified with the aggregation parameter.\n",
    "    try:\n",
    "        non_pers_ratings = non_pers_ratings.sort_values(by=aggregation, ascending=False).head(k_top)\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "        print(\"Check if aggregation argument results in valid column names.\")\n",
    "        print(f\"aggregation = {aggregation}\\nrating columns = {non_pers_ratings.columns}\")\n",
    "        raise e\n",
    "        \n",
    "    non_pers_reco_list = non_pers_ratings.index.to_list()\n",
    "    return non_pers_reco_list\n",
    "\n",
    "\n",
    "non_pers_recommendations = non_pers_reco_order(data_train, \"recipe_id\", \"rating\", k_top=k_top)\n",
    "print(non_pers_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Output non-personalized solution\n",
    "\n",
    "Here we create recommendations for the specified users based on the non-personalized recommendations obtained above. Basically, we recommend the same to everyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_pers_reco_output(user_id_list:list, non_pers_reco_list:list):\n",
    "    \"\"\"\n",
    "    Creates a non-personalized recommendations dataframe for specified users.\n",
    "    \"\"\"\n",
    "    nr_test_users = len(user_id_list)\n",
    "    user_id_df = pd.DataFrame(user_id_list, columns = [\"user_id\"])\n",
    "    non_pers_reco_repeated =  pd.DataFrame(pd.DataFrame(non_pers_reco_list).T.values.repeat(nr_test_users, axis=0))\n",
    "    non_pers_reco_output = pd.concat([user_id_df, non_pers_reco_repeated], axis=1)\n",
    "    \n",
    "    # Reset columns numbering. Useful later.\n",
    "    non_pers_reco_output.columns = np.arange(len(non_pers_reco_output.columns))\n",
    "    \n",
    "    return non_pers_reco_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test for a couple of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>452355</td>\n",
       "      <td>154351</td>\n",
       "      <td>515167</td>\n",
       "      <td>55309</td>\n",
       "      <td>487111</td>\n",
       "      <td>18446</td>\n",
       "      <td>24768</td>\n",
       "      <td>69051</td>\n",
       "      <td>104292</td>\n",
       "      <td>153877</td>\n",
       "      <td>...</td>\n",
       "      <td>73825</td>\n",
       "      <td>100450</td>\n",
       "      <td>146563</td>\n",
       "      <td>163220</td>\n",
       "      <td>209670</td>\n",
       "      <td>228909</td>\n",
       "      <td>13275</td>\n",
       "      <td>50958</td>\n",
       "      <td>74182</td>\n",
       "      <td>94087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18540</td>\n",
       "      <td>154351</td>\n",
       "      <td>515167</td>\n",
       "      <td>55309</td>\n",
       "      <td>487111</td>\n",
       "      <td>18446</td>\n",
       "      <td>24768</td>\n",
       "      <td>69051</td>\n",
       "      <td>104292</td>\n",
       "      <td>153877</td>\n",
       "      <td>...</td>\n",
       "      <td>73825</td>\n",
       "      <td>100450</td>\n",
       "      <td>146563</td>\n",
       "      <td>163220</td>\n",
       "      <td>209670</td>\n",
       "      <td>228909</td>\n",
       "      <td>13275</td>\n",
       "      <td>50958</td>\n",
       "      <td>74182</td>\n",
       "      <td>94087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2743667</td>\n",
       "      <td>154351</td>\n",
       "      <td>515167</td>\n",
       "      <td>55309</td>\n",
       "      <td>487111</td>\n",
       "      <td>18446</td>\n",
       "      <td>24768</td>\n",
       "      <td>69051</td>\n",
       "      <td>104292</td>\n",
       "      <td>153877</td>\n",
       "      <td>...</td>\n",
       "      <td>73825</td>\n",
       "      <td>100450</td>\n",
       "      <td>146563</td>\n",
       "      <td>163220</td>\n",
       "      <td>209670</td>\n",
       "      <td>228909</td>\n",
       "      <td>13275</td>\n",
       "      <td>50958</td>\n",
       "      <td>74182</td>\n",
       "      <td>94087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2      3       4      5      6      7       8   \\\n",
       "0   452355  154351  515167  55309  487111  18446  24768  69051  104292   \n",
       "1    18540  154351  515167  55309  487111  18446  24768  69051  104292   \n",
       "2  2743667  154351  515167  55309  487111  18446  24768  69051  104292   \n",
       "\n",
       "       9   ...     41      42      43      44      45      46     47     48  \\\n",
       "0  153877  ...  73825  100450  146563  163220  209670  228909  13275  50958   \n",
       "1  153877  ...  73825  100450  146563  163220  209670  228909  13275  50958   \n",
       "2  153877  ...  73825  100450  146563  163220  209670  228909  13275  50958   \n",
       "\n",
       "      49     50  \n",
       "0  74182  94087  \n",
       "1  74182  94087  \n",
       "2  74182  94087  \n",
       "\n",
       "[3 rows x 51 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_pers_reco_output([452355, 18540, 2743667], non_pers_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created a recommendation dataframe in the format of our example output file. Each row represents a user, the first column is the user id and the remaining columns are the recommended recipe ids ordered and numbered from best recommended to least recommended. Now we will produce recommendations for the validation users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Non-personalized recommendations for validation data\n",
    "\n",
    "We just need to evoke the function `non_pers_reco_output` with the validation users and the non-personalized recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations were saved in file non_personalized_recommendations_VAL.csv.\n"
     ]
    }
   ],
   "source": [
    "non_pers_reco_solution_val = non_pers_reco_output(users_val, non_pers_recommendations)\n",
    "save_recommendations(non_pers_reco_solution_val, \"non_personalized_recommendations_VAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the most exciting part - how good are the recommendations? We will use the function `evaluate_solution` with the solution file name as the first argument and the ground-truth as the second argument to calculate map@50. The function returns the map@50 and in addition a list of average precisions for all the users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00583057274805967 [0.0, 0.0, 0.0, 0.0, 0.0, 0.03562696390944565, 0.0, 0.0088142028578581, 0.0, 0.0, 0.0, 0.0025295889000065026, 0.013664943211518364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02008194520266223, 0.0, 0.0, 0.014464943211518365, 0.013664943211518364, 0.0, 0.0, 0.014464943211518365, 0.0, 0.0, 0.15449250233994755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00649292283069572, 0.0, 0.027919893202374937, 0.0, 0.0, 0.024019526902008637, 0.0, 0.03562696390944565, 0.0025295889000065026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0020851444555620583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03562696390944565, 0.0, 0.0, 0.0, 0.0, 0.011440685987261138, 0.0, 0.0, 0.0, 0.0020851444555620583, 0.0]\n"
     ]
    }
   ],
   "source": [
    "## Second argument is the recommendation file to compare\n",
    "map50_val_np, map50_val_np_list = evaluate_solution('non_personalized_recommendations_VAL', 'validation_recommendations')\n",
    "print(map50_val_np, map50_val_np_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad baseline, we got at least some recommendations right!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collaborative recommendations with LightFM\n",
    "\n",
    "Now that we have a baseline model, we can try collaborative filtering. We are going to use [LightFM](https://making.lyst.com/lightfm/docs/home.html) which is a library implementing matrix factorization methods.\n",
    "\n",
    "Matrix factorization means that a matrix is expressed as a product of other matrices. We have used matrix factorization in dimension reduction methods in the NLP specialization. In the case of recommender systems, we look for a factorization of the ratings matrix. As the factorization permits to calculate the original matrix, it allows us to fill in the missing ratings that we want to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create the dataset\n",
    "We start by using the lightFM [Dataset](https://making.lyst.com/lightfm/docs/lightfm.data.html?highlight=dataset#lightfm.data.Dataset) function to create the user and item mapping that defines the vectorial space of the rating matrix. Note that we include all recipe ids, also from the val set because to be able to make predictions, we need to have all users in the same feature space. If a test user had different features (recipe ids in this case) than the training users, we wouldn't be able to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the alias lfmDataset() instead of the standard Dataset()\n",
    "# Used to distiguish between lightFM Dataset() and another Dataset() that we'll use later.\n",
    "# We are sorting the user and item ids just so that it's prettier.\n",
    "lfmdataset = lfmDataset()\n",
    "lfmdataset.fit(sorted(data_train['user_id'].unique()), sorted(data['recipe_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the vectorial space is defined as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 36,431, num_items 29,670.\n"
     ]
    }
   ],
   "source": [
    "num_users, num_items = lfmdataset.interactions_shape()\n",
    "print('Num users: {:,}, num_items {:,}.'.format(num_users, num_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mapping between external user IDs (the ones in our data) and the internal user IDs can be obtained with the method `.mapping()`. The same applies for items. The method returns a mapping for ids and features. In the case of collaborative recommenders, the ids are the features (so-called indicator features), so both mappings are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_map, user_feature_map, item_id_map, item_feature_map = lfmdataset.mapping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need the reverse mappings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id_map_reverse = {v: k for k, v in item_id_map.items()}\n",
    "user_id_map_reverse = {v: k for k, v in user_id_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the ratings matrix with the `build_interactions` method. The argument is an iterable of tuples of the form (user_id, item_id) or (user_id, item_id, weight) where weight is what we call rating.\n",
    "\n",
    "The method returns two COO matrices, the interactions and the weights matrices. The interactions matrix indicates which user-item pairs interacted, i.e. where we have existing ratings, so it's like the ratings matrix, but all nonzero entries are 1. The weights matrix is what we called the ratings matrix until now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<COOrdinate sparse matrix of dtype 'float32'\n",
       "\twith 92448 stored elements and shape (36431, 29670)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(interactions, weights) = lfmdataset.build_interactions((row for row in data_train.to_numpy()))\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Fit the model\n",
    "We now define the model that is going to predict the recommendations. The [lighFM](https://making.lyst.com/lightfm/docs/lightfm.html#lightfm) model learns the user representations in the item space that encode user preferences for items. The optimization proceeds via the stochastic gradient descent. We select the `warp` loss function as it is [recommended](https://making.lyst.com/lightfm/docs/lightfm.html#id2) for optimizing the top of the recommendations list (precision@k), which is our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfmodel = LightFM(loss='warp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model with our interactions and ratings data. As you can see, the syntax of LightFM is the same as for scikit-learn. We can choose to use just the interactions matrix or include also the sample weights. The interactions matrix already has a lot of information because users are more likely to interact with items they expect to like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7ff6d6815c40>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfmodel.fit(interactions, sample_weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Predictions\n",
    "After fitting come the predictions. The [predict](https://making.lyst.com/lightfm/docs/lightfm.html#lightfm.LightFM.predict) method calculates the rating of each item for the given users.\n",
    "\n",
    "If we are predicting for a user which the model has already seen and so is included in the ratings matrix, we need to supply the user id and the item ids for which we'd like the predictions.\n",
    "\n",
    "The predictions are done for a user-item pairs and this reflects also in the syntax of the `predict` method. If you want to predict for two users, you need to repeat the item ids. For example, the syntax for predicting items 7, 8, 9 for users 0 and 1 is `predict(user_ids=lfm.predict(user_ids=[0, 0, 0, 1, 1, 1], item_ids=[7, 8, 9, 7, 8, 9])`.\n",
    "\n",
    "Let's predict for the first user in the ratings matrix. This user has the internal user id 0. We can find the original user id with the reverse map dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1533"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_map_reverse[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we predict for this user and the first three items in the ratings matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.38904777, -1.1438911 , -1.3138323 ], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfmodel.predict(user_ids=0, item_ids=[0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted scores are not the ratings, they are just used to compare the items for the given user. The scores can also be negative. If we are predicting for several users, the scores cannot be compared between users, the ranking is calculated for each user separately.\n",
    " \n",
    "If we want to predict for all the items in the ratings matrix, we do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.38904777, -1.1438911 , -1.3138323 , ..., -1.234284  ,\n",
       "       -1.2034111 , -1.259371  ], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfmodel.predict(user_ids=0, item_ids=np.array(range(num_items)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have users which are not in the ratings matrix, we need to supply a csr matrix of user features. In our case, all the users from the final validation set are also in the train set, but let's imagine that we have such a user and their ratings just for the sake of the example.\n",
    "\n",
    "We're going to calculate predictions for the first user from the validation set with the id 4470. First we construct the matrix of user features - the ratings from the `data_val` dataframe for the given user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_id_ext=4470\n",
    "new_user_data=data_val[data_val.user_id==new_user_id_ext]\n",
    "# transform the item id to internal ids\n",
    "new_user_item_ids=new_user_data.recipe_id.map(item_id_map)\n",
    "# construct the item features matrix\n",
    "new_user_features=np.zeros(num_items)\n",
    "new_user_features[new_user_item_ids]=new_user_data.rating\n",
    "new_user_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we predict. We use 0 for the user id (or 0, 1, 2, ... if we have more new users) and we supply the use features. Like this, the model knows that this is a new user and not the existing user with the user id 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-285.96283, -281.7072 , -283.8933 , ..., -282.43283, -283.08655,\n",
       "       -279.35614], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_user_preds=lfmodel.predict(user_ids=0, item_ids=np.array(range(num_items)), user_features=csr_matrix(new_user_features))\n",
    "new_user_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that was the hypothetical situation of a new user, but this user actually exists, so we're going to get their predictions for real now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.4202138, -2.0770044, -2.2205834, ..., -2.217663 , -2.1790965,\n",
       "       -2.1855004], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_ext = 4470\n",
    "user_id_int = user_id_map[user_id_ext]\n",
    "collab_preds_4470 = lfmodel.predict(user_ids=user_id_int, item_ids=np.array(range(num_items)))\n",
    "collab_preds_4470"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the predictions, we need to select the best items. We sort the items by the predicted score and select the `k_top` best items. We also need to transform the item ids to external to compare them for our known validation set data.\n",
    "\n",
    "But, there's one more detail - we don't want to include items which the user already rated. We're going to set the scores for these predictions to null values, so they end up at the end of the array after sorting and we can remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107786, 129926, 26110, 150863, 63689, 92095, 28768, 97496, 66121, 106251, 200296, 27210, 8701, 52035, 3470, 33921, 150384, 37413, 8782, 63828, 52253, 30081, 80536, 51537, 79944, 205890, 44232, 54351, 66241, 44888, 42094, 35805, 1356, 25730, 42780, 102617, 9494, 78579, 55768, 10125, 32147, 29884, 13546, 13949, 52272, 155021, 101954, 155018, 36984, 125399]\n"
     ]
    }
   ],
   "source": [
    "k_top = 50\n",
    "\n",
    "# set scores for existing rating to NaN\n",
    "row = interactions.nonzero()[0] # row indices with existing ratings\n",
    "col = interactions.nonzero()[1] # col indices with existing ratings\n",
    "int_item_id = col[np.asarray(row==user_id_int).nonzero()]\n",
    "collab_preds_4470[int_item_id]=np.nan\n",
    "\n",
    "# sort and remove the NaNs\n",
    "collab_preds_4470_items = np.argsort(-collab_preds_4470)[:k_top]\n",
    "\n",
    "# convert item ids to external\n",
    "collab_preds_4470_items_ext=[item_id_map_reverse[i] for i in collab_preds_4470_items]\n",
    "print(collab_preds_4470_items_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now that we know how this works, we can recommended recipes for more users. We're going to ignore the users that exist only in the validation set and not in the train set because that is not likely to happen in real settings (but there is a function to construct user features for such cases in the utils file). \n",
    "\n",
    "We will distinguish two kinds of users - existing and new. Existing users have ratings and the model knows them, so we can make a prediction. New users don't have any ratings, so the best we can do is give them non-personalized recommendations. Here comes a rather long function to make collaborative predictions (which should have been split into more parts because, ehm, clean code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_collab_lfm(user_id: list, model, k_top=50, num_items=num_items):\n",
    "    \"\"\"\n",
    "    Makes collaborative predictions with the trained lightFM model for new users.\n",
    "    \"\"\"\n",
    "    # divide the users into existing and new, convert existing to internal ids\n",
    "    existing = [i for i in user_id if i in user_id_map.keys()]\n",
    "    new = [i for i in user_id if i not in user_id_map.keys()]\n",
    "\n",
    "    # make predictions for new users\n",
    "    df_new = non_pers_reco_output(new, non_pers_recommendations)\n",
    "    \n",
    "    # make predictions for existing users\n",
    "    existing_int = [user_id_map[i] for i in existing]\n",
    "    user_ids = [i for i in existing_int for j in range(num_items)]\n",
    "    item_ids = [i for j in existing_int for i in range(num_items)]\n",
    "    existing_preds=model.predict(user_ids, item_ids)\n",
    "\n",
    "    # set scores for existing ratings to NaN\n",
    "    existing_preds = existing_preds.reshape(len(existing_int),-1)\n",
    "    row = interactions.nonzero()[0] # row indices with existing ratings\n",
    "    col = interactions.nonzero()[1] # col indices with existing ratings\n",
    "    mask = np.isin(row, existing_int) # where the existing user ids are\n",
    "    # mapping from internal ids to rows in the prediction score array\n",
    "    user_score_row_map = dict(zip(existing_int,np.argsort(existing_int)))\n",
    "    row_mask = [user_score_row_map[i] for i in row[mask]]\n",
    "    existing_preds[row_mask, col[mask]] = np.nan\n",
    "    \n",
    "    # sort score and get k_top item ids\n",
    "    existing_preds_items = np.argsort(-existing_preds)[:,:k_top]\n",
    "   \n",
    "    # convert items ids to external\n",
    "    for i in range(existing_preds_items.shape[0]):\n",
    "        for j in range(existing_preds_items.shape[1]):\n",
    "            existing_preds_items[i,j]=item_id_map_reverse[existing_preds_items[i,j]]\n",
    "\n",
    "    df_existing = pd.DataFrame(existing_preds_items, index=existing).reset_index()\n",
    "\n",
    "    # test if dataframes with predictions exist\n",
    "    if df_new.shape[0]>0 and df_existing.shape[0]>0:\n",
    "        return pd.concat([df_existing, df_new])\n",
    "    elif df_new.shape[0]>0:\n",
    "        return df_new\n",
    "    elif df_existing.shape[0]>0:\n",
    "        return df_existing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, here are our predictions for the 73 users from the final validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4470</td>\n",
       "      <td>107786</td>\n",
       "      <td>129926</td>\n",
       "      <td>26110</td>\n",
       "      <td>150863</td>\n",
       "      <td>63689</td>\n",
       "      <td>92095</td>\n",
       "      <td>28768</td>\n",
       "      <td>97496</td>\n",
       "      <td>66121</td>\n",
       "      <td>...</td>\n",
       "      <td>32147</td>\n",
       "      <td>29884</td>\n",
       "      <td>13546</td>\n",
       "      <td>13949</td>\n",
       "      <td>52272</td>\n",
       "      <td>155021</td>\n",
       "      <td>101954</td>\n",
       "      <td>155018</td>\n",
       "      <td>36984</td>\n",
       "      <td>125399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5060</td>\n",
       "      <td>33671</td>\n",
       "      <td>68955</td>\n",
       "      <td>26110</td>\n",
       "      <td>63689</td>\n",
       "      <td>129926</td>\n",
       "      <td>66121</td>\n",
       "      <td>97496</td>\n",
       "      <td>87782</td>\n",
       "      <td>107786</td>\n",
       "      <td>...</td>\n",
       "      <td>29544</td>\n",
       "      <td>32147</td>\n",
       "      <td>78579</td>\n",
       "      <td>25730</td>\n",
       "      <td>13546</td>\n",
       "      <td>155018</td>\n",
       "      <td>55768</td>\n",
       "      <td>137530</td>\n",
       "      <td>125399</td>\n",
       "      <td>155021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8688</td>\n",
       "      <td>129926</td>\n",
       "      <td>68955</td>\n",
       "      <td>107786</td>\n",
       "      <td>97496</td>\n",
       "      <td>8739</td>\n",
       "      <td>28768</td>\n",
       "      <td>150863</td>\n",
       "      <td>52035</td>\n",
       "      <td>8701</td>\n",
       "      <td>...</td>\n",
       "      <td>78579</td>\n",
       "      <td>12591</td>\n",
       "      <td>18816</td>\n",
       "      <td>9494</td>\n",
       "      <td>24672</td>\n",
       "      <td>129598</td>\n",
       "      <td>155021</td>\n",
       "      <td>137530</td>\n",
       "      <td>108105</td>\n",
       "      <td>101954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9869</td>\n",
       "      <td>129926</td>\n",
       "      <td>26110</td>\n",
       "      <td>68955</td>\n",
       "      <td>28768</td>\n",
       "      <td>107786</td>\n",
       "      <td>97496</td>\n",
       "      <td>150863</td>\n",
       "      <td>87782</td>\n",
       "      <td>150384</td>\n",
       "      <td>...</td>\n",
       "      <td>12591</td>\n",
       "      <td>155018</td>\n",
       "      <td>55768</td>\n",
       "      <td>36984</td>\n",
       "      <td>52272</td>\n",
       "      <td>137530</td>\n",
       "      <td>125633</td>\n",
       "      <td>32147</td>\n",
       "      <td>25730</td>\n",
       "      <td>13949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17803</td>\n",
       "      <td>68955</td>\n",
       "      <td>66121</td>\n",
       "      <td>129926</td>\n",
       "      <td>150863</td>\n",
       "      <td>26110</td>\n",
       "      <td>33671</td>\n",
       "      <td>107786</td>\n",
       "      <td>97496</td>\n",
       "      <td>63689</td>\n",
       "      <td>...</td>\n",
       "      <td>13546</td>\n",
       "      <td>44232</td>\n",
       "      <td>30081</td>\n",
       "      <td>78579</td>\n",
       "      <td>11345</td>\n",
       "      <td>32147</td>\n",
       "      <td>101954</td>\n",
       "      <td>137530</td>\n",
       "      <td>102617</td>\n",
       "      <td>24672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       0       1       2       3       4      5       6      7  \\\n",
       "0   4470  107786  129926   26110  150863   63689  92095   28768  97496   \n",
       "1   5060   33671   68955   26110   63689  129926  66121   97496  87782   \n",
       "2   8688  129926   68955  107786   97496    8739  28768  150863  52035   \n",
       "3   9869  129926   26110   68955   28768  107786  97496  150863  87782   \n",
       "4  17803   68955   66121  129926  150863   26110  33671  107786  97496   \n",
       "\n",
       "        8  ...     40      41     42     43     44      45      46      47  \\\n",
       "0   66121  ...  32147   29884  13546  13949  52272  155021  101954  155018   \n",
       "1  107786  ...  29544   32147  78579  25730  13546  155018   55768  137530   \n",
       "2    8701  ...  78579   12591  18816   9494  24672  129598  155021  137530   \n",
       "3  150384  ...  12591  155018  55768  36984  52272  137530  125633   32147   \n",
       "4   63689  ...  13546   44232  30081  78579  11345   32147  101954  137530   \n",
       "\n",
       "       48      49  \n",
       "0   36984  125399  \n",
       "1  125399  155021  \n",
       "2  108105  101954  \n",
       "3   25730   13949  \n",
       "4  102617   24672  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collab_preds_val = predict_collab_lfm(user_id=users_val, model=lfmodel,\n",
    "                             k_top=50, num_items=num_items)\n",
    "collab_preds_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the results to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations were saved in file collaborative_recommendations_VAL.csv.\n"
     ]
    }
   ],
   "source": [
    "save_recommendations(collab_preds_val, 'collaborative_recommendations_VAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is looking better! The scores is higher and we got more items right. These are all collaborative recommendations btw, all users from the final validation set are in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04077638381762753 [0.04915179354174705, 0.05998410676658849, 0.0986452330329991, 0.05998410676658849, 0.0, 0.0, 0.033404741687223426, 0.07984007128984522, 0.06093734705760168, 0.03263374230103448, 0.08275106859134229, 0.002984134354551957, 0.026951116636123314, 0.01664907756607032, 0.0, 0.0, 0.029586559869041604, 0.033404741687223426, 0.10213907846813534, 0.026918872577090348, 0.0, 0.012895712442287594, 0.0, 0.09459937571091431, 0.02495286023534197, 0.052284630532342655, 0.0, 0.0, 0.12229914554594716, 0.09879830962444659, 0.0, 0.01707693267133391, 0.060529661304050214, 0.09320227651381513, 0.0, 0.004413245987860981, 0.02008194520266223, 0.10361484763168409, 0.0, 0.12943056633993105, 0.0882375124823047, 0.027919893202374937, 0.12946938862875335, 0.09493696700193047, 0.09430154686651032, 0.023619526902008636, 0.022369526902008635, 0.02107967547058127, 0.041893093908047414, 0.0, 0.025891135529192012, 0.0, 0.0012081632653061225, 0.08998410676658848, 0.0, 0.06992448472002294, 0.027584462649686343, 0.0, 0.06120893669856129, 0.0020851444555620583, 0.0, 0.05998410676658849, 0.0, 0.0, 0.0, 0.0, 0.0823553309424384, 0.07737899197818958, 0.09390954787640071, 0.0, 0.04033759068388895, 0.018538937923531583, 0.15231264513050793]\n"
     ]
    }
   ],
   "source": [
    "map50_val_collab, map50_val_collab_list = evaluate_solution('collaborative_recommendations_VAL', 'validation_recommendations')\n",
    "print(map50_val_collab, map50_val_collab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Content-based recommendations with lightFM\n",
    "\n",
    "We are now going to create recommendations that take into account also the recipes information. We will use a `lightFM` model and introduce the recipe information as item features. We will explore the recipe information, identify potentially useful features, and process some of them to use in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Exploring and cleaning recipe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bananas 4 ice cream  pie</td>\n",
       "      <td>70971</td>\n",
       "      <td>180</td>\n",
       "      <td>102353</td>\n",
       "      <td>2003-09-10</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[4270.8, 254.0, 1306.0, 111.0, 127.0, 431.0, 2...</td>\n",
       "      <td>8</td>\n",
       "      <td>['crumble cookies into a 9-inch pie plate , or...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['chocolate sandwich style cookies', 'chocolat...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beat this  banana bread</td>\n",
       "      <td>75452</td>\n",
       "      <td>70</td>\n",
       "      <td>15892</td>\n",
       "      <td>2003-11-04</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[2669.3, 160.0, 976.0, 107.0, 62.0, 310.0, 138.0]</td>\n",
       "      <td>12</td>\n",
       "      <td>['preheat oven to 350 degrees', 'butter two 9x...</td>\n",
       "      <td>from ann hodgman's</td>\n",
       "      <td>['sugar', 'unsalted butter', 'bananas', 'eggs'...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>better than sex  strawberries</td>\n",
       "      <td>42198</td>\n",
       "      <td>1460</td>\n",
       "      <td>41531</td>\n",
       "      <td>2002-10-03</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[734.1, 66.0, 199.0, 10.0, 10.0, 117.0, 28.0]</td>\n",
       "      <td>8</td>\n",
       "      <td>['crush vanilla wafers into fine crumbs and li...</td>\n",
       "      <td>simple but sexy. this was in my local newspape...</td>\n",
       "      <td>['vanilla wafers', 'butter', 'powdered sugar',...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>better then bush s  baked beans</td>\n",
       "      <td>67547</td>\n",
       "      <td>2970</td>\n",
       "      <td>85627</td>\n",
       "      <td>2003-07-26</td>\n",
       "      <td>['weeknight', 'time-to-make', 'course', 'main-...</td>\n",
       "      <td>[462.4, 28.0, 214.0, 69.0, 14.0, 29.0, 23.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['in a very large sauce pan cover the beans an...</td>\n",
       "      <td>i'd have to say that this is a labor of love d...</td>\n",
       "      <td>['great northern bean', 'chicken bouillon cube...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chinese  candy</td>\n",
       "      <td>23933</td>\n",
       "      <td>15</td>\n",
       "      <td>35268</td>\n",
       "      <td>2002-03-29</td>\n",
       "      <td>['15-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[232.7, 21.0, 77.0, 4.0, 6.0, 38.0, 8.0]</td>\n",
       "      <td>4</td>\n",
       "      <td>['melt butterscotch chips in heavy saucepan ov...</td>\n",
       "      <td>a little different, and oh so good. i include ...</td>\n",
       "      <td>['butterscotch chips', 'chinese noodles', 'sal...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name     id  minutes  contributor_id  \\\n",
       "0         bananas 4 ice cream  pie  70971      180          102353   \n",
       "1          beat this  banana bread  75452       70           15892   \n",
       "2    better than sex  strawberries  42198     1460           41531   \n",
       "3  better then bush s  baked beans  67547     2970           85627   \n",
       "4                   chinese  candy  23933       15           35268   \n",
       "\n",
       "    submitted                                               tags  \\\n",
       "0  2003-09-10  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "1  2003-11-04  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "2  2002-10-03  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "3  2003-07-26  ['weeknight', 'time-to-make', 'course', 'main-...   \n",
       "4  2002-03-29  ['15-minutes-or-less', 'time-to-make', 'course...   \n",
       "\n",
       "                                           nutrition  n_steps  \\\n",
       "0  [4270.8, 254.0, 1306.0, 111.0, 127.0, 431.0, 2...        8   \n",
       "1  [2669.3, 160.0, 976.0, 107.0, 62.0, 310.0, 138.0]       12   \n",
       "2      [734.1, 66.0, 199.0, 10.0, 10.0, 117.0, 28.0]        8   \n",
       "3       [462.4, 28.0, 214.0, 69.0, 14.0, 29.0, 23.0]        9   \n",
       "4           [232.7, 21.0, 77.0, 4.0, 6.0, 38.0, 8.0]        4   \n",
       "\n",
       "                                               steps  \\\n",
       "0  ['crumble cookies into a 9-inch pie plate , or...   \n",
       "1  ['preheat oven to 350 degrees', 'butter two 9x...   \n",
       "2  ['crush vanilla wafers into fine crumbs and li...   \n",
       "3  ['in a very large sauce pan cover the beans an...   \n",
       "4  ['melt butterscotch chips in heavy saucepan ov...   \n",
       "\n",
       "                                         description  \\\n",
       "0                                                NaN   \n",
       "1                                from ann hodgman's    \n",
       "2  simple but sexy. this was in my local newspape...   \n",
       "3  i'd have to say that this is a labor of love d...   \n",
       "4  a little different, and oh so good. i include ...   \n",
       "\n",
       "                                         ingredients  n_ingredients  \n",
       "0  ['chocolate sandwich style cookies', 'chocolat...              6  \n",
       "1  ['sugar', 'unsalted butter', 'bananas', 'eggs'...              9  \n",
       "2  ['vanilla wafers', 'butter', 'powdered sugar',...              7  \n",
       "3  ['great northern bean', 'chicken bouillon cube...             13  \n",
       "4  ['butterscotch chips', 'chinese noodles', 'sal...              3  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recipe information\n",
    "recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38636.000000</td>\n",
       "      <td>3.863600e+04</td>\n",
       "      <td>3.863600e+04</td>\n",
       "      <td>38636.000000</td>\n",
       "      <td>38636.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>193975.615980</td>\n",
       "      <td>5.569485e+04</td>\n",
       "      <td>4.374955e+06</td>\n",
       "      <td>9.603427</td>\n",
       "      <td>8.935630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>137631.486315</td>\n",
       "      <td>1.092531e+07</td>\n",
       "      <td>8.823688e+07</td>\n",
       "      <td>5.931588</td>\n",
       "      <td>3.722484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.700000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>76392.250000</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>4.653400e+04</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>168196.500000</td>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>1.338420e+05</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>295416.250000</td>\n",
       "      <td>6.500000e+01</td>\n",
       "      <td>3.305450e+05</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>537485.000000</td>\n",
       "      <td>2.147484e+09</td>\n",
       "      <td>2.002248e+09</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id       minutes  contributor_id       n_steps  \\\n",
       "count   38636.000000  3.863600e+04    3.863600e+04  38636.000000   \n",
       "mean   193975.615980  5.569485e+04    4.374955e+06      9.603427   \n",
       "std    137631.486315  1.092531e+07    8.823688e+07      5.931588   \n",
       "min        62.000000  0.000000e+00    2.700000e+01      1.000000   \n",
       "25%     76392.250000  2.000000e+01    4.653400e+04      6.000000   \n",
       "50%    168196.500000  3.800000e+01    1.338420e+05      8.000000   \n",
       "75%    295416.250000  6.500000e+01    3.305450e+05     12.000000   \n",
       "max    537485.000000  2.147484e+09    2.002248e+09    110.000000   \n",
       "\n",
       "       n_ingredients  \n",
       "count   38636.000000  \n",
       "mean        8.935630  \n",
       "std         3.722484  \n",
       "min         1.000000  \n",
       "25%         6.000000  \n",
       "50%         9.000000  \n",
       "75%        11.000000  \n",
       "max        43.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numeric summary\n",
    "recipes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears there are some interesting columns that we can use to characterize each recipe. For this example, we are going to use the columns `minutes`, `tags` and, `n_ingredients`. You are encouraged to use other features and different processing steps.\n",
    " \n",
    "The columns `minutes` and `n_ingredients` are going to be rescaled with the `StandardScaler()`. The column `tags` is going to be one-hot encoded. We will split it into several columns, each representing one tag. When a recipe has a specific tag, the value of the corresponding feature is given value 1. If the recipe does not have that tag, then the respective feature has value 0."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 Rescaling `minutes` and `n_ingredients`\n",
    "\n",
    "Before rescaling, notice that there is one recipe that takes 2147483647 minutes or around 4085 years!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>tags</th>\n",
       "      <th>nutrition</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>steps</th>\n",
       "      <th>description</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24259</th>\n",
       "      <td>no bake granola balls</td>\n",
       "      <td>261647</td>\n",
       "      <td>2147483647</td>\n",
       "      <td>464080</td>\n",
       "      <td>2007-10-26</td>\n",
       "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
       "      <td>[330.3, 23.0, 110.0, 4.0, 15.0, 24.0, 15.0]</td>\n",
       "      <td>9</td>\n",
       "      <td>['preheat the oven to 350 degrees', 'spread oa...</td>\n",
       "      <td>healthy snacks that kids (and grown ups) will ...</td>\n",
       "      <td>['rolled oats', 'unsweetened dried shredded co...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name      id     minutes  contributor_id   submitted  \\\n",
       "24259  no bake granola balls  261647  2147483647          464080  2007-10-26   \n",
       "\n",
       "                                                    tags  \\\n",
       "24259  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
       "\n",
       "                                         nutrition  n_steps  \\\n",
       "24259  [330.3, 23.0, 110.0, 4.0, 15.0, 24.0, 15.0]        9   \n",
       "\n",
       "                                                   steps  \\\n",
       "24259  ['preheat the oven to 350 degrees', 'spread oa...   \n",
       "\n",
       "                                             description  \\\n",
       "24259  healthy snacks that kids (and grown ups) will ...   \n",
       "\n",
       "                                             ingredients  n_ingredients  \n",
       "24259  ['rolled oats', 'unsweetened dried shredded co...              8  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes.loc[recipes[\"minutes\"] == recipes[\"minutes\"].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly a mistake. To simplify, we are going to remove this recipe manually to prevent the outlier to disrupt the rescaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>n_ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70971</td>\n",
       "      <td>0.040799</td>\n",
       "      <td>-0.788628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75452</td>\n",
       "      <td>-0.025590</td>\n",
       "      <td>0.017286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42198</td>\n",
       "      <td>0.813321</td>\n",
       "      <td>-0.519990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67547</td>\n",
       "      <td>1.724656</td>\n",
       "      <td>1.091838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23933</td>\n",
       "      <td>-0.058784</td>\n",
       "      <td>-1.594542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   minutes  n_ingredients\n",
       "0  70971  0.040799      -0.788628\n",
       "1  75452 -0.025590       0.017286\n",
       "2  42198  0.813321      -0.519990\n",
       "3  67547  1.724656       1.091838\n",
       "4  23933 -0.058784      -1.594542"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_rescale = recipes.copy()\n",
    "\n",
    "recipes_rescale = recipes_rescale[[\"id\",\"minutes\", \"n_ingredients\"]]\n",
    "\n",
    "# remove outlier\n",
    "recipes_rescale = recipes_rescale.loc[recipes[\"minutes\"] < recipes[\"minutes\"].max()]\n",
    "\n",
    "min_max_scaler = StandardScaler()\n",
    "recipes_rescale[[\"minutes\", \"n_ingredients\"]] = min_max_scaler.fit_transform(recipes_rescale[[\"minutes\", \"n_ingredients\"]])\n",
    "recipes_rescale.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 Encoding `tags`\n",
    "\n",
    "As explained before, the `tags` column is going to be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th>1-day-or-more</th>\n",
       "      <th>15-minutes-or-less</th>\n",
       "      <th>3-steps-or-less</th>\n",
       "      <th>30-minutes-or-less</th>\n",
       "      <th>4-hours-or-less</th>\n",
       "      <th>5-ingredients-or-less</th>\n",
       "      <th>60-minutes-or-less</th>\n",
       "      <th>a1-sauce</th>\n",
       "      <th>...</th>\n",
       "      <th>whitefish</th>\n",
       "      <th>whole-chicken</th>\n",
       "      <th>whole-duck</th>\n",
       "      <th>whole-turkey</th>\n",
       "      <th>wild-game</th>\n",
       "      <th>wings</th>\n",
       "      <th>winter</th>\n",
       "      <th>yams-sweet-potatoes</th>\n",
       "      <th>yeast</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42198</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67547</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23933</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 496 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     1-day-or-more  15-minutes-or-less  3-steps-or-less  \\\n",
       "0  70971  0              0                   0                0   \n",
       "1  75452  0              0                   0                0   \n",
       "2  42198  0              1                   0                0   \n",
       "3  67547  0              1                   0                0   \n",
       "4  23933  0              0                   1                0   \n",
       "\n",
       "   30-minutes-or-less  4-hours-or-less  5-ingredients-or-less  \\\n",
       "0                   0                1                      0   \n",
       "1                   0                1                      0   \n",
       "2                   0                0                      0   \n",
       "3                   0                0                      0   \n",
       "4                   0                0                      1   \n",
       "\n",
       "   60-minutes-or-less  a1-sauce  ...  whitefish  whole-chicken  whole-duck  \\\n",
       "0                   0         0  ...          0              0           0   \n",
       "1                   0         0  ...          0              0           0   \n",
       "2                   0         0  ...          0              0           0   \n",
       "3                   0         0  ...          0              0           0   \n",
       "4                   0         0  ...          0              0           0   \n",
       "\n",
       "   whole-turkey  wild-game  wings  winter  yams-sweet-potatoes  yeast  \\\n",
       "0             0          0      0       0                    0      0   \n",
       "1             0          0      0       0                    0      0   \n",
       "2             0          0      0       0                    0      0   \n",
       "3             0          0      0       0                    0      0   \n",
       "4             0          0      0       0                    0      0   \n",
       "\n",
       "   zucchini  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 496 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes_encoding = recipes.copy()\n",
    "# convert string of list of strings into list of strings\n",
    "recipes_encoding[\"tags\"] = recipes_encoding[\"tags\"].apply(eval)\n",
    "# split each value from list into its own column, one-hot encoding style\n",
    "tags_exploded = recipes_encoding['tags'].explode()\n",
    "recipes_encoding = recipes_encoding[['id']].join(pd.crosstab(tags_exploded.index, tags_exploded))\n",
    "recipes_encoding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3 Considerations on tags that appear only once.\n",
    "\n",
    "There are tags that only appear in a single recipe. These tags won't help us connect similar recipes so they are useless for content-based recommendations. Of course, with time, more recipes may have these tags and the model then could be retrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "college                             1\n",
       "beef-kidney                         1\n",
       "pot-pie                             1\n",
       "pickeral                            1\n",
       "chinese-new-year                    1\n",
       "octopus                             1\n",
       "bear                                1\n",
       "stews-poultry                       1\n",
       "april-fools-day                     1\n",
       "irish-st-patricks-day               1\n",
       "laotian                             1\n",
       "georgian                            1\n",
       "mongolian                           1\n",
       "quail                               2\n",
       "congolese                           2\n",
       "angolan                             2\n",
       "goose                               2\n",
       "halloween-cakes                     2\n",
       "fillings-and-frostings-chocolate    2\n",
       "pasta-elbow-macaroni                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some examples of tags that only appear on one recipe\n",
    "pd.Series(recipes_encoding.drop(columns=[\"id\"]).sum()).sort_values()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will filter out the tags associated with a single recipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_encoding = recipes_encoding[recipes_encoding.columns[recipes_encoding.sum()>1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.4 Joining features\n",
    "We will join all newly create recipe feature into one dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>minutes</th>\n",
       "      <th>n_ingredients</th>\n",
       "      <th></th>\n",
       "      <th>1-day-or-more</th>\n",
       "      <th>15-minutes-or-less</th>\n",
       "      <th>3-steps-or-less</th>\n",
       "      <th>30-minutes-or-less</th>\n",
       "      <th>4-hours-or-less</th>\n",
       "      <th>5-ingredients-or-less</th>\n",
       "      <th>...</th>\n",
       "      <th>whitefish</th>\n",
       "      <th>whole-chicken</th>\n",
       "      <th>whole-duck</th>\n",
       "      <th>whole-turkey</th>\n",
       "      <th>wild-game</th>\n",
       "      <th>wings</th>\n",
       "      <th>winter</th>\n",
       "      <th>yams-sweet-potatoes</th>\n",
       "      <th>yeast</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70971</td>\n",
       "      <td>0.040799</td>\n",
       "      <td>-0.788628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75452</td>\n",
       "      <td>-0.025590</td>\n",
       "      <td>0.017286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42198</td>\n",
       "      <td>0.813321</td>\n",
       "      <td>-0.519990</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67547</td>\n",
       "      <td>1.724656</td>\n",
       "      <td>1.091838</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23933</td>\n",
       "      <td>-0.058784</td>\n",
       "      <td>-1.594542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 485 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id   minutes  n_ingredients     1-day-or-more  15-minutes-or-less  \\\n",
       "0  70971  0.040799      -0.788628  0              0                   0   \n",
       "1  75452 -0.025590       0.017286  0              0                   0   \n",
       "2  42198  0.813321      -0.519990  0              1                   0   \n",
       "3  67547  1.724656       1.091838  0              1                   0   \n",
       "4  23933 -0.058784      -1.594542  0              0                   1   \n",
       "\n",
       "   3-steps-or-less  30-minutes-or-less  4-hours-or-less  \\\n",
       "0                0                   0                1   \n",
       "1                0                   0                1   \n",
       "2                0                   0                0   \n",
       "3                0                   0                0   \n",
       "4                0                   0                0   \n",
       "\n",
       "   5-ingredients-or-less  ...  whitefish  whole-chicken  whole-duck  \\\n",
       "0                      0  ...          0              0           0   \n",
       "1                      0  ...          0              0           0   \n",
       "2                      0  ...          0              0           0   \n",
       "3                      0  ...          0              0           0   \n",
       "4                      1  ...          0              0           0   \n",
       "\n",
       "   whole-turkey  wild-game  wings  winter  yams-sweet-potatoes  yeast  \\\n",
       "0             0          0      0       0                    0      0   \n",
       "1             0          0      0       0                    0      0   \n",
       "2             0          0      0       0                    0      0   \n",
       "3             0          0      0       0                    0      0   \n",
       "4             0          0      0       0                    0      0   \n",
       "\n",
       "   zucchini  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 485 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_features_df = recipes_rescale.merge(recipes_encoding, on=\"id\")\n",
    "recipe_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.5 Formating recipe features\n",
    "\n",
    "In this step, we format the recipe features dataframe so that we can feed in into the `lightFM` model. We define `id` as the index and rename the columns to a sequence of integers formatted as strings. We do this because `lightFM` does not deal well with some of the characters in the column names. Since identifying the features is not important for us at the moment, we don't care too much about their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>474</th>\n",
       "      <th>475</th>\n",
       "      <th>476</th>\n",
       "      <th>477</th>\n",
       "      <th>478</th>\n",
       "      <th>479</th>\n",
       "      <th>480</th>\n",
       "      <th>481</th>\n",
       "      <th>482</th>\n",
       "      <th>483</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70971</th>\n",
       "      <td>0.040799</td>\n",
       "      <td>-0.788628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75452</th>\n",
       "      <td>-0.025590</td>\n",
       "      <td>0.017286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42198</th>\n",
       "      <td>0.813321</td>\n",
       "      <td>-0.519990</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67547</th>\n",
       "      <td>1.724656</td>\n",
       "      <td>1.091838</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23933</th>\n",
       "      <td>-0.058784</td>\n",
       "      <td>-1.594542</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1  2  3  4  5  6  7  8  9  ...  474  475  476  477  \\\n",
       "id                                                 ...                       \n",
       "70971  0.040799 -0.788628  0  0  0  0  0  1  0  0  ...    0    0    0    0   \n",
       "75452 -0.025590  0.017286  0  0  0  0  0  1  0  0  ...    0    0    0    0   \n",
       "42198  0.813321 -0.519990  0  1  0  0  0  0  0  0  ...    0    0    0    0   \n",
       "67547  1.724656  1.091838  0  1  0  0  0  0  0  0  ...    0    0    0    0   \n",
       "23933 -0.058784 -1.594542  0  0  1  0  0  0  1  0  ...    0    0    0    0   \n",
       "\n",
       "       478  479  480  481  482  483  \n",
       "id                                   \n",
       "70971    0    0    0    0    0    0  \n",
       "75452    0    0    0    0    0    0  \n",
       "42198    0    0    0    0    0    0  \n",
       "67547    0    0    0    0    0    0  \n",
       "23933    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 484 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_features_df = recipe_features_df.set_index(\"id\", drop=True)\n",
    "recipe_features_df.columns = [str(i) for i in range(len(recipe_features_df.columns))]\n",
    "recipe_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Content-based recommendations\n",
    "We will now replicate the steps performed for the collaborative filtering with some additions: \n",
    "\n",
    "1. include `item_features` while fitting the dataset.\n",
    "2. create a new object (`item_features`) that will store the item features.\n",
    "3. include the new `item features` while fitting the model.\n",
    "\n",
    "To create the item features, we will use the method [build_item_features](https://making.lyst.com/lightfm/docs/lightfm.data.html?highlight=build_item_features#lightfm.data.Dataset.build_item_features) with an iterable of form `(item id, {feature name: feature weight})`. We can create such an iterable with the dataframe method [itertuples](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples). It will return a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recipe_generator = recipe_features_df.itertuples(index=True, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we include all recipes in creating the dataset, from both the train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_dataset = lfmDataset()\n",
    "content_dataset.fit(sorted(data_train['user_id'].unique()), sorted(data['recipe_id'].unique()),\n",
    "                    item_features=recipe_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = content_dataset.build_item_features(recipe_generator)\n",
    "(interactions, weights) = content_dataset.build_interactions((row for row in data_train.to_numpy()))\n",
    "user_id_map, user_feature_map, item_id_map, item_feature_map = content_dataset.mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7ff6d68142f0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_model = LightFM(loss='warp')\n",
    "content_model.fit(interactions, sample_weight=weights, item_features=item_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset is prepared and the model is fitted, we can make predictions. In the predict step, we will include the item features. These are the predictions for the first user of the validation set. We did the same predictions with the collaborative model in section 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.0811977, -2.0701058, -2.1361632, ..., -2.1344864, -2.1688569,\n",
       "       -2.230037 ], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_ext = 4470\n",
    "user_id_int = user_id_map[user_id_ext]\n",
    "content_preds_4470 = content_model.predict(user_ids=user_id_int, item_ids=np.array(range(num_items)), \n",
    "                              item_features=item_features)\n",
    "content_preds_4470"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we remove the already rated items and select the best ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106251, 150863, 66121, 8701, 63689, 26110, 97496, 129926, 28768, 92095, 200296, 27210, 107786, 150384, 1356, 80536, 33921, 37413, 52035, 54351, 42780, 52253, 63828, 55768, 29884, 35805, 44888, 3470, 11107, 42094, 66241, 30081, 8782, 10125, 79944, 108105, 105594, 205890, 9494, 51537, 44232, 25730, 29493, 208583, 13546, 107072, 52272, 24672, 27221, 129598]\n"
     ]
    }
   ],
   "source": [
    "k_top = 50\n",
    "\n",
    "# set scores for existing rating to NaN\n",
    "row = interactions.nonzero()[0] # row indices with existing ratings\n",
    "col = interactions.nonzero()[1] # col indices with existing ratings\n",
    "int_item_id = col[np.asarray(row==user_id_int).nonzero()]\n",
    "content_preds_4470[int_item_id]=np.nan\n",
    "\n",
    "# sort and remove the NaNs\n",
    "content_preds_4470_items = np.argsort(-content_preds_4470)[:k_top]\n",
    "\n",
    "# convert item ids to external\n",
    "content_preds_4470_items_ext=[item_id_map_reverse[i] for i in content_preds_4470_items]\n",
    "print(content_preds_4470_items_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a nice (long) function again. It's basically the same as for the collaborative recommendations, we just include the item features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_content_lfm(user_id: list, item_features: csr_matrix, model, \n",
    "                        k_top=50, num_items=num_items):\n",
    "    \"\"\"\n",
    "    Makes content-based predictions with the trained lightFM model for new users.\n",
    "    \"\"\"\n",
    "    # divide the users into existing and new, convert existing to internal ids\n",
    "    existing = [i for i in user_id if i in user_id_map.keys()]\n",
    "    new = [i for i in user_id if i not in user_id_map.keys()]\n",
    "\n",
    "    # make predictions for new users\n",
    "    df_new = non_pers_reco_output(new, non_pers_recommendations)\n",
    "    \n",
    "    # make predictions for existing users\n",
    "    existing_int = [user_id_map[i] for i in existing]\n",
    "    user_ids = [i for i in existing_int for j in range(num_items)]\n",
    "    item_ids = [i for j in existing_int for i in range(num_items)]\n",
    "    existing_preds=model.predict(user_ids, item_ids, item_features=item_features)\n",
    "\n",
    "    # set scores for existing ratings to NaN\n",
    "    existing_preds = existing_preds.reshape(len(existing_int),-1)\n",
    "    row = interactions.nonzero()[0] # row indices with existing ratings\n",
    "    col = interactions.nonzero()[1] # col indices with existing ratings\n",
    "    mask = np.isin(row, existing_int) # where the existing user ids are\n",
    "    # mapping from internal ids to rows in the prediction score array\n",
    "    user_score_row_map = dict(zip(existing_int,np.argsort(existing_int)))\n",
    "    row_mask = [user_score_row_map[i] for i in row[mask]]\n",
    "    existing_preds[row_mask, col[mask]] = np.nan\n",
    "    \n",
    "    # sort score and get k_top item ids\n",
    "    existing_preds_items = np.argsort(-existing_preds)[:,:k_top]\n",
    "   \n",
    "    # convert items ids to external\n",
    "    for i in range(existing_preds_items.shape[0]):\n",
    "        for j in range(existing_preds_items.shape[1]):\n",
    "            existing_preds_items[i,j]=item_id_map_reverse[existing_preds_items[i,j]]\n",
    "\n",
    "    df_existing = pd.DataFrame(existing_preds_items, index=existing).reset_index()\n",
    "\n",
    "    # test if dataframes with predictions exist\n",
    "    if df_new.shape[0]>0 and df_existing.shape[0]>0:\n",
    "        return pd.concat([df_existing, df_new])\n",
    "    elif df_new.shape[0]>0:\n",
    "        return df_new\n",
    "    elif df_existing.shape[0]>0:\n",
    "        return df_existing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we predict content-based recommendations for the validation set and save the result to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_preds_val = predict_content_lfm(user_id=users_val, item_features=item_features, model=content_model, \n",
    "                        k_top=50, num_items=num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations were saved in file content_recommendations_VAL.csv.\n"
     ]
    }
   ],
   "source": [
    "save_recommendations(content_preds_val, \"content_recommendations_VAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision went slightly up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043636944629536746 [0.07041926690122312, 0.044317440099921834, 0.1679967284653638, 0.08998410676658848, 0.0, 0.0, 0.03812696390944565, 0.07901342039030336, 0.05536591848617311, 0.03011244973270436, 0.06964910861714281, 0.012154971701546856, 0.03529761484555385, 0.013664943211518364, 0.0, 0.0, 0.02495286023534197, 0.05998410676658849, 0.10447064388386432, 0.026918872577090348, 0.0, 0.011440685987261138, 0.0, 0.11359660457395593, 0.048317440099921824, 0.06417137207504395, 0.0, 0.0, 0.10245533798423341, 0.1069327451583066, 0.0, 0.012154971701546856, 0.06128733034886896, 0.09261063527862508, 0.0, 0.002984134354551957, 0.01008436414818068, 0.1280099908579135, 0.0, 0.06674418589865588, 0.10704321658212644, 0.0409841067665885, 0.16839752715689188, 0.07134675372363669, 0.10591843735381841, 0.02495286023534197, 0.023619526902008636, 0.06489735275444948, 0.058873258168796384, 0.0, 0.03269425683523323, 0.0, 0.0, 0.0916344686134549, 0.0, 0.04817478204749417, 0.038059300045499796, 0.0, 0.07038410676658849, 0.0, 0.0, 0.048317440099921824, 0.0, 0.0, 0.0, 0.0, 0.07832469927155328, 0.07594908156062016, 0.08998410676658848, 0.0, 0.054026195504009264, 0.015077278777691867, 0.13361898696643215]\n"
     ]
    }
   ],
   "source": [
    "map50_val_content, map50_val_content_list = evaluate_solution('content_recommendations_VAL',\n",
    "                                                              'validation_recommendations')\n",
    "print(map50_val_content, map50_val_content_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Collaborative recommendations with Surprise\n",
    "\n",
    "[Surprise](http://surpriselib.com/) is a [SciKit](https://projects.scipy.org/scikits.html), i.e. an add-on package for SciPy, that can be used to build recommender systems for explicit rating data. It uses different algorithms such as matrix factorization or neighborhood methods. It doesn't support content-based information though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Create the dataset\n",
    "We start by preparing the data and the [reader](https://surprise.readthedocs.io/en/stable/reader.html). These will be used by the method [load_from_df](https://surprise.readthedocs.io/en/stable/dataset.html#surprise.dataset.Dataset.load_from_df) to load the data into a dataset object. The dataframe to be loaded must have the columns `userID`, `itemID` and `rating`. Because of this, we need to rename our columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x7ff6d6817d40>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_surprise = data_train.copy().rename(columns={\"user_id\":\"userID\", \"recipe_id\":\"itemID\"})\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data_surprise = sDataset.load_from_df(data_train_surprise[['userID', 'itemID', 'rating']], reader)\n",
    "data_surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already split the data intro training and validation we will build the train set with the method `build_full_trainset()`. This method uses all the loaded data as the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = data_surprise.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the available surprise models is the [KNNBasic](https://surprise.readthedocs.io/en/stable/knn_inspired.html) model. This a basic collaborative filtering algorithm. We could say it's an improved version of the algorithm that we developed in BLU10. One issue with this model is that the similarity matrices generated while training the model are not sparse, but dense. This means that, even for moderately large datasets, the model will use gigabytes of memory which isn't feasible for most consumer PCs.\n",
    "\n",
    "As an alternative, will use the [SVD](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD) which is based on matrix factorization to approximate the rating matrix using lower dimensionality matrixes. [Here's](https://cs.carleton.edu/cs_comps/0607/recommend/recommender/svd.html) a brief summary of usage of SVD. Surprise's SVD uses stochastic gradient descent to minimize the error between the estimated rating matrix and the actual rating matrix during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7ff6d6b1dbb0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svdmodel = SVD(random_state=123)\n",
    "svdmodel.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Predict\n",
    "\n",
    "As was the case for lightFM, we need to provide the `.predict` method of the model with the user-item pair for which we want the predictions.\n",
    "\n",
    "The steps followed in the next cell are:\n",
    "\n",
    "1. Select the users for who we want to recommend\n",
    "2. Create 3 lists: one to place user ids, one to place item ids and another to place the respective rating. The lists are created empty with the size `nr. users * nr. items` to allocate all user/item combinations.\n",
    "3. For each user/item combination, make a prediction.\n",
    "4. Store the user id, item id, and the prediction in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first three users from the validation set\n",
    "users_surprise = users_val[:3]\n",
    "\n",
    "recipe_ids = sorted(data.recipe_id.unique())\n",
    "\n",
    "# length of the list for storing the predictions\n",
    "test_total_len = len(users_surprise) * len(recipe_ids)\n",
    "\n",
    "# create empty lists to avoid appending\n",
    "user_id_pred = [None] * test_total_len\n",
    "recipe_id_pred = [None] * test_total_len\n",
    "rating_pred = [None] * test_total_len\n",
    "\n",
    "# predict for each user\n",
    "index_counter = 0\n",
    "for user in users_surprise:\n",
    "    for recipe in recipe_ids:\n",
    "        \n",
    "        prediction = svdmodel.predict(user, recipe)\n",
    "        user_id_pred[index_counter] = prediction.uid\n",
    "        recipe_id_pred[index_counter] = prediction.iid\n",
    "        rating_pred[index_counter] = prediction.est\n",
    "        \n",
    "        index_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the lists above we can build a predictive rating dataframe to then select best 50 items per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recipe_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>4470</td>\n",
       "      <td>4.997062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136</td>\n",
       "      <td>4470</td>\n",
       "      <td>4.783294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142</td>\n",
       "      <td>4470</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>4470</td>\n",
       "      <td>4.867363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152</td>\n",
       "      <td>4470</td>\n",
       "      <td>4.922688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   recipe_id  user_id    rating\n",
       "0         62     4470  4.997062\n",
       "1        136     4470  4.783294\n",
       "2        142     4470  5.000000\n",
       "3        150     4470  4.867363\n",
       "4        152     4470  4.922688"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collab_preds_surprise = {'recipe_id': recipe_id_pred,\n",
    "                'user_id': user_id_pred,\n",
    "                'rating': rating_pred}\n",
    "collab_preds_surprise_df = pd.DataFrame(collab_preds_surprise)\n",
    "collab_preds_surprise_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the function that we defined earlier to select the best k recommendations for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4470</td>\n",
       "      <td>16272</td>\n",
       "      <td>407040</td>\n",
       "      <td>95414</td>\n",
       "      <td>168676</td>\n",
       "      <td>132263</td>\n",
       "      <td>97903</td>\n",
       "      <td>24072</td>\n",
       "      <td>53198</td>\n",
       "      <td>17524</td>\n",
       "      <td>...</td>\n",
       "      <td>158168</td>\n",
       "      <td>179336</td>\n",
       "      <td>464220</td>\n",
       "      <td>64811</td>\n",
       "      <td>187621</td>\n",
       "      <td>115335</td>\n",
       "      <td>25098</td>\n",
       "      <td>91248</td>\n",
       "      <td>378833</td>\n",
       "      <td>348190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5060</td>\n",
       "      <td>407040</td>\n",
       "      <td>132263</td>\n",
       "      <td>97903</td>\n",
       "      <td>17861</td>\n",
       "      <td>124103</td>\n",
       "      <td>17524</td>\n",
       "      <td>16272</td>\n",
       "      <td>184719</td>\n",
       "      <td>464220</td>\n",
       "      <td>...</td>\n",
       "      <td>312992</td>\n",
       "      <td>372087</td>\n",
       "      <td>197982</td>\n",
       "      <td>22227</td>\n",
       "      <td>292395</td>\n",
       "      <td>317846</td>\n",
       "      <td>35785</td>\n",
       "      <td>124176</td>\n",
       "      <td>83433</td>\n",
       "      <td>158168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8688</td>\n",
       "      <td>14927</td>\n",
       "      <td>132263</td>\n",
       "      <td>53198</td>\n",
       "      <td>95414</td>\n",
       "      <td>97903</td>\n",
       "      <td>168676</td>\n",
       "      <td>124103</td>\n",
       "      <td>88611</td>\n",
       "      <td>407040</td>\n",
       "      <td>...</td>\n",
       "      <td>184719</td>\n",
       "      <td>29439</td>\n",
       "      <td>321719</td>\n",
       "      <td>480137</td>\n",
       "      <td>158809</td>\n",
       "      <td>56070</td>\n",
       "      <td>149548</td>\n",
       "      <td>508302</td>\n",
       "      <td>74644</td>\n",
       "      <td>27079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0       1       2      3       4       5       6       7       8   \\\n",
       "0  4470   16272  407040  95414  168676  132263   97903   24072   53198   \n",
       "1  5060  407040  132263  97903   17861  124103   17524   16272  184719   \n",
       "2  8688   14927  132263  53198   95414   97903  168676  124103   88611   \n",
       "\n",
       "       9   ...      41      42      43      44      45      46      47  \\\n",
       "0   17524  ...  158168  179336  464220   64811  187621  115335   25098   \n",
       "1  464220  ...  312992  372087  197982   22227  292395  317846   35785   \n",
       "2  407040  ...  184719   29439  321719  480137  158809   56070  149548   \n",
       "\n",
       "       48      49      50  \n",
       "0   91248  378833  348190  \n",
       "1  124176   83433  158168  \n",
       "2  508302   74644   27079  \n",
       "\n",
       "[3 rows x 51 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_preds_val = top_items_per_user(collab_preds_surprise_df, \"user_id\", \"rating\")\n",
    "surprise_preds_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not make a prediction for the whole validation set because the code is not parallelized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model selection\n",
    "\n",
    "At the end of the day, we need to select the best model. We obtained the best score for the validation set with the content-based lightFM model, although it was just very slightly better than the collaborative model. Let's calculate map@50 also on the test set for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join('data', 'test_users.csv')\n",
    "users_test = list(pd.read_csv(test_path).user_id.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations were saved in file collaborative_recommendations_TEST.csv.\n",
      "2.9479495090297437e-05 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011440685987261138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0088142028578581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005952382290155179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "collab_preds_test = predict_collab_lfm(user_id=users_test, model=lfmodel,\n",
    "                             k_top=50, num_items=num_items)\n",
    "save_recommendations(collab_preds_test, 'collaborative_recommendations_TEST')\n",
    "map50_test_collab, map50_test_collab_list = evaluate_solution('collaborative_recommendations_TEST')\n",
    "print(map50_test_collab, map50_test_collab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations were saved in file content_recommendations_TEST.csv.\n",
      "3.153522890707132e-05 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002984134354551957, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012154971701546856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.012895712442287594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "content_preds_test = predict_content_lfm(user_id=users_test, item_features=item_features, model=content_model, \n",
    "                        k_top=50, num_items=num_items)\n",
    "save_recommendations(content_preds_test, 'content_recommendations_TEST')\n",
    "map50_test_content, map50_test_content_list = evaluate_solution('content_recommendations_TEST')\n",
    "print(map50_test_content, map50_test_content_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are much worse than in the validation set, it seems that we were not lucky this time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next steps\n",
    "\n",
    "We have successfully trained a couple of recommendation models to recommend recipes to our users! Both you and your boss are happy... \n",
    "\n",
    "If you'd like to improve your scores in the future, here are a couple of suggestions:\n",
    "\n",
    "- Cross-validation: Here we have used out-of-sample validation and selected the best model. Try to implement cross-validation using the module's own methods or create your own pipelines.\n",
    "\n",
    "- Hyperparameter tuning: We haven't performed any hyperparameter tuning in this workflow. Use hyperparameter tuning to explore more models and find better ones.\n",
    "\n",
    "- Other modules: Try to use other recommender systems modules to see if they are simpler to use, give better results or present other advantages. You can check [this GitHub repo](https://github.com/microsoft/recommenders) with a vast selection of recommender system modules with examples. Remember that you should try to understand how a model works before using it and what are its limitations.\n",
    " \n",
    "- More data: You can try, with this or another dataset, to gradually introduce data to the model to simulate new data streaming in. Make use of methods that allow to add new data to the fitted model (usually called someting like [fit_partial](https://making.lyst.com/lightfm/docs/lightfm.html#lightfm.LightFM.fit_partial)) or retrain the model with all the data.\n",
    "\n",
    "- Different data: Practice your modelling skills with other data sets. See what changes you need to carry out when the data has different properties.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you're at the end! The remaining notebook is just a skeleton of this workflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
