Abstract
Implementing existing federated learning massive Internet Things ( IoT ) network face critical challenge imbalanced statistically heterogeneous data device diversity . To end propose semi-federated learning ( SemiFL ) framework provide potential solution realization intelligent IoT . By seamlessly integrating centralized federated paradigm SemiFL framework show high scalability term number IoT device even presence computing-limited sensor . Furthermore compared traditional learning approach proposed SemiFL make better use distributed data computing resource due collaborative model training edge server local device . Simulation result show effectiveness SemiFL framework massive IoT network . The code found http : //github.com/niwanli/SemiFL_IoT .
We present accurate stereo matching method using local expansion move based graph cut . This new move-making scheme used efficiently infer per-pixel 3D plane label pairwise Markov random field ( MRF ) effectively combine recently proposed slanted patch matching curvature regularization term . The local expansion move presented many alpha-expansions defined small grid region . The local expansion move extend traditional expansion move two way : localization spatial propagation . By localization use different candidate alpha-labels according location local alpha-expansions . By spatial propagation design local alpha-expansions propagate currently assigned label nearby region . With localization spatial propagation method efficiently infer MRF model continuous label space using randomized search . Our method several advantage previous approach based fusion move belief propagation ; produce submodular move deriving subproblem optimality ; help find good smooth piecewise linear disparity map ; suitable parallelization ; use cost-volume filtering technique accelerating matching cost computation . Even using simple pairwise MRF method shown best performance Middlebury stereo benchmark V2 V3 .
In work present novel approach 3D layout recovery indoor environment using non-central acquisition system . From non-central panorama full scaled 3D line independently recovered geometry reasoning without geometric scale assumption . However sensitivity noise complex geometric modeling led panorama little investigated . Our new pipeline aim extract boundary structural line indoor environment neural network exploit property non-central projection system new geometrical processing recover scaled 3D layout . The result experiment show improve state-of-the-art method layout reconstruction line extraction non-central projection system . We completely solve problem Manhattan Atlanta environment handling occlusion retrieving metric scale room without extra measurement . As far author knowledge go approach first work using deep learning non-central panorama recovering scaled layout single panorama .
Real data often appear form multiple incomplete view . Incomplete multi-view clustering effective method integrate incomplete view . Previous method learn consistent information different view ignore unique information view limit clustering performance generalization . To overcome limitation propose novel View Variation View Heredity approach ( V3H ) . Inspired variation heredity genetics V3H first decomposes subspace variation matrix corresponding view heredity matrix view represent unique information consistent information respectively . Then aligning different view based cluster indicator matrix V3H integrates unique information different view improve clustering performance . Finally help adjustable low-rank representation based heredity matrix V3H recovers underlying true data structure reduce influence large incompleteness . More importantly V3H present possibly first work introduce genetics clustering algorithm learning simultaneously consistent information unique information incomplete multi-view data . Extensive experimental result fifteen benchmark datasets validate superiority state-of-the-arts .
This paper present tree-to-tree transduction method sentence compression . Our model based synchronous tree substitution grammar formalism allows local distortion tree topology thus naturally capture structural mismatch . We describe algorithm decoding framework show model trained discriminatively within large margin framework . Experimental result sentence compression bring significant improvement state-of-the-art model .
The process automatic generation road map GPS trajectory called map inference remains challenging task perform geospatial data variety domain majority existing study focus road map city . Inherently existing algorithm guaranteed work unusual geospatial site airport tarmac pedestrianized path shortcut animal migration route etc . Moreover deep learning explored well enough task . This paper introduces COLTRANE ConvolutiOnaL TRAjectory NEtwork novel deep map inference framework operates GPS trajectory collected various environment . This framework includes Iterated Trajectory Mean Shift ( ITMS ) module localize road centerline cope noisy GPS data point . Convolutional Neural Network trained novel trajectory descriptor introduced framework detect accurately classify junction refinement road map . COLTRANE yield 37 % improvement F1 score existing method two distinct real-world datasets : city road airport tarmac .
Modern data set healthcare e-commerce often derived many individual system insufficient data source alone separately estimate individual often high-dimensional model parameter . If shared structure among system however may possible leverage data system help estimate individual parameter could otherwise non-identifiable . In paper assume system share latent low-dimensional parameter space propose method recovering $ $ -dimensional parameter $ N $ different linear system even $ T < $ observation per system . To develop three-step algorithm estimate low-dimensional subspace spanned system ' parameter produce refined parameter estimate within subspace . We provide finite sample subspace estimation error guarantee proposed method . Finally experimentally validate method simulation i.i.d . regression data well correlated time series data .
Cognitive computing system require human labeled data evaluation often training . The standard practice used gathering data minimizes disagreement annotator found result data fails account ambiguity inherent language . We proposed CrowdTruth method collecting ground truth crowdsourcing reconsiders role people machine learning based observation disagreement annotator provides useful signal phenomenon ambiguity text . We report using method build annotated data set medical relation extraction $ cause $ $ treat $ relation data performed supervised training experiment . We demonstrate modeling ambiguity labeled data gathered crowd worker ( 1 ) reach level quality domain expert task reducing cost ( 2 ) provide better training data scale distant supervision . We propose validate new weighted measure precision recall F-measure account ambiguity human machine performance task .
State-of-the-art method attribute detection face almost always assume presence full unoccluded face . Hence performance degrades partially visible occluded face . In paper introduce SPLITFACE deep convolutional neural network-based method explicitly designed perform attribute detection partially occluded face . Taking several facial segment full face input proposed method take data driven approach determine attribute localized facial segment . The unique architecture network allows attribute predicted multiple segment permit implementation committee machine technique combining local global decision boost performance . With access segment-based prediction SPLITFACE predict well attribute localized visible part face without rely presence whole face . We use CelebA LFWA facial attribute datasets standard evaluation . We also modify datasets occlude face evaluate performance attribute detection algorithm partial face . Our evaluation show SPLITFACE significantly outperforms recent method especially partial face .
Learning 3D scene-based point cloud received extensive attention promising application many field well-annotated multisource datasets catalyze development data-driven approach . To facilitate research area present richly-annotated 3D point cloud dataset multiple outdoor scene understanding task also effective learning framework hierarchical segmentation task . The dataset generated via photogrammetric processing unmanned aerial vehicle ( UAV ) image National University Singapore ( NUS ) campus point-wisely annotated hierarchical instance-based label . Based formulate hierarchical learning problem 3D point cloud segmentation propose measurement evaluating consistency across various hierarchy . To solve problem two-stage method including multi-task ( MT ) learning hierarchical ensemble ( HE ) consistency consideration proposed . Experimental result demonstrate superiority proposed method potential advantage hierarchical annotation . In addition benchmark result semantic instance segmentation accessible online http : //3d.dataset.site dataset source code .
Recent advancement large language model ( LLMs ) facilitated development chatbots sophisticated conversational capability . However LLMs exhibit frequent inaccurate response query hindering application educational setting . In paper investigate effectiveness integrating knowledge base ( KB ) LLM intelligent tutor increase response reliability . To achieve design scaleable KB affords educational supervisor seamless integration lesson curriculum automatically processed intelligent tutoring system . We detail evaluation student participant presented question artificial intelligence curriculum respond . GPT-4 intelligent tutor varying hierarchy KB access human domain expert assessed response . Lastly student cross-examined intelligent tutor ' response domain expert ' ranked various pedagogical ability . Results suggest although intelligent tutor still demonstrate lower accuracy compared domain expert accuracy intelligent tutor increase access KB granted . We also observe intelligent tutor KB access exhibit better pedagogical ability speak like teacher understand student domain expert ability help student remains lagging behind domain expert .
Generative Artificial Intelligence ( AI ) integrated everyday technology including news education social medium . AI pervaded private conversation conversational partner auto-completion response suggestion . As social medium becomes young people 's main method peer support exchange need understand AI facilitate assist exchange beneficial safe socially appropriate way . We asked 622 young people complete online survey evaluate blinded human- AI-generated response help-seeking message . We found participant preferred AI-generated response situation relationship self-expression physical health . However addressing sensitive topic like suicidal thought young people preferred human response . We also discus role training online peer support exchange implication supporting young people 's well-being . Disclaimer : This paper includes sensitive topic including suicide ideation . Reader discretion advised .
In work evaluate various existing dialogue relevance metric find strong dependency dataset often poor correlation human score relevance propose modification reduce data requirement domain sensitivity improving correlation . Our proposed metric achieves state-of-the-art performance HUMOD dataset reducing measured sensitivity dataset 37 % -66 % . We achieve without fine-tuning pretrained language model using 3750 unannotated human dialogue single negative example . Despite limitation demonstrate competitive performance four datasets different domain . Our code including metric experiment open sourced .
This paper present new method shadow removal using unpaired data enabling u avoid tedious annotation obtain diverse training sample . However directly employing adversarial learning cycle-consistency constraint insufficient learn underlying relationship shadow shadow-free domain since mapping shadow shadow-free image simply one-to-one . To address problem formulate Mask-ShadowGAN new deep framework automatically learns produce shadow mask input shadow image take mask guide shadow generation via re-formulated cycle-consistency constraint . Particularly framework simultaneously learns produce shadow mask learns remove shadow maximize overall performance . Also prepared unpaired dataset shadow removal demonstrated effectiveness Mask-ShadowGAN various experiment even trained unpaired data .
Conditional human motion synthesis ( HMS ) aim generate human motion sequence conform specific condition . Text audio represent two predominant modality employed HMS control condition . While existing research primarily focused single condition multi-condition human motion synthesis remains underexplored . In study propose multi-condition HMS framework termed MCM based dual-branch structure composed main branch control branch . This framework effectively extends applicability diffusion model initially predicated solely textual condition auditory condition . This extension encompasses music-to-dance co-speech HMS preserving intrinsic quality motion capability semantic association inherent original model . Furthermore propose implementation Transformer-based diffusion model designated MWNet main branch . This model adeptly apprehends spatial intricacy inter-joint correlation inherent motion sequence facilitated integration multi-wise self-attention module . Extensive experiment show method achieves competitive result single-condition multi-condition HMS task .
Knowledge human visual system help develop better computational model visual attention . State-of-the-art model developed mimic visual attention system young adult however largely ignore variation occur age . In paper investigated visual scene processing change age propose age-adapted framework help develop computational model predict saliency across different age group . Our analysis uncovers explorativeness observer varies age well saliency map age group agree fixation point observer different age group age influence center bias . We analyzed eye movement behavior 82 observer belonging four age group explored visual scene . Explorativeness quantified term entropy saliency map area curve ( AUC ) metric used quantify agreement analysis center bias . These result used develop age adapted saliency model . Our result suggest proposed age-adapted saliency model outperforms existing saliency model predicting region interest across age group .
Driven deep learning technique perception technology autonomous driving developed rapidly recent year enabling vehicle accurately detect interpret surrounding environment safe efficient navigation . To achieve accurate robust perception capability autonomous vehicle often equipped multiple sensor making sensor fusion crucial part perception system . Among fused sensor radar camera enable complementary cost-effective perception surrounding environment regardless lighting weather condition . This review aim provide comprehensive guideline radar-camera fusion particularly concentrating perception task related object detection semantic segmentation.Based principle radar camera sensor delve data processing process representation followed in-depth analysis summary radar-camera fusion datasets . In review methodology radar-camera fusion address interrogative question including `` fuse `` `` fuse `` `` fuse `` `` fuse `` `` fuse `` subsequently discussing various challenge potential research direction within domain . To ease retrieval comparison datasets fusion method also provide interactive website : http : //radar-camera-fusion.github.io .
A surface often modeled triangulated mesh 3D point texture associated face mesh . The 3D point could either sampled range data derived set image using stereo Structure-from-Motion algorithm . When point lie critical point maximum curvature discontinuity real surface face mesh lie close modeled surface . This result textural artifact model perfectly coherent set actual image -- one used texture-map mesh . This paper present technique perfecting 3D surface model repositioning vertex coherent set observed image object . The textural artifact incoherence image due non-planarity surface patch approximated planar face observed multiple viewpoint . Image area viewpoint used represent texture patch Eigenspace . The Eigenspace representation capture variation texture seek minimize . A coherence measure based difference face texture reconstructed Eigenspace actual image used reposition vertex model improved faired . We refer technique model refinement EigenFairing model faired geometrically texturally better approximate real surface .
Traditional slot filling natural language understanding ( NLU ) predicts one-hot vector word . This form label representation lack semantic correlation modelling lead severe data sparsity problem especially adapting NLU model new domain . To address issue novel label embedding based slot filling framework proposed paper . Here distributed label embedding constructed slot using prior knowledge . Three encoding method investigated incorporate different kind prior knowledge slot : atomic concept slot description slot exemplar . The proposed label embeddings tend share text pattern reuses data different slot label . This make useful adaptive NLU limited data . Also since label embedding independent NLU model compatible almost deep learning based slot filling model . The proposed approach evaluated three datasets . Experiments single domain domain adaptation task show label embedding achieves significant performance improvement traditional one-hot label representation well advanced zero-shot approach .
Content-Based Image Retrieval ( CBIR ) locates retrieves display image alike one given query using set feature . It demand accessible data medical archive medical equipment infer meaning processing . A problem similar sense target image aid clinician . CBIR complement text-based retrieval improves evidence-based diagnosis administration teaching research healthcare . It facilitates visual/automatic diagnosis decision-making real-time remote consultation/screening store-and-forward test home care assistance overall patient surveillance . Metrics help comparing visual data improve diagnostic . Specially designed architecture benefit application scenario . CBIR use call file storage standardization querying procedure efficient image transmission realistic database global availability access simplicity Internet-based structure . This chapter recommends important complex aspect required handle visual content healthcare .
Early precise detection nutrient deficiency stress ( NDS ) key economic well environmental impact ; precision application chemical place blanket application reduces operational cost grower reducing amount chemical may enter environment unnecessarily . Furthermore earlier treatment reduces amount loss therefore boost crop production given season . With mind collect sequence high-resolution aerial imagery construct semantic segmentation model detect predict NDS across field . Our work sits intersection agriculture remote sensing modern computer vision deep learning . First establish baseline full-field detection NDS quantify impact pretraining backbone architecture input representation sampling strategy . We quantify amount information available different point season building single-timestamp model based UNet . Next construct proposed spatiotemporal architecture combine UNet convolutional LSTM layer accurately detect region field showing NDS ; approach impressive IOU score 0.53 . Finally show architecture trained predict region field expected show NDS later flight -- potentially three week future -- maintaining IOU score 0.47-0.51 depending far advance prediction made . We also release dataset believe benefit computer vision remote sensing well agriculture field . This work contributes recent development deep learning remote sensing agriculture addressing key social challenge implication economics sustainability .
Objective : To develop evaluate FastContext efficient scalable implementation ConText algorithm suitable large-scale clinical natural language processing . Background : The ConText algorithm performs state-of-art accuracy detecting experiencer negation status temporality concept mention clinical narrative . However speed limitation current implementation hinders use big data processing . Methods : We developed FastContext hashing ConText 's rule compared speed accuracy JavaConText GeneralConText two widely used Java implementation . Results : FastContext ran two order magnitude faster less decelerated rule increase two implementation used study comparison . Additionally FastContext consistently gained accuracy improvement rule increased ( desired outcome adding new rule ) two implementation . Conclusions : FastContext efficient scalable implementation popular ConText algorithm suitable natural language application large clinical corpus .
Electronic Health Records ( EHR ) crucial success digital healthcare focus putting consumer center transformation . However digitalization healthcare record brings along security privacy risk personal data . The major concern different country varying standard security privacy medical data . This paper proposed novel comprehensive framework standardize rule globally bringing together common platform . To support proposal study review existing literature understand research interest issue . It also examines six key law standard related security privacy identifying twenty concept . The proposed framework utilized K-means clustering categorize concept identify five key factor . Finally Ordinal Priority Approach applied determine preferred implementation factor context EHRs . The proposed study provides descriptive prescriptive framework implementation privacy security context electronic health record . Therefore finding proposed framework useful professional policymakers improving security privacy associated EHRs .
Depression detection research increased last decade one major bottleneck limited data availability representation learning . Recently self-supervised learning seen success pretraining text embeddings applied broadly related task sparse data pretrained audio embeddings based self-supervised learning rarely investigated . This paper proposes DEPA self-supervised pretrained depression audio embedding method depression detection . An encoder-decoder network used extract DEPA in-domain depressed datasets ( DAIC MDD ) out-domain ( Switchboard Alzheimer 's ) datasets . With DEPA audio embedding extracted response-level significant performance gain achieved downstream task evaluated sparse datasets like DAIC large major depression disorder dataset ( MDD ) . This paper exhibit novel embedding extracting method capturing response-level representation depression detection significantly exploration self-supervised learning specific task within audio processing .
A control system consists plant component controller periodically computes control input plant . We consider system controller implemented feedforward neural network ReLU activation . The reachability problem asks given set initial state whether set target state reached . We show problem undecidable even trivial plant fixed-depth neural network three input output . We also show problem becomes semi-decidable plant well input target set given automaton infinite word .
Manual identification fission track practical problem variation due observer-observation efficiency . An automatic processing method could identify fission track photomicrograph could solve problem improve speed track counting . However separation non-trivial image one difficult task image processing . Several commercial free software available software meant used specific image . In paper automatic method based starlet wavelet presented order separate fission track mineral photomicrograph . Automatization obtained Matthews correlation coefficient result evaluated precision recall accuracy . This technique improvement method aimed segmentation scanning electron microscopy image . This method applied photomicrograph epidote phenocrystals accuracy higher 89 % obtained fission track segmentation even difficult image . Algorithms corresponding proposed method available download . Using method presented user could easily determine fission track photomicrograph mineral sample .
Hash coding widely used approximate nearest neighbor search large-scale image retrieval . Given semantic annotation class label pairwise similarity training data hashing method learn generate effective compact binary code . While newly introduced image may contain undefined semantic label call unseen image zeor-shot hashing technique studied . However existing zeor-shot hashing method focus retrieval single-label image handle multi-label image . In paper first time novel transductive zero-shot hashing method proposed multi-label unseen image retrieval . In order predict label unseen/target data visual-semantic bridge built via instance-concept coherence ranking seen/source data . Then pairwise similarity loss focal quantization loss constructed training hashing model using seen/source unseen/target data . Extensive evaluation three popular multi-label datasets demonstrate proposed hashing method achieves significantly better result competing method .
As algorithmic system come scrutiny potential inflict societal harm increasing number organization hold power harmful algorithm chosen ( required law ) abandon . While social movement call abandon harmful algorithm emerged across application domain little academic attention paid studying abandonment mean mitigate algorithmic harm . In paper take first step towards conceptualizing `` algorithm abandonment `` organization 's decision stop designing developing using algorithmic system due ( potential ) harm . We conduct thematic analysis real-world case algorithm abandonment characterize dynamic leading outcome . Our analysis 40 case reveals campaign abandon algorithm follow common process six iterative phase : discovery diagnosis dissemination dialogue decision death term `` 6 D 's abandonment `` . In addition highlight key factor facilitate ( prohibit ) abandonment include characteristic technical social system algorithm embedded within . We discus implication several stakeholder including proprietor technologist power influence algorithm 's ( dis ) continued use FAccT researcher policymakers .
As social VR application grow popularity blind low vision user encounter continued accessibility barrier . Yet social VR enables multiple people engage virtual space present unique opportunity allow people support user 's access need . To explore opportunity designed framework based physical sighted guidance enables guide support blind low vision user navigation visual interpretation . A user virtually hold guide move guide describe environment . We studied use framework 16 blind low vision participant found wide range preference . For example found participant wanted use guide support social interaction establish human connection human-appearing guide . We also highlight opportunity novel guidance ability VR dynamically altering inaccessible environment . Through work open novel design space versatile approach making VR fully accessible .
Prediction task student practical significance student college . Making multiple prediction student important part smart campus . For instance predicting whether student fail graduate alert student affair office take predictive measure help student improve his/her academic performance . With development information technology college collect digital footprint encode heterogeneous behavior continuously . In paper focus modeling heterogeneous behavior making multiple prediction together since prediction task related learning model specific task may data sparsity problem . To end propose variant LSTM soft-attention mechanism . The proposed LSTM able learn student profile-aware representation heterogeneous behavior sequence . The proposed soft-attention mechanism dynamically learn different importance degree different day every student . In way heterogeneous behavior well modeled . In order model interaction among multiple prediction task propose co-attention mechanism based unit . With help stacked unit explicitly control knowledge transfer among multiple task . We design three motivating behavior prediction task based real-world dataset collected college . Qualitative quantitative experiment three prediction task demonstrated effectiveness model .
Machine Learning ( ML ) demonstrated great potential medical data analysis . Large datasets collected diverse source setting essential ML model healthcare achieve better accuracy generalizability . Sharing data across different healthcare institution challenging complex varying privacy regulatory requirement . Hence hard crucial allow multiple party collaboratively train ML model leveraging private datasets available party without need direct sharing datasets compromising privacy datasets collaboration . In paper address challenge proposing Decentralized Collaborative Privacy-preserving ML Multi-Hospital Data ( DeCaPH ) . It offer following key benefit : ( 1 ) allows different party collaboratively train ML model without transferring private datasets ; ( 2 ) safeguard patient privacy limiting potential privacy leakage arising content shared across party training process ; ( 3 ) facilitates ML model training without relying centralized server . We demonstrate generalizability power DeCaPH three distinct task using real-world distributed medical datasets : patient mortality prediction using electronic health record cell-type classification using single-cell human genome pathology identification using chest radiology image . We demonstrate ML model trained DeCaPH framework improved utility-privacy trade-off showing enables model good performance preserving privacy training data point . In addition ML model trained DeCaPH framework general outperform trained solely private datasets individual party showing DeCaPH enhances model generalizability .
Arbitrary-oriented object detection ( AOOD ) play significant role image understanding remote sensing scenario . The existing AOOD method face challenge ambiguity high cost angle representation . To end multi-grained angle representation ( MGAR ) method consisting coarse-grained angle classification ( CAC ) fine-grained angle regression ( FAR ) proposed . Specifically designed CAC avoids ambiguity angle prediction discrete angular encoding ( DAE ) reduces complexity coarsening granularity DAE . Based CAC FAR developed refine angle prediction much lower cost narrowing granularity DAE . Furthermore Intersection Union ( IoU ) aware FAR-Loss ( IFL ) designed improve accuracy angle prediction using adaptive re-weighting mechanism guided IoU . Extensive experiment performed several public remote sensing datasets demonstrate effectiveness proposed MGAR . Moreover experiment embedded device demonstrate proposed MGAR also friendly lightweight deployment .
Deep learning method person identification based electroencephalographic ( EEG ) brain activity encounter problem exploiting temporally correlated structure recording session specific variability within EEG . Furthermore recent method mostly trained evaluated based single session EEG data . We address problem invariant representation learning perspective . We propose adversarial inference approach extend deep learning model learn session-invariant person-discriminative representation provide robustness term longitudinal usability . Using adversarial learning within deep convolutional network empirically assess show improvement approach based longitudinally collected EEG data person identification half-second EEG epoch .
The humanity like many area society currently undergoing major change wake digital transformation . However order make collection digitised material area easily accessible often still lack adequate search functionality . For instance digital archive textile offer keyword search fairly well understood arrange content following certain taxonomy search functionality level thread structure still missing . To facilitate clustering search introduce approach recognising similar weaving pattern based structure textile archive . We first represent textile structure using hypergraphs extract multisets k-neighbourhoods describing weaving pattern graph . Then resulting multisets clustered using various distance measure various clustering algorithm ( K-Means simplicity hierarchical agglomerative algorithm precision ) . We evaluate different variant approach experimentally showing implemented efficiently ( meaning linear complexity ) demonstrate quality query cluster datasets containing large textile sample . As est knowledge first practical approach explicitly modelling complex irregular weaving pattern usable retrieval aim establishing solid baseline .
Unmanned aerial vehicle ( UAVs ) widely used platform carry data capturing sensor various application . The reason success found many aspect : high maneuverability UAVs capability performing autonomous data acquisition flying different height possibility reach almost vantage point . The selection appropriate viewpoint planning optimum trajectory UAVs emerging topic aim increasing automation efficiency reliability data capturing process achieve dataset desired quality . On hand 3D reconstruction using data captured UAVs also attracting attention research industry . This review paper investigates wide range model-free model-based algorithm viewpoint path planning 3D reconstruction large-scale object . The analyzed approach limited employ single-UAV data capturing platform outdoor 3D reconstruction purpose . In addition discussing evaluation strategy paper also highlight innovation limitation investigated approach . It concludes critical analysis existing challenge future research perspective .
Labelling user 's utterance understanding attends called Dialogue Act ( DA ) classification considered key player dialogue language understanding layer automatic dialogue system . In paper proposed novel approach user 's utterance labeling Egyptian spontaneous dialogue Instant Messages using Machine Learning ( ML ) approach without relying special lexicon cue rule . Due lack Egyptian dialect dialogue corpus system evaluated multi-genre corpus includes 4725 utterance three domain collected annotated manually Egyptian call-centers . The system achieves F1 score 70 . 36 % overall domain .
Over 30 paper proposed use convolutional neural network ( CNN ) AD classification anatomical MRI . However classification performance difficult compare across study due variation component participant selection image preprocessing validation procedure . Moreover study hardly reproducible framework publicly accessible implementation detail lacking . Lastly paper may report biased performance due inadequate unclear validation model selection procedure . In present work aim address limitation three main contribution . First performed systematic literature review found half surveyed paper may suffered data leakage . Our second contribution extension open-source framework classification AD using CNN T1-weighted MRI . Finally used framework rigorously compare different CNN architecture . The data split training/validation/test set beginning training/validation set used model selection . To avoid overfitting test set left untouched end peer-review process . Overall different 3D approach ( 3D-subject 3D-ROI 3D-patch ) achieved similar performance 2D slice approach lower . Of note different CNN approach perform better SVM voxel-based feature . The different approach generalized well similar population datasets different inclusion criterion demographical characteristic .
Artificial intelligence applied wildfire science management since 1990s early application including neural network expert system . Since field rapidly progressed congruently wide adoption machine learning ( ML ) environmental science . Here present scoping review ML wildfire science management . Our objective improve awareness ML among wildfire scientist manager well illustrate challenging range problem wildfire science available data scientist . We first present overview popular ML approach used wildfire science date review use wildfire science within six problem domain : 1 ) fuel characterization fire detection mapping ; 2 ) fire weather climate change ; 3 ) fire occurrence susceptibility risk ; 4 ) fire behavior prediction ; 5 ) fire effect ; 6 ) fire management . We also discus advantage limitation various ML approach identify opportunity future advance wildfire science management within data science context . We identified 298 relevant publication frequently used ML method included random forest MaxEnt artificial neural network decision tree support vector machine genetic algorithm . There exists opportunity apply current ML method ( e.g . deep learning agent based learning ) wildfire science . However despite ability ML model learn expertise wildfire science necessary ensure realistic modelling fire process across multiple scale complexity ML method requires sophisticated knowledge application . Finally stress wildfire research management community play active role providing relevant high quality data use practitioner ML method .
The generalization end-to-end deep reinforcement learning ( DRL ) object-goal visual navigation long-standing challenge since object class placement vary new test environment . Learning domain-independent visual representation critical enabling trained DRL agent ability generalize unseen scene object . In letter target-directed attention network ( TDANet ) proposed learn end-to-end object-goal visual navigation policy zero-shot ability . TDANet feature novel target attention ( TA ) module learns spatial semantic relationship among object help TDANet focus relevant observed object target . With Siamese architecture ( SA ) design TDANet distinguishes difference current target state generates domain-independent visual representation . To evaluate navigation performance TDANet extensive experiment conducted AI2-THOR embodied AI environment . The simulation result demonstrate strong generalization ability TDANet unseen scene target object higher navigation success rate ( SR ) success weighted length ( SPL ) state-of-the-art model . TDANet finally deployed wheeled robot real scene demonstrating satisfactory generalization TDANet real world .
In paper investigate problem facial kinship verification learning hierarchical reasoning graph network . Conventional method usually focus learning discriminative feature facial image paired sample neglect fuse obtained two facial image feature reason relation . To address propose Star-shaped Reasoning Graph Network ( S-RGN ) . Our S-RGN first construct star-shaped graph surrounding node encodes information comparison feature dimension central node employed bridge interaction surrounding node . Then perform relational reasoning star graph iterative message passing . The proposed S-RGN us one central node analyze process information surrounding node limit reasoning capacity . We develop Hierarchical Reasoning Graph Network ( H-RGN ) exploit powerful flexible capacity . More specifically H-RGN introduces set latent reasoning node construct hierarchical graph . Then bottom-up comparative information abstraction top-down comprehensive signal propagation iteratively performed hierarchical graph update node feature . Extensive experimental result four widely used kinship database show proposed method achieve competitive result .
This paper present new approach automatic license plate recognition includes SIFT algorithm step locate plate input image . In new approach besides comparison feature obtained SIFT algorithm correspondence spatial orientation positioning associated keypoints also observed . Afterwards algorithm used character recognition plate fast make possible application real time . The result obtained proposed approach presented good success rate much locating character input image recognition .
Sentiment analysis ( SA ) automated process detecting understanding emotion conveyed written text . Over past decade SA gained significant popularity field Natural Language Processing ( NLP ) . With widespread use social medium online platform SA become crucial company gather customer feedback shape marketing strategy . Additionally researcher rely SA analyze public sentiment various topic . In particular research study comprehensive survey conducted explore latest trend technique SA . The survey encompassed wide range method including lexicon-based graph-based network-based machine learning deep learning ensemble-based rule-based hybrid technique . The paper also address challenge opportunity SA dealing sarcasm irony analyzing multi-lingual data addressing ethical concern . To provide practical case study Twitter chosen one largest online social medium platform . Furthermore researcher shed light diverse application area SA including social medium healthcare marketing finance politics . The paper also present comparative comprehensive analysis existing trend technique datasets evaluation metric . The ultimate goal offer researcher practitioner systematic review SA technique identify existing gap suggest possible improvement . This study aim enhance efficiency accuracy SA process leading smoother error-free outcome .
Integration indispensable mathematics also wide range field . A deep learning method recently developed shown capable integrating mathematical function could previously integrated computer . However method treat integration equivalent natural language translation reflect mathematical information . In study adjusted learning model take mathematical information account developed wide range learning model learn order numerical operation robustly . In way achieved 98.80 % correct answer rate symbolic integration higher rate existing method . We judged correctness integration based whether derivative primitive function consistent integrand . By building integrated model based strategy achieved 99.79 % rate correct answer symbolic integration .
We present multiway fusion algorithm capable directly processing uncertain pairwise affinity . In contrast existing work require initial pairwise association MIXER algorithm improves accuracy leveraging additional information provided pairwise affinity . Our main contribution multiway fusion formulation particularly suited processing non-binary affinity novel continuous relaxation whose solution guaranteed binary thus avoiding typical potentially problematic solution binarization step may cause infeasibility . A crucial insight formulation allows three mode association ranging non-match undecided match . Exploiting insight allows fusion delayed data pair information available effective feature fusion data multiple attributes/information source . We evaluate MIXER typical synthetic data benchmark datasets show increased accuracy state art multiway matching especially noisy regime low observation redundancy . Additionally collect RGB data car parking lot demonstrate MIXER 's ability fuse data multiple attribute ( color visual appearance bounding box ) . On challenging dataset MIXER achieves 74 % F1 accuracy 49x faster next best algorithm 42 % accuracy . Open source code available http : //github.com/mit-acl/mixer .
In paper design novel interactive deep learning method improve semantic interaction visual analytics application . The ability semantic interaction infer analyst ' precise intent sensemaking dependent quality underlying data representation . We propose $ \text { DeepSI } _ { \text { finetune } } $ framework integrates deep learning human-in-the-loop interactive sensemaking pipeline two important property . First deep learning extract meaningful representation raw data improves semantic interaction inference . Second semantic interaction exploited fine-tune deep learning representation improves semantic interaction inference . This feedback loop human interaction deep learning enables efficient learning user- task-specific representation . To evaluate advantage embedding deep learning within semantic interaction loop compare $ \text { DeepSI } _ { \text { finetune } } $ state-of-the-art basic use deep learning feature extractor pre-processed outside interactive loop . Results two complementary study human-centered qualitative case study algorithm-centered simulation-based quantitative experiment show $ \text { DeepSI } _ { \text { finetune } } $ accurately capture user ' complex mental model fewer interaction .
Future human action forecasting partial observation activity important problem many practical application assistive robotics video surveillance security . We present method forecast action unseen future video using neural machine translation technique us encoder-decoder architecture . The input model observed RGB video objective forecast correct future symbolic action sequence . Unlike prior method make action prediction unseen percentage video one frame predict complete action sequence required accomplish activity . We coin task action sequence forecasting . To cater two type uncertainty future prediction propose novel loss function . We show combination optimal transport future uncertainty loss help improve result . We extend action sequence forecasting model perform weakly supervised action forecasting two challenging datasets Breakfast 50Salads . Specifically propose model predict action future unseen frame without using frame level annotation training . Using Fisher vector feature supervised model outperforms state-of-the-art action forecasting model 0.83 % 7.09 % Breakfast 50Salads datasets respectively . Our weakly supervised model 0.6 % behind recent state-of-the-art supervised model obtains comparable result published fully supervised method sometimes even outperforms Breakfast dataset . Most interestingly weakly supervised model outperforms prior model 1.04 % leveraging proposed weakly supervised architecture effective use attention mechanism loss function .
In paper proposed framework constructing two type automatic image aesthetic assessment model different CNN architecture improving performance image 's aesthetic score prediction ensemble . Moreover attention region model image extracted analyze consistency subject image . The experimental result verify proposed method effective improving AS prediction . Moreover found AS classification model trained XiheAA dataset seem learn latent photography principle although ca n't said learn aesthetic sense .
UAV-based image retrieval modern agriculture enables gathering large amount spatially referenced crop image data . In large-scale experiment however UAV image suffer containing multitudinous amount crop complex canopy architecture . Especially observation temporal effect complicates recognition individual plant several image extraction relevant information tremendously . In work present hands-on workflow automatized temporal spatial identification individualization crop image UAVs abbreviated `` cataloging `` based comprehensible computer vision method . We evaluate workflow two real-world datasets . One dataset recorded observation Cercospora leaf spot - fungal disease - sugar beet entire growing cycle . The one deal harvest prediction cauliflower plant . The plant catalog utilized extraction single plant image seen multiple time point . This gather large-scale spatio-temporal image dataset turn applied train machine learning model including various data layer . The presented approach improves analysis interpretation UAV data agriculture significantly . By validation reference data method show accuracy similar complex deep learning-based recognition technique . Our workflow able automatize plant cataloging training image extraction especially large datasets .
Deep reinforcement learning ( DRL ) one promising approach introducing robot complicated environment . The recent remarkable progress DRL stand regularization policy allows policy improve stably efficiently . A popular method so-called proximal policy optimization ( PPO ) variant constrain density ratio latest baseline policy density ratio exceeds given threshold . This threshold designed relatively intuitively fact recommended value range suggested . However density ratio asymmetric center possible error scale center close threshold would depend baseline policy given . In order maximize value regularization policy paper proposes new PPO derived using relative Pearson ( RPE ) divergence therefore so-called PPO-RPE design threshold adaptively . In PPO-RPE relative density ratio formed symmetry replaces raw density ratio . Thanks symmetry error scale center easily estimated hence threshold adapted estimated error scale . From three simple benchmark simulation importance algorithm-dependent threshold design revealed . By simulating additional four locomotion task verified proposed method statistically contributes task accomplishment appropriately restricting policy update .
In work study empirical risk minimization ( ERM ) within federated learning framework central server minimizes ERM objective function using training data stored across $ $ client . In setting Federated Averaging ( FedAve ) algorithm staple determining $ \epsilon $ -approximate solution ERM problem . Similar standard optimization algorithm convergence analysis FedAve relies smoothness loss function optimization parameter . However loss function often smooth training data . To exploit additional smoothness propose Federated Low Rank Gradient Descent ( FedLRGD ) algorithm . Since smoothness data induces approximate low rank structure loss function method first performs round communication server client learn weight server use approximate client ' gradient . Then method solves ERM problem server using inexact gradient descent . To show FedLRGD superior performance FedAve present notion federated oracle complexity counterpart canonical oracle complexity . Under assumption loss function e.g . strong convexity parameter $ \eta $ -H\ `` older smoothness data etc . prove federated oracle complexity FedLRGD scale like $ \phi ( p/\epsilon ) ^ { \Theta ( d/\eta ) } $ FedAve scale like $ \phi ( p/\epsilon ) ^ { 3/4 } $ ( neglecting sub-dominant factor ) $ \phi\gg 1 $ `` communication-to-computation ratio `` $ p $ parameter dimension $ $ data dimension . Then show $ $ small loss function sufficiently smooth data FedLRGD beat FedAve federated oracle complexity . Finally course analyzing FedLRGD also establish result low rank approximation latent variable model .
Federated learning ( FL ) powerful distributed machine learning framework server aggregate model trained different client without accessing private data . Hierarchical FL client-edge-cloud aggregation hierarchy effectively leverage cloud server 's access many client ' data edge server ' closeness client achieve high communication efficiency . Neural network quantization reduce communication overhead model uploading . To fully exploit advantage hierarchical FL accurate convergence analysis respect key system parameter needed . Unfortunately existing analysis loose consider model quantization . In paper derive tighter convergence bound hierarchical FL quantization . The convergence result lead practical guideline important design problem client-edge aggregation edge-client association strategy . Based obtained analytical result optimize two aggregation interval show client-edge aggregation interval slowly decay edge-cloud aggregation interval need adapt ratio client-edge edge-cloud propagation delay . Simulation result shall verify design guideline demonstrate effectiveness proposed aggregation strategy .
CAPTCHAs reverse Turing test real-time assessment used program ( computer ) tell human machine apart . This achieved assigning assessing hard AI problem could solved easily human machine . Applications assessment range stopping spammer automatically filling online form preventing hacker performing dictionary attack . Today race maker breaker CAPTCHAs juncture CAPTCHAs proposed even answerable human . We consider CAPTCHAs non user friendly . In paper propose novel technique reverse Turing test - call Line CAPTCHAs - mainly focus user friendliness compromising security aspect expected provided system .
Neural Radiance Fields ( NeRF ) offer potential benefit 3D reconstruction task including aerial photogrammetry . However scalability accuracy inferred geometry well-documented large-scale aerial asset since datasets usually result high memory consumption slow convergence .. In paper aim scale NeRF large-scael aerial datasets provide thorough geometry assessment NeRF . Specifically introduce location-specific sampling technique well multi-camera tiling ( MCT ) strategy reduce memory consumption image loading RAM representation training GPU memory increase convergence rate within tile . MCT decomposes large-frame image multiple tiled image different camera model allowing small-frame image fed training process needed specific location without loss accuracy . We implement method representative approach Mip-NeRF compare geometry performance threephotgrammetric MVS pipeline two typical aerial datasets LiDAR reference data . Both qualitative quantitative result suggest proposed NeRF approach produce better completeness object detail traditional approach although still fall short term accuracy .
Convolutional Neural Networks ( CNNs ) revolutionized research computer vision due ability capture complex pattern resulting high inference accuracy . However increasingly complex nature neural network mean particularly suited server computer powerful GPUs . We envision deep learning application eventually widely deployed mobile device e.g . smartphones self-driving car drone . Therefore paper aim understand resource requirement ( time memory ) CNNs mobile device . First deploying several popular CNNs mobile CPUs GPUs measure analyze performance resource usage every layer CNNs . Our finding point potential way optimizing performance mobile device . Second model resource requirement different CNN computation . Finally based measurement pro ling modeling build evaluate modeling tool Augur take CNN configuration ( descriptor ) input estimate compute time resource usage CNN give insight whether e ciently CNN run given mobile platform . In Augur tackle several challenge : ( ) overcome pro ling measurement overhead ; ( ii ) capture variance different mobile platform different processor memory cache size ; ( iii ) account variance number type size layer different CNN configuration .
Object proposal ensemble bounding box high potential contain object . In order determine small set proposal high recall common scheme extracting multiple feature followed ranking algorithm however incurs two major challenge : { \bf 1 ) } The ranking model often imposes pairwise constraint proposal rendering problem away efficient training/testing phase ; { \bf 2 ) } Linear kernel utilized due computational memory bottleneck training kernelized model . In paper remedy two issue suggesting { \em kernelized partial ranking model } . In particular demonstrate { \bf ) } partial ranking model reduces number constraint $ O ( n^2 ) $ $ O ( nk ) $ $ n $ number potential proposal image interested top- $ k $ largest overlap ground truth ; { \bf ii ) } permit non-linear kernel model often superior linear classifier term accuracy . For sake mitigating computational memory issue introduce consistent weighted sampling~ ( CWS ) paradigm approximates non-linear kernel well facilitates efficient learning . In fact show training linear CWS model amount learning kernelized model . Extensive experiment demonstrate equipped non-linear kernel partial ranking algorithm recall top- $ k $ proposal substantially improved .
Two main principle underlying life cycle artificial intelligence ( AI ) module communication network adaptation monitoring . Adaptation refers need adjust operation AI module depending current condition ; monitoring requires measure reliability AI module 's decision . Classical frequentist learning method design AI module fall short count adaptation monitoring catering one-off training providing overconfident decision . This paper proposes solution address challenge integrating meta-learning Bayesian learning . As specific use case problem demodulation equalization fading channel based availability pilot studied . Meta-learning process pilot information multiple frame order extract useful shared property effective demodulator across frame . The resulting trained demodulator demonstrated via experiment offer better calibrated soft decision computational cost running ensemble network run time . The capacity quantify uncertainty model parameter space leveraged extending Bayesian meta-learning active setting . In designer select sequential fashion channel condition generate data meta-learning channel simulator . Bayesian active meta-learning seen experiment significantly reduce number frame required obtain efficient adaptation procedure new frame .
Long distance imaging subject impact turbulent atmosphere . This result geometric distortion blur effect observed frame . Despite existence several turbulence mitigation algorithm literature common dataset exists objectively evaluate efficiency . In paper describe new dataset called OTIS ( Open Turbulent Images Set ) contains several sequence ( either static dynamic ) acquired turbulent atmosphere . For almost sequence provide corresponding groundtruth order make comparison algorithm easier . We also discus possible metric perform comparison .
Multi-view learning algorithm typically assume complete bipartite mapping different view order exchange information learning process . However many application provide partial mapping view creating challenge current method . To address problem propose multi-view algorithm based constrained clustering operate incomplete mapping . Given set pairwise constraint view approach propagates constraint using local similarity measure instance mapped view allowing propagated constraint transferred across view via partial mapping . It us co-EM iteratively estimate propagation within view based current clustering model transfer constraint across view update clustering model . By alternating learning process view approach produce unified clustering model consistent view . We show approach significantly improves clustering performance several method transferring constraint allows multi-view clustering reliably applied given limited mapping view . Our evaluation reveals propagated constraint high precision respect true cluster data explaining benefit clustering performance single- multi-view learning scenario .
Designing digital artifact linear straightforward process . This particularly true applying user-centered design approach co-design user unable participate design process . Although reduced participation particular user group may harm end result literature solving issue sparse . In article proxy design outlined method involving user group proxy user speak behalf group difficult reach . We present design ethnography spanning three year cancer rehabilitation clinic digital artifact designed used collaboratively nurse patient . The empirical data analyzed using content analysis consisted 20 observation day clinic six proxy design workshop 21 telephone consultation patient nurse log data digital artifact . We show simulated consultation nurse roleplaying proxy patient ignited initiated design process enabled efficient in-depth understanding patient . Moreover reveal proxy design method expanded design . We illustrate : ( 1 ) proxy design method initiating design ( 2 ) proxy design embedded element co-design ( 3 ) six design guideline considered engaging proxy design . The main contribution conceptualization proxy design method ignite initiate co-design process important user unreachable vulnerable unable represent co-design process . Based empirical finding design ethnography involved nurse proxy user speaking behalf patient article show roleplaying proxy design fitting way initiating design process outlining proxy design embedded element co-design .
Knowledge Graph Embeddings ( KGEs ) intensively explored recent year due promise wide range application . However existing study focus improving final model performance without acknowledging computational cost proposed approach term execution time environmental impact . This paper proposes simple yet effective KGE framework reduce training time carbon footprint order magnitude compared state-of-the-art approach producing competitive performance . We highlight three technical innovation : full batch learning via relational matrix closed-form Orthogonal Procrustes Analysis KGEs non-negative-sampling training . In addition first KGE method whose entity embeddings also store full relation information trained model encode rich semantics highly interpretable . Comprehensive experiment ablation study involving 13 strong baseline two standard datasets verify effectiveness efficiency algorithm .
Social ( folksonomic ) tagging become popular way describe content within Web 2.0 website . However tag informally defined continually changing ungoverned often criticised lowering rather increasing efficiency searching . To address issue variety approach proposed recommend user tag use labeling looking resource . These technique work well dense folksonomies fail tag usage exhibit power law distribution often happens real-life folksonomies . To tackle issue propose approach induces creation dense folksonomy fully automatic transparent way : user label resource innovative tag similarity metric deployed enrich chosen tag set related tag already present folksonomy . The proposed metric represents core approach based mutual reinforcement principle . Our experimental evaluation prof accuracy coverage search guaranteed metric higher achieved applying classical metric .
Adaptive flexible image editing desirable function modern generative model . In work present generative model auto-encoder architecture per-region style manipulation . We apply code consistency loss enforce explicit disentanglement content style latent representation making content style generated sample consistent corresponding content style reference . The model also constrained content alignment loss ensure foreground editing interfere background content . As result given interested region mask provided user model support foreground region-wise style transfer . Specially model receives extra annotation semantic label except self-supervision . Extensive experiment show effectiveness proposed method exhibit flexibility proposed model various application including region-wise style editing latent space interpolation cross-domain style transfer .
Argumentation mining rising subject computational linguistics domain focusing extracting structured argument natural text often unstructured noisy text . The initial approach modeling argument aiming identify flawless argument specific field ( Law Scientific Papers ) serving specific need ( completeness effectiveness ) . With emerge Web 2.0 explosion use social medium diffusion data argument structure changed . In survey article bridge gap theoretical approach argumentation mining pragmatic scheme satisfy need social medium generated data recognizing need adapting flexible expandable scheme capable adjust argumentation condition exist social medium . We review compare classify existing approach technique tool identifying positive outcome combining task feature eventually propose conceptual architecture framework . The proposed theoretical framework argumentation mining scheme able identify distinct sub-tasks capture need social medium text revealing need adopting flexible extensible framework .
The Facial Action Coding System ( FACS ) encodes action unit ( AUs ) facial image attracted extensive research attention due wide use facial expression analysis . Many method perform well automatic facial action unit ( AU ) detection primarily focus modeling various type AU relation corresponding local muscle area simply mining global attention-aware facial feature however neglect dynamic interaction among local-global feature . We argue encoding AU feature one perspective may capture rich contextual information regional global face feature well detailed variability across AUs diversity expression individual characteristic . In paper propose novel Multi-level Graph Relational Reasoning Network ( termed MGRR-Net ) facial AU detection . Each layer MGRR-Net performs multi-level ( i.e . region-level pixel-wise channel-wise level ) feature learning . While region-level feature learning local face patch feature via graph neural network encode correlation across different AUs pixel-wise channel-wise feature learning via graph attention network enhance discrimination ability AU feature global face feature . The fused feature three level lead improved AU discriminative ability . Extensive experiment DISFA BP4D AU datasets show proposed approach achieves superior performance state-of-the-art method .
In paper propose first effective genetic algorithm ( GA ) -based jigsaw puzzle solver . We introduce novel crossover procedure merges two `` parent `` solution improved `` child `` configuration detecting extracting combining correctly assembled puzzle segment . The solver proposed exhibit state-of-the-art performance far handling previously attempted puzzle accurately efficiently well puzzle size attempted . The extended experimental result provided paper include among others thorough inspection 30745-piece puzzle ( compared previous attempt 22755-piece puzzle ) using considerably faster concurrent implementation algorithm . Furthermore explore impact different phase novel crossover operator experimenting several variant GA . Finally compare different fitness function effect overall result GA-based solver .
3D modeling non-linear object stylized sketch challenge even expert Computer Graphics ( CG ) . The extrapolation object parameter stylized sketch complex cumbersome task . In present study propose broker system mediates modeler 3D modelling software transform stylized sketch tree complete 3D model . The input sketch need accurate detailed need represent rudimentary outline tree modeler wish 3D-model . Our approach based well-defined Deep Neural Network ( DNN ) architecture called TreeSketchNet ( TSN ) based convolution able generate Weber Penn parameter interpreted modelling software generate 3D model tree starting simple sketch . The training dataset consists Synthetically-Generated \revision { ( SG ) } sketch associated Weber-Penn parameter generated dedicated Blender modelling software add-on . The accuracy proposed method demonstrated testing TSN synthetic hand-made sketch . Finally provide qualitative analysis result evaluating coherence predicted parameter several distinguishing feature .
In recent year 3D point cloud ( PCs ) gained significant attention due diverse application across various field computer vision ( CV ) condition monitoring ( CM ) virtual reality robotics autonomous driving etc . Deep learning ( DL ) proven effective leveraging 3D PCs address various challenge encountered 2D vision . However applying deep neural network ( DNNs ) process 3D PCs present unique challenge . This paper provides in-depth review recent advancement DL-based industrial CM using 3D PCs specific focus defect shape classification segmentation within industrial application . Recognizing crucial role aspect industrial maintenance paper offer insightful observation strength limitation reviewed DL-based PC processing method . This knowledge synthesis aim contribute understanding enhancing CM process particularly within framework remaining useful life ( RUL ) industrial system .
Remote Sensing Image Retrieval remains challenging topic due special nature Remote Sensing Imagery . Such image contain various different semantic object clearly complicates retrieval task . In paper present image retrieval pipeline us attentive local convolutional feature aggregate using Vector Locally Aggregated Descriptors ( VLAD ) produce global descriptor . We study various system parameter multiplicative additive attention mechanism descriptor dimensionality . We propose query expansion method requires external input . Experiments demonstrate even without training local convolutional feature global representation outperform system . After system tuning achieve state-of-the-art competitive result . Furthermore observe query expansion method increase overall system performance 3 % using top-three retrieved image . Finally show dimensionality reduction produce compact descriptor increased retrieval performance fast retrieval computation time e.g . 50 % faster current system .
The theory-guided neural network ( TgNN ) kind method improves effectiveness efficiency neural network architecture incorporating scientific knowledge physical information . Despite great success theory-guided ( deep ) neural network possesses certain limit maintaining tradeoff training data domain knowledge training process . In paper Lagrangian dual-based TgNN ( TgNN-LD ) proposed improve effectiveness TgNN . We convert original loss function constrained form fewer item partial differential equation ( PDEs ) engineering control ( ECs ) expert knowledge ( EK ) regarded constraint one Lagrangian variable per constraint . These Lagrangian variable incorporated achieve equitable tradeoff observation data corresponding constraint order improve prediction accuracy conserve time computational resource adjusted ad-hoc procedure . To investigate performance proposed method original TgNN model set optimized weight value adjusted ad-hoc procedure compared subsurface flow problem L2 error R square ( R2 ) computational time analyzed . Experimental result demonstrate superiority Lagrangian dual-based TgNN .
We study problem stochastic combinatorial pure exploration ( CPE ) agent sequentially pull set single arm ( a.k.a . super arm ) try find best super arm . Among variety problem setting CPE focus full-bandit setting observe reward single arm sum reward . Although regard CPE full-bandit feedback special case pure exploration linear bandit approach based linear bandit computationally feasible since number super arm may exponential . In paper first propose polynomial-time bandit algorithm CPE general combinatorial constraint provide upper bound sample complexity . Second design approximation algorithm 0-1 quadratic maximization problem arises many bandit algorithm confidence ellipsoid . Based approximation algorithm propose novel bandit algorithm top-k selection problem prove algorithm run polynomial time . Finally conduct experiment synthetic real-world datasets confirm validity theoretical analysis term computation time sample complexity .
Since human listen audio watch video faster speed actually observed often listen watch piece content higher playback speed increase time efficiency content comprehension . To utilize capability system automatically adjust playback speed according user 's condition type content assist efficient comprehension time-series content developed . However still room system extend human speed-listening ability generating speech playback speed optimized even finer time unit providing human . In study determine whether human hear optimized speech propose system automatically adjusts playback speed unit small phoneme ensuring speech intelligibility . The system us speech recognizer score proxy well human hear certain unit speech maximizes speech playback speed extent human hear . This method used produce fast intelligible speech . In evaluation experiment compared speech played back constant fast speed flexibly speed-up speech generated proposed method blind test confirmed proposed method produced speech easier listen .
Facial action unit ( AUs ) defined Facial Action Coding System ( FACS ) received significant research interest owing diverse range application facial state analysis . Current mainstream FAU recognition model notable limitation i.e . focusing accuracy AU recognition overlooking explanation corresponding AU state . In paper propose end-to-end Vision-Language joint learning network explainable FAU recognition ( termed VL-FAU ) aim reinforce AU representation capability language interpretability integration joint multimodal task . Specifically VL-FAU brings together language model generate fine-grained local muscle description distinguishable global face description optimising FAU recognition . Through global facial representation local AU representation achieve higher distinguishability among different AUs different subject . In addition multi-level AU representation learning utilised improve AU individual attention-aware representation capability based multi-scale combined facial stem feature . Extensive experiment DISFA BP4D AU datasets show proposed approach achieves superior performance state-of-the-art method metric . In addition compared mainstream FAU recognition method VL-FAU provide local- global-level interpretability language description AUs ' prediction .
Visual place recognition ( VPR ) fundamental task many application robot localization augmented reality . Recently hierarchical VPR method received considerable attention due trade-off accuracy efficiency . They usually first use global feature retrieve candidate image verify spatial consistency matched local feature re-ranking . However latter typically relies RANSAC algorithm fitting homography time-consuming non-differentiable . This make existing method compromise train network global feature extraction . Here propose transformer-based deep homography estimation ( DHE ) network take dense feature map extracted backbone network input fit homography fast learnable geometric verification . Moreover design re-projection error inliers loss train DHE network without additional homography label also jointly trained backbone network help extract feature suitable local matching . Extensive experiment benchmark datasets show method outperform several state-of-the-art method . And one order magnitude faster mainstream hierarchical VPR method using RANSAC . The code released http : //github.com/Lu-Feng/DHE-VPR .
Object detection important task remote sensing image analysis . To reduce computational complexity redundant information improve efficiency image processing visual saliency model widely applied field . In paper novel saliency detection model based Contrast-weighted Dictionary Learning ( CDL ) proposed remote sensing image . Specifically proposed CDL learns salient non-salient atom positive negative sample construct discriminant dictionary contrast-weighted term proposed encourage contrast-weighted pattern present learned salient dictionary discouraging present non-salient dictionary . Then measure saliency combining coefficient sparse representation ( SR ) reconstruction error . Furthermore using proposed joint saliency measure variety saliency map generated based discriminant dictionary . Finally fusion method based global gradient optimization proposed integrate multiple saliency map . Experimental result four datasets demonstrate proposed model outperforms state-of-the-art method .
This article provides overview recent research Child-Computer Interaction mobile device describe framework ChildCI intended : ) overcoming lack large-scale publicly available database area ii ) generating better understanding cognitive neuromotor development child along time contrary previous study literature focused single-session acquisition iii ) enabling new application e-Learning e-Health acquisition additional information school grade child 's disorder among others . Our framework includes new mobile application specific data acquisition protocol first release ChildCI dataset ( ChildCIdb v1 ) planned extended yearly enable longitudinal study . In framework child interact tablet device using pen stylus finger performing different task require different level neuromotor cognitive skill . ChildCIdb first database literature comprises 400 child 18 month 8 year old considering therefore first three development stage Piaget 's theory . In addition demonstration potential ChildCI framework include experimental result one many application enabled ChildCIdb : child age detection based device interaction .
Object recognition commonly performed camera fundamental requirement robot complete complex task . Some task require recognizing object far robot 's camera . A challenging example Ultra-Range Gesture Recognition ( URGR ) human-robot interaction user exhibit directive gesture distance 25~m robot . However training model recognize hardly visible object located ultra-range requires exhaustive collection significant amount labeled sample . The generation synthetic training datasets recent solution lack real-world data unable properly replicate realistic visual characteristic distant object image . In letter propose Diffusion Ultra-Range ( DUR ) framework based Diffusion model generate labeled image distant object various scene . The DUR generator receives desired distance class ( e.g . gesture ) output corresponding synthetic image . We apply DUR train URGR model directive gesture fine detail gesturing hand challenging distinguish . DUR compared type generative model showcasing superiority fidelity recognition success rate training URGR model . More importantly training DUR model limited amount real data using generate synthetic data training URGR model outperforms directly training URGR model real data . The synthetic-based URGR model also demonstrated gesture-based direction ground robot .
Recent advance molecular machine learning especially deep neural network Graph Neural Networks ( GNNs ) predicting structure activity relationship ( SAR ) shown tremendous potential computer-aided drug discovery . However applicability deep neural network limited requirement large amount training data . In order cope limited training data target task transfer learning SAR modeling recently adopted leverage information data related task . In work contrast popular parameter-based transfer learning pretraining develop novel deep transfer learning method TAc TAc-fc leverage source domain data transfer useful information target domain . TAc learns generate effective molecular feature generalize well one domain another increase classification performance target domain . Additionally TAc-fc extends TAc incorporating novel component selectively learn feature-wise compound-wise transferability . We used bioassay screening data PubChem identified 120 pair bioassay active compound pair similar compared inactive compound . Our experiment clearly demonstrate TAc achieves significant improvement baseline across large number target task . Furthermore although TAc-fc achieves slightly worse ROC-AUC average compared TAc TAc-fc still achieves best performance task term PR-AUC F1 compared method . In summary TAc-fc also found strong model competitive even better performance TAc notable number target task .
Statistical technique analyze text referred text analytics departed use simple word count statistic towards new paradigm . Text mining hinge sophisticated set method including representation term complex network . While well-established word-adjacency ( co-occurrence ) method successfully grasp syntactical feature written text unable represent important aspect textual data topical structure i.e . sequence subject developing mesoscopic level along text . Such aspect often overlooked current methodology . In order grasp mesoscopic characteristic semantical content written text devised network model able analyze document multi-scale fashion . In proposed model limited amount adjacent paragraph represented node connected whenever share minimum semantical content . To illustrate capability model present case example qualitative analysis `` Alice 's Adventures Wonderland `` . We show mesoscopic structure document modeled network reveals many semantic trait text . Such approach pave way myriad semantic-based application . In addition approach illustrated machine learning context text classified among real text randomized instance .
Neurosymbolic approach add robustness opaque neural system incorporating explainable symbolic representation . However previous approach used formal logic contextualize query validate output large language model ( LLMs ) . We propose \systemname { } novel neurosymbolic framework improve robustness reliability LLMs question-answering task . We provide \systemname { } domain-specific knowledge base logical reasoning system integration existing LLM . This framework two capability ( 1 ) context gathering : generating explainable relevant context given query ( 2 ) validation : confirming validating factual accuracy statement accordance knowledge base ( KB ) . Our work open new area neurosymbolic generative AI text validation user personalization .
Feature generating network face important question fitting difference ( inconsistence ) distribution generated feature real data . This inconsistence influence performance network model training sample seen class disjointed testing sample unseen class zero-shot learning ( ZSL ) . In generalization zero-shot learning ( GZSL ) testing sample come seen class also unseen class closer practical situation . Therefore feature generating network difficultly obtain satisfactory performance challenging GZSL adversarial learning distribution semantic class . To alleviate negative influence inconsistence ZSL GZSL transfer feature generating network semantic class structure ( TFGNSCS ) proposed construct network model improving performance ZSL GZSL . TFGNSCS consider semantic structure relationship seen unseen class also learn difference generating feature transferring classification model information seen unseen class network . The proposed method integrate transfer loss classification loss Wasserstein distance loss generate enough CNN feature softmax classifier trained ZSL GZSL . Experiments demonstrate performance TFGNSCS outperforms state art four challenging datasets CUB FLO SUN AWA GZSL .
Error Correcting Output Codes ECOC output representation method capable discovering error produced classification task . This paper describes application ECOC training feed forward neural network FFNN improving overall accuracy classification system . Indeed improve generalization FFNN classifier paper proposes ECOC-Based training method Neural Networks use ECOC output representation adopts traditional Back-Propagation algorithm BP adjust weight network . Experimental result face recognition problem Yale database demonstrate effectiveness method . With rejection scheme defined simple robustness rate high reliability achieved application .
Vegetation structure mapping critical understanding global carbon cycle monitoring nature-based approach climate adaptation mitigation . Repeated measurement data allow observation deforestation degradation existing forest natural forest regeneration implementation sustainable agricultural practice like agroforestry . Assessments tree canopy height crown projected area high spatial resolution also important monitoring carbon flux assessing tree-based land us since forest structure highly spatially heterogeneous especially agroforestry system . Very high resolution satellite imagery ( less one meter ( 1m ) Ground Sample Distance ) make possible extract information tree level allowing monitoring large scale . This paper present first high-resolution canopy height map concurrently produced multiple sub-national jurisdiction . Specifically produce high resolution canopy height map state California Sao Paulo significant improvement resolution ten meter ( 10m ) resolution previous Sentinel / GEDI based worldwide map canopy height . The map generated extraction feature self-supervised model trained Maxar imagery 2017 2020 training dense prediction decoder aerial lidar map . We also introduce post-processing step using convolutional network trained GEDI observation . We evaluate proposed map set-aside validation lidar data well comparing remotely sensed map field-collected data find model produce average Mean Absolute Error ( MAE ) 2.8 meter Mean Error ( ME ) 0.6 meter .
Manifold model provide low-dimensional representation useful processing analyzing data transformation-invariant way . In paper study problem learning smooth pattern transformation manifold image set represent observation geometrically transformed signal . In order construct manifold build representative pattern whose transformation accurately fit various input image . We examine two objective manifold building problem namely approximation classification . For approximation problem propose greedy method construct representative pattern selecting analytic atom continuous dictionary manifold . We present DC ( Difference-of-Convex ) optimization scheme applicable wide range transformation dictionary model demonstrate application transformation manifold generated rotation translation anisotropic scaling reference pattern . Then generalize approach setting multiple transformation manifold manifold represents different class signal . We present iterative multiple manifold building algorithm classification accuracy promoted learning representative pattern . Experimental result suggest proposed method yield high accuracy approximation classification data compared reference method invariance geometric transformation achieved due transformation manifold model .
An accurate substantial dataset essential training reliable well-performing model . However even manually annotated datasets contain label error mention automatically labeled one . Previous method label denoising primarily focused detecting outlier permanent removal - process likely over- underfilter dataset . In work propose AGRA : new method learning noisy label using Adaptive GRAdient-based outlier removal . Instead cleaning dataset prior model training dataset dynamically adjusted training process . By comparing aggregated gradient batch sample individual example gradient method dynamically decides whether corresponding example helpful model point counter-productive left current update . Extensive evaluation several datasets demonstrates AGRA 's effectiveness comprehensive result analysis support initial hypothesis : permanent hard outlier removal always model benefit .
Deformable image registration fundamental many medical image analysis . A key obstacle accurate image registration lie image appearance variation variation texture intensity noise . These variation readily apparent medical image especially brain image registration frequently used . Recently deep learning-based registration method ( DLRs ) using deep neural network shown computational efficiency several order magnitude faster traditional optimization-based registration method ( ORs ) . DLRs rely globally optimized network trained set training sample achieve faster registration . DLRs tend however disregard target-pair-specific optimization inherent ORs thus degraded adaptability variation testing sample . This limitation severe registering medical image large appearance variation especially since existing DLRs explicitly take account appearance variation . In study propose Appearance Adjustment Network ( AAN ) enhance adaptability DLRs appearance variation . Our AAN integrated DLR provides appearance transformation reduce appearance variation registration . In addition propose anatomy-constrained loss function AAN generates anatomy-preserving transformation . Our AAN purposely designed readily inserted wide range DLRs trained cooperatively unsupervised end-to-end manner . We evaluated AAN three state-of-the-art DLRs three well-established public datasets 3D brain magnetic resonance imaging ( MRI ) . The result show AAN consistently improved existing DLRs outperformed state-of-the-art ORs registration accuracy adding fractional computational load existing DLRs .
We propose ClipFace novel self-supervised approach text-guided editing textured 3D morphable model face . Specifically employ user-friendly language prompt enable control expression well appearance 3D face . We leverage geometric expressiveness 3D morphable model inherently possess limited controllability texture expressivity develop self-supervised generative model jointly synthesize expressive textured articulated face 3D . We enable high-quality texture generation 3D face adversarial self-supervised training guided differentiable rendering collection real RGB image . Controllable editing manipulation given language prompt adapt texture expression 3D morphable model . To end propose neural network predicts texture expression latent code morphable model . Our model trained self-supervised fashion exploiting differentiable rendering loss based pre-trained CLIP model . Once trained model jointly predicts face texture UV-space along expression parameter capture geometry texture change facial expression single forward pas . We show applicability method generate temporally changing texture given animation sequence .
Berkeley FrameNet lexico-semantic resource English based theory frame semantics . It exploited range natural language processing application inspired development framenets many language . We present methodological approach extraction generation computational multilingual FrameNet-based grammar lexicon . The approach leverage FrameNet-annotated corpus automatically extract set cross-lingual semantico-syntactic valence pattern . Based data Berkeley FrameNet Swedish FrameNet proposed approach implemented Grammatical Framework ( GF ) categorial grammar formalism specialized multilingual grammar . The implementation grammar lexicon supported design FrameNet providing frame semantic abstraction layer interlingual semantic API ( application programming interface ) interlingual syntactic API already provided GF Resource Grammar Library . The evaluation acquired grammar lexicon show feasibility approach . Additionally illustrate FrameNet-based grammar lexicon exploited two distinct multilingual controlled natural language application . The produced resource available open source license .
Emotion key element user-generated video . However difficult understand emotion conveyed video due complex unstructured nature user-generated content sparsity video frame expressing emotion . In paper first time study problem transferring knowledge heterogeneous external source including image textual data facilitate three related task understanding video emotion : emotion recognition emotion attribution emotion-oriented summarization . Specifically framework ( 1 ) learns video encoding auxiliary emotional image dataset order improve supervised video emotion recognition ( 2 ) transfer knowledge auxiliary textual corpus zero-shot recognition emotion class unseen training . The proposed technique knowledge transfer facilitates novel application emotion attribution emotion-oriented summarization . A comprehensive set experiment multiple datasets demonstrate effectiveness framework .
Domain adaptation solves learning problem target domain leveraging knowledge relevant source domain . While remarkable advance made almost existing domain adaptation method heavily require large amount unlabeled target domain data learning domain invariant representation achieve good generalizability target domain . In fact many real-world application target domain data may always available . In paper study case training phase target domain data unavailable well-labeled source domain data available called robust domain adaptation . To tackle problem assumption causal relationship feature class variable robust across domain propose novel Causal AutoEncoder ( CAE ) integrates deep autoencoder causal structure learning unified model learn causal representation using data single source domain . Specifically deep autoencoder model adopted learn low-dimensional representation causal structure learning model designed separate low-dimensional representation two group : causal representation task-irrelevant representation . Using three real-world datasets extensive experiment validated effectiveness CAE compared eleven state-of-the-art method .
Recent advance protecting node privacy graph data attacking graph neural network ( GNNs ) gain much attention . The eye bring two essential task together yet . Imagine adversary utilize powerful GNNs infer user ' private label social network . How adversarially defend privacy attack maintaining utility perturbed graph ? In work propose novel research task adversarial defense GNN-based privacy attack present graph perturbation-based approach NetFense achieve goal . NetFense simultaneously keep graph data unnoticeability ( i.e . limited change graph structure ) maintain prediction confidence targeted label classification ( i.e . preserving data utility ) reduce prediction confidence private label classification ( i.e . protecting privacy node ) . Experiments conducted single- multiple-target perturbation using three real graph data exhibit perturbed graph NetFense effectively maintain data utility ( i.e . model unnoticeability ) targeted label classification significantly decrease prediction confidence private label classification ( i.e . privacy protection ) . Extensive study also bring several insight flexibility NetFense preserving local neighborhood data unnoticeability better privacy protection high-degree node .
This paper present robust dynamic face recognition technique based extraction matching devised probabilistic graph drawn SIFT feature related independent face area . The face matching strategy based matching individual salient facial graph characterized SIFT feature connected facial landmark eye mouth . In order reduce face matching error Dempster-Shafer decision theory applied fuse individual matching score obtained pair salient facial feature . The proposed algorithm evaluated ORL IITK face database . The experimental result demonstrate effectiveness potential proposed face recognition technique also case partially occluded face .
Bridge inspection important step preserving rehabilitating transportation infrastructure extending service life . The advancement mobile robotic technology allows rapid collection large amount inspection video data . However data mainly image complex scene wherein bridge various structural element mix cluttered background . Assisting bridge inspector extracting structural element bridge big complex video data sorting class prepare inspector element-wise inspection determine condition bridge . This paper motivated develop assistive intelligence model segmenting multiclass bridge element inspection video captured aerial inspection platform . With small initial training dataset labeled inspector Mask Region-based Convolutional Neural Network ( Mask R-CNN ) pre-trained large public dataset transferred new task multiclass bridge element segmentation . Besides temporal coherence analysis attempt recover false negative identify weakness neural network learn improve . Furthermore semi-supervised self-training ( S $ ^3 $ T ) method developed engage experienced inspector refining network iteratively . Quantitative qualitative result evaluating developed deep neural network demonstrate proposed method utilize small amount time guidance experienced inspector ( 3.58 hour labeling 66 image ) build network excellent performance ( 91.8 % precision 93.6 % recall 92.7 % f1-score ) . Importantly paper illustrates approach leveraging domain knowledge experience bridge professional computational intelligence model efficiently adapt model varied bridge National Bridge Inventory .
Context : The number TV series offered nowadays high . Due large amount many series canceled due lack originality generates low audience . Problem : Having decision support system show show huge success would facilitate choice renewing starting show . Solution : We studied case series Arrow broadcasted CW Network used descriptive predictive modeling technique predict IMDb rating . We assumed theme episode would affect evaluation user dataset composed director episode number review episode got percentual theme extracted Latent Dirichlet Allocation ( LDA ) model episode number viewer Wikipedia rating IMDb . The LDA model generative probabilistic model collection document made word . Method : In prescriptive research case study method used result analyzed using quantitative approach . Summary Results : With feature episode model performed best predict rating Catboost due similar mean squared error KNN model better standard deviation test phase . It possible predict IMDb rating acceptable root mean squared error 0.55 .
Multimodal electronic health record ( EHR ) data widely used clinical application . Conventional method usually assume sample ( patient ) associated unified observed modality modality available sample . However missing modality caused various clinical social reason common issue real-world clinical scenario . Existing method mostly rely solving generative model learns mapping latent space original input space unstable ill-posed inverse problem . To relieve underdetermined system propose model solving direct problem dubbed learning Missing Modalities Multimodal healthcare data ( M3Care ) . M3Care end-to-end model compensating missing information patient missing modality perform clinical analysis . Instead generating raw missing data M3Care imputes task-related information missing modality latent space auxiliary information patient 's similar neighbor measured task-guided modality-adaptive similarity metric thence conduct clinical task . The task-guided modality-adaptive similarity metric utilizes uncensored modality patient patient also uncensored modality find similar patient . Experiments real-world datasets show M3Care outperforms state-of-the-art baseline . Moreover finding discovered M3Care consistent expert medical knowledge demonstrating capability potential providing useful insight explanation .
In work examine evaluation process task detecting financial report high risk containing misstatement . This task often referred literature `` misstatement detection financial report `` . We provide extensive review related literature . We propose new realistic evaluation framework task unlike large part previous work : ( ) focus misstatement class rarity ( b ) considers dimension time splitting data training test ( c ) considers fact misstatement take long time detect . Most importantly show evaluation process significantly affect system performance analyze performance different model feature type new realistic framework .
As major branch Non-Photorealistic Rendering ( NPR ) image stylization mainly us computer algorithm render photo artistic painting . Recent work shown extraction style information stroke texture color target style image key image stylization . Given stroke texture color characteristic new stroke rendering method proposed fully considers tonal characteristic representative color original oil painting order fit tone original oil painting image stylized image make close artist 's creative effect . The experiment validated efficacy proposed model . This method would suitable work pointillism painter relatively uniform sense direction especially natural scene . When original painting brush stroke clearer sense direction using method simulate brushwork texture feature less satisfactory .
In order handle modern convolutional neural network ( CNNs ) efficiently hardware architecture CNN inference accelerator proposed handle depthwise convolution regular convolution essential building block embedded-computer-vision algorithm . Different related work proposed architecture support filter kernel different size high flexibility since require extra cost intra-kernel parallelism generate convolution result faster architecture related work . The experimental result show importance supporting depthwise convolution dilated convolution proposed hardware architecture . In addition depthwise convolution large-kernels new structure called DDC layer includes combination depthwise convolution dilated convolution also analyzed paper . For face detection computational cost decrease 30 % model size decrease 20 % DDC layer applied network . For image classification accuracy increased 1 % simply replacing $ 3 \times 3 $ filter $ 5 \times 5 $ filter depthwise convolution .
Pseudo-relevance feedback mechanism Rocchio relevance model shown usefulness expanding reweighting user ' initial query using information occurring initial set retrieved document known pseudo-relevant set . Recently dense retrieval -- use neural contextual language model BERT analysing document ' query ' content computing relevance score -- shown promising performance several information retrieval task still relying traditional inverted index identifying document relevant query . Two different dense retrieval family emerged : use single embedded representation passage query ( e.g . using BERT 's [ CLS ] token ) via multiple representation ( e.g . using embedding token query document ) . In work conduct first study potential multiple representation dense retrieval enhanced using pseudo-relevance feedback . In particular based pseudo-relevant set document identified using first-pass dense retrieval extract representative feedback embeddings ( using KMeans clustering ) -- ensuring embeddings discriminate among passage ( based IDF ) -- added query representation . These additional feedback embeddings shown enhance effectiveness reranking well additional dense retrieval operation . Indeed experiment MSMARCO passage ranking dataset show MAP improved upto 26 % TREC 2019 query set 10 % TREC 2020 query set application proposed ColBERT-PRF method ColBERT dense retrieval approach .
This survey give overview Monte Carlo methodology using surrogate model dealing density intractable costly and/or noisy . This type problem found numerous real-world scenario including stochastic optimization reinforcement learning evaluation density function may incur computationally-expensive even physical ( real-world activity ) cost likely give different result time . The surrogate model incur cost important trade-off consideration involved choice design methodology . We classify different methodology three main class describe specific instance algorithm unified notation . A modular scheme encompasses considered method also presented . A range application scenario discussed special attention likelihood-free setting reinforcement learning . Several numerical comparison also provided .
Volumetric change glioblastoma multiforme ( GBM ) time critical factor treatment decision . Typically tumor volume computed slice-by-slice basis using MRI scan obtained regular interval . ( 3D ) Slicer - free platform biomedical research - provides alternative manual slice-by-slice segmentation process significantly faster requires less user interaction . In study 4 physician segmented GBMs 10 patient using competitive region-growing based GrowCut segmentation module Slicer purely drawing boundary completely manually slice-by-slice basis . Furthermore provide variability analysis three physician 12 GBMs . The time required GrowCut segmentation average 61 % time required pure manual segmentation . A comparison Slicer-based segmentation manual slice-by-slice segmentation resulted Dice Similarity Coefficient 88.43 +/- 5.23 % Hausdorff Distance 2.32 +/- 5.23 mm .
Achieving human-level performance Machine Reading Comprehension ( MRC ) datasets longer challenging help powerful Pre-trained Language Models ( PLMs ) . However necessary provide answer prediction explanation improve MRC system 's reliability especially real-life application . In paper propose new benchmark called ExpMRC evaluating explainability MRC system . ExpMRC contains four subset including SQuAD CMRC 2018 RACE $ ^+ $ C $ ^3 $ additional annotation answer 's evidence . The MRC system required give correct answer also explanation . We use state-of-the-art pre-trained language model build baseline system adopt various unsupervised approach extract evidence without human-annotated training set . The experimental result show model still far human performance suggesting ExpMRC challenging . Resources available http : //github.com/ymcui/expmrc
Combined joint intra-governmental inter-agency multinational ( CJIIM ) operation require rapid data sharing without bottleneck metadata curation alignment . Curation alignment particularly infeasible external open source information ( OSINF ) e.g . social medium become increasingly valuable understanding unfolding situation . Large language model ( transformer ) facilitate semantic data metadata alignment inefficient CJIIM setting characterised denied degraded intermittent low bandwidth ( DDIL ) . Vector symbolic architecture ( VSA ) support semantic information processing using highly compact binary vector typically 1-10k bit suitable DDIL setting . We demonstrate novel integration transformer model VSA combining power former semantic matching compactness representational structure latter . The approach illustrated via proof-of-concept OSINF data discovery portal allows partner CJIIM operation share data source minimal metadata curation low communication bandwidth . This work carried bridge previous low technology readiness level ( TRL ) research future higher-TRL technology demonstration deployment .
We recently developed new approach get stabilized image sequence frame acquired atmospheric turbulence . The goal algorihtm remove geometric distortion due atmosphere movement . This method based variational formulation efficiently solved use Bregman iteration operator splitting method . In paper propose study influence choice regularizing term model . Then proposed experiment used regularization constraint available litterature .
Driven recent vision graphic application image segmentation object recognition computing pixel-accurate saliency value uniformly highlight foreground object becomes increasingly important . In paper propose unified framework called PISA stand Pixelwise Image Saliency Aggregating various bottom-up cue prior . It generates spatially coherent yet detail-preserving pixel-accurate fine-grained saliency overcomes limitation previous method use homogeneous superpixel-based color treatment . PISA aggregate multiple saliency cue global context complementary color structure contrast measure spatial prior image domain . The saliency confidence jointly modeled neighborhood consistence constraint energy minimization formulation pixel evaluated multiple hypothetical saliency level . Instead using global discrete optimization method employ cost-volume filtering technique solve formulation assigning saliency level smoothly preserving edge-aware structure detail . In addition faster version PISA developed using gradient-driven image sub-sampling strategy greatly improve runtime efficiency keeping comparable detection accuracy . Extensive experiment number public datasets suggest PISA convincingly outperforms state-of-the-art approach . In addition work also create new dataset containing $ 800 $ commodity image evaluating saliency detection . The dataset source code PISA downloaded http : //vision.sysu.edu.cn/project/PISA/
Recently generating adversarial example become important mean measuring robustness deep learning model . Adversarial example help u identify susceptibility model counter vulnerability applying adversarial training technique . In natural language domain small perturbation form misspelling paraphrase drastically change semantics text . We propose reinforcement learning based approach towards generating adversarial example black-box setting . We demonstrate method able fool well-trained model ( ) IMDB sentiment classification task ( b ) AG 's news corpus news categorization task significantly high success rate . We find adversarial example generated semantics-preserving perturbation original text .
Vascular graph embed number high-level feature morphological parameter functional biomarkers represent invaluable tool longitudinal cross-sectional clinical inference . This however feasible graph co-registered together allowing coherent multiple comparison . The robust registration vascular topology stand therefore key enabling technology group-wise analysis . In work present end-to-end vascular graph registration approach aligns network non-linear geometry topological deformation introducing novel overconnected geodesic vascular graph formulation without enforcing anatomical prior constraint . The 3D elastic graph registration performed state-of-the-art graph matching method used computer vision . Promising result vascular matching found using graph synthetic real angiography . Observations future design discussed towards potential clinical application .
In recent year growing interest image generation deep learning . While important part evaluation generated image usually involves visual inspection inclusion human perception factor training process often overlooked . In paper propose alternative perceptual regulariser image-to-image translation using conditional generative adversarial network ( cGANs ) . To automatically ( avoiding visual inspection ) use Normalised Laplacian Pyramid Distance ( NLPD ) measure perceptual similarity generated image original image . The NLPD based principle normalising value coefficient respect local estimate mean energy different scale already successfully tested different experiment involving human perception . We compare regulariser originally proposed L1 distance note using NLPD generated image contain realistic value local global contrast . We found using NLPD regulariser improves image segmentation accuracy generated image well improving two no-reference image quality metric .
Face detection one relevant application image processing biometric system . Artificial neural network ( ANN ) used field image processing pattern recognition . There lack literature survey give overview study research related using ANN face detection . Therefore research includes general review face detection study system based different ANN approach algorithm . The strength limitation literature study system included also .
Autonomous car indispensable human go hands-free route . Although existing literature highlight acceptance autonomous car increase drive human-like manner sparse research offer naturalistic experience passenger 's seat perspective examine humanness current autonomous car . The present study tested whether AI driver could create human-like ride experience passenger based 69 participant ' feedback real-road scenario . We designed ride experience-based version non-verbal Turing test automated driving . Participants rode autonomous car ( driven either human AI driver ) passenger judged whether driver human AI . The AI driver failed pas test passenger detected AI driver chance . In contrast human driver drove car passenger ' judgement around chance . We investigated human passenger ascribe humanness test . Based Lewin 's field theory advanced computational model combining signal detection theory pre-trained language model predict passenger ' humanness rating behaviour . We employed affective transition pre-study baseline emotion corresponding post-stage emotion signal strength model . Results showed passenger ' ascription humanness would increase greater affective transition . Our study suggested important role affective transition passenger ' ascription humanness might become future direction autonomous driving .
Many visual representation volume-rendered image metro map feature noticeable amount information loss . At glance seem numerous opportunity viewer misinterpret data visualized hence undermining benefit visual representation . In practice little doubt visual representation useful . The recently-proposed information-theoretic measure analyzing cost-benefit ratio visualization process explain usefulness experienced practice postulate viewer ' knowledge reduce potential distortion ( e.g . misinterpretation ) due information loss . This suggests viewer ' knowledge estimated comparing potential distortion without knowledge actual distortion knowledge . In paper describe several case study collecting instance ( ) support evaluation several candidate measure estimating potential distortion distortion visualization ( ii ) demonstrate applicability practical scenario . Because theoretical discourse choosing appropriate bounded measure estimating potential distortion yet conclusive real world data visualization informs selection bounded measure providing practical evidence aid theoretical conclusion . Meanwhile measure potential distortion bounded manner interpret numerical value characterizing benefit visualization intuitively .
Matching articulated shape represented voxel-sets reduces maximal sub-graph isomorphism set described weighted graph . Spectral graph theory used map graph onto lower dimensional space match shape aligning embeddings virtue invariance change pose . Classical graph isomorphism scheme relying ordering eigenvalue align eigenspaces fail handling large data-sets noisy data . We derive new formulation find best alignment two congruent $ K $ -dimensional set point selecting best subset eigenfunctions Laplacian matrix . The selection done matching eigenfunction signature built histogram retained set provides smart initialization alignment problem considerable impact overall performance . Dense shape matching casted graph matching reduces point registration embeddings orthogonal transformation ; registration solved using framework unsupervised clustering EM algorithm . Maximal subset matching non identical shape handled defining appropriate outlier class . Experimental result challenging example show algorithm naturally treat change topology shape variation different sampling density .
Well-established automatic analysis text mainly consider frequency linguistic unit e.g . letter word bigram method based co-occurrence network consider structure text regardless node label ( i.e . word semantics ) . In paper reconcile distinct viewpoint introducing generalized similarity measure compare text account network structure text role individual word network . We use similarity measure authorship attribution three collection book composed 8 author 10 book per author . High accuracy rate obtained typical value 90 % 98.75 % much higher traditional TF-IDF approach collection . These accuracy also higher taking topology network account . We conclude different property specific word macroscopic scale structure whole text relevant frequency appearance ; conversely considering identity node brings knowledge piece text represented network .
There opportunity modern power system explore demand flexibility incentivizing consumer dynamic price . In paper quantify demand flexibility using efficient tool called time-varying elasticity whose value may change depending price decision dynamic . This tool particularly useful evaluating demand response potential system reliability . Recent empirical evidence highlighted abnormal feature studying demand flexibility delayed response vanishing elasticity price spike . Existing method fail capture complicated feature heavily rely predefined ( often over-simplified ) regression expression . Instead paper proposes model-free methodology automatically accurately derive optimal estimation pattern . We develop two-stage estimation process Siamese long short-term memory ( LSTM ) network . Here LSTM network encodes price response network estimate time-varying elasticity . In case study proposed framework model validated achieve higher overall estimation accuracy better description various abnormal feature compared state-of-the-art method .
Sparsity-based subspace clustering algorithm attracted significant attention thanks excellent performance practical application . A prominent example sparse subspace clustering ( SSC ) algorithm Elhamifar Vidal performs spectral clustering based adjacency matrix obtained sparsely representing data point term data point via Lasso . When number data point large dimension ambient space high computational complexity SSC quickly becomes prohibitive . Dyer et al . observed SSC-OMP obtained replacing Lasso greedy orthogonal matching pursuit ( OMP ) algorithm result significantly lower computational complexity often yielding comparable performance . The central goal paper analytical performance characterization SSC-OMP noisy data . Moreover introduce analyze SSC-MP algorithm employ matching pursuit ( MP ) lieu OMP . Both SSC-OMP SSC-MP proven succeed even subspace intersect data point contaminated severe noise . The clustering condition obtain SSC-OMP SSC-MP similar SSC thresholding-based subspace clustering ( TSC ) algorithm due Heckel B\ `` olcskei . Analytical result combination numerical result indicate SSC-OMP SSC-MP data-dependent stopping criterion automatically detect dimension subspace underlying data . Moreover experiment synthetic real data show SSC-MP compare favorably SSC SSC-OMP TSC nearest subspace neighbor algorithm term clustering performance running time . In addition find contrast SSC-OMP performance SSC-MP robust respect choice parameter stopping criterion .
As front-burner problem incremental learning class incremental semantic segmentation ( CISS ) plagued catastrophic forgetting semantic drift . Although recent method utilized knowledge distillation transfer knowledge old model still unable avoid pixel confusion result severe misclassification incremental step due lack annotation past future class . Meanwhile data-replay-based approach suffer storage burden privacy concern . In paper propose address CISS without exemplar memory resolve catastrophic forgetting well semantic drift synchronously . We present Inherit Distillation Evolve Contrast ( IDEC ) consists Dense Knowledge Distillation Aspects ( DADA ) manner Asymmetric Region-wise Contrastive Learning ( ARCL ) module . Driven devised dynamic class-specific pseudo-labelling strategy DADA distils intermediate-layer feature output-logits collaboratively emphasis semantic-invariant knowledge inheritance . ARCL implement region-wise contrastive learning latent space resolve semantic drift among known class current class unknown class . We demonstrate effectiveness method multiple CISS task state-of-the-art performance including Pascal VOC 2012 ADE20K ISPRS datasets . Our method also show superior anti-forgetting ability particularly multi-step CISS task .
This study evaluates effectiveness machine learning ( ML ) deep learning ( DL ) model detecting COVID-19-related misinformation online social network ( OSNs ) aiming develop effective tool countering spread health misinformation pan-demic . The study trained tested various ML classifier ( Naive Bayes SVM Random Forest etc . ) DL model ( CNN LSTM hybrid CNN+LSTM ) pretrained language model ( DistilBERT RoBERTa ) `` COVID19-FNIR DATASET `` . These model evaluated accuracy F1 score recall precision ROC used preprocessing technique like stemming lemmatization . The result showed SVM performed well achieving 94.41 % F1-score . DL model Word2Vec embeddings exceeded 98 % performance metric ( accuracy F1 score recall precision & ROC ) . The CNN+LSTM hybrid model also exceeded 98 % across performance metric outperforming pretrained model like DistilBERT RoBERTa . Our study concludes DL hybrid DL model effective conventional ML algorithm detecting COVID-19 misinformation OSNs . The finding highlight importance advanced neural network approach large-scale pretraining misinformation detection . Future research optimize model various misinformation type adapt changing OSNs aiding combating health misinformation .
Cross-modal hashing favored effectiveness efficiency received wide attention facilitating efficient retrieval across different modality . Nevertheless existing method sufficiently exploit discriminative power semantic information learning hash code often involving time-consuming training procedure handling large-scale dataset . To tackle issue formulate learning similarity-preserving hash code term orthogonally rotating semantic data minimize quantization loss mapping data hamming space propose efficient Fast Discriminative Discrete Hashing ( FDDH ) approach large-scale cross-modal retrieval . More specifically FDDH introduces orthogonal basis regress targeted hash code training example corresponding semantic label utilizes `` -dragging technique provide provable large semantic margin . Accordingly discriminative power semantic information explicitly captured maximized . Moreover orthogonal transformation scheme proposed map nonlinear embedding data semantic subspace well guarantee semantic consistency data feature semantic representation . Consequently efficient closed form solution derived discriminative hash code learning computationally efficient . In addition effective stable online learning strategy presented optimizing modality-specific projection function featuring adaptivity different training size streaming data . The proposed FDDH approach theoretically approximates bi-Lipschitz continuity run sufficiently fast also significantly improves retrieval performance state-of-the-art method . The source code released : http : //github.com/starxliu/FDDH .
Breast cancer significant health concern affecting million woman worldwide . Accurate survival risk stratification play crucial role guiding personalised treatment decision improving patient outcome . Here present BioFusionNet deep learning framework fuse image-derived feature genetic clinical data obtain holistic profile achieve survival risk stratification ER+ breast cancer patient . We employ multiple self-supervised feature extractor ( DINO MoCoV3 ) pretrained histopathological patch capture detailed image feature . These feature fused variational autoencoder fed self-attention network generating patient-level feature . A co-dual-cross-attention mechanism combine histopathological feature genetic data enabling model capture interplay . Additionally clinical data incorporated using feed-forward network enhancing predictive performance achieving comprehensive multimodal feature integration . Furthermore introduce weighted Cox loss function specifically designed handle imbalanced survival data common challenge . Our model achieves mean concordance index 0.77 time-dependent area curve 0.84 outperforming state-of-the-art method . It predicts risk ( high versus low ) prognostic significance overall survival univariate analysis ( HR=2.99 95 % CI : 1.88 -- 4.78 p < 0.005 ) maintains independent significance multivariate analysis incorporating standard clinicopathological variable ( HR=2.91 95\ % CI : 1.80 -- 4.68 p < 0.005 ) .
We feel happy web-browsing operation provide u necessary information ; otherwise feel bitter . How measure happiness ( bitterness ) ? How profile happiness grow decay course web-browsing ? We propose probabilistic framework model evolution user satisfaction top his/her continuous frustration finding required information . It found cumulative satisfaction profile web-searching individual modeled effectively sum random number random term term mutually independent random variable originating 'memoryless ' Poisson flow . Evolution satisfaction entire time interval user 's browsing modeled auto-correlation analysis . A utilitarian marker magnitude greater unity describe happy web-searching operation ; empirical limit connects user 's satisfaction frustration level - proposed . Presence pertinent information first page web-site magnitude decay parameter user satisfaction ( frustration irritation etc . ) found two key aspect dominate web-browser 's psychology . The proposed model employed different combination decay parameter searching time number helpful web-sites . Obtained result found match result three real-life case-studies .
Neural architecture search ( NAS ) emerged promising avenue automatically designing task-specific neural network . Existing NAS approach require one complete search deployment specification hardware objective . This computationally impractical endeavor given potentially large number application scenario . In paper propose Neural Architecture Transfer ( NAT ) overcome limitation . NAT designed efficiently generate task-specific custom model competitive multiple conflicting objective . To realize goal learn task-specific supernets specialized subnets sampled without additional training . The key approach integrated online transfer learning many-objective evolutionary search procedure . A pre-trained supernet iteratively adapted simultaneously searching task-specific subnets . We demonstrate efficacy NAT 11 benchmark image classification task ranging large-scale multi-class small-scale fine-grained datasets . In case including ImageNet NATNets improve upon state-of-the-art mobile setting ( $ \leq $ 600M Multiply-Adds ) . Surprisingly small-scale fine-grained datasets benefit NAT . At time architecture search transfer order magnitude efficient existing NAS method . Overall experimental evaluation indicates across diverse image classification task computational objective NAT appreciably effective alternative conventional transfer learning fine-tuning weight existing network architecture learned standard datasets . Code available http : //github.com/human-analysis/neural-architecture-transfer
Respiratory motion associated deformation abdominal organ tumor essential information clinical application . However inter- intra-patient multi-organ deformation complex statistically formulated whereas single organ deformation widely studied . In paper introduce multi-organ deformation library application deformation reconstruction based shape feature multiple abdominal organ . Statistical multi-organ motion/deformation model stomach liver left right kidney duodenum generated shape matching region label defined four-dimensional computed tomography image . A total 250 volume measured 25 pancreatic cancer patient . This paper also proposes per-region-based deformation learning using reproducing kernel predict displacement pancreatic cancer adaptive radiotherapy . The experimental result show proposed concept estimate deformation better general per-patient-based learning model achieves clinically acceptable estimation error mean distance 1.2 $ \pm $ 0.7 mm Hausdorff distance 4.2 $ \pm $ 2.3 mm throughout respiratory motion .
We present incomplete gamma kernel generalization Locally Optimal Projection ( LOP ) operator . In particular reveal relation classical localized $ L_1 $ estimator used LOP operator point cloud denoising common Mean Shift framework via novel kernel . Furthermore generalize result whole family kernel built upon incomplete gamma function represents localized $ L_p $ estimator . By deriving various property kernel family concerning distributional Mean Shift induced aspect strict positive definiteness obtain deeper understanding operator 's projection behavior . From theoretical insight illustrate several application ranging improved Weighted LOP ( WLOP ) density weighting scheme accurate Continuous LOP ( CLOP ) kernel approximation definition novel set robust loss function . These incomplete gamma loss include Gaussian LOP loss special case applied various task including normal filtering . Furthermore show novel kernel included prior neural network . We demonstrate effect application range quantitative qualitative experiment highlight benefit induced modification .
This paper develops hierarchical reinforcement learning architecture multimission spaceflight campaign design uncertainty including vehicle design infrastructure deployment planning space transportation scheduling . This problem involves high-dimensional design space challenging especially uncertainty present . To tackle challenge developed framework hierarchical structure reinforcement learning network-based mixed-integer linear programming ( MILP ) former optimizes campaign-level decision ( e.g . design vehicle used throughout campaign destination demand assigned mission campaign ) whereas latter optimizes detailed mission-level decision ( e.g . launch ) . The framework applied set human lunar exploration campaign scenario uncertain situ resource utilization performance case study . The main value work integration rapidly growing reinforcement learning research existing MILP-based space logistics method hierarchical framework handle otherwise intractable complexity space mission design uncertainty . This unique framework expected critical steppingstone emerging research direction artificial intelligence space mission design .
The tracing neural pathway large volume image data incredibly tedious time-consuming process significantly encumbers progress neuroscience . We exploring deep learning 's potential automate segmentation high-resolution scanning electron microscope ( SEM ) image data remove barrier . We started neural pathway tracing 5.1GB whole-brain serial-section slice larval zebrafish collected Center Brain Science Harvard University . This kind manual image segmentation requires year careful work properly trace neural pathway organism small zebrafish larva ( approximately 5mm total body length ) . In automating process would vastly improve productivity leading faster data analysis breakthrough understanding complexity brain . We build upon prior attempt employ deep learning automatic image segmentation extending method unconventional deep learning data .
Traditional image codecs emphasize signal fidelity human perception often expense machine vision task . Deep learning method demonstrated promising coding performance utilizing rich semantic embeddings optimized human machine vision . However compact embeddings struggle capture fine detail contour texture resulting imperfect reconstruction . Furthermore existing learning-based codecs lack scalability . To address limitation paper introduces content-adaptive diffusion model scalable image compression . The proposed method encodes fine texture diffusion process enhancing perceptual quality preserving essential feature machine vision task . The approach employ Markov palette diffusion model combined widely used feature extractor image generator enabling efficient data compression . By leveraging collaborative texture-semantic feature extraction pseudo-label generation method accurately capture texture information . A content-adaptive Markov palette diffusion model applied represent low-level texture high-level semantic content scalable manner . This framework offer flexible control compression ratio selecting intermediate diffusion state eliminating need retraining deep learning model different operating point . Extensive experiment demonstrate effectiveness proposed framework image reconstruction downstream machine vision task object detection segmentation facial landmark detection achieving superior perceptual quality compared state-of-the-art method .
The general aim multi-focus image fusion gather focused region different image generate unique all-in-focus fused image . Deep learning based method become mainstream image fusion virtue powerful feature representation ability . However existing deep learning structure failed balance fusion quality end-to-end implementation convenience . End-to-end decoder design often lead unrealistic result non-linear mapping mechanism . On hand generating intermediate decision map achieves better quality fused image relies rectification empirical post-processing parameter choice . In work handle requirement output image quality comprehensive simplicity structure implementation propose cascade network simultaneously generate decision map fused result end-to-end training procedure . It avoids dependence empirical post-processing method inference stage . To improve fusion quality introduce gradient aware loss function preserve gradient information output fused image . In addition design decision calibration strategy decrease time consumption application multiple image fusion . Extensive experiment conducted compare 19 different state-of-the-art multi-focus image fusion structure 6 assessment metric . The result prove designed structure generally ameliorate output fused image quality implementation efficiency increase 30\ % multiple image fusion .
We study linear model heavy-tailed prior probabilistic viewpoint . Instead computing single sparse probable ( MAP ) solution standard deterministic approach focus Bayesian compressed sensing framework shift towards capturing full posterior distribution latent variable allows quantifying estimation uncertainty learning model parameter using maximum likelihood . The exact posterior distribution sparse linear model intractable concentrate variational Bayesian technique approximate . Repeatedly computing Gaussian variance turn key requisite constitutes main computational bottleneck applying variational technique large-scale problem . We leverage recently proposed Perturb-and-MAP algorithm drawing exact sample Gaussian Markov random field ( GMRF ) . The main technical contribution paper show estimating Gaussian variance using relatively small number efficiently drawn random sample much effective alternative general-purpose variance estimation technique . By reducing problem variance estimation standard optimization primitive resulting variational algorithm fully scalable parallelizable allowing Bayesian computation extremely large-scale problem memory time complexity requirement conventional point estimation technique . We illustrate idea experiment image deblurring .
In letter propose novel computationally efficient coupled dictionary learning method enforces pairwise correlation atom dictionary learned represent underlying feature space two different representation signal e.g . representation different modality representation signal measured different quality . The jointly learned correlated feature space represented coupled dictionary used sparse representation based classification recognition reconstruction task . The presented experimental result show proposed coupled dictionary learning method significantly lower computational cost . Moreover visual presentation jointly learned dictionary show pairwise correlation corresponding atom ensured .
Music preference reported factor could elicit innermost music emotion entailing accurate ground-truth data music therapy efficiency . This study executes statistical analysis investigate distinction music preference familiarity score response time ( response rate ) brain response ( EEG ) . Twenty participant self-assessment listening two type popular music 's chorus section : music without lyric ( Melody ) music lyric ( Song ) . \textcolor { red } { We conduct music preference classification using support vector machine random forest k-nearest neighbor familiarity score response rate EEG feature vector . The statistical analysis F1-score EEG congruent brain 's right side outperformed left side classification performance . } Finally behavioral brain study support preference familiarity response rate contribute music emotion experiment 's design understand music emotion listener . Not music industry biomedical healthcare industry also exploit experiment collect data patient improve efficiency healing music .
UAV-based intelligent data acquisition 3D reconstruction monitoring infrastructure experienced increasing surge interest due recent advancement image processing deep learning-based technique . View planning essential part task dictate information capture strategy heavily impact quality 3D model generated captured data . Recent method used prior knowledge partial reconstruction target accomplish view planning active reconstruction ; former approach pose challenge complex newly identified target latter computationally expensive . In work present Bag-of-Views ( BoV ) fully appearance-based model used assign utility captured view offline dataset refinement online next-best-view ( NBV ) planning application targeting task 3D reconstruction . With contribution also developed View Planning Toolbox ( VPT ) lightweight package training testing machine learning-based view planning framework custom view dataset generation arbitrary 3D scene 3D reconstruction . Through experiment pair BoV-based reinforcement learning model VPT demonstrate efficacy model reducing number required view high-quality reconstruction dataset refinement NBV planning .
Microgrids ( MGs ) small local power grid operate independently larger utility grid . Combined Internet Things ( IoT ) smart MG leverage sensory data machine learning technique intelligent energy management . This paper focus deep reinforcement learning ( DRL ) -based energy dispatch IoT-driven smart isolated MGs diesel generator ( DGs ) photovoltaic ( PV ) panel battery . A finite-horizon Partial Observable Markov Decision Process ( POMDP ) model formulated solved learning historical data capture uncertainty future electricity consumption renewable power generation . In order deal instability problem DRL algorithm unique characteristic finite-horizon model two novel DRL algorithm namely finite-horizon deep deterministic policy gradient ( FH-DDPG ) finite-horizon recurrent deterministic policy gradient ( FH-RDPG ) proposed derive energy dispatch policy without fully observable state information . A case study using real isolated MG data performed performance proposed algorithm compared baseline DRL non-DRL algorithm . Moreover impact uncertainty MG performance decoupled two level evaluated respectively .
When deploying deep neural network robot physical system learned model reliably quantify predictive uncertainty . A reliable uncertainty allows downstream module reason safety action . In work address metric evaluating uncertainty . Specifically focus regression task investigate Area Under Sparsification Error ( AUSE ) Calibration Error Spearman 's Rank Correlation Negative Log-Likelihood ( NLL ) . Using synthetic regression datasets look metric behave four typical type uncertainty stability regarding size test set reveal strength weakness . Our result indicate Calibration Error stable interpretable metric AUSE NLL also respective use case . We discourage usage Spearman 's Rank Correlation evaluating uncertainty recommend replacing AUSE .
The font recognition character extraction immense importance many scenario data form processed like image form hard copy . So procedure developed paper basically related identifying font ( Times New Roman Arial Comic Sans MS ) afterwards recovering text using simple correlation based method binary template correlated input image text character . All extraction done presence little noise image may noisy pattern due photocopying . The significance method exists extraction data various monitoring ( Surveillance ) camera footage even . The method developed Matlab\c { opyright } take input image recovers text font information text file .
The extraction useful deep feature important many computer vision task . Deep feature extracted classification network proved perform well task . To obtain feature greater usefulness end-to-end distance metric learning ( DML ) applied train feature extractor directly . However DML study equitable comparison feature extracted DML-based network softmax-based network . In paper presenting objective comparison two approach network architecture show softmax-based feature perform competitive even better state-of-the-art DML feature size dataset number training sample per class large . The result suggest softmax-based feature properly taken account evaluating performance deep feature .
Tourette Syndrome ( TS ) behavior disorder onset childhood characterized expression involuntary movement sound commonly referred tic . Behavioral therapy first-line treatment patient TS help patient raise awareness tic occurrence well develop tic inhibition strategy . However limited availability therapist difficulty in-home follow work limit effectiveness . An automatic tic detection system easy deploy could alleviate difficulty home-therapy providing feedback patient exercising tic awareness . In work propose novel architecture ( T-Net ) automatic tic detection classification untrimmed video . T-Net combine temporal detection segmentation operates feature interpretable clinician . We compare T-Net several state-of-the-art system working deep feature extracted raw video T-Net achieves comparable performance term average precision relying interpretable feature needed clinical practice .
Face recognition popular form biometric authentication due widespread use attack become common well . Recent study show Face Recognition Systems vulnerable attack lead erroneous identification face . Interestingly attack white-box manipulating facial image way physically realizable . In paper propose attack scheme attacker generate realistic synthesized face image subtle perturbation physically realize onto face attack black-box face recognition system . Comprehensive experiment analysis show subtle perturbation realized attacker face create successful attack state-of-the-art face recognition system black-box setting . Our study expose underlying vulnerability posed Face Recognition Systems realizable black-box attack .
We introduceDropDim structured dropout method designed regularizing self-attention mechanism key component transformer . In contrast general dropout method randomly drop neuron DropDim drop part embedding dimension . In way semantic information completely discarded . Thus excessive coadapting different embedding dimension broken self-attention forced encode meaningful featureswith certain number embedding dimension erased . Experiments wide range task executed MUST-C English-Germany dataset show DropDim effectively improve model performance reduce over-fitting show complementary effect regularization method . When combined label smoothing WER reduced 19.1 % 15.1 % ASR task BLEU value increased from26.90 28.38 MT task . On ST task model reach BLEU score 22.99 increase 1.86 BLEU point compared strong baseline .
We survey Natural Language Processing ( NLP ) approach summarizing simplifying generating patent ' text . While solving task important practical application - given patent ' centrality R & D process - patent ' idiosyncrasy open peculiar challenge current NLP state art . This survey aim ) describing patent ' characteristic question raise current NLP system b ) critically presenting previous work evolution c ) drawing attention direction research work needed . To best knowledge first survey generative approach patent domain .
While societal event often impact people worldwide significant fraction event local focus primarily affect specific language community . Examples include national election development Coronavirus pandemic different country local film festival C\'esar Awards France Moscow International Film Festival Russia . However existing entity recommendation approach sufficiently address language context recommendation . This article introduces novel task language-specific event recommendation aim recommend event relevant user query language-specific context . This task support essential information retrieval activity including web navigation exploratory search considering language context user information need . We propose LaSER novel approach toward language-specific event recommendation . LaSER blend language-specific latent representation ( embeddings ) entity event spatio-temporal event feature learning rank model . This model trained publicly available Wikipedia Clickstream data . The result user study demonstrate LaSER outperforms state-of-the-art recommendation baseline 33 percentage point MAP @ 5 concerning language-specific relevance recommended event .
This paper report CPU-level real-time stereo matching method surgical image ( 10 Hz 640 * 480 image single core i5-9400 ) . The proposed method built fast `` dense inverse searching `` algorithm estimate disparity stereo image . The overlapping image patch ( arbitrary squared image segment ) image different scale aligned based photometric consistency presumption . We propose Bayesian framework evaluate probability optimized patch disparity different scale . Moreover introduce spatial Gaussian mixed probability distribution address pixel-wise probability within patch . In-vivo synthetic experiment show method handle ambiguity resulted textureless surface photometric inconsistency caused Lambertian reflectance . Our Bayesian method correctly balance probability patch stereo image different scale . Experiments indicate estimated depth higher accuracy fewer outlier baseline method surgical scenario .
Existing pre-trained transformer analysis work usually focus one two model family time overlooking variability architecture pre-training objective . In work utilize oLMpics benchmark psycholinguistic probing datasets diverse set 29 model including T5 BART ALBERT . Additionally adapt oLMpics zero-shot setup autoregressive model evaluate GPT network different size . Our finding show none model resolve compositional question zero-shot fashion suggesting skill learnable using existing pre-training objective . Furthermore find global model decision architecture directionality size dataset pre-training objective predictive model 's linguistic capability .
Even though web environment facilitates daily life emotional problem caused incompatibility human cognition becoming increasingly serious . To alleviate negative emotion web use developed browser extension present memorized product image user form web advertisement . This system utilizes cognitive architecture Adaptive Control Thought-Rational ( ACT-R ) model memory emotion . A heart rate sensor modulates ACT-R model parameter : The emotional state model synchronized counterbalanced physiological state user . An experiment demonstrates counterbalance model suppresses negative ruminative web browsing . The author claim approach advantageous term explainability .
In paper propose accurate edge detector using richer convolutional feature ( RCF ) . Since object nature image various scale aspect ratio automatically learned rich hierarchical representation CNNs critical effective detect edge object boundary . And convolutional feature gradually become coarser receptive field increasing . Based observation proposed network architecture make full use multiscale multi-level information perform image-to-image edge prediction combining useful convolutional feature holistic framework . It first attempt adopt rich convolutional feature computer vision task . Using VGG16 network achieve \sArt result several available datasets . When evaluating well-known BSDS500 benchmark achieve ODS F-measure \textbf { .811 } retaining fast speed ( \textbf { 8 } FPS ) . Besides fast version RCF achieves ODS F-measure \textbf { .806 } \textbf { 30 } FPS .
Synthetic data essential assessing clustering technique complementing extending real data allowing complete coverage given problem 's space . In turn synthetic data generator potential creating vast amount data -- crucial activity real-world data premium -- providing well-understood generation procedure interpretable instrument methodically investigating cluster analysis algorithm . Here present Clugen modular procedure synthetic data generation capable creating multidimensional cluster supported line segment using arbitrary distribution . Clugen open source comprehensively unit tested documented available Python R Julia MATLAB/Octave ecosystem . We demonstrate proposal produce rich varied result various dimension fit use assessment clustering algorithm potential widely used framework diverse clustering-related research task .
Identity document recognition important sub-field document analysis deal task robust document detection type identification text field recognition well identity fraud prevention document authenticity validation given photo scan video frame identity document capture . Significant amount research published topic recent year however chief difficulty research scarcity datasets due subject matter protected security requirement . A datasets identity document available lack diversity document type capturing condition variability document field value . In addition published datasets typically designed subset document recognition problem complex identity document analysis . In paper present dataset MIDV-2020 consists 1000 video clip 2000 scanned image 1000 photo 1000 unique mock identity document unique text field value unique artificially generated face rich annotation . For presented benchmark dataset baseline provided task document location identification text field recognition face detection . With 72409 annotated image total date publication proposed dataset largest publicly available identity document dataset variable artificially generated data believe prove invaluable advancement field document analysis recognition . The dataset available download ftp : //smartengines.com/midv-2020 http : //l3i-share.univ-lr.fr .
In leading collaborative filtering ( CF ) model representation user item prone learn popularity bias training data shortcut . The popularity shortcut trick good in-distribution ( ID ) performance poorly generalized out-of-distribution ( OOD ) data i.e . popularity distribution test data shift w.r.t . training one . To close gap debiasing strategy try assess shortcut degree mitigate representation . However exist two deficiency : ( 1 ) measuring shortcut degree strategy use statistical metric single aspect ( i.e . item frequency item user frequency user aspect ) failing accommodate compositional degree user-item pair ; ( 2 ) mitigating shortcut many strategy assume test distribution known advance . This result low-quality debiased representation . Worse still strategy achieve OOD generalizability sacrifice ID performance . In work present simple yet effective debiasing strategy PopGo quantifies reduces interaction-wise popularity shortcut without assumption test data . It first learns shortcut model yield shortcut degree user-item pair based popularity representation . Then train CF model adjusting prediction interaction-wise shortcut degree . By taking causal- information-theoretical look PopGo justify encourages CF model capture critical popularity-agnostic feature leaving spurious popularity-relevant pattern . We use PopGo debias two high-performing CF model ( MF LightGCN ) four benchmark datasets . On ID OOD test set PopGo achieves significant gain state-of-the-art debiasing strategy ( e.g . DICE MACR ) .
Attributed graph clustering one fundamental task among graph learning field goal group node similar representation cluster without human annotation . Recent study based graph contrastive learning method achieved remarkable result exploit graph-structured data . However existing method 1 ) directly address clustering task since representation learning clustering process separated ; 2 ) depend much data augmentation greatly limit capability contrastive learning ; 3 ) ignore contrastive message clustering task adversely degenerate clustering result . In paper propose Neighborhood Contrast Framework Attributed Graph Clustering namely NCAGC seeking conquering aforementioned limitation . Specifically leveraging Neighborhood Contrast Module representation neighbor node 'push closer ' become clustering-oriented neighborhood contrast loss . Moreover Contrastive Self-Expression Module built minimizing node representation self-expression layer constraint learning self-expression matrix . All module NCAGC optimized unified framework learned node representation contains clustering-oriented message . Extensive experimental result four attributed graph datasets demonstrate promising performance NCAGC compared 16 state-of-the-art clustering method . The code available http : //github.com/wangtong627/NCAGC .
In paper propose novel color constancy approach called Bag Color Features ( BoCF ) building upon Bag-of-Features pooling . The proposed method substantially reduces number parameter needed illumination estimation . At time proposed method consistent color constancy assumption stating global spatial information relevant illumination estimation local information ( edge etc . ) sufficient . Furthermore BoCF consistent color constancy statistical approach interpreted learning-based generalization many statistical approach . To improve illumination estimation accuracy propose novel attention mechanism BoCF model two variant based self-attention . BoCF approach variant achieve competitive compared state art result requiring much fewer parameter three benchmark datasets : ColorChecker RECommended INTEL-TUT version 2 NUS8 .
Forensic license plate recognition ( FLPR ) remains open challenge legal context criminal investigation unreadable license plate ( LPs ) need deciphered highly compressed and/or low resolution footage e.g . surveillance camera . In work propose side-informed Transformer architecture embeds knowledge input compression level improve recognition strong compression . We show effectiveness Transformers license plate recognition ( LPR ) low-quality real-world dataset . We also provide synthetic dataset includes strongly degraded illegible LP image analyze impact knowledge embedding . The network outperforms existing FLPR method standard state-of-the art image recognition model requiring less parameter . For severest degraded image improve recognition 8.9 percent point .
For speech emotion datasets difficult acquire large quantity reliable data acted emotion may top compared less expressive emotion displayed everyday life . Lately larger datasets natural emotion created . Instead ignoring smaller acted datasets study investigates whether information learnt acted emotion useful detecting natural emotion . Cross-corpus research mostly considered cross-lingual even cross-age datasets difficulty arise different method annotating emotion causing drop performance . To consistent four adult English datasets covering acted elicited natural emotion considered . A state-of-the-art model proposed accurately investigate degradation performance . The system involves bi-directional LSTM attention mechanism classify emotion across datasets . Experiments study effect training model cross-corpus multi-domain fashion result show transfer information successful . Out-of-domain model followed adapting missing dataset domain adversarial training ( DAT ) shown suitable generalising emotion across datasets . This show positive information transfer acted datasets natural emotion benefit training different corpus .
Long story generation ( LSG ) one coveted goal natural language processing . Different text generation task LSG requires output long story rich content based much shorter text input often suffers information sparsity . In paper propose \emph { TopNet } alleviate problem leveraging recent advance neural topic modeling obtain high-quality skeleton word complement short input . In particular instead directly generating story first learn map short text input low-dimensional topic distribution ( pre-assigned topic model ) . Based latent topic distribution use reconstruction decoder topic model sample sequence inter-related word skeleton story . Experiments two benchmark datasets show proposed framework highly effective skeleton word selection significantly outperforms state-of-the-art model automatic evaluation human evaluation .
Genres understood many different way . They often perceived primarily sociological construction alternatively stylostatistically observable objective characteristic text . The latter view common research field information language technology . These two view quite compatible inform ; present investigation discusses knowledge source studying genre variation change observing reader author behaviour rather performing analysis information object .
We present ConvoCache conversational caching system solves problem slow expensive generative AI model spoken chatbots . ConvoCache find semantically similar prompt past reuses response . In paper evaluate ConvoCache DailyDialog dataset . We find ConvoCache apply UniEval coherence threshold 90 % respond 89 % prompt using cache average latency 214ms replacing LLM voice synthesis take 1 . To reduce latency test prefetching find limited usefulness . Prefetching 80 % request lead 63 % hit rate drop overall coherence . ConvoCache used chatbot reduce cost reducing usage generative AI 89 % .
Neural-network classifier achieve high accuracy predicting class input trained identify . Maintaining accuracy dynamic environment input frequently fall outside fixed set initially known class remains challenge . The typical approach detect input novel class retrain classifier augmented dataset . However classifier also detection mechanism need adapt order distinguish newly learned yet unknown input class . To address challenge introduce algorithmic framework active monitoring neural network . A monitor wrapped framework operates parallel neural network interacts human user via series interpretable labeling query incremental adaptation . In addition propose adaptive quantitative monitor improve precision . An experimental evaluation diverse set benchmark varying number class confirms benefit active monitoring framework dynamic scenario .
In recent time deep neural network achieved outstanding predictive performance various classification pattern recognition task . However many real-world prediction problem ordinal response variable ordering information ignored conventional classification loss multi-category cross-entropy . Ordinal regression method deep neural network address . One method CORAL method based earlier binary label extension framework achieves rank consistency among output layer task imposing weight-sharing constraint . However earlier experiment showed CORAL 's rank consistency beneficial performance limited weight-sharing constraint neural network 's fully connected output layer may restrict expressiveness capacity network trained using CORAL . We propose new method rank-consistent ordinal regression without limitation . Our rank-consistent ordinal regression framework ( CORN ) achieves rank consistency novel training scheme . This training scheme us conditional training set obtain unconditional rank probability applying chain rule conditional probability distribution . Experiments various datasets demonstrate efficacy proposed method utilize ordinal target information absence weight-sharing restriction improves performance substantially compared CORAL reference approach . Additionally suggested CORN method tied specific architecture utilized deep neural network classifier train ordinal regression task .
Fake news detection play crucial role protecting social medium user maintaining healthy news ecosystem . Among existing work comment-based fake news detection method empirically shown promising comment could reflect user ' opinion stance emotion deepen model ' understanding fake news . Unfortunately due exposure bias user ' different willingness comment easy obtain diverse comment reality especially early detection scenario . Without obtaining comment `` silent `` user perceived opinion may incomplete subsequently affecting news veracity judgment . In paper explore possibility finding alternative source comment guarantee availability diverse comment especially silent user . Specifically propose adopt large language model ( LLMs ) user simulator comment generator design GenFEND generated feedback-enhanced detection framework generates comment prompting LLMs diverse user profile aggregating generated comment multiple subpopulation group . Experiments demonstrate effectiveness GenFEND analysis show generated comment cover diverse user could even effective actual comment .
Root Cause Analysis ( RCA ) service-disrupting incident one critical well complex task IT process especially cloud industry leader like Salesforce . Typically RCA investigation leverage data-sources like application error log service call trace . However rich goldmine root cause information also hidden natural language documentation past incident investigation domain expert . This generally termed Problem Review Board ( PRB ) Data constitute core component IT Incident Management . However owing raw unstructured nature PRBs root cause knowledge directly reusable manual automated pipeline RCA new incident . This motivates u leverage widely-available data-source build Incident Causation Analysis ( ICA ) engine using SoTA neural NLP technique extract targeted information construct structured Causal Knowledge Graph PRB document . ICA form backbone simple-yet-effective Retrieval based RCA new incident Information Retrieval system search rank past incident detect likely root cause given incident symptom . In work present ICA downstream Incident Search Retrieval based RCA pipeline built Salesforce 2K documented cloud service incident investigation collected year . We also establish effectiveness ICA downstream task various quantitative benchmark qualitative analysis well domain expert 's validation real incident case study deployment .
Does progress simulation translate progress robot ? If one method outperforms another simulation likely trend hold reality robot ? We examine question embodied PointGoal navigation developing engineering tool research paradigm evaluating simulator sim2real predictivity . First develop Habitat-PyRobot Bridge ( HaPy ) library seamless execution identical code simulated agent robot transferring simulation-trained agent LoCoBot platform one-line code change . Second investigate sim2real predictivity Habitat-Sim PointGoal navigation . We 3D-scan physical lab space create virtualized replica run parallel test 9 different model reality simulation . We present new metric called Sim-vs-Real Correlation Coefficient ( SRCC ) quantify predictivity . We find SRCC Habitat used CVPR19 challenge low ( 0.18 success metric ) suggesting performance difference simulator-based challenge persist physical deployment . This gap largely due AI agent learning exploit simulator imperfection abusing collision dynamic 'slide ' along wall leading shortcut otherwise non-navigable space . Naturally exploit work real world . Our experiment show possible tune simulation parameter improve sim2real predictivity ( e.g . improving $ SRCC_ { Succ } $ 0.18 0.844 ) increasing confidence in-simulation comparison translate deployed system reality .
Automatic summarization legal text important still challenging task since legal document often long complicated unusual structure style . Recent advance deep model trained end-to-end differentiable loss well-summarize natural text yet applied legal domain show limited result . In paper propose use reinforcement learning train current deep summarization model improve performance legal domain . To end adopt proximal policy optimization method introduce novel reward function encourage generation candidate summary satisfying lexical semantic criterion . We apply method training different summarization backbone observe consistent significant performance gain across 3 public legal datasets .
A key challenge visual place recognition ( VPR ) recognizing place despite drastic visual appearance change due factor time day season weather lighting condition . Numerous approach based deep-learnt image descriptor sequence matching domain translation probabilistic localization success addressing challenge rely availability carefully curated representative reference image possible place . In paper propose novel approach dubbed Bayesian Selective Fusion actively selecting fusing informative reference image determine best place match given query image . The selective element approach avoids counterproductive fusion every reference image enables dynamic selection informative reference image environment changing visual condition ( indoors flickering light outdoors sunshowers day-night cycle ) . The probabilistic element approach provides mean fusing multiple reference image account varying uncertainty via novel training-free likelihood function VPR . On difficult query image two benchmark datasets demonstrate approach match exceeds performance several alternative fusion approach along state-of-the-art technique provided prior ( unfair ) knowledge best reference image . Our approach well suited long-term robot autonomy dynamic visual environment commonplace since training-free descriptor-agnostic complement existing technique sequence matching .
We propose efficient framework called Simple Swap ( SimSwap ) aiming generalized high fidelity face swapping . In contrast previous approach either lack ability generalize arbitrary identity fail preserve attribute like facial expression gaze direction framework capable transferring identity arbitrary source face arbitrary target face preserving attribute target face . We overcome defect following two way . First present ID Injection Module ( IIM ) transfer identity information source face target face feature level . By using module extend architecture identity-specific face swapping algorithm framework arbitrary face swapping . Second propose Weak Feature Matching Loss efficiently help framework preserve facial attribute implicit way . Extensive experiment wild face demonstrate SimSwap able achieve competitive identity performance preserving attribute better previous state-of-the-art method . The code already available github : http : //github.com/neuralchen/SimSwap .
In preoperative imaging demarcation rectal cancer magnetic resonance image provides important basis cancer staging treatment planning . Recently deep learning greatly improved state-of-the-art method automatic segmentation . However limitation data availability medical field cause large variance consequent overfitting medical image segmentation network . In study propose method reduce model variance rectal cancer segmentation network adding rectum segmentation task performing data augmentation ; geometric correlation rectum rectal cancer motivated former approach . Moreover propose method perform bias-variance analysis within arbitrary region-of-interest ( ROI ) segmentation network applied assess efficacy approach reducing model variance . As result adding rectum segmentation task reduced model variance rectal cancer segmentation network within tumor region factor 0.90 ; data augmentation reduced variance factor 0.89 . These approach also reduced training duration factor 0.96 factor 0.78 respectively . Our approach improve quality rectal cancer staging increasing accuracy automatic demarcation providing rectum boundary information since rectal cancer staging requires demarcation rectum rectal cancer . Besides clinical benefit method also enables segmentation network assessed bias-variance analysis within arbitrary ROI cancerous region .
In paper apply Conformal Prediction ( CP ) k-Nearest Neighbours Regression ( k-NNR ) algorithm propose way extending typical nonconformity measure used regression far . Unlike traditional regression method produce point prediction Conformal Predictors output predictive region satisfy given confidence level . The region produced Conformal Predictor automatically valid however tightness therefore usefulness depends nonconformity measure used CP . In effect nonconformity measure evaluates strange given example compared set example based traditional machine learning algorithm . We define six novel nonconformity measure based k-Nearest Neighbours Regression algorithm develop corresponding CPs following original ( transductive ) inductive CP approach . A comparison predictive region produced measure typical regression measure suggests major improvement term predictive region tightness achieved new measure .
This paper address problem large-scale image retrieval focusing improving accuracy robustness . We target enhanced robustness search factor variation illumination object appearance scale partial occlusion cluttered background - particularly important search performed across large datasets significant variability . We propose novel CNN-based global descriptor called REMAP learns aggregate hierarchy deep feature multiple CNN layer trained end-to-end triplet loss . REMAP explicitly learns discriminative feature mutually-supportive complementary various semantic level visual abstraction . These dense local feature max-pooled spatially layer within multi-scale overlapping region aggregation single image-level descriptor . To identify semantically useful region layer retrieval propose measure information gain region layer using KL-divergence . Our system effectively learns training useful various region layer weight accordingly . We show relative entropy-guided aggregation outperforms classical CNN-based aggregation controlled SGD . The entire framework trained end-to-end fashion outperforming latest state-of-the-art result . On image retrieval datasets Holidays Oxford MPEG REMAP descriptor achieves mAP 95.5 % 91.5 % 80.1 % respectively outperforming result published date . REMAP also formed core winning submission Google Landmark Retrieval Challenge Kaggle .
We present Tencent 's ad recommendation system examine challenge practice learning appropriate recommendation representation . Our study begin showcasing approach preserving prior knowledge encoding feature diverse type embedding representation . We specifically address sequence feature numeric feature pre-trained embedding feature . Subsequently delve two crucial challenge related feature representation : dimensional collapse embeddings interest entanglement across different task scenario . We propose several practical approach address challenge result robust disentangled recommendation representation . We explore several training technique facilitate model optimization reduce bias enhance exploration . Additionally introduce three analysis tool enable u study feature correlation dimensional collapse interest entanglement . This work build upon continuous effort Tencent 's ad recommendation team past decade . It summarizes general design principle present series readily applicable solution analysis tool . The reported performance based online advertising platform handle hundred billion request daily serf million ad billion user .
Automated analysis complex system based multiple readout remains challenge . Change point detection algorithm aimed locating abrupt change time series behaviour process . In paper present novel change point detection algorithm based Latent Neural Stochastic Differential Equations ( SDE ) . Our method learns non-linear deep learning transformation process latent space estimate SDE describes evolution time . The algorithm us likelihood ratio learned stochastic process different timestamps find change point process . We demonstrate detection capability performance algorithm synthetic real-world datasets . The proposed method outperforms state-of-the-art algorithm majority experiment .
When image formed factor lighting ( spectrum source intensity ) camera characteristic ( sensor response lens ) affect appearance image . Therefore prime factor reduces quality image noise . It hide important detail information image . In order enhance quality image removal noise become imperative cost loss image information . Noise removal one pre-processing stage image processing . In paper new method enhancement grayscale image introduced image corrupted fixed valued impulse noise ( salt pepper noise ) . The proposed methodology ensures better output low medium density fixed value impulse noise compared famous filter like Standard Median Filter ( SMF ) Decision Based Median Filter ( DBMF ) Modified Decision Based Median Filter ( MDBMF ) etc . The main objective proposed method improve peak signal noise ratio ( PSNR ) visual perception reduction blurring image . The proposed algorithm replaced noisy pixel trimmed mean value . When previous pixel value 0 255s present particular window pixel value 0 255s remaining noisy pixel replaced mean value . The gray-scale image mandrill Lena tested via proposed method . The experimental result show better peak signal noise ratio ( PSNR ) mean square error value better visual human perception .
We develop cylindrical shape decomposition ( CSD ) algorithm decompose object union several tubular structure semantic component . We decompose object using curve skeleton restricted translational sweep . For CSD partition curve skeleton maximal-length sub-skeletons orientation cost sub-skeleton corresponds semantic component . To find intersection tubular component CSD translationally sweep object decomposition interval identify critical point shape object change substantially . CSD cut object critical point assigns label part along sub-skeleton thereby constructing semantic component . The proposed method reconstructs acquired semantic component intersection object part using generalized cylinder . We apply CSD segmenting axon large 3D electron microscopy image decomposing vascular network synthetic object . We show proposal robust severe surface noise outperforms state-of-the-art decomposition technique application .
Image ordinal estimation predict ordinal label given image categorized ordinal regression problem . Recent method formulate ordinal regression problem series binary classification problem . Such method ensure global ordinal relationship preserved since relationship among different binary classifier neglected . We propose novel ordinal regression approach termed Convolutional Ordinal Regression Forest CORF image ordinal estimation integrate ordinal regression differentiable decision tree convolutional neural network obtaining precise stable global ordinal relationship . The advantage proposed CORF twofold . First instead learning series binary classifier \emph { independently } proposed method aim learning ordinal distribution ordinal regression optimizing binary classifier \emph { simultaneously } . Second differentiable decision tree proposed CORF trained together ordinal distribution end-to-end manner . The effectiveness proposed CORF verified two image ordinal estimation task i.e . facial age estimation image aesthetic assessment showing significant improvement better stability state-of-the-art ordinal regression method .
Mistakes AI system inevitable arising technical limitation sociotechnical gap . While black-boxing AI system make user experience seamless hiding seam risk disempowering user mitigate fallout AI mistake . Instead hiding AI imperfection leverage help user ? While Explainable AI ( XAI ) predominantly tackled algorithmic opaqueness propose seamful design foster AI explainability revealing leveraging sociotechnical infrastructural mismatch . We introduce concept Seamful XAI ( 1 ) conceptually transferring `` seam `` AI context ( 2 ) developing design process help stakeholder anticipate design seam . We explore process 43 AI practitioner real end-users using scenario-based co-design activity informed real-world use case . We found Seamful XAI design process helped user foresee AI harm identify underlying reason ( seam ) locate AI 's lifecycle learn leverage seamful information improve XAI user agency . We share empirical insight implication reflection process help practitioner anticipate craft seam AI seamfulness improve explainability empower end-users facilitate Responsible AI .
The use graph convolution development recommender system algorithm recently achieved state-of-the-art result collaborative filtering task ( CF ) . While demonstrated graph convolution operation connected filtering operation graph spectral domain theoretical rationale lead higher performance collaborative filtering problem remains unknown . The presented work make two contribution . First investigate effect using graph convolution throughout user item representation learning process demonstrating latent feature learned pushed filtering operation subspace spanned eigenvectors associated highest eigenvalue normalised adjacency matrix vector lying subspace optimal solution objective function related sum prediction function training data . Then present approach directly leverage eigenvectors emulate solution obtained graph convolution eliminating requirement time-consuming gradient descent training procedure also delivering higher performance three real-world datasets .
Augmented Reality simply AR incorporation information digital format includes live footage certain user 's real-time environment . Also various university using Augmented Reality . Applying technology education sector result smart campus . In line paper discus Augmented Reality used different learning area .
This paper proposes method prioritizing replay experience referred Hindsight Goal Ranking ( HGR ) overcoming limitation Hindsight Experience Replay ( HER ) generates hindsight goal based uniform sampling . HGR sample higher probability state visited episode larger temporal difference ( TD ) error considered proxy measure amount RL agent learn experience . The actual sampling large TD error performed two step : first episode sampled relay buffer according average TD error experience sampled episode hindsight goal leading larger TD error sampled higher probability future visited state . The proposed method combined Deep Deterministic Policy Gradient ( DDPG ) off-policy model-free actor-critic algorithm accelerates learning significantly faster without prioritization four challenging simulated robotic manipulation task . The empirical result show HGR us sample efficiently previous method across task .
We introduce novel learning-based visibility-aware surface reconstruction method large-scale defect-laden point cloud . Our approach cope scale variety point cloud defect encountered real-life Multi-View Stereo ( MVS ) acquisition . Our method relies 3D Delaunay tetrahedralization whose cell classified inside outside surface graph neural network energy model solvable graph cut . Our model making use local geometric attribute line-of-sight visibility information able learn visibility model small amount synthetic training data generalizes real-life acquisition . Combining efficiency deep learning method scalability energy based model approach outperforms learning non learning-based reconstruction algorithm two publicly available reconstruction benchmark . Our code data available http : //github.com/raphaelsulzer/dgnn .
The time needed apply hierarchical clustering algorithm often dominated number computation pairwise dissimilarity measure . Such constraint larger data set put disadvantage use classical linkage criterion single linkage one . However known single linkage clustering algorithm sensitive outlier produce highly skewed dendrograms therefore usually reflect true underlying data structure -- unless cluster well-separated . To overcome limitation propose new hierarchical clustering linkage criterion called Genie . Namely algorithm link two cluster way chosen economic inequity measure ( e.g . Gini- Bonferroni-index ) cluster size drastically increase given threshold . The presented benchmark indicate high practical usefulness introduced method : often outperforms Ward average linkage term clustering quality retaining single linkage 's speed . The Genie algorithm easily parallelizable thus may run multiple thread speed execution even . Its memory overhead small : need precompute complete distance matrix perform computation order obtain desired clustering . It applied arbitrary space equipped dissimilarity measure e.g . real vector DNA protein sequence image ranking informetric data etc . A reference implementation algorithm included open source 'genie ' package R. See also http : //genieclust.gagolewski.com new implementation ( genieclust ) -- available R Python .
Multivariate time series ( MTS ) prediction ubiquitous real-world field MTS data often contains missing value . In recent year increasing interest using end-to-end model handle MTS missing value . To generate feature prediction existing method either merge input dimension MTS tackle input dimension independently . However approach hard perform well former usually produce many unreliable feature latter lack correlated information . In paper propose Learning Individual Features ( LIFE ) framework provides new paradigm MTS prediction missing value . LIFE generates reliable feature prediction using correlated dimension auxiliary information suppressing interference uncorrelated dimension missing value . Experiments three real-world data set verify superiority LIFE existing state-of-the-art model .
While deep learning strategy achieve outstanding result computer vision task one issue remains : The current strategy rely heavily huge amount labeled data . In many real-world problem feasible create amount labeled training data . Therefore common incorporate unlabeled data training process reach equal result fewer label . Due lot concurrent research difficult keep track recent development . In survey provide overview often used idea method image classification fewer label . We compare 34 method detail based performance commonly used idea rather fine-grained taxonomy . In analysis identify three major trend lead future research opportunity . 1 . State-of-the-art method scaleable real-world application theory issue like class imbalance robustness fuzzy label considered . 2 . The degree supervision needed achieve comparable result usage label decreasing therefore method need extended setting variable number class . 3 . All method share common idea identify cluster method share many idea . We show combining idea different cluster lead better performance .
Under framework spectral clustering key subspace clustering building similarity graph describes neighborhood relation among data point . Some recent work build graph using sparse low-rank $ \ell_2 $ -norm-based representation achieved state-of-the-art performance . However method suffered following two limitation . First time complexity method least proportional cube data size make method inefficient solving large-scale problem . Second cope out-of-sample data used construct similarity graph . To cluster out-of-sample datum method recalculate similarity graph cluster membership whole data set . In paper propose unified framework make representation-based subspace clustering algorithm feasible cluster out-of-sample large-scale data . Under framework large-scale problem tackled converting out-of-sample problem manner `` sampling clustering coding classifying `` . Furthermore give estimation error bound treating subspace point hyperspace . Extensive experimental result various benchmark data set show method outperform several recently-proposed scalable method clustering large-scale data set .
Autonomous driving car becoming reality key component high-definition ( HD ) map show value market place industry . Even though HD map generation LiDAR stereo/perspective imagery achieved impressive success inherent defect ignored . In paper proposal novel method Highway HD map modeling using pixel-wise segmentation satellite imagery formalized hypothesis linking cheaper faster current HD map modeling approach LiDAR point cloud perspective view imagery let becomes ideal complementary state art . We also manual code/label HD road model dataset ground truth aligned Bing tile image server train test evaluate methodology . This dataset publish time contribute research HD map modeling aerial imagery .
In paper propose novel highly practical score-level fusion approach called dynamic belief fusion ( DBF ) directly integrates inference score individual detection multiple object detection method . To effectively integrate individual output multiple detector level ambiguity detection score estimated using confidence model built precision-recall relationship corresponding detector . For detector output DBF calculates probability three hypothesis ( target non-target intermediate state ( target non-target ) ) based confidence level detection score conditioned prior confidence model individual detector referred basic probability assignment . The probability distribution three hypothesis detector optimally fused via Dempster 's combination rule . Experiments ARL PASCAL VOC 07 12 datasets show detection accuracy DBF significantly higher baseline fusion approach well individual detector used fusion .
In oriented object detection current representation oriented bounding box ( OBBs ) often suffer boundary discontinuity problem . Methods designing continuous regression loss essentially solve problem . Although Gaussian bounding box ( GBB ) representation avoids problem directly regressing GBB susceptible numerical instability . We propose linear GBB ( LGBB ) novel OBB representation . By linearly transforming element GBB LGBB avoids boundary discontinuity problem high numerical stability . In addition existing convolution-based rotation-sensitive feature extraction method local receptive field resulting slow feature aggregation . We propose ring-shaped rotated convolution ( RRC ) adaptively rotates feature map arbitrary orientation extract rotation-sensitive feature ring-shaped receptive field rapidly aggregating feature contextual information . Experimental result demonstrate LGBB RRC achieve state-of-the-art performance . Furthermore integrating LGBB RRC various model effectively improves detection accuracy .
Punctuation prediction automatic speech recognition ( ASR ) output transcript play crucial role improving readability ASR transcript improving performance downstream natural language processing application . However achieving good performance punctuation prediction often requires large amount labeled speech transcript expensive laborious . In paper propose Discriminative Self-Training approach weighted loss discriminative label smoothing exploit unlabeled speech transcript . Experimental result English IWSLT2011 benchmark test set internal Chinese spoken language dataset demonstrate proposed approach achieves significant improvement punctuation prediction accuracy strong baseline including BERT RoBERTa ELECTRA model . The proposed Discriminative Self-Training approach outperforms vanilla self-training approach . We establish new state-of-the-art ( SOTA ) IWSLT2011 test set outperforming current SOTA model 1.3 % absolute gain F $ _1 $ .
Table extraction PDF image document ubiquitous task real-world . Perfect extraction quality difficult achieve one single out-of-box model due ( 1 ) wide variety table style ( 2 ) lack training data representing variety ( 3 ) inherent ambiguity subjectivity table definition end-users . Meanwhile building customized model scratch difficult due expensive nature annotating table data . We attempt solve challenge TableLab providing system user model seamlessly work together quickly customize high-quality extraction model labelled example user 's document collection contains page table . Given input document collection TableLab first detects table similar structure ( template ) clustering embeddings extraction model . Document collection often contain table created limited set template similar structure . It selects representative table example already extracted pre-trained base deep learning model . Via easy-to-use user interface user provide feedback selection without necessarily identify every single error . TableLab applies feedback finetune pre-trained model return result finetuned model back user . The user choose repeat process iteratively obtaining customized model satisfactory performance .
Faithfulness arguably critical metric assess reliability explainable AI . In NLP current method faithfulness evaluation fraught discrepancy bias often failing capture true reasoning model . We introduce Adversarial Sensitivity novel approach faithfulness evaluation focusing explainer 's response model adversarial attack . Our method account faithfulness explainers capturing sensitivity adversarial input change . This work address significant limitation existing evaluation technique furthermore quantifies faithfulness crucial yet underexplored paradigm .
Pattern recognition machine learning technique increasingly adopted adversarial setting spam intrusion malware detection although security well-crafted attack aim evade detection manipulating data test time yet thoroughly assessed . While previous work mainly focused devising adversary-aware classification algorithm counter evasion attempt author considered impact using reduced feature set classifier security attack . An interesting preliminary result classifier security evasion may even worsened application feature selection . In paper provide detailed investigation aspect shedding light security property feature selection evasion attack . Inspired previous work adversary-aware classifier propose novel adversary-aware feature selection model improve classifier security evasion attack incorporating specific assumption adversary 's data manipulation strategy . We focus efficient wrapper-based implementation approach experimentally validate soundness different application example including spam malware detection .
Big data often emergent structure exists multiple level abstraction useful characterizing complex interaction dynamic observation . Here consider multiple level abstraction via multiresolution geometry data point different granularity . To construct geometry define time-inhomogeneous diffusion process effectively condenses data point together uncover nested grouping larger larger granularity . This inhomogeneous process creates deep cascade intrinsic low pas filter data affinity graph applied sequence gradually eliminate local variability adjusting learned data geometry increasingly coarser resolution . We provide visualization exhibit method continuously-hierarchical clustering direction eliminated variation highlighted step . The utility algorithm demonstrated via neuronal data condensation constructed multiresolution data geometry uncovers organization grouping connectivity neuron .
Scientific article long text document organized section describing aspect research . Analyzing scientific production become progressively challenging due increase number available article . Within scenario approach consisted fine-tuning transformer language model generate sentence-level embeddings scientific article considering following label : background objective method result conclusion . We trained model three datasets contrastive learning . Two datasets article 's abstract computer science medical domain . Also introduce PMC-Sents-FULL novel dataset sentence extracted full text medical article . We compare fine-tuned baseline model clustering classification task evaluate approach . On average clustering agreement measure value five time higher . For classification measure best-case scenario average improvement F1-micro 30.73\ % . Results show fine-tuning sentence transformer contrastive learning using generated embeddings downstream task feasible approach sentence classification scientific article . Our experiment code available GitHub .
Feature selection essential step data science pipeline reduce complexity associated large datasets . While much research topic focus optimizing predictive performance study investigate stability context feature selection process . In study present Repeated Elastic Net Technique ( RENT ) Feature Selection . RENT us ensemble generalized linear model elastic net regularization trained distinct subset training data . The feature selection based three criterion evaluating weight distribution feature across elementary model . This fact lead selection feature high stability improve robustness final model . Furthermore unlike established feature selector RENT provides valuable information model interpretation concerning identification object data difficult predict training . In experiment benchmark RENT six established feature selector eight multivariate datasets binary classification regression . In experimental comparison RENT show well-balanced trade-off predictive performance stability . Finally underline additional interpretational value RENT exploratory post-hoc analysis healthcare dataset .
Digital contact tracing limit spread infectious disease . Nevertheless remain barrier attaining sufficient adoption . In study investigate willingness participate contact tracing affected two critical factor : mode data collection type data collected . We conducted scenario-based survey study among 220 respondent United States ( U.S. ) understand perception contact tracing associated automated manual contact tracing method . The finding indicate promising use smartphones combination public health official medical health record information source . Through quantitative analysis describe different modality individual demographic factor may affect user compliance providing four key piece information contact tracing .
This paper evaluates different task carried translation pronominal anaphora machine translation ( MT ) system . The MT interlingua approach named AGIR ( Anaphora Generation Interlingua Representation ) improves upon proposal presented date able translate intersentential anaphor detect co-reference chain translate Spanish zero pronoun English -- -issues hardly considered system . The paper present resolution evaluation anaphora problem AGIR use different kind knowledge ( lexical morphological syntactic semantic ) . The translation English Spanish anaphoric third-person personal pronoun ( including Spanish zero pronoun ) target language evaluated unrestricted corpus . We obtained precision 80.4 % 84.8 % translation Spanish English pronoun respectively . Although studied Spanish English language approach easily extended language Portuguese Italian Japanese .
Spatio-temporal graph ( ST-graphs ) used model time series task traffic forecasting human motion modeling action recognition . The high-level structure corresponding feature ST-graphs led improved performance traditional architecture . However current method tend limited simple feature despite rich information provided full graph structure lead inefficiency suboptimal performance downstream task . We propose use feature derived meta-paths walk across different type edge ST-graphs improve performance Structural Recurrent Neural Network . In paper present Meta-path Enhanced Structural Recurrent Neural Network ( MESRNN ) generic framework applied spatio-temporal task simple scalable manner . We employ MESRNN pedestrian trajectory prediction utilizing meta-path based feature capture relationship trajectory pedestrian different point time space . We compare MESRNN state-of-the-art ST-graph method standard datasets show performance boost provided meta-path information . The proposed model consistently outperforms baseline trajectory prediction long time horizon 32\ % produce socially compliant trajectory dense crowd . For information please refer project website http : //sites.google.com/illinois.edu/mesrnn/home .
Pixel-wise classification remote sensing identifies entity large-scale satellite-based image pixel level . Few fully annotated large-scale datasets pixel-wise classification exist due challenge annotating individual pixel . Training data scarcity inevitably ensues annotation challenge leading overfitting classifier degraded classification performance . The lack annotated pixel also necessarily result hard example various entity critical generating robust classification hyperplane . To overcome problem data scarcity lack hard example training introduce two-step hard example generation ( HEG ) approach first generates hard example candidate mine actual hard example . In first step generator creates hard example candidate learned via adversarial learning framework fooling discriminator pixel-wise classification model time . In second step mining performed build fixed number hard example large pool real artificially generated example . To evaluate effectiveness proposed HEG approach design 9-layer fully convolutional network suitable pixel-wise classification . Experiments show using generated hard example proposed HEG approach improves pixel-wise classification model 's accuracy red tide detection hyperspectral image classification task .
Artificial intelligence ( AI ) model increasingly finding application field medicine . Concerns raised explainability decision made AI model . In article give systematic analysis explainable artificial intelligence ( XAI ) primary focus model currently used field healthcare . The literature search conducted following preferred reporting item systematic review meta-analyses ( PRISMA ) standard relevant work published 1 January 2012 02 February 2022 . The review analyzes prevailing trend XAI lay major direction research headed . We investigate us XAI model implication . We present comprehensive examination XAI methodology well explanation trustworthy AI derived describing AI model healthcare field . The discussion work contribute formalization XAI field .
Automation feature analysis dynamic image frame dataset deal complexity intensity mapping normal abnormal class . The threshold-based data clustering feature analysis requires iterative model learn component image frame multi-pattern different image frame data type . This paper proposed novel model feature analysis method CNN based Convoluted Pattern Wavelet Transform ( CPWT ) feature vector optimized Grey Wolf Optimization ( GWO ) algorithm . Initially image frame get normalized applying median filter image frame reduce noise apply smoothening . From edge information represents boundary region bright spot image frame . Neural network-based image frame classification performs repeated learning feature minimum training dataset cluster image frame pixel . Features filtered image frame analyzed different pattern feature extraction model based convoluted model wavelet transformation method . These feature represent different class image frame spatial textural pattern . Convolutional Neural Network ( CNN ) classifier support analyze feature classify action label image frame dataset . This process enhances classification minimum number training dataset . The performance proposed method validated comparing traditional state-of-art method .
Schlieren imaging optical technique observe flow transparent medium air water without particle seeding . However conventional frame-based technique require high spatial temporal resolution camera impose bright illumination expensive computation limitation . Event camera offer potential advantage ( high dynamic range high temporal resolution data efficiency ) overcome limitation due bio-inspired sensing principle . This paper present novel technique perceiving air convection using event frame providing first theoretical analysis connects event data schlieren . We formulate problem variational optimization one combining linearized event generation model physically-motivated parameterization estimate temporal derivative air density . The experiment accurately aligned frame- event camera data reveal proposed method enables event camera obtain par result existing frame-based optical flow technique . Moreover proposed method work dark condition frame-based schlieren fails also enables slow-motion analysis leveraging event camera 's advantage . Our work pioneer open new stack event camera application publish source code well first schlieren dataset high-quality frame event data . http : //github.com/tub-rip/event_based_bos
To deal exhausting annotation self-supervised representation learning unlabeled point cloud drawn much attention especially centered augmentation-based contrastive method . However specific augmentation hardly produce sufficient transferability high-level task different datasets . Besides augmentation point cloud may also change underlying semantics . To address issue propose simple efficient augmentation fusion contrastive learning framework combine data augmentation Euclidean space feature augmentation feature space . In particular propose data augmentation method based sampling graph generation . Meanwhile design data augmentation network enable correspondence representation maximizing consistency augmented graph pair . We design feature augmentation network encourages model learn representation invariant perturbation using encoder perturbation . We comprehensively conduct extensive object classification experiment object part segmentation experiment validate transferability proposed framework . Experimental result demonstrate proposed framework effective learn point cloud representation self-supervised manner yield state-of-the-art result community . The source code publicly available : http : //zhiyongsu.github.io/Project/AFSRL.html .
Live music making understood enactive process whereby musical experience created human action . This suggests musical world coevolve agent repeated sensorimotor interaction environment ( music created ) time separated sociocultural context . This paper investigates claim exploring way technology physiology context bound within two different musical scenario : live electronic musical performance ; person-centred art application NIMEs . In paper I outline ethnographic phenomenological enquiry experience performer live electronic electro-instrumental music well extensive background working new technology various therapeutic person-centred artistic situation . This order explore sociocultural technological context activity take place . I propose understanding creative musical participation highly contextualised practice may discover greatest impact rapidly developing technological resource ability afford richly diverse personalised embodied form music making . I argue applicable wide range musical community .
The cross-domain recommendation technique effective way alleviating data sparse issue recommender system leveraging knowledge relevant domain . Transfer learning class algorithm underlying technique . In paper propose novel transfer learning approach cross-domain recommendation using neural network base model . In contrast matrix factorization based cross-domain technique method deep transfer learning learn complex user-item interaction relationship . We assume hidden layer two base network connected cross mapping leading collaborative cross network ( CoNet ) . CoNet enables dual knowledge transfer across domain introducing cross connection one base network another vice versa . CoNet achieved multi-layer feedforward network adding dual connection joint loss function trained efficiently back-propagation . The proposed model thoroughly evaluated two large real-world datasets . It outperforms baseline relative improvement 7.84\ % NDCG . We demonstrate necessity adaptively selecting representation transfer . Our model reduce ten thousand training example comparing non-transfer method still competitive performance .
The purpose paper introduce set four test image containing feature structure facilitate effective examination comparison image processing algorithm . More specifically image designed explicitly expose characteristic property algorithm image compression virtual resolution adjustment enhancement . This set developed Naval Research Laboratory ( NRL ) late 1990s rigorous alternative Lena image come common use purely ad hoc reason little rigorous consideration suitability . The increasing number test image appearing literature make difficult compare result different paper also introduces potential cherry-picking influence result . The key contribution paper proposal establish { \em } canonical set ensure published result analyzed compared rigorous way one paper another consideration four NRL image proposed purpose .
We apply concept user ' emotion vector ( UVECs ) movie ' emotion vector ( MVECs ) building component Emotion Aware Recommender System . We built comparative platform consists five recommenders based content-based collaborative filtering algorithm . We employed Tweets Affective Classifier classify movie ' emotion profile movie overview . We construct MVECs movie emotion profile . We track user ' movie watching history formulate UVECs taking average MVECs movie user watched . With MVECs built Emotion Aware Recommender one comparative platform ' algorithm . We evaluated top-N recommendation list generated Recommenders found top-N list Emotion Aware Recommender showed serendipity recommendation .
Extracting block interest referred segmenting specified block image studying characteristic general research interest could challenging segmentation task carried directly compressed image . This objective present research work . The proposal evolve method would segment extract specified block carry characterization without decompressing compressed image two major reason image archive contain image compressed format decompressing image indent additional computing time space . Specifically research work proposal work run-length compressed document image .
Cross-Lingual Word Embeddings ( CLWEs ) encode word two language shared high-dimensional space vector representing word similar meaning ( regardless language ) closely located . Existing method building high-quality CLWEs learn mapping minimise $ \ell_ { 2 } $ norm loss function . However optimisation objective demonstrated sensitive outlier . Based robust Manhattan norm ( aka . $ \ell_ { 1 } $ norm ) goodness-of-fit criterion paper proposes simple post-processing step improve CLWEs . An advantage approach fully agnostic training process original CLWEs therefore applied widely . Extensive experiment performed involving ten diverse language embeddings trained different corpus . Evaluation result based bilingual lexicon induction cross-lingual transfer natural language inference task show $ \ell_ { 1 } $ refinement substantially outperforms four state-of-the-art baseline supervised unsupervised setting . It therefore recommended strategy adopted standard CLWE method .
Saliency perceptual capacity visual system focus attention ( i.e . gaze ) relevant object . Neural network saliency estimation require ground truth saliency map training usually achieved via eyetracking experiment . In current paper demonstrate saliency map generated side-effect training object recognition deep neural network endowed saliency branch . Such network require ground-truth saliency map training.Extensive experiment carried real synthetic saliency datasets demonstrate approach able generate accurate saliency map achieving competitive result synthetic real datasets compared method require ground truth data .
In paper study spectral property re-parameterized light field . Following previous study light field spectrum notably provided sampling guideline focus two plane parameterization light field . However introduce additional flexibility allowing image plane tilted parallel . A formal theoretical analysis first presented show flexible sampling guideline ( i.e . wider camera baseline ) used sample light field adapting image plane orientation scene geometry . We present simulation result support theoretical finding . While work introduced paper mostly theoretical believe new finding open exciting avenue practical application light field view synthesis compact representation .
Graphical perception study typically measure visualization encoding effectiveness using error `` average observer `` leading canonical ranking encoding numerical attribute : e.g . position > area > angle > volume . Yet different people may vary ability read different visualization type leading variance ranking across individual captured population-level metric using `` average observer `` model . One way bridge gap recasting classic visual perception task tool assessing individual performance addition overall visualization performance . In paper replicate extend Cleveland McGill 's graphical comparison experiment using Bayesian multilevel regression using model explore individual difference visualization skill multiple perspective . The result experiment modeling indicate people show pattern accuracy credibly deviate canonical ranking visualization effectiveness . We discus implication finding need new way communicate visualization effectiveness designer pattern individual ' response may show systematic bias strategy visualization judgment recasting classic visual perception task tool assessing individual performance may offer new way quantify aspect visualization literacy . Experiment data source code analysis script available following repository : http : //osf.io/8ub7t/ ? view\_only=9be4798797404a4397be3c6fc2a68cc0 .
We propose 6D RGB-D odometry approach find relative camera pose consecutive RGB-D frame keypoint extraction feature matching RGB depth image plane . Furthermore feed estimated pose highly accurate KinectFusion algorithm us fast ICP ( Iterative Closest Point ) fine-tune frame-to-frame relative pose fuse depth data global implicit surface . We evaluate method publicly available RGB-D SLAM benchmark dataset Sturm et al . The experimental result show proposed reconstruction method solely based visual odometry KinectFusion outperforms state-of-the-art RGB-D SLAM system accuracy . Moreover algorithm output ready-to-use polygon mesh ( highly suitable creating 3D virtual world ) without postprocessing step .
Pervasive computing promotes integration smart device living space develop service providing assistance people . Such smart device increasingly relying cloud-based Machine Learning raise question term security ( data privacy ) reliance ( latency ) communication cost . In context Federated Learning ( FL ) introduced new machine learning paradigm enhancing use local device . At server level FL aggregate model learned locally distributed client obtain general model . In way private data sent network communication cost reduced . Unfortunately however popular federated learning algorithm shown adapted highly heterogeneous pervasive computing environment . In paper propose new FL algorithm termed FedDist modify model ( deep neural network ) training identifying dissimilarity neuron among client . This permit account client ' specificity without impairing generalization . FedDist evaluated three state-of-the-art federated learning algorithm three large heterogeneous mobile Human Activity Recognition datasets . Results shown ability FedDist adapt heterogeneous data capability FL deal asynchronous situation .
Recently significant improvement made semantic object segmentation due development deep convolutional neural network ( DCNNs ) . Training DCNN usually relies large number image pixel-level segmentation mask annotating image costly term finance human effort . In paper propose simple complex ( STC ) framework image-level annotation utilized learn DCNNs semantic segmentation . Specifically first train initial segmentation network called Initial-DCNN saliency map simple image ( i.e . single category major object ( ) clean background ) . These saliency map automatically obtained existing bottom-up salient object detection technique supervision information needed . Then better network called Enhanced-DCNN learned supervision predicted segmentation mask simple image based Initial-DCNN well image-level annotation . Finally pixel-level segmentation mask complex image ( two category object cluttered background ) inferred using Enhanced-DCNN image-level annotation utilized supervision information learn Powerful-DCNN semantic segmentation . Our method utilizes $ 40 $ K simple image Flickr.com 10K complex image PASCAL VOC step-wisely boosting segmentation network . Extensive experimental result PASCAL VOC 2012 segmentation benchmark well demonstrate superiority proposed STC framework compared state-of-the-arts .
Human parsing human body part semantic segmentation active research topic due wide potential application . In paper propose novel GRAph PYramid Mutual Learning ( Grapy-ML ) method address cross-dataset human parsing problem annotation different granularity . Starting prior knowledge human body hierarchical structure devise graph pyramid module ( GPM ) stacking three level graph structure coarse granularity fine granularity subsequently . At level GPM utilizes self-attention mechanism model correlation context node . Then adopts top-down mechanism progressively refine hierarchical feature level . GPM also enables efficient mutual learning . Specifically network weight first two level shared exchange learned coarse-granularity information across different datasets . By making use multi-granularity label Grapy-ML learns discriminative feature representation achieves state-of-the-art performance demonstrated extensive experiment three popular benchmark e.g . CIHP dataset . The source code publicly available http : //github.com/Charleshhy/Grapy-ML .
We present framework embedding graph structured data vector space taking account node feature topology graph optimal transport ( OT ) problem . Then propose novel distance two graph named linearFGW defined Euclidean distance embeddings . The advantage proposed distance twofold : 1 ) take account node feature structure graph measuring similarity graph kernel-based framework 2 ) much faster computing kernel matrix pairwise OT-based distance particularly fused Gromov-Wasserstein making possible deal large-scale data set . After discussing theoretical property linearFGW demonstrate experimental result classification clustering task showing effectiveness proposed linearFGW .
The black-box nature machine learning model hinders deployment high-accuracy model medical diagnosis . It risky put one 's life hand model medical researcher fully understand . However model interpretation black-box model promptly reveal significant biomarkers medical practitioner may overlooked due surge infected patient COVID-19 pandemic . This research leverage database 92 patient confirmed SARS-CoV-2 laboratory test 18th Jan. 2020 5th Mar . 2020 Zhuhai China identify biomarkers indicative severity prediction . Through interpretation four machine learning model decision tree random forest gradient boosted tree neural network using permutation feature importance Partial Dependence Plot ( PDP ) Individual Conditional Expectation ( ICE ) Accumulated Local Effects ( ALE ) Local Interpretable Model-agnostic Explanations ( LIME ) Shapley Additive Explanation ( SHAP ) identify increase N-Terminal pro-Brain Natriuretic Peptide ( NTproBNP ) C-Reaction Protein ( CRP ) lactic dehydrogenase ( LDH ) decrease lymphocyte ( LYM ) associated severe infection increased risk death consistent recent medical research COVID-19 research using dedicated model . We validate method large open dataset 5644 confirmed patient Hospital Israelita Albert Einstein S\~ao Paulo Brazil Kaggle unveil leukocyte eosinophil platelet three indicative biomarkers COVID-19 .
The Braille system used visually impaired reading writing . Due limited availability Braille text book efficient usage book becomes necessity . This paper proposes method convert scanned Braille document text read many computer . The Braille document pre processed enhance dot reduce noise . The Braille cell segmented dot cell extracted converted number sequence . These mapped appropriate alphabet language . The converted text spoken speech synthesizer . The paper also provides mechanism type Braille character number pad keyboard . The typed Braille character mapped alphabet spoken . The Braille cell standard representation mapping differs language . In paper mapping English Hindi Tamil considered .
We present analysis diacritic recognition performance Arabic Automatic Speech Recognition ( ASR ) system . As existing Arabic speech corpus contain diacritical mark represent short vowel phonetic information Arabic script current state-of-the-art ASR model produce full diacritization output . Automatic text-based diacritization previously employed pre-processing step train diacritized ASR post-processing step diacritize resulting ASR hypothesis . It generally believed input diacritization degrades ASR performance systematic evaluation ASR diacritization performance independent ASR performance conducted date . In paper attempt experimentally clarify whether input diacritiztation indeed degrades ASR quality compare diacritic recognition performance text-based diacritization post-processing step . We start pre-trained Arabic ASR model fine-tune transcribed speech data different diacritization condition : manual automatic diacritization . We isolate diacritic recognition performance overall ASR performance using coverage precision metric . We find ASR diacritization significantly outperforms text-based diacritization post-processing particularly ASR model fine-tuned manually diacritized transcript .
This paper present development systematic machine learning ( ML ) approach enable explainable rapid assessment fire resistance fire-induced spalling reinforced concrete ( RC ) column . The developed approach comprises ensemble three novel ML algorithm namely ; random forest ( RF ) extreme gradient boosted tree ( ExGBT ) deep learning ( DL ) . These algorithm trained account wide collection geometric characteristic material property well loading condition examine fire performance normal high strength RC column analyzing comprehensive database fire test comprising 494 observation . The developed ensemble also capable presenting quantifiable insight ML prediction ; thus breaking free notion 'blackbox ' ML establishing solid step towards transparent explainable ML . Most importantly work tackle scarcity available fire test proposing new technique leverage use real synthetic augmented fire test observation . The developed ML ensemble calibrated validated standard design fire exposure one two three four-sided fire exposure thus ; covering wide range practical scenario present fire incident . When fully deployed developed ensemble analyze 5000 RC column 60 second thus providing attractive solution researcher practitioner . The presented approach also easily extended evaluating fire resistance spalling structural member varying fire scenario loading condition hence pave way modernize state research area practice .
The aim work classify aerospace structure defect detected eddy current non-destructive testing . The proposed method based assumption defect bound reaction probe coil impedance test . Impedance plane analysis used extract feature vector shape coil impedance complex plane use geometric parameter . Shape recognition tested three different machine-learning based classifier : decision tree neural network Naive Bayes . The performance proposed detection system measured term accuracy sensitivity specificity precision Matthews correlation coefficient . Several experiment performed dataset eddy current signal sample aircraft structure . The obtained result demonstrate usefulness approach competiveness existing descriptor .
This paper explores novel mathematical approach extract archaeological insight ensemble similar artifact shape . We show considering shape information find collection possible identify shape pattern would difficult discern considering artifact individually classifying shape predefined archaeological type analyzing associated distinguishing characteristic . Recently series high-resolution digital representation artifact become available explore potential set 3D model ancient Greek Roman sundial aim providing alternative traditional archaeological method `` trend extraction ordination `` ( typology ) . In proposed approach 3D shape represented point shape space -- high-dimensional curved non-Euclidean space . By performing regression shape space find Roman sundial bend sundial ' shadow-receiving surface change location 's latitude . This suggests apart inscribed hour line also sundial 's shape adjusted place installation . As example advanced inference use identified trend infer latitude sundial whose installation location unknown placed . We also derive novel method differentiated morphological trend assertion building upon extending theory geometric statistic shape analysis . Specifically present regression-based method statistical normalization shape serf mean disentangling parameter-dependent effect ( trend ) unexplained variability .
The natural gradient field vector field life model equipped distinguished Riemannian metric e.g . Fisher-Rao metric represents direction steepest ascent objective function model respect metric . In practice one try obtain corresponding direction parameter space multiplying ordinary gradient inverse Gram matrix associated metric . We refer vector parameter space natural parameter gradient . In paper study pushforward natural parameter gradient equal natural gradient . Furthermore investigate invariance property natural parameter gradient . Both question addressed overparametrised setting .
OpenStreetMap unique source openly available worldwide map data increasingly adopted real-world application . Vandalism detection OpenStreetMap critical remarkably challenging due large scale dataset sheer number contributor various vandalism form lack annotated data train machine learning algorithm . This paper present Ovid - novel machine learning method vandalism detection OpenStreetMap . Ovid relies neural network architecture adopts multi-head attention mechanism effectively summarize information indicating vandalism OpenStreetMap changesets . To facilitate automated vandalism detection introduce set original feature capture changeset user edit information . Our evaluation result real-world vandalism data demonstrate proposed Ovid method outperforms baseline 4.7 percentage point F1 score .
The paper cope task automatic assessment second language proficiency language learner ' spoken response test prompt . The task significant relevance field computer assisted language learning . The approach presented paper relies two separate module : ( 1 ) automatic speech recognition system yield text transcript spoken interaction involved ( 2 ) multiple classifier system based deep learner rank transcript proficiency class . Different deep neural network architecture ( feed-forward recurrent ) specialized diverse representation text term : reference grammar outcome probabilistic language model several word embeddings two bag-of-word model . Combination individual classifier realized either via probabilistic pseudo-joint model via neural mixture expert . Using data third Spoken CALL Shared Task challenge highest value date obtained term three popular evaluation metric .
Privacy preference signal digital representation user want personal data processed . Such signal must adopted sender ( user ) intended recipient ( data processor ) . Adoption represents coordination problem remains unsolved despite effort dating back 1990s . Browsers implemented standard like Platform Privacy Preferences ( P3P ) Do Not Track ( DNT ) vendor profiting personal data faced incentive receive respect expressed wish data subject . In wake recent privacy law coalition AdTech firm published Transparency Consent Framework ( TCF ) defines opt-in consent signal . This paper integrates post-GDPR development wider history privacy preference signal . Our main contribution high-frequency longitudinal study describing TCF signal gained dominance February 2021 . We explore factor correlate adoption website level . Both number third party website presence Google Ads associated higher adoption TCF . Further show vendor acted early adopter TCF 2.0 provide two case-studies describing Consent Management Providers shifted existing customer TCF 2.0 . We sketch way forward pro-privacy signal .
Deep convolutional neural network ( DCNNs ) used achieve state-of-the-art performance many computer vision task ( e.g . object recognition object detection semantic segmentation ) thanks large repository annotated image data . Large labeled datasets sensor modality e.g . multispectral imagery ( MSI ) available due large cost manpower required . In paper adapt state-of-the-art DCNN framework computer vision semantic segmentation MSI imagery . To overcome label scarcity MSI data substitute real MSI generated synthetic MSI order initialize DCNN framework . We evaluate network initialization scheme new RIT-18 dataset present paper . This dataset contains very-high resolution MSI collected unmanned aircraft system . The model initialized synthetic imagery less prone over-fitting provide state-of-the-art baseline future work .
Recently safe reinforcement learning ( RL ) actor-critic structure continuous control task received increasing attention . It still challenging learn near-optimal control policy safety convergence guarantee . Also work addressed safe RL algorithm design time-varying safety constraint . This paper proposes safe RL algorithm optimal control nonlinear system time-varying state control constraint . In proposed approach construct novel barrier force-based control policy structure guarantee control safety . A multi-step policy evaluation mechanism proposed predict policy 's safety risk time-varying safety constraint guide policy update safely . Theoretical result stability robustness proven . Also convergence actor-critic implementation analyzed . The performance proposed algorithm outperforms several state-of-the-art RL algorithm simulated Safety Gym environment . Furthermore approach applied integrated path following collision avoidance problem two real-world intelligent vehicle . A differential-drive vehicle Ackermann-drive one used verify offline deployment online learning performance respectively . Our approach show impressive sim-to-real transfer capability satisfactory online control performance experiment .
Purpose : This paper present algorithm elicitate ( infer ) combination ELECTRE Tri-B parameter . For example decision-maker maintain value indifference preference veto threshold algorithm find criterion weight reference profile lambda cutting level . Our approach inspired Machine Learning ensemble technique Random Forest named approach ELECTRE Tree algorithm . Methodology : First generate set ELECTRE Tri-B model model solves random sample criterion alternative . Each sample made replacement least two criterion 10 % 25 % alternative . Each model parameter optimized genetic algorithm use ordered cluster assignment example reference optimization . Finally optimization phase two procedure performed first one merge model finding way elicitated parameter second procedure alternative classified ( voted ) separated model majority vote decides final class . Findings : We noted concerning voting procedure non-linear decision boundary generated suitable analyzing problem nature . In contrast merged model generates linear decision boundary . Originality : The elicitation ELECTRE Tri-B parameter made ensemble technique composed set multicriteria model engaged generating robust solution .
In paper study applicability active learning operative scenario : particularly consider well-known contradiction active learning heuristic rank pixel according uncertainty user 's confidence labeling related homogeneity pixel context user 's knowledge scene . We propose filtering scheme based classifier learns confidence user labeling thus minimizing query user would able provide class pixel . The capacity model learn user 's confidence studied detail also showing effect resolution learning task . Experiments two QuickBird image different resolution ( without pansharpening ) considering committee user prove efficiency filtering scheme proposed maximizes number useful query respect traditional active learning .
Determining number cluster present dataset important problem cluster analysis . Conventional clustering technique generally assume parameter provided front . % user supplied . % Recently robustness given clustering algorithm analyzed measure cluster stability/instability turn determines cluster number . In paper propose method analyzes cluster stability predicting cluster number . Under computational framework technique also find representative cluster . The method apt handling big data design algorithm using \emph { Monte-Carlo } simulation . Also explore pertinent issue found also clustering . Experiments reveal proposed method capable identifying single cluster . It robust handling high dimensional dataset performs reasonably well datasets cluster imbalance . Moreover indicate cluster hierarchy present . Overall observed significant improvement speed quality predicting cluster number well composition cluster large dataset .
We present probabilistic model us prosodic lexical cue automatic segmentation speech topically coherent unit . We propose two method combining lexical prosodic information using hidden Markov model decision tree . Lexical information obtained speech recognizer prosodic feature extracted automatically speech waveform . We evaluate approach Broadcast News corpus using DARPA-TDT evaluation metric . Results show prosodic model alone competitive word-based segmentation method . Furthermore achieve significant reduction error combining prosodic word-based knowledge source .
Essential improving accuracy reliability bowel cancer screening three-dimensional ( 3D ) surface reconstruction using capsule endoscopy ( CE ) image remains challenging due CE hardware software limitation . This report generally focus challenge associated 3D visualization specifically investigates impact indeterminate selection angle line sight 3D surface . Furthermore demonstrates impact 3D surface viewed azimuth angle different elevation angle line sight . The report concludes 3D printing reconstructed 3D surface potentially overcome line sight indeterminate selection 2D screen visual restriction-related error .
A single digital newsletter usually contains many message ( region ) . Users ' reading time spent read level ( skip/skim/read-in-detail ) message important platform understand user ' interest personalize content make recommendation . Based accurate expensive-to-collect eyetracker-recorded data built model predict per-region reading time based easy-to-collect Javascript browser tracking data . With eye-tracking collected 200k ground-truth datapoints participant reading news browser . Then trained machine learning deep learning model predict message-level reading time based user interaction like mouse position scrolling clicking . We reached 27\ % percentage error reading time estimation two-tower neural network based user interaction eye-tracking ground truth data heuristic baseline around 46\ % percentage error . We also discovered benefit replacing per-session model per-timestamp model adding user pattern feature . We concluded suggestion developing message-level reading estimation technique based available data .
Nowadays abundance short text generated us nonstandard writing style influenced regional language . Such informal code-switched content under-resourced term labeled datasets language model even popular task like sentiment classification . In work ( 1 ) present labeled dataset called MultiSenti sentiment classification code-switched informal short text ( 2 ) explore feasibility adapting resource resource-rich language informal one ( 3 ) propose deep learning-based model sentiment classification code-switched informal short text . We aim achieve without lexical normalization language translation code-switching indication . The performance proposed model compared three existing multilingual sentiment classification model . The result show proposed model performs better general adapting character-based embeddings yield equivalent performance computationally efficient training word-based domain-specific embeddings .
Open set recognition emerging research area aim simultaneously classify sample predefined class identify rest 'unknown ' . In process one key challenge reduce risk generalizing inherent characteristic numerous unknown sample learned small amount known data . In paper propose new concept Reciprocal Point potential representation extra-class space corresponding known category . The sample classified known unknown otherness reciprocal point . To tackle open set problem offer novel open space risk regularization term . Based bounded space constructed reciprocal point risk unknown reduced multi-category interaction . The novel learning framework called Reciprocal Point Learning ( RPL ) indirectly introduce unknown information learner known class learn compact discriminative representation . Moreover construct new large-scale challenging aircraft dataset open set recognition : Aircraft 300 ( Air-300 ) . Extensive experiment multiple benchmark datasets indicate framework significantly superior existing approach achieves state-of-the-art performance standard open set benchmark .
Traffic prediction spatiotemporal predictive task play essential role intelligent transportation system . Today graph convolutional neural network ( GCNNs ) become prevailing model traffic prediction literature since excel extracting spatial correlation . In work classify component successful GCNN prediction model analyze effect matrix factorization attention mechanism weight sharing performance . Furthermore compare variation random forest traditional regression method predates GCNNs 15 year . We evaluated method using simulated data two region Toronto well real-world sensor data selected California highway . We found incorporating matrix factorization attention location-specific model weight either individually collectively GCNNs result better overall performance . Moreover although random forest regression less compact model match exceeds performance variation GCNNs experiment . This suggests current graph convolutional method may best approach traffic prediction still room improvement . Finally finding also suggest future research GCNN traffic prediction credible researcher must include performance comparison random forest .
Personalized web service strive adapt service ( advertisement news article etc ) individual user making use content user information . Despite recent advance problem remains challenging least two reason . First web service featured dynamically changing pool content rendering traditional collaborative filtering method inapplicable . Second scale web service practical interest call solution fast learning computation . In work model personalized recommendation news article contextual bandit problem principled approach learning algorithm sequentially selects article serve user based contextual information user article simultaneously adapting article-selection strategy based user-click feedback maximize total user click . The contribution work three-fold . First propose new general contextual bandit algorithm computationally efficient well motivated learning theory . Second argue bandit algorithm reliably evaluated offline using previously recorded random traffic . Finally using offline evaluation method successfully applied new algorithm Yahoo ! Front Page Today Module dataset containing 33 million event . Results showed 12.5 % click lift compared standard context-free bandit algorithm advantage becomes even greater data get scarce .
Resolution deep convolutional neural network ( CNNs ) typically bounded receptive field size filter size subsampling layer strided convolution feature map . The optimal resolution may vary significantly depending dataset . Modern CNNs hard-code resolution hyper-parameters network architecture make tuning hyper-parameters cumbersome . We propose away hard-coded resolution hyper-parameters aim learn appropriate resolution data . We use scale-space theory obtain self-similar parametrization filter make use N-Jet : truncated Taylor series approximate filter learned combination Gaussian derivative filter . The parameter sigma Gaussian basis control amount detail filter encodes spatial extent filter . Since sigma continuous parameter optimize respect loss . The proposed N-Jet layer achieves comparable performance used state-of-the art architecture learning correct resolution layer automatically . We evaluate N-Jet layer classification segmentation show learning sigma especially beneficial input multiple size .
Representing video densely extracted local space-time feature recently become popular approach analysing action . In paper tackle problem categorising human action devising Bag Words ( BoW ) model based covariance matrix spatio-temporal feature feature formed histogram optical flow . Since covariance matrix form special type Riemannian manifold space Symmetric Positive Definite ( SPD ) matrix non-Euclidean geometry taken account discriminating covariance matrix . To end propose embed SPD manifold Euclidean space via diffeomorphism extend BoW approach Riemannian version . The proposed BoW approach take account manifold geometry SPD matrix generation codebook histogram . Experiments challenging human action datasets show proposed method obtains notable improvement discrimination accuracy comparison several state-of-the-art method .
The development Autonomous Vehicle ( AV ) created novel job safety driver recruited experienced driver supervise operate AV numerous driving mission . Safety driver usually work non-perfect AV high-risk real-world traffic environment road testing task . However group worker under-explored HCI community . To fill gap conducted semi-structured interview 26 safety driver . Our result present safety driver cope defective algorithm shape calibrate perception working AV . We found front-line worker safety driver forced take risk accumulated AV industry upstream also confronting restricted self-development working AV development . We contribute first empirical evidence lived experience safety driver first passenger development AV also grassroots worker AV shed light future human-AI interaction research .
Algorithmic fairness attracted increasing attention machine learning community . Various definition proposed literature difference connection among clearly addressed . In paper review reflect various fairness notion previously proposed machine learning literature make attempt draw connection argument moral political philosophy especially theory justice . We also consider fairness inquiry dynamic perspective consider long-term impact induced current prediction decision . In light difference characterized fairness present flowchart encompasses implicit assumption expected outcome different type fairness inquiry data generating process predicted outcome induced impact respectively . This paper demonstrates importance matching mission ( kind fairness one would like enforce ) mean ( spectrum fairness analysis interest appropriate analyzing scheme ) fulfill intended purpose .
Implicit bias stereotype often pervasive different form creative writing novel screenplay child 's book . To understand kind bias writer concerned mitigate writing conducted formative interview nine writer . The interview suggested despite writer 's best interest tracking managing implicit bias lack agency supporting submissive role harmful language character representing marginalized group challenging story becomes longer complicated . Based interview developed DramatVis Personae ( DVP ) visual analytics tool allows writer assign social identity character evaluate character different intersectional social identity represented story . To evaluate DVP first conducted think-aloud session three writer found DVP easy-to-use naturally integrates writing process could potentially help writer several critical bias identification task . We conducted follow-up user study 11 writer found participant could answer question related bias detection efficiently using DVP comparison simple text editor .
Estimator algorithm learning automaton useful tool adaptive real-time optimization computer science engineering application . This paper investigates theoretical convergence property special case estimator algorithm : pursuit learning algorithm . In note identify fill gap existing proof probabilistic convergence pursuit learning . It tradition take pursuit learning tuning parameter fixed practical application proof shed light importance vanishing sequence tuning parameter theoretical convergence analysis .
Researchers continually perform corroborative test classify ancient historical document based physical material writing surface . However test often performed on-site requires actual access manuscript object . The procedure involve considerable amount time cost damage manuscript . Developing technique classify document using digital image useful efficient . In order tackle problem study us image famous historical collection Dead Sea Scrolls propose novel method classify material manuscript . The proposed classifier us two-dimensional Fourier Transform identify pattern within manuscript surface . Combining binary classification system employing transform majority voting process shown effective classification task . This pilot study show successful classification percentage 97 % confined amount manuscript produced either parchment papyrus material . Feature vector based Fourier-space grid representation outperformed concentric Fourier-space format .
Machine transliteration method automatically converting word one language phonetically equivalent one another language . Machine transliteration play important role natural language application information retrieval machine translation especially handling proper noun technical term . Four machine transliteration model -- grapheme-based transliteration model phoneme-based transliteration model hybrid transliteration model correspondence-based transliteration model -- proposed several researcher . To date however little research framework multiple transliteration model operate simultaneously . Furthermore comparison four model within framework using data . We addressed problem 1 ) modeling four model within framework 2 ) comparing condition 3 ) developing way improve machine transliteration comparison . Our comparison showed hybrid correspondence-based model effective four model used complementary manner improve machine transliteration performance .
Visualization virtual environment ( VEs ) two interconnected parallel strand visual computing decade . Some VEs purposely developed visualization application many visualization application exemplary showcase general-purpose VEs . Because development operation cost VEs majority visualization application practice yet benefit capacity VEs . In paper examine perplexity information-theoretic perspective . Our objective conduct cost-benefit analysis typical VE system ( including augmented mixed reality theatre-based system large powerwalls ) explain visualization application benefit VEs others sketch pathway future development visualization application VEs . We support theoretical proposition analysis using theory discovery literature cognitive science practical evidence reported literature visualization VEs .
In paper system build music intuitive accessible way Lego brick presented . The system make use new powerful cheap possibility technology offer making old thing new way . The Raspberry Pi used control system run necessary algorithm customized Lego brick used building melody custom electronic design software piece 3D printed part complete item employed . The system designed modular allows creating melody chord percussion melody perform beatbox melody box . The main interaction system made using Lego-type building block . Tests demonstrated versatility ease use well usefulness music learning child adult .
Deep neural network ( DNNs ) greatly contributed performance gain semantic segmentation . Nevertheless training DNNs generally requires large amount pixel-level labeled data expensive time-consuming collect practice . To mitigate annotation burden paper proposes self-ensembling generative adversarial network ( SE-GAN ) exploiting cross-domain data semantic segmentation . In SE-GAN teacher network student network constitute self-ensembling model generating semantic segmentation map together discriminator form GAN . Despite simplicity find SE-GAN significantly boost performance adversarial training enhance stability model latter common barrier shared adversarial training-based method . We theoretically analyze SE-GAN provide $ \mathcal O ( 1/\sqrt { N } ) $ generalization bound ( $ N $ training sample size ) suggests controlling discriminator 's hypothesis complexity enhance generalizability . Accordingly choose simple network discriminator . Extensive systematic experiment two standard setting demonstrate proposed method significantly outperforms current state-of-the-art approach . The source code model available online ( http : //github.com/YonghaoXu/SE-GAN ) .
Understanding information encoded deep model spoken written language focus much research recent year crucial debugging improving architecture . Most previous work focused probing speaker characteristic acoustic phonological information model spoken language syntactic information model written language . Here focus encoding syntax several self-supervised visually grounded model spoken language . We employ two complementary probing method combined baseline reference representation quantify degree syntactic structure encoded activation target model . We show syntax captured prominently middle layer network explicitly within model parameter .
This article present result study involving translation short story Kurt Vonnegut English Catalan Dutch using three modality : machine-translation ( MT ) post-editing ( PE ) translation without aid ( HT ) . Our aim explore creativity understood involve novelty acceptability quantitative perspective . The result show HT highest creativity score followed PE lastly MT unanimous reviewer . A neural MT system trained literary data currently necessary capability creative translation ; render literal solution translation problem . More importantly using MT post-edit raw output constrains creativity translator resulting poorer translation often fit publication according expert .
Clustering ensemble consensus clustering emerged powerful tool improving robustness stability result individual clustering method . Weighted clustering ensemble arises naturally clustering ensemble . One argument weighted clustering ensemble element ( clustering cluster ) clustering ensemble different quality object feature varying significance . However possible directly apply weighting mechanism classification ( supervised ) domain clustering ( unsupervised ) domain also clustering inherently ill-posed problem . This paper provides overview weighted clustering ensemble discussing different type weight major approach determining weight value application weighted clustering ensemble complex data . The unifying framework presented paper help clustering practitioner select appropriate weighting mechanism problem .
This work present systematic study objective evaluation abstaining classification using Information-Theoretic Measures ( ITMs ) . First define objective measure depend free parameter . This definition provides technical simplicity examining `` objectivity `` `` subjectivity `` directly classification evaluation . Second propose twenty four normalized ITMs derived either mutual information divergence cross-entropy investigation . Contrary conventional performance measure apply empirical formula based user ' intuition preference ITMs theoretically sound realizing objective evaluation classification . We apply distinguish `` error type `` `` reject type `` binary classification without need input data cost term . Third better understand select ITMs suggest three desirable feature classification assessment measure appear crucial appealing viewpoint classification application . Using feature `` meta-measures `` reveal advantage limitation ITMs higher level evaluation knowledge . Numerical example given corroborate claim compare difference among proposed measure . The best measure selected term meta-measures specific property regarding error type reject type analytically derived .
Companies across globe keen targeting potential high-value customer attempt expand revenue could achieved understanding customer . Customer Lifetime Value ( CLV ) total monetary value transactions/purchases made customer business intended period time used mean estimate future customer interaction . CLV find application number distinct business domain Banking Insurance Online-entertainment Gaming E-Commerce . The existing distribution-based basic ( recency frequency & monetary ) based model face limitation term handling wide variety input feature . Moreover advanced Deep learning approach could superfluous add undesirable element complexity certain application area . We therefore propose system able qualify effective comprehensive yet simple interpretable . With mind develop meta-learning-based stacked regression model combine prediction bagging boosting model found perform well individually . Empirical test carried openly available Online Retail dataset evaluate various model show efficacy proposed approach .
Poetry prose written artistic expression help u appreciate reality live . Each style set subjective property rhyme rhythm easily caught human reader 's eye ear . With recent advance artificial intelligence gap human machine may decreased today observe algorithm mastering task exclusively performed human . In paper propose automated method distinguish poetry prose based solely aural rhythmic property . In compare prose poetry rhythm represent rhyme phone temporal sequence thus propose procedure extracting rhythmic feature sequence . The classification considered text using set feature extracted resulted best accuracy 0.78 obtained neural network . Interestingly using approach based complex network visualize similarity different text considered found pattern poetry vary much prose . Consequently much richer complex set rhythmic possibility tends found modality .
LAMDA-SSL open-sourced GitHub detailed usage documentation available http : //ygzwqzd.github.io/LAMDA-SSL/ . This documentation introduces LAMDA-SSL detail various aspect divided four part . The first part introduces design idea feature function LAMDA-SSL . The second part show usage LAMDA-SSL abundant example detail . The third part introduces algorithm implemented LAMDA-SSL help user quickly understand choose SSL algorithm . The fourth part show APIs LAMDA-SSL . This detailed documentation greatly reduces cost familiarizing user LAMDA-SSL toolkit SSL algorithm .
Earth observation ( EO ) prime instrument monitoring land ocean process studying dynamic work taking pulse planet . This article give bird 's eye view essential scientific tool approach informing supporting transition raw EO data usable EO-based information . The promise well current challenge development highlighted dedicated section . Specifically cover impact ( ) Computer vision ; ( ii ) Machine learning ; ( iii ) Advanced processing computing ; ( iv ) Knowledge-based AI ; ( v ) Explainable AI causal inference ; ( vi ) Physics-aware model ; ( vii ) User-centric approach ; ( viii ) much-needed discussion ethical societal issue related massive use ML technology EO .
In recent year unmanned aerial vehicle ( UAV ) imaging suitable solution real-time monitoring different vehicle urban scale . Real-time vehicle detection use uncertainty estimation deep meta-learning portable platform ( e.g . UAV ) potentially improves video understanding real-world application small training dataset many vehicle monitoring approach appear understand single-time detection big training dataset . The purpose real-time vehicle detection oblique UAV image locate vehicle time series UAV image using semantic segmentation . Real-time vehicle detection difficult due variety depth scale vehicle oblique view UAV image . Motivated fact manuscript consider problem real-time vehicle detection oblique UAV image based small training dataset deep meta-learning . The proposed architecture called SA-Net.v2 developed method based SA-CNN real-time vehicle detection reformulating squeeze-and-attention mechanism . The SA-Net.v2 composed two component including squeeze-and-attention function extract high-level feature based small training dataset gated CNN . For real-time vehicle detection scenario test model UAVid dataset . UAVid time series oblique UAV image dataset consisting 30 video sequence . We examine proposed method 's applicability stand real-time vehicle detection urban environment using time series UAV image . The experiment show SA-Net.v2 achieves promising performance time series oblique UAV image .
We propose method reconstructing continuous light field target scene single observed image . Our method take best two world : joint aperture-exposure coding compressive light-field acquisition neural radiance field ( NeRF ) view synthesis . Joint aperture-exposure coding implemented camera enables effective embedding 3-D scene information observed image previous work used reconstructing discretized light-field view . NeRF-based neural rendering enables high quality view synthesis 3-D scene continuous viewpoint single image given input struggle achieve satisfactory quality . Our method integrates two technique efficient end-to-end trainable pipeline . Trained wide variety scene method reconstruct continuous light field accurately efficiently without test time optimization . To knowledge first work bridge two world : camera design efficiently acquiring 3-D information neural rendering .
We present novel Bayesian topic model learning discourse-level document structure . Our model leverage insight discourse theory constrain latent topic assignment way reflects underlying organization document topic . We propose global model topic selection ordering biased similar across collection related document . We show space ordering effectively represented using distribution permutation called Generalized Mallows Model . We apply method three complementary discourse-level task : cross-document alignment document segmentation information ordering . Our experiment show incorporating permutation-based model application yield substantial improvement performance previously proposed method .
Ultrasonic metal welding ( UMW ) key joining technology widespread industrial application . Condition monitoring ( CM ) capability critically needed UMW application process anomaly significantly deteriorate joining quality . Recently machine learning model emerged promising tool CM many manufacturing application due ability learn complex pattern . Yet successful deployment model requires substantial training data may expensive time-consuming collect . Additionally many existing machine learning model lack generalizability directly applied new process configuration ( i.e . domain ) . Such issue may potentially alleviated pooling data across manufacturer data sharing raise critical data privacy concern . To address challenge paper present Federated Transfer Learning Task Personalization ( FTL-TP ) framework provides domain generalization capability distributed learning ensuring data privacy . By effectively learning unified representation feature space FTL-TP adapt CM model client working similar task thereby enhancing overall adaptability performance jointly . To demonstrate effectiveness FTL-TP investigate two distinct UMW CM task tool condition monitoring workpiece surface condition classification . Compared state-of-the-art FL algorithm FTL-TP achieves 5.35 % -- 8.08 % improvement accuracy CM new target domain . FTL-TP also shown perform excellently challenging scenario involving unbalanced data distribution limited client fraction . Furthermore implementing FTL-TP method edge-cloud architecture show method viable efficient practice . The FTL-TP framework readily extensible various manufacturing application .
Unsupervised video person re-identification ( reID ) method usually depend global-level feature . And many supervised reID method employed local-level feature achieved significant performance improvement . However applying local-level feature unsupervised method may introduce unstable performance . To improve performance stability unsupervised video reID paper introduces general scheme fusing part model unsupervised learning . In scheme global-level feature divided equal local-level feature . A local-aware module employed explore poentials local-level feature unsupervised learning . A global-aware module proposed overcome disadvantage local-level feature . Features two module fused form robust feature representation input image . This feature representation advantage local-level feature without suffering disadvantage . Comprehensive experiment conducted three benchmark including PRID2011 iLIDS-VID DukeMTMC-VideoReID result demonstrate proposed approach achieves state-of-the-art performance . Extensive ablation study demonstrate effectiveness robustness proposed scheme local-aware module global-aware module . The code generated feature available http : //github.com/deropty/uPMnet .
Self-Supervised learning ( SSL ) become new state-of-art several domain classification segmentation task . Of one popular category SSL distillation network BYOL . This work proposes RSDnet applies distillation network ( BYOL ) remote sensing ( RS ) domain data non-trivially different natural RGB image . Since Multi-spectral ( MS ) synthetic aperture radar ( SAR ) sensor provide varied spectral spatial resolution information utilised implicit augmentation learn invariant feature embeddings . In order learn RS based invariant feature SSL trained RSDnet two way i.e . single channel feature learning three channel feature learning . This work explores usefulness single channel feature learning random MS SAR band compared common notion using three band . In linear evaluation single channel feature reached 0.92 F1 score EuroSAT classification task 59.6 mIoU DFC segmentation task certain single band . We also compared result ImageNet weight showed RS based SSL model outperforms supervised ImageNet based model . We explored usefulness multi-modal data compared single modality data shown utilising MS SAR data learn better invariant representation utilising MS data .
In research focus usage adversarial sampling test fairness prediction deep neural network model across different class image given dataset . While several framework proposed ensure robustness machine learning model adversarial attack includes adversarial training algorithm . There still pitfall adversarial training algorithm tends cause disparity accuracy robustness among different group . Our research aimed using adversarial sampling test fairness prediction deep neural network model across different class category image given dataset . We successfully demonstrated new method ensuring fairness across various group input deep neural network classifier . We trained neural network model original image without training model perturbed attacked image . When feed adversarial sampling model able predict original category/ class image adversarial sample belongs . We also introduced used separation concern concept software engineering whereby additional standalone filter layer filter perturbed image heavily removing noise attack automatically passing network classification able accuracy 93.3 % . Cifar-10 dataset ten category dataset order account fairness applied hypothesis across category dataset able get consistent result accuracy .
In letter note denoising performance Non-Local Means ( NLM ) large noise level improved replacing mean Euclidean median . We call new denoising algorithm Non-Local Euclidean Medians ( NLEM ) . At heart NLEM observation median robust outlier mean . In particular provide simple geometric insight explains NLEM performs better NLM vicinity edge particularly large noise level . NLEM efficiently implemented using iteratively reweighted least square computational complexity comparable NLM . We provide preliminary result study proposed algorithm compare NLM .
Interpreting regulatory document building code computer-processable format essential intelligent design construction building infrastructure . Although automated rule interpretation ( ARI ) method investigated year highly depend early manual filtering interpretable clause building code . While considered machine interpretability represents potential transformed computer-processable format clause- document-level . Therefore research aim propose novel approach automatically evaluate enhance machine interpretability single clause building code . First category introduced classify clause building code considering requirement rule interpretation dataset developed model training . Then efficient text classification model developed based pretrained domain-specific language model transfer learning technique . Finally quantitative evaluation method proposed assess overall interpretability building code . Experiments show proposed text classification algorithm outperforms existing CNN- RNN-based method improving F1-score 72.16 % 93.60 % . It also illustrated proposed classification method enhance downstream ARI method improvement 4 % . Furthermore analyzing result 150 building code China showed average interpretability 34.40 % implies still hard fully transform entire regulatory document computer-processable format . It also argued interpretability building code improved human side machine side .
Recent development biosignal processing enabled user exploit physiological status manipulating device reliable safe manner . One major challenge physiological sensing lie variability biosignals across different user task . To address issue propose adversarial feature extractor transfer learning exploit disentangled universal representation . We consider trade-off task-relevant feature user-discriminative information introducing additional adversary nuisance network order manipulate latent representation learned feature extractor applicable unknown user various task . Results cross-subject transfer evaluation exhibit benefit proposed framework 8.8 % improvement average accuracy classification demonstrate adaptability broader range subject .
We study Frank-Wolfe algorithm - standard pairwise away-steps - efficient optimization Dominant Set Clustering . We present unified computationally efficient framework employ different variant Frank-Wolfe method investigate effectiveness via several experimental study . In addition provide explicit convergence rate algorithm term so-called Frank-Wolfe gap . The theoretical analysis specialized Dominant Set Clustering cover consistently different variant .
Text summarization process condensing piece text fewer sentence still preserving content . Chat transcript context textual copy digital online conversation customer ( caller ) agent ( ) . This paper present indigenously ( locally ) developed hybrid method first combine extractive abstractive summarization technique compressing ill-punctuated un-punctuated chat transcript produce readable punctuated summary optimizes overall quality summarization reinforcement learning . Extensive testing evaluation comparison validation demonstrated efficacy approach large-scale deployment chat transcript summarization absence manually generated reference ( annotated ) summary .
This work address performance comparison four clustering technique objective achieving strong hybrid model supervised learning task . A real dataset bio-climatic house named Sotavento placed experimental wind farm located Xermade ( Lugo ) Galicia ( Spain ) collected . Authors chosen thermal solar generation system order study work applying several cluster method followed regression technique predict output temperature system . With objective defining quality clustering method two possible solution implemented . The first one based three unsupervised learning metric ( Silhouette Calinski-Harabasz Davies-Bouldin ) second one employ common error measurement regression algorithm Multi Layer Perceptron .
We address problem person re-identification ( reID ) retrieving person image large dataset given query image person interest . A key challenge learn person representation robust intra-class variation different person could attribute person ' appearance look different e.g . viewpoint change . Recent reID method focus learning person feature discriminative particular factor variation ( e.g . human pose ) also requires corresponding supervisory signal ( e.g . pose annotation ) . To tackle problem propose factorize person image identity-related unrelated feature . Identity-related feature contain information useful specifying particular person ( e.g . clothing ) identity-unrelated one hold factor ( e.g . human pose ) . To end propose new generative adversarial network dubbed identity shuffle GAN ( IS-GAN ) . It disentangles identity-related unrelated feature person image identity-shuffling technique exploit identification label alone without auxiliary supervisory signal . We restrict distribution identity-unrelated feature encourage identity-related unrelated feature uncorrelated facilitating disentanglement process . Experimental result validate effectiveness IS-GAN showing state-of-the-art performance standard reID benchmark including Market-1501 CUHK03 DukeMTMC-reID . We demonstrate advantage disentangling person representation long-term reID task setting new state art Celeb-reID dataset .
We study best arm identification federated multi-armed bandit setting central server multiple client client access { \em subset } arm arm yield independent Gaussian observation . The goal identify best arm client subject upper bound error probability ; best arm one largest { \em average } value mean averaged across client access arm . Our interest asymptotics error probability vanishes . We provide asymptotic lower bound growth rate expected stopping time algorithm . Furthermore show algorithm whose upper bound expected stopping time match lower bound multiplicative constant ( { \em almost-optimal } algorithm ) ratio two consecutive communication time instant must { \em bounded } result independent interest . We thereby infer algorithm communicate sparsely exponential time instant order almost-optimal . For class almost-optimal algorithm present first-of-its-kind asymptotic lower bound expected number { \em communication round } stoppage . We propose novel algorithm communicates exponential time instant demonstrate asymptotically almost-optimal .
This paper present recognition system handwritten Pashto letter . However handwritten character recognition challenging task . These letter differ shape style also vary among individual . The recognition becomes daunting due lack standard datasets inscribed Pashto letter . In work designed database moderate size encompasses total 4488 image stemming 102 distinguishing sample 44 letter Pashto . The recognition framework us zoning feature extractor followed K-Nearest Neighbour ( KNN ) Neural Network ( NN ) classifier classifying individual letter . Based evaluation proposed system overall classification accuracy approximately 70.05 % achieved using KNN 72 % achieved using NN .
Speech-based automatic detection Alzheimer 's disease ( AD ) depression attracted increased attention . Confidence estimation crucial trust-worthy automatic diagnostic system informs clinician confidence model prediction help reduce risk misdiagnosis . This paper investigates confidence estimation automatic detection AD depression based clinical interview . A novel Bayesian approach proposed us dynamic Dirichlet prior distribution model second-order probability predictive distribution . Experimental result publicly available ADReSS DAIC-WOZ datasets demonstrate proposed method outperforms range baseline classification accuracy confidence estimation .
There new generation emoticon called emojis increasingly used mobile communication social medium . In past two year ten billion emojis used Twitter . Emojis Unicode graphic symbol used shorthand express concept idea . In contrast small number well-known emoticon carry clear emotional content hundred emojis . But emotional content ? We provide first emoji sentiment lexicon called Emoji Sentiment Ranking draw sentiment map 751 frequently used emojis . The sentiment emojis computed sentiment tweet occur . We engaged 83 human annotator label 1.6 million tweet 13 European language sentiment polarity ( negative neutral positive ) . About 4 % annotated tweet contain emojis . The sentiment analysis emojis allows u draw several interesting conclusion . It turn emojis positive especially popular one . The sentiment distribution tweet without emojis significantly different . The inter-annotator agreement tweet emojis higher . Emojis tend occur end tweet sentiment polarity increase distance . We observe significant difference emoji ranking 13 language Emoji Sentiment Ranking . Consequently propose Emoji Sentiment Ranking European language-independent resource automated sentiment analysis . Finally paper provides formalization sentiment novel visualization form sentiment bar .
Consider family set single set called query set . How one quickly find member family maximal intersection query set ? Time constraint query possible preprocessing set family make problem challenging . Such maximal intersection query arise wide range application including web search recommendation system distributing on-line advertisement . In general maximal intersection query computationally expensive . We investigate two well-motivated distribution family set propose algorithm . We show high probability almost optimal solution found time logarithmic size family . Moreover point threshold phenomenon probability intersecting set two input model lead efficient algorithm mentioned .
Event camera inspired biological vision system provide natural data efficient representation visual information . Visual information acquired form event triggered local brightness change . Each pixel location camera 's sensor record event asynchronously independently high temporal resolution . However brightness change triggered relative motion camera scene event recorded single sensor location seldom correspond world point . To extract meaningful information event camera helpful register event triggered underlying world point . In work propose new model event data capture natural spatio-temporal structure . We start developing model aligned event data . That develop model data though perfectly registered already . In particular model aligned data spatio-temporal Poisson point process . Based model develop maximum likelihood approach registering event yet aligned . That find transformation observed event make likely possible model . In particular extract camera rotation lead best event alignment . We show new state art accuracy rotational velocity estimation DAVIS 240C dataset . In addition method also faster lower computational complexity several competing method .
It remains uncertain regarding safety driving autonomous vehicle long passive control inattention driving situation driver effectively informed take-over control emergency . In particular active role vehicle force feedback driver 's risk perception curve fully explored . To investigate current paper examined driver 's cognitive visual response whole-body haptic feedback curve negotiation . The effect force feedback driver ' response curve investigated high-fidelity driving simulator measuring EEG visual gaze ten participant . The preliminary analysis first two participant revealed pupil diameter fixation time curve significantly longer driver received whole-body feedback compared none . The finding suggest whole-body feedback used effective `` advance notification `` hazard .
One well-established application machine learning deciding content show website visitor . When observation data come high-velocity user-generated data stream machine learning method perform balancing act model complexity training time computational cost . Furthermore model freshness critical training model becomes time-constrained . Parallelized batch offline training although horizontally scalable often time-considerate cost-effective . In paper propose Lambda Learner new framework training model incremental update response mini-batches data stream . We show resulting model framework closely estimate periodically updated model trained offline data outperforms model update time-sensitive . We provide theoretical proof incremental learning update improve loss-function stale batch model . We present large-scale deployment sponsored content platform large social network serving hundred million user across different channel ( e.g . desktop mobile ) . We address challenge complexity algorithm infrastructure perspective illustrate system detail computation storage streaming production training data .
We extend adversarial/non-stochastic multi-play multi-armed bandit ( MPMAB ) case number arm play variable . The work motivated fact resource allocated scan different critical location interconnected transportation system change dynamically time depending environment . By modeling malicious hacker intrusion monitoring system attacker defender respectively formulate problem two player sequential pursuit-evasion game . We derive condition Nash equilibrium strategic game exists . For defender side provide exponential-weighted based algorithm sublinear pseudo-regret . We extend model heterogeneous reward player obtain lower upper bound average reward attacker . We provide numerical experiment demonstrate effectiveness variable-arm play .
Save special case current training method Generative Adversarial Networks ( GANs ) best guaranteed converge ` local Nash equilibrium ` ( LNE ) . Such LNEs however arbitrarily far actual Nash equilibrium ( NE ) implies guarantee quality found generator classifier . This paper proposes model GANs explicitly finite game mixed strategy thereby ensuring every LNE NE . With formulation propose solution method proven monotonically converge resource-bounded Nash equilibrium ( RB-NE ) : increasing computational resource find better solution . We empirically demonstrate method less prone typical GAN problem mode collapse produce solution less exploitable produced GANs MGANs closely resemble theoretical prediction NEs .
There increasing role IT design community play regulation emerging IT . Article 25 EU General Data Protection Regulation ( GDPR ) 2016 put strict legal basis establishing need information privacy design default ( PbD ) personal data-driven technology . Against backdrop examine legal commercial technical perspective around newly created legal right data portability ( RTDP ) GDPR . We motivated pressing need address regulatory challenge stemming Internet Things ( IoT ) . We need find channel support protection new legal right user practice . In Part I introduce internet thing information PbD detail . We briefly consider regulatory challenge posed IoT nature practical challenge surrounding regulatory response information privacy design . In Part II look depth legal nature RTDP determining requires IT designer practice also limitation right relates IoT . In Part III focus technical approach support realisation right . We consider state art data management architecture tool platform provide portability increased transparency user control data flow . In Part IV bring perspective together reflect technical legal business barrier opportunity shape implementation RTDP practice relationship may shape emerging IoT innovation business model . We finish brief conclusion future RTDP PbD IoT .
While number remarkable breakthrough machine learning ( ML ) much focus placed model development . However truly realize potential machine learning real-world setting additional aspect must considered across ML pipeline . Data-centric AI emerging unifying paradigm could enable reliable end-to-end pipeline . However remains nascent area standardized framework guide practitioner necessary data-centric consideration communicate design data-centric driven ML system . To address gap propose DC-Check actionable checklist-style framework elicit data-centric consideration different stage ML pipeline : Data Training Testing Deployment . This data-centric lens development aim promote thoughtfulness transparency prior system development . Additionally highlight specific data-centric AI challenge research opportunity . DC-Check aimed practitioner researcher guide day-to-day development . As easily engage use DC-Check associated resource provide DC-Check companion website ( http : //www.vanderschaar-lab.com/dc-check/ ) . The website also serve updated resource method tooling evolve time .
Compressive sensing ( CS ) work acquire measurement sub-Nyquist rate recover scene image . Existing CS method always recover scene image pixel level . This cause smoothness recovered image lack structure information especially low measurement rate . To overcome drawback paper propose perceptual CS obtain high-level structured recovery . Our task longer focus pixel level . Instead work make better visual effect . In detail employ perceptual loss defined feature level enhance structure information recovered image . Experiments show method achieves better visual result stronger structure information existing CS method measurement rate .
While pre-training large-scale video-language model ( VLMs ) shown remarkable potential various downstream video-language task existing VLMs still suffer certain commonly seen limitation e.g . coarse-grained cross-modal aligning under-modeling temporal dynamic detached video-language view . In work target enhancing VLMs fine-grained structural spatio-temporal alignment learning method ( namely Finsta ) . First represent input text video fine-grained scene graph ( SG ) structure unified holistic SG ( HSG ) bridging two modality . Then SG-based framework built textual SG ( TSG ) encoded graph Transformer video dynamic SG ( DSG ) HSG modeled novel recurrent graph Transformer spatial temporal feature propagation . A spatial-temporal Gaussian differential graph Transformer devised strengthen sense change object across spatial temporal dimension . Next based fine-grained structural feature TSG DSG perform object-centered spatial alignment predicate-centered temporal alignment respectively enhancing video-language grounding spatiality temporality . We design method plug & play system integrated existing well-trained VLMs representation augmentation without training scratch relying SG annotation downstream application . On 6 representative VL modeling task 12 datasets standard long-form video scenario Finsta consistently improves existing 13 strong-performing VLMs persistently refreshes current state-of-the-art end task performance significantly fine-tuning zero-shot setting .
Texture characterization key problem image understanding pattern recognition . In paper present flexible shape-based texture representation using shape co-occurrence pattern . More precisely texture image first represented tree shape associated several geometrical radiometric attribute . Then four typical kind shape co-occurrence pattern based hierarchical relationship shape tree learned codewords . Three different coding method investigated learn codewords given texture image encoded descriptive vector . In contrast existing work proposed method inherits strong ability depict geometrical aspect texture high robustness variation imaging condition shape-based method also provides flexible way consider shape relationship compute high-order statistic tree . To knowledge first time use co-occurrence pattern explicit shape tool texture analysis . Experiments various texture datasets scene datasets demonstrate efficiency proposed method .
The aim work develop fully-distributed algorithmic framework training graph convolutional network ( GCNs ) . The proposed method able exploit meaningful relational structure input data collected set agent communicate sparse network topology . After formulating centralized GCN training problem first show make inference distributed scenario underlying data graph split among different agent . Then propose distributed gradient descent procedure solve GCN training problem . The resulting model distributes computation along three line : inference back-propagation optimization . Convergence stationary solution GCN training problem also established mild condition . Finally propose optimization criterion design communication topology agent order match graph describing data relationship . A wide set numerical result validate proposal . To best knowledge first work combining graph convolutional neural network distributed optimization .
Despite transition digital information exchange many document invoice tax memo questionnaire historical data answer exam question still require handwritten input . In regard need implement Handwritten Text Recognition ( HTR ) automatic way decrypt record using computer . Handwriting recognition challenging virtually infinite number way person write message . For proposal introduce Kazakh handwritten text recognition research comprehensive dataset Kazakh handwritten text necessary . This particularly true given lack dataset handwritten Kazakh text . In paper proposed extensive Kazakh offline Handwritten Text dataset ( KOHTD ) 3000 handwritten exam paper 140335 segmented image approximately 922010 symbol . It serve researcher field handwriting recognition task using deep machine learning . We used variety popular text recognition method word line recognition study including CTC-based attention-based method . The finding demonstrate KOHTD 's diversity . Also proposed Genetic Algorithm ( GA ) line word segmentation based random enumeration parameter . The dataset GA code available http : //github.com/abdoelsayed2016/KOHTD .
Understanding measuring resilience food supply network global imperative tackle increasing food insecurity . However complexity network multidimensional interaction decision present significant challenge . This paper proposes FLEE-GNN novel Federated Learning System Edge-Enhanced Graph Neural Network designed overcome challenge enhance analysis geospatial resilience multicommodity food flow network one type spatial network . FLEE-GNN address limitation current methodology entropy-based method term generalizability scalability data privacy . It combine robustness adaptability graph neural network privacy-conscious decentralized aspect federated learning food supply network resilience analysis across geographical region . This paper also discusses FLEE-GNN 's innovative data generation technique experimental design future direction improvement . The result show advancement approach quantifying resilience multicommodity food flow network contributing effort towards ensuring global food security using AI method . The developed FLEE-GNN potential applied spatial network spatially heterogeneous sub-network distribution .
In work based local phase information image objective index called feature similarity index tone-mapped image ( FSITM ) proposed . To evaluate tone mapping operator ( TMO ) proposed index compare locally weighted mean phase angle map original high dynamic range ( HDR ) associated tone-mapped image calculated using output TMO method . In experiment two standard database shown proposed FSITM method outperforms state-of-the-art index tone mapped quality index ( TMQI ) . In addition higher performance obtained combining FSITM TMQI index . The MATLAB source code proposed metric ( ) available http : //www.mathworks.com/matlabcentral/fileexchange/59814 .
With ubiquity mobile touchscreen device like smartphones two widely used text entry method emerged : small touch-based keyboard speech recognition . Although speech recognition available desktop computer year continued improve rapid pace currently unknown today 's modern speech recognizers compare state-of-the-art mobile touch keyboard also improved considerably since inception . To discover method ' `` upper-bound performance `` evaluated English Mandarin Chinese Apple iPhone 6 Plus laboratory setting . Our experiment carried using Baidu 's Deep Speech 2 deep learning-based speech recognition system built-in Qwerty ( English ) Pinyin ( Mandarin ) Apple iOS keyboard . We found speech recognition English input rate 2.93 time faster ( 153 vs. 52 WPM ) Mandarin Chinese input rate 2.87 time faster ( 123 vs. 43 WPM ) keyboard short message transcription laboratory condition method . Furthermore although speech made fewer error entry ( 5.30 % vs. 11.22 % corrected error rate ) left slightly error final transcribed text ( 1.30 % vs. 0.79 % uncorrected error rate ) . Our result show comparatively ideal condition method upper-bound speech recognition performance greatly improved compared prior system might see greater uptake future although study required quantify performance non-laboratory setting method .
Achieving high performance facial age estimation subject borderline adulthood non-adulthood always challenge . Several study used different approach age baby elder adult different datasets employed measure mean absolute error ( MAE ) ranging 1.47 8 year . The weakness algorithm specifically borderline motivation paper . In approach developed ensemble technique improves accuracy underage estimation conjunction deep learning model ( DS13K ) fine-tuned Deep Expectation ( DEX ) model . We achieved accuracy 68 % age group 16 17 year old 4 time better DEX accuracy age range . We also present evaluation existing cloud-based offline facial age prediction service Amazon Rekognition Microsoft Azure Cognitive Services How-Old.net DEX .
Since shooting Black teenager Michael Brown White police officer Darren Wilson Ferguson Missouri protest hashtag # BlackLivesMatter amplified critique extrajudicial killing Black Americans . In response # BlackLivesMatter Twitter user adopted # AllLivesMatter counter-protest hashtag whose content argues equal attention given life regardless race . Through multi-level analysis 860000 tweet study protest counter-protests diverge quantifying aspect discourse . We find # AllLivesMatter facilitates opposition # BlackLivesMatter hashtags # PoliceLivesMatter # BlueLivesMatter way historically echo tension Black protester law enforcement . In addition show significant portion # AllLivesMatter use stem hijacking # BlackLivesMatter advocate . Beyond simply injecting # AllLivesMatter # BlackLivesMatter content hijacker use hashtag directly confront counter-protest notion `` All life matter . `` Our finding suggest Black Lives Matter movement able grow exhibit diverse conversation avoid derailment social medium making discussion counter-protest opinion central topic # AllLivesMatter rather movement .
Purpose : Navigation guidance key requirement multitude lung intervention using video bronchoscopy . State-of-the-art solution focus lung biopsy using electromagnetic tracking intraoperative image registration w.r.t . preoperative CT scan guidance . The requirement patient-specific CT scan hamper utilisation navigation guidance application intensive care unit . Methods : This paper address navigation guidance solely incorporating bronchosopy video data . In contrast state-of-the-art approach entirely omit use electromagnetic tracking patient-specific CT scan . Guidance enabled mean topological bronchoscope localization w.r.t . interpatient airway model . Particularly take maximally advantage anatomical constraint airway tree sequentially traversed . This realized incorporating sequence CNN-based airway likelihood Hidden Markov Model . Results : Our approach evaluated based multiple experiment inside lung phantom model . With consideration temporal context use anatomical knowledge regularization able improve accuracy 0.98 compared 0.81 ( weighted F1 : 0.98 compared 0.81 ) classification based individual frame . Conclusion : We combine CNN-based single image classification airway segment anatomical constraint temporal HMM-based inference first time . Our approach render vision-only guidance bronchoscopy intervention absence electromagnetic tracking patient-specific CT scan possible .
To achieve ambitious goal artificial intelligence reinforcement learning must include planning model world abstract state time . Deep learning made progress state abstraction temporal abstraction rarely used despite extensively developed theory based option framework . One reason space possible option immense method previously proposed option discovery take account option model used planning . Options typically discovered posing subsidiary task reaching bottleneck state maximizing cumulative sum sensory signal reward . Each subtask solved produce option model option learned made available planning process . In previous work subtasks ignore reward original problem whereas propose subtasks use original reward plus bonus based feature state time option terminates . We show option model obtained reward-respecting subtasks much likely useful planning eigenoptions shortest path option based bottleneck state reward-respecting option generated option-critic . Reward respecting subtasks strongly constrain space option thereby also provide partial solution problem option discovery . Finally show value policy option model learned online off-policy using standard algorithm general value function .
Hydrological storm event primary driver transporting water quality constituent turbidity suspended sediment nutrient . Analyzing concentration ( C ) water quality constituent response increased streamflow discharge ( Q ) particularly monitored high temporal resolution hydrological event help characterize dynamic flux constituent . A conventional approach storm event analysis reduce C-Q time series two-dimensional ( 2-D ) hysteresis loop analyze 2-D pattern . While effective informative extent hysteresis loop approach limitation projecting C-Q time series onto 2-D plane obscures detail ( e.g . temporal variation ) associated C-Q relationship . In paper address issue using multivariate time series clustering approach . Clustering applied sequence river discharge suspended sediment data ( acquired turbidity-based monitoring ) six watershed located Lake Champlain Basin northeastern United States . While cluster hydrological storm event using multivariate time series approach found correlated 2-D hysteresis loop classification watershed location cluster differed 2-D hysteresis classification . Additionally using available meteorological data associated storm event examine characteristic computational cluster storm event study watershed identify feature driving clustering approach .
The object recognition complex problem image processing . Mathematical morphology Shape oriented operation simplify image data preserving essential shape characteristic eliminating irrelevancy . This paper briefly describes morphological operator using hypergraph application thinning algorithm . The morphological operator using hypergraph method used preventing error irregularity skeleton important step recognizing line object . The morphological operator using hypergraph dilation erosion opening closing novel approach image processing act filter remove noise error image .
This paper address automatic generation typographic font subset character . Specifically use subset typographic font extrapolate additional character . Consequently obtain complete font containing number character sufficient daily use . The automated generation Japanese font high demand Japanese font requires 1000 character . Unfortunately professional typographer create font resulting significant financial time investment font generation . The proposed method great aid font creation designer need create majority character new font . The proposed method us stroke given sample font generation . The stroke construct character extracted exploiting character skeleton dataset . This study make three main contribution : novel method extracting stroke character applicable standard font variation ; fully automated approach constructing character ; selection method sample character . We demonstrate proposed method generating 2965 character 47 font . Objective subjective evaluation verify generated character similar handmade character .
We introduce learning framework automated floorplan generation combine generative modeling using deep neural network user-in-the-loop design enable human user provide sparse design constraint . Such constraint represented layout graph . The core component learning framework deep neural network Graph2Plan convert layout graph along building boundary floorplan fulfills layout boundary constraint . Given input building boundary allow user specify room count layout constraint used retrieve set floorplans associated layout graph database . For retrieved layout graph along input boundary Graph2Plan first generates corresponding raster floorplan image refined set box representing room . Graph2Plan trained RPLAN large-scale dataset consisting 80K annotated floorplans . The network mainly based convolutional processing layout graph via graph neural network ( GNN ) input building boundary well raster floorplan image via conventional image convolution .
360 { \deg } image informative -- contains omnidirectional visual information around camera . However area cover 360 { \deg } image much larger human 's field view therefore important information different view direction easily overlooked . To tackle issue propose method predicting optimal set Region Interest ( RoI ) single 360 { \deg } image using visual saliency clue . To deal scarce strongly biased training data existing single 360 { \deg } image saliency prediction dataset also propose data augmentation method based spherical random data rotation . From predicted saliency map redundant candidate region obtain optimal set RoIs considering saliency within region Interaction-Over-Union ( IoU ) region . We conduct subjective evaluation show proposed method select region properly summarize input 360 { \deg } image .
Long-term metric self-localization essential capability autonomous mobile robot remains challenging vision-based system due appearance change caused lighting weather seasonal variation . While experience-based mapping proven effective technique bridging ` appearance gap ' number experience required reliable metric localization day month large method reducing necessary number experience needed approach scale . Taking inspiration color constancy theory learn nonlinear RGB-to-grayscale mapping explicitly maximizes number inlier feature match image captured different lighting weather condition use pre-processing step conventional single-experience localization pipeline improve robustness appearance change . We train mapping approximating target non-differentiable localization pipeline deep neural network find incorporating learned low-dimensional context feature improve cross-appearance feature matching . Using synthetic real-world datasets demonstrate substantial improvement localization performance across day-night cycle enabling continuous metric localization 30-hour period using single mapping experience allowing experience-based localization scale long deployment dramatically reduced data requirement .
Much Earth 's charismatic megafauna endangered human activity particularly rhino risk extinction due poaching crisis Africa . Monitoring rhino ' movement crucial protection unfortunately proven difficult rhino elusive . Therefore instead tracking rhino propose novel approach mapping communal defecation site called midden give information rhino ' spatial behavior valuable anti-poaching management reintroduction effort . This paper provides first-ever mapping rhino midden location building classifier detect using remotely sensed thermal RGB LiDAR imagery passive active learning setting . As existing active learning method perform poorly due extreme class imbalance dataset design MultimodAL active learning system employing ranking technique multimodality achieve competitive performance passive learning model 94 % fewer label . Our method could therefore save 76 hour labeling time used similarly-sized dataset . Unexpectedly midden map reveals rhino midden randomly distributed throughout landscape ; rather clustered . Consequently ranger targeted area high midden density strengthen anti-poaching effort line UN Target 15.7 .
We propose hierarchical approach multi-action recognition performs joint classification segmentation . A given video ( containing several consecutive action ) processed via sequence overlapping temporal window . Each frame temporal window represented selective low-level spatio-temporal feature efficiently capture relevant local dynamic . Features window represented Fisher vector capture first second order statistic . Instead directly classifying Fisher vector converted vector class probability . The final classification decision frame obtained integrating class probability frame level exploit overlapping temporal window . Experiments performed two datasets : s-KTH ( stitched version KTH dataset simulate multi-actions ) challenging CMU-MMAC dataset . On s-KTH proposed approach achieves accuracy 85.0 % significantly outperforming two recent approach based GMMs HMMs obtained 78.3 % 71.2 % respectively . On CMU-MMAC proposed approach achieves accuracy 40.9 % outperforming GMM HMM approach obtained 33.7 % 38.4 % respectively . Furthermore proposed system average 40 time faster GMM based approach .
Two-view relative pose estimation structure reconstruction classical problem computer vision . The typical method usually employ singular value decomposition essential matrix get multiple solution relative pose right solution picked reconstructing three-dimension ( 3D ) feature point imposing constraint positive depth . This paper revisits two-view geometry problem discovers two-view imaging geometry equivalently governed Pair new Pose-Only ( PPO ) constraint : same-side constraint intersection constraint . From perspective solving equation complete pose solution essential matrix explicitly derived rigorously prove orientation part pose still recovered case pure rotation . The PPO constraint simplified formulated form inequality directly identify right pose solution need 3D reconstruction 3D reconstruction analytically achieved identified right pose . Furthermore intersection inequality also enables robust criterion pure rotation identification . Experiment result validate correctness analysis robustness derived pose solution/pure rotation identification analytical 3D reconstruction .
Revived interest lunar planetary exploration heralding new era human spaceflight characterized frequent strain astronaut 's mental well-being stem increased exposure isolated confined extreme ( ICE ) condition . Whilst Immersive Virtual Reality ( IVR ) employed facilitate self-help intervention mitigate challenge caused isolated environment several domain applicability support future space expedition remains largely unexplored . To address limitation administered use distinct IVR environment crew member ( n=5 ) partaking simulated lunar habitat study . Utilizing Bayesian approach scrutinize small group data discovered significant relationship IVR usage reduction perceived stress-related symptom particularly associated asthenia ( syndrome often linked chronic fatigue weakness ; condition characterized feeling energy depletion exhaustion amplified ICE condition ) . The reduction prominent use interactive virtual environment . The 'Aesthetic Realities ' - virtual environment conceived art exhibit - received exceptional praise participant . These environment mark fascinating convergence art science holding promise mitigate effect related isolation spaceflight training beyond .
The goal rank fusion information retrieval ( IR ) deliver single output list multiple search result . Improving performance combining output various IR system challenging task . A central point fact many non-obvious factor involved estimation relevance inducing nonlinear interrelation data . The ability model complex dependency relationship random variable become increasingly popular realm information retrieval need explore dependency data fusion recently acknowledged . Copulas provide framework separate dependence structure margin . Inspired theory copula propose new unsupervised dynamic nonlinear rank fusion method based nested composition non-algebraic function pair . The dependence structure model tailored leveraging query-document correlation per-query basis . We experimented three topic set CLEF corpus fusing 3 6 retrieval system comparing method CombMNZ technique nonlinear unsupervised strategy . The experiment show fusion approach improves performance explicit condition providing insight circumstance linear fusion technique comparable performance nonlinear method .
Infrared visible image fusion aim integrate modality strength visually enhanced informative image . Visible imaging real-world scenario susceptible dynamic environmental brightness fluctuation leading texture degradation . Existing fusion method lack robustness brightness perturbation significantly compromising visual fidelity fused imagery . To address challenge propose Brightness Adaptive multimodal dynamic fusion framework ( BA-Fusion ) achieves robust image fusion despite dynamic brightness fluctuation . Specifically introduce Brightness Adaptive Gate ( BAG ) module designed dynamically select feature brightness-related channel normalization preserving brightness-independent structural information within source image . Furthermore propose brightness consistency loss function optimize BAG module . The entire framework tuned via alternating training strategy . Extensive experiment validate method surpasses state-of-the-art method preserving multi-modal image information visual fidelity exhibiting remarkable robustness across varying brightness level . Our code available : http : //github.com/SunYM2020/BA-Fusion .
This paper proposes improved method maximum likelihood ( ML ) estimation equivalent number look $ L $ . This parameter meaningful interpretation context polarimetric synthetic aperture radar ( PolSAR ) image . Due presence coherent illumination processing PolSAR system generate image present granular noise called speckle . As potential solution reducing interference parameter $ L $ control signal-noise ratio . Thus proposal efficient estimation methodology $ L $ sought . To end consider firstly PolSAR image well described scaled complex Wishart distribution . In recent year Anfinsen et al . derived analyzed estimation method based ML trace statistical moment obtaining parameter $ L $ unscaled version probability law . This paper generalizes approach . We present second-order bias expression proposed Cox Snell ML estimator parameter . Moreover formula profile likelihood modified Barndorff-Nielsen term $ L $ discussed . Such derivation yield two new ML estimator parameter $ L $ compared estimator proposed Anfinsen et al . The performance estimator assessed mean Monte Carlo experiment adopting three statistical measure comparison criterion : mean square error bias coefficient variation . Equivalently simulation study application actual PolSAR data concludes proposed estimator outperform others homogeneous scenario .
This paper study problem time series forecasting ( TSF ) perspective compressed sensing . First convert TSF inclusive problem called tensor completion arbitrary sampling ( TCAS ) restore tensor subset entry sampled arbitrary manner . While known framework Tucker low-rankness theoretically impossible identify target tensor based arbitrarily selected entry work shall show TCAS indeed tackleable light new concept called convolutional low-rankness generalization well-known Fourier sparsity . Then introduce convex program termed Convolution Nuclear Norm Minimization ( CNNM ) prove CNNM succeeds solving TCAS long sampling condition -- depends convolution rank target tensor -- obeyed . This theory provides meaningful answer fundamental question minimum sampling size needed making given number forecast . Experiments univariate time series image video show encouraging result .
Head detection indoor video essential component building occupancy detection . While deep model achieved remarkable progress general object detection satisfying enough complex indoor scene . The indoor surveillance video often includes cluttered background object among head small scale diverse pose . In paper propose Motion-aware Pseudo Siamese Network ( MPSN ) end-to-end approach leverage head motion information guide deep model extract effective head feature indoor scenario . By taking pixel-wise difference adjacent frame auxiliary input MPSN effectively enhances human head motion information remove irrelevant object background . Compared prior method achieves superior performance two indoor video datasets . Our experiment show MPSN successfully suppresses static background object highlight moving instance especially human head indoor video . We also compare different method capture head motion demonstrates simplicity flexibility MPSN . To validate robustness MPSN conduct adversarial experiment mathematical solution small perturbation robust model selection . Finally confirming potential building control system apply MPSN occupancy counting . Code available http : //github.com/pl-share/MPSN .
Quickly understanding lengthy lecture video essential learner limited time interest various topic improve learning efficiency . To end video summarization actively researched enable user view important scene video . However study focus either visual audio information video extract important segment video . Therefore risk missing important information teacher 's speech visual information blackboard slide important lecture video . To tackle issue propose FastPerson video summarization approach considers visual auditory information lecture video . FastPerson creates summary video utilizing audio transcription along on-screen image text minimizing risk overlooking crucial information learner . Further provides feature allows learner switch summary original video chapter video enabling adjust pace learning based interest level understanding . We conducted evaluation 40 participant assess effectiveness method confirmed reduced viewing time 53\ % level comprehension using traditional video playback method .
This paper introduces concept accessibility field transportation planning adopts within context Information Retrieval ( IR ) . An analogy drawn field motivates development document accessibility measure IR system . Considering accessibility document within collection given IR System provides different perspective analysis evaluation system could used inform design tuning management current future IR system .
The need accurately estimate speed road vehicle becoming increasingly important least two main reason . First number speed camera installed worldwide growing recent year introduction enforcement appropriate speed limit considered one effective mean increase road safety . Second traffic monitoring forecasting road network play fundamental role enhance traffic emission energy consumption smart city speed vehicle one relevant parameter traffic state . Among technology available accurate detection vehicle speed use vision-based system brings great challenge solved also great potential advantage drastic reduction cost due absence expensive range sensor possibility identifying vehicle accurately . This paper provides review vision-based vehicle speed estimation . We describe terminology application domain propose complete taxonomy large selection work categorizes stage involved . An overview performance evaluation metric available datasets provided . Finally discus current limitation future direction .
The large still increasing popularity deep learning clash major limit neural network architecture consists lack capability providing human-understandable motivation decision . In situation machine expected support decision human expert providing comprehensible explanation feature crucial importance . The language used communicate explanation must formal enough implementable machine friendly enough understandable wide audience . In paper propose general approach Explainable Artificial Intelligence case neural architecture showing mindful design network lead family interpretable deep learning model called Logic Explained Networks ( LENs ) . LENs require input human-understandable predicate provide explanation term simple First-Order Logic ( FOL ) formula involving predicate . LENs general enough cover large number scenario . Amongst consider case LENs directly used special classifier capability explainable act additional network role creating condition making black-box classifier explainable FOL formula . Despite supervised learning problem mostly emphasized also show LENs learn provide explanation unsupervised learning setting . Experimental result several datasets task show LENs may yield better classification established white-box model decision tree Bayesian rule list providing compact meaningful explanation .
Extracting query-document relevance sparse biased clickthrough log among fundamental task web search system . Prior art mainly learns relevance judgment model semantic feature query document ignores directly counterfactual relevance evaluation clicking log . Though learned semantic matching model provide relevance signal tail query long semantic feature available . However paradigm lack capability introspectively adjust biased relevance estimation whenever conflict massive implicit user feedback . The counterfactual evaluation method contrary ensure unbiased relevance estimation sufficient click information . However suffer sparse even missing click caused long-tailed query distribution . In paper propose unify counterfactual evaluating learning approach unbiased relevance estimation search query various popularity . Specifically theoretically develop doubly robust estimator low bias variance intentionally combine benefit existing relevance evaluating learning approach . We instantiate proposed unbiased relevance estimation framework Baidu search comprehensive practical solution designed regarding data pipeline click behavior tracking online relevance estimation approximated deep neural network . Finally present extensive empirical evaluation verify effectiveness proposed framework finding robust practice manages improve online ranking performance substantially .
This paper present method leverage arbitrary neural network architecture control variate . Control variate crucial reducing variance Monte Carlo integration hinge finding function correlate integrand known analytical integral . Traditional approach rely heuristic choose function might expressive enough correlate well integrand . Recent research alleviates issue modeling integrands learnable parametric model neural network . However challenge remains creating expressive parametric model known analytical integral . This paper proposes novel approach construct learnable parametric control variate function arbitrary neural network architecture . Instead using network approximate integrand directly employ network approximate anti-derivative integrand . This allows u use automatic differentiation create function whose integration constructed antiderivative network . We apply method solve partial differential equation using Walk-on-sphere algorithm . Our result indicate approach unbiased us various network architecture achieve lower variance control variate method .
Many feature subset selection ( FSS ) algorithm proposed appropriate given feature selection problem . At time far rarely good way choose appropriate FSS algorithm problem hand . Thus FSS algorithm automatic recommendation important practically useful . In paper meta learning based FSS algorithm automatic recommendation method presented . The proposed method first identifies data set similar one hand k-nearest neighbor classification algorithm distance among data set calculated based commonly-used data set characteristic . Then rank candidate FSS algorithm according performance similar data set chooses algorithm best performance appropriate one . The performance candidate FSS algorithm evaluated multi-criteria metric take account classification accuracy selected feature also runtime feature selection number selected feature . The proposed recommendation method extensively tested 115 real world data set 22 well-known frequently-used different FSS algorithm five representative classifier . The result show effectiveness proposed FSS algorithm recommendation method .
Video analysis task action recognition received increasing research interest growing application field smart healthcare thanks introduction large-scale datasets deep learning-based representation . However video model trained existing datasets suffer significant performance degradation deployed directly real-world application due domain shift training public video datasets ( source video domain ) real-world video ( target video domain ) . Further high cost video annotation practical use unlabeled video training . To tackle performance degradation address concern high video annotation cost uniformly video unsupervised domain adaptation ( VUDA ) introduced adapt video model labeled source domain unlabeled target domain alleviating video domain shift improving generalizability portability video model . This paper survey recent progress VUDA deep learning . We begin motivation VUDA followed definition recent progress method closed-set VUDA VUDA different scenario current benchmark datasets VUDA research . Eventually future direction provided promote VUDA research . The repository survey provided http : //github.com/xuyu0010/awesome-video-domain-adaptation .
The rapid development computer hardware Internet technology make large scale data dependent model computationally tractable open bright avenue annotating image innovative machine learning algorithm . Semi-supervised learning ( SSL ) consequently received intensive attention recent year successfully deployed image annotation . One representative work SSL Laplacian regularization ( LR ) smoothes conditional distribution classification along manifold encoded graph Laplacian however observed LR bias classification function towards constant function possibly result poor generalization . In addition LR developed handle uniformly distributed data ( single view data ) although instance object image video usually represented multiview feature color shape texture . In paper present multiview Hessian regularization ( mHR ) address two problem LR-based image annotation . In particular mHR optimally combine multiple Hessian regularization obtained particular view instance steer classification function varies linearly along data manifold . We apply mHR kernel least square support vector machine two example image annotation . Extensive experiment PASCAL VOC'07 dataset validate effectiveness mHR comparing baseline algorithm including LR HR .
As natural extension link prediction graph hyperlink prediction aim inference missing hyperlink hypergraphs hyperlink connect two node . Hyperlink prediction application wide range system chemical reaction network social communication network protein-protein interaction network . In paper provide systematic comprehensive survey hyperlink prediction . We propose new taxonomy classify existing hyperlink prediction method four category : similarity-based probability-based matrix optimization-based deep learning-based method . To compare performance method different category perform benchmark study various hypergraph application using representative method category . Notably deep learning-based method prevail method hyperlink prediction .
Recent decade witnessed significant increase use visual odometry ( VO ) computer vision area . It also used variety robotic application example Mars Exploration Rovers . This paper firstly discusses two popular existing visual odometry approach namely LSD-SLAM ORB-SLAM2 improve performance metric visual SLAM system using Umeyama Method . We carefully evaluate method referred three different well-known KITTI datasets EuRoC MAV dataset TUM RGB-D dataset obtain best result graphically compare result evaluation metric different visual odometry approach . Secondly propose approach running real-time stereo camera combine existing feature-based ( indirect ) method existing feature-less ( direct ) method matching accurate semidense direct image alignment reconstructing accurate 3D environment directly pixel image gradient . Keywords VO performance metric Umeyama Method feature-based method feature-less method & semi-dense real-time .
Hand pose estimation single depth image essential topic computer vision human computer interaction . Despite recent advancement area promoted convolutional neural network accurate hand pose estimation still challenging problem . In paper propose Pose guided structured Region Ensemble Network ( Pose-REN ) boost performance hand pose estimation . The proposed method extract region feature map convolutional neural network guide initially estimated pose generating optimal representative feature hand pose estimation . The extracted feature region integrated hierarchically according topology hand joint employing tree-structured fully connection . A refined estimation hand pose directly regressed proposed network final hand pose obtained utilizing iterative cascaded method . Comprehensive experiment public hand pose datasets demonstrate proposed method outperforms state-of-the-art algorithm .
The Russian Drug Reaction Corpus ( RuDReC ) new partially annotated corpus consumer review Russian pharmaceutical product detection health-related named entity effectiveness pharmaceutical product . The corpus consists two part raw one labelled one . The raw part includes 1.4 million health-related user-generated text collected various Internet source including social medium . The labelled part contains 500 consumer review drug therapy drug- disease-related information . Labels sentence include health-related issue absence . The sentence one additionally labelled expression level identification fine-grained subtypes drug class drug form drug indication drug reaction . Further present baseline model named entity recognition ( NER ) multi-label sentence classification task corpus . The macro F1 score 74.85 % NER task achieved RuDR-BERT model . For sentence classification task model achieves macro F1 score 68.82 % gaining 7.47 % score BERT model trained Russian data . We make RuDReC corpus pretrained weight domain-specific BERT model freely available http : //github.com/cimm-kzn/RuDReC
With increasing number smart device like internet thing ( IoT ) device deployed field offloadingtraining neural network ( NNs ) central server becomes infeasible . Recent effort toimprove user ' privacy led on-device learning emerging alternative . However model trainedonly single device using local data unlikely reach high accuracy . Federated learning ( FL ) introduced solution offering privacy-preserving trade-off communication overheadand model accuracy sharing knowledge device disclosing device ' private data . Theapplicability benefit applying baseline FL however limited many relevant use case dueto heterogeneity present environment . In survey outline heterogeneity challengesFL overcome widely applicable real-world application . We especially focus aspect ofcomputation heterogeneity among participating device provide comprehensive overview recentworks heterogeneity-aware FL . We discus two group : work adapt NN architecture worksthat approach heterogeneity system level covering Federated Averaging ( FedAvg ) distillation splitlearning-based approach well synchronous asynchronous aggregation scheme .
Music summarization allows higher efficiency processing storage sharing datasets . Machine-oriented approach agnostic human consumption optimize aspect even . Such summary already successfully validated MIR task . We generalize previous conclusion evaluating impact generic summarization music probabilistic perspective . We estimate Gaussian distribution original summarized song compute relative entropy order measure information loss incurred summarization . Our result suggest relative entropy good predictor summarization performance context task relying bag-of-features model . Based observation propose straightforward yet expressive summarizer minimizes relative entropy respect original song objectively outperforms previous method better suited avoid potential copyright issue .
To establish appropriate model photo aesthetic assessment paper D-measure reflects disentanglement degree final layer FC node CNN introduced . By combining F-measure D-measure obtain FD measure algorithm determining optimal model multiple photo score prediction model generated CNN-based repetitively self-revised learning ( RSRL ) proposed . Furthermore first fixation perspective ( FFP ) assessment interest region ( AIR ) model defined calculated . The experimental result show FD measure effective establishing appropriate model multiple score prediction model different CNN structure . Moreover FD-determined optimal model comparatively high FD always FFP AIR close human 's aesthetic perception enjoying photo .
Translating natural language Bash Commands emerging research field gained attention recent year . Most effort focused producing accurate translation model . To best knowledge two datasets available one based . Both datasets involve scraping known data source ( platform like stack overflow crowdsourcing etc . ) hiring expert validate correct either English text Bash Commands . This paper provides two contribution research synthesizing Bash Commands scratch . First describe state-of-the-art translation model used generate Bash Commands corresponding English text . Second introduce new NL2CMD dataset automatically generated involves minimal human intervention six time larger prior datasets . Since generation pipeline rely existing Bash Commands distribution type command custom adjusted . We evaluate performance ChatGPT task discus potential using data generator . Our empirical result show scale diversity dataset offer unique opportunity semantic parsing researcher .
Pricing rental property Airbnb challenging task owner determines number customer place . On hand customer evaluate offered price minimal knowledge optimal value property . This paper aim develop reliable price prediction model using machine learning deep learning natural language processing technique aid property owner customer price evaluation given minimal available information property . Features rental owner characteristic customer review comprise predictor range method linear regression tree-based model support-vector regression ( SVR ) K-means Clustering ( KMC ) neural network ( NNs ) used creating prediction model .
The creation machine learning algorithm intelligent agent capable continuous lifelong learning critical objective algorithm deployed real-life system dynamic environment . Here present algorithm inspired neuromodulatory mechanism human brain integrates expands upon Stephen Grossberg\ 's ground-breaking Adaptive Resonance Theory proposal . Specifically build concept uncertainty employ series neuromodulatory mechanism enable continuous learning including self-supervised one-shot learning . Algorithm component evaluated series benchmark experiment demonstrate stable learning without catastrophic forgetting . We also demonstrate critical role developing system closed-loop manner environment agent\ 's behavior constrain guide learning process . To end integrated algorithm embodied simulated drone agent . The experiment show algorithm capable continuous learning new task changed condition high classification accuracy ( greater 94 percent ) virtual environment without catastrophic forgetting . The algorithm accepts high dimensional input state-of-the-art detection feature extraction algorithm making flexible addition existing system . We also describe future development effort focused imbuing algorithm mechanism seek new knowledge well employ broader range neuromodulatory process .
Retrievability measure influence retrieval system access information given collection item . This measure help making evaluation search system based insight drawn . In paper investigate retrievability integrated search system consisting item various category particularly focussing datasets publication \ijdl { variable } real-life Digital Library ( DL ) . The traditional metric Lorenz curve Gini coefficient employed visualize diversity retrievability score \ijdl { three } retrievable document type ( specifically datasets publication variable ) . Our result show significant popularity bias certain item retrieved often others . Particularly shown certain datasets likely retrieved datasets category . In contrast retrievability score item variable publication category evenly distributed . We observed distribution document retrievability diverse datasets compared publication variable .
This paper present contribution SemEval-2021 Task 2 : Multilingual Cross-lingual Word-in-Context Disambiguation ( MCL-WiC ) . Our experiment cover English ( EN-EN ) sub-track multilingual setting task . We experiment several pre-trained language model investigate impact different top-layers fine-tuning . We find combination Cosine Similarity ReLU activation leading effective fine-tuning procedure . Our best model result accuracy 92.7 % fourth-best score EN-EN sub-track .
Exploiting image patch instead whole image proved powerful approach tackle various problem image processing . Recently Wasserstein patch prior ( WPP ) based comparison patch distribution unknown image reference image successfully used data-driven regularizers variational formulation superresolution . However input image approach requires solution non-convex minimization problem computationally costly . In paper propose learn two kind neural network unsupervised way based WPP loss function . First show convolutional neural network ( CNNs ) incorporated . Once network called WPPNet learned efficiently applied input image . Second incorporate conditional normalizing flow provide tool uncertainty quantification . Numerical example demonstrate good performance WPPNets superresolution various image class even forward operator known approximately .
Knowledge graph ( KG ) link prediction aim infer new fact based existing fact KG . Recent study shown using graph neighborhood node via graph neural network ( GNNs ) provides useful information compared using query information . Conventional GNNs KG link prediction follow standard message-passing paradigm entire KG lead superfluous computation over-smoothing node representation also limit expressive power . On large scale becomes computationally expensive aggregate useful information entire KG inference . To address limitation existing KG link prediction framework propose novel retrieve-and-read framework first retrieves relevant subgraph context query jointly reason context query high-capacity reader . As part exemplar instantiation new framework propose novel Transformer-based GNN reader incorporates graph-based attention structure cross-attention query context deep fusion . This simple yet effective design enables model focus salient context information relevant query . Empirical result two standard KG link prediction datasets demonstrate competitive performance proposed method . Furthermore analysis yield valuable insight designing improved retriever within framework .
We reveal complete set constraint need imposed set 3-by-3 matrix ensure matrix represent genuine homographies associated multiple plane two view . We also show exploit constraint obtain accurate estimate homography matrix two view . Our study resolve long-standing research question provides fresh perspective in-depth understanding multiple homography estimation task .
The fundamental task classification given limited number training data sample considered physical system known parametric statistical model . The standalone learning-based statistical model-based classifier face major challenge towards fulfillment classification task using small training set . Specifically classifier solely rely physics-based statistical model usually suffer inability properly tune underlying unobservable parameter lead mismatched representation system 's behavior . Learning-based classifier hand typically rely large number training data underlying physical process might feasible practical scenario . In paper hybrid classification method -- termed HyPhyLearn -- proposed exploit physics-based statistical model learning-based classifier . The proposed solution based conjecture HyPhyLearn would alleviate challenge associated individual approach learning-based statistical model-based classifier fusing respective strength . The proposed hybrid approach first estimate unobservable model parameter using available ( suboptimal ) statistical estimation procedure subsequently use physics-based statistical model generate synthetic data . Then training data sample incorporated synthetic data learning-based classifier based domain-adversarial training neural network . Specifically order address mismatch problem classifier learns mapping training data synthetic data common feature space . Simultaneously classifier trained find discriminative feature within space order fulfill classification task .
Quantization emerging efficient approach promote hardware-friendly deep learning run deep neural network resource-limited hardware . However still cause significant decrease network accuracy . We summarize challenge quantization two category : Quantization Diverse Architectures Quantization Complex Scenes . Our study focus mainly applying quantization various architecture scene pushing limit quantization extremely compress accelerate network . The comprehensive research quantization achieve powerful efficient flexible hardware-friendly deep learning make better suited real-world application .
The multi-armed bandit ( MAB ) model attracted significant research attention due applicability effectiveness various real-world scenario resource allocation online advertising dynamic pricing . As important branch adversarial MAB problem delayed feedback proposed studied many researcher recently conceptual adversary strategically selects reward distribution associated arm challenge learning algorithm agent experience delay taking action receiving corresponding reward feedback . However existing model restrict feedback generated one user make model inapplicable prevailing scenario multiple user ( e.g . ad recommendation group user ) . In paper consider delayed feedback result multiple user unrestricted internal distribution . In contrast feedback delay arbitrary unknown player advance . Also different user round delay feedback assumption latent correlation . Thus formulate adversarial MAB problem multi-user delayed feedback design modified EXP3 algorithm MUD-EXP3 make decision round considering importance-weighted estimator received feedback different user . On premise known terminal round index $ T $ number user $ M $ number arm $ N $ upper bound delay $ d_ { max } $ prove regret $ \mathcal { O } ( \sqrt { TM^2\ln { N } ( N\mathrm { e } +4d_ { max } ) } ) $ . Furthermore common case unknown $ T $ adaptive algorithm AMUD-EXP3 proposed sublinear regret respect $ T $ . Finally extensive experiment conducted indicate correctness effectiveness algorithm .
The task next POI recommendation studied extensively recent year . However developing unified recommendation framework incorporate multiple factor associated POIs user remains challenging heterogeneity nature information . Further effective mechanism handle cold-start endow system interpretability also difficult topic . Inspired recent success neural network many area paper present simple effective neural network framework next POI recommendation named NEXT . NEXT unified framework learn hidden intent regarding user 's next move incorporating different factor unified manner . Specifically NEXT incorporate meta-data information two kind temporal context ( i.e . time interval visit time ) . To leverage sequential relation geographical influence propose adopt DeepWalk network representation learning technique encode knowledge . We evaluate effectiveness NEXT state-of-the-art alternative neural network based solution . Experimental result three publicly available datasets demonstrate NEXT significantly outperforms baseline real-time next POI recommendation . Further experiment demonstrate superiority NEXT handling cold-start . More importantly show NEXT provides meaningful explanation dimension hidden intent space .
This paper present unified fashion deterministic well statistical Lagrangian-verification technique . They formally quantify behavioral robustness time-continuous process formulated continuous-depth model . To end review LRT-NG SLR GoTube algorithm constructing tight reachtube over-approximation set state reachable within given time-horizon provide guarantee reachtube bound . We compare usage variational equation associated system equation mean value theorem Lipschitz constant achieving deterministic statistical guarantee . In LRT-NG Lipschitz constant used bloating factor initial perturbation compute radius ellipsoid optimal metric over-approximates set reachable state . In SLR GoTube get statistical guarantee using Lipschitz constant compute local ball around sample . These needed calculate probability found upper bound true maximum perturbation every timestep . Our experiment demonstrate superior performance Lagrangian technique compared LRT Flow * CAPD illustrate use robustness analysis various continuous-depth model .
This paper develops model-based reinforcement learning ( MBRL ) framework learning online value function infinite-horizon optimal control problem obeying safety constraint expressed control barrier function ( CBFs ) . Our approach facilitated development novel class CBFs termed Lyapunov-like CBFs ( LCBFs ) retain beneficial property CBFs developing minimally-invasive safe control policy also possessing desirable Lyapunov-like quality positive semi-definiteness . We show LCBFs used augment learning-based control policy guarantee safety leverage approach develop safe exploration framework MBRL setting . We demonstrate approach handle general safety constraint comparative method via numerical example .
Visual odometry ( VO ) prevalent way deal relative localization problem becoming increasingly mature accurate tends fragile challenging environment . Comparing classical geometry-based method deep learning-based method automatically learn effective robust representation depth optical flow feature ego-motion etc . data without explicit computation . Nevertheless still lack thorough review recent advance deep learning-based VO ( Deep VO ) . Therefore paper aim gain deep insight deep learning profit optimize VO system . We first screen number qualification including accuracy efficiency scalability dynamicity practicability extensibility employ criterion . Then using offered criterion uniform measurement detailedly evaluate discus deep learning improves performance VO aspect depth estimation feature extraction matching pose estimation . We also summarize complicated emerging area Deep VO mobile robot medical robot augmented reality virtual reality etc . Through literature decomposition analysis comparison finally put forward number open issue raise future research direction field .
Large Language Models ( LLMs ) GPT developed OpenAI already shown astonishing result introducing quick change society . This intensified release ChatGPT allows anyone interact simple conversational way LLMs without experience field needed . As result ChatGPT rapidly applied many different task code- song-writer education virtual assistant etc . showing impressive result task trained ( zero-shot learning ) . The present study aim explore ability ChatGPT based recent GPT-4 multimodal LLM task face biometrics . In particular analyze ability ChatGPT perform task face verification soft-biometrics estimation explainability result . ChatGPT could valuable increase explainability transparency automatic decision human scenario . Experiments carried order evaluate performance robustness ChatGPT using popular public benchmark comparing result state-of-the-art method field . The result achieved study show potential LLMs ChatGPT face biometrics especially enhance explainability . For reproducibility reason release code GitHub .
Instead directly utilizing observed image including outlier noise intensity inhomogeneity use ideal value ( e.g . noise-free image ) favorable impact clustering . Hence accurate estimation residual ( e.g . unknown noise ) observed image ideal value important task . To propose $ \ell_0 $ regularization-based Fuzzy $ C $ -Means ( FCM ) algorithm incorporating morphological reconstruction operation tight wavelet frame transform . To achieve sound trade-off detail preservation noise suppression morphological reconstruction used filter observed image . By combining observed filtered image weighted sum image generated . Since tight wavelet frame system sparse representation image employed decompose weighted sum image thus forming corresponding feature set . Taking data clustering present improved FCM algorithm imposing $ \ell_0 $ regularization term residual feature set ideal value implies favorable estimation residual obtained ideal value participates clustering . Spatial information also introduced clustering since naturally encountered image segmentation . Furthermore make estimation residual reliable . To enhance segmentation effect improved FCM algorithm also employ morphological reconstruction smoothen label generated clustering . Finally based prototype smoothed label segmented image reconstructed using tight wavelet frame reconstruction operation . Experimental result reported synthetic medical color image show proposed algorithm effective efficient outperforms algorithm .
Machine learning algorithm increasingly applied security-related task spam malware detection although security property deliberate attack yet widely understood . Intelligent adaptive attacker may indeed exploit specific vulnerability exposed machine learning technique violate system security . Being robust adversarial data manipulation thus important additional requirement machine learning algorithm successfully operate adversarial setting . In work evaluate security Support Vector Machines ( SVMs ) well-crafted adversarial label noise attack . In particular consider attacker aim maximize SVM 's classification error flipping number label training data . We formalize corresponding optimal attack strategy solve mean heuristic approach keep computational complexity tractable . We report extensive experimental analysis effectiveness considered attack linear non-linear SVMs synthetic real-world datasets . We finally argue approach also provide useful insight developing secure SVM learning algorithm also novel technique number related research area semi-supervised active learning .
Session-based recommendation ( SR ) become important popular component various e-commerce platform aim predict next interacted item based given session . Most existing SR model focus exploiting consecutive item session interacted certain user capture transition pattern among item . Although proven effective following two insight often neglected . First user 's micro-behaviors manner user locates item activity user commits item ( e.g . reading comment adding cart ) offer fine-grained deep understanding user 's preference . Second item attribute also known item knowledge provide side information model transition pattern among interacted item alleviate data sparsity problem . These insight motivate u propose novel SR model MKM-SR paper incorporates user Micro-behaviors item Knowledge Multi-task learning Session-based Recommendation . Specifically given session modeled micro-behavior level MKM-SR i.e . sequence item-operation pair rather sequence item capture transition pattern session sufficiently . Furthermore propose multi-task learning paradigm involve learning knowledge embeddings play role auxiliary task promote major task SR . It enables model obtain better session representation resulting precise SR recommendation result . The extensive evaluation two benchmark datasets demonstrate MKM-SR 's superiority state-of-the-art SR model justifying strategy incorporating knowledge learning .
Several factor contribute appearance object visual scene including pose illumination deformation among others . Each factor account source variability data multiplicative interaction factor emulate entangled variability giving rise rich structure visual object appearance . Disentangling unobserved factor visual data challenging task especially data captured uncontrolled recording condition ( also referred `` in-the-wild `` ) label information available . In paper propose first unsupervised deep learning method ( pseudo-supervision ) disentangling multiple latent factor variation face image captured in-the-wild . To end propose deep latent variable model multiplicative interaction multiple latent factor variation explicitly modelled mean multilinear ( tensor ) structure . We demonstrate proposed approach indeed learns disentangled representation facial expression pose used various application including face editing well 3D face reconstruction classification facial expression identity pose .
Graph neural network achieved great success learning node representation graph task node classification link prediction . Graph representation learning requires graph pooling obtain graph representation node representation . It challenging develop graph pooling method due variable size isomorphic structure graph . In work propose use second-order pooling graph pooling naturally solves challenge . In addition compared existing graph pooling method second-order pooling able use information node collect second-order statistic making powerful . We show direct use second-order pooling graph neural network lead practical problem . To overcome problem propose two novel global graph pooling method based second-order pooling ; namely bilinear mapping attentional second-order pooling . In addition extend attentional second-order pooling hierarchical graph pooling flexible use GNNs . We perform thorough experiment graph classification task demonstrate effectiveness superiority proposed method . Experimental result show method improve performance significantly consistently .
Event camera bio-inspired sensor capable providing continuous stream event low latency high dynamic range . As single event carry limited information brightness change particular pixel event commonly accumulated spatio-temporal window processing . However optimal window length varies depending scene camera motion task performed factor . In research develop novel ensemble-based scheme combining temporal window varying length processed parallel . For application increased computational requirement approach practical also introduce new `` approximate `` ensemble scheme achieves significant computational efficiency without unduly compromising original performance gain provided ensemble approach . We demonstrate ensemble scheme visual place recognition ( VPR ) task introducing new Brisbane-Event-VPR dataset annotated recording captured using DAVIS346 color event camera . We show proposed ensemble scheme significantly outperforms single-window baseline conventional model-based ensemble irrespective image reconstruction feature extraction method used VPR pipeline evaluate ensemble combination technique performs best . These result demonstrate significant benefit ensemble scheme event camera processing VPR domain may relevance related process including feature tracking visual-inertial odometry steering prediction driving .
Computer vision-based deep learning object detection algorithm developed sufficiently powerful support ability recognize various object . Although currently general datasets object detection still lack large-scale open-source dataset construction industry limit development object detection algorithm tend data-hungry . Therefore paper develops new large-scale image dataset specifically collected annotated construction site called Site Object Detection dAtaset ( SODA ) contains 15 kind object class categorized worker material machine layout . Firstly 20000 image collected multiple construction site different site condition weather condition construction phase covered different angle perspective . After careful screening processing 19846 image including 286201 object obtained annotated label accordance predefined category . Statistical analysis show developed dataset advantageous term diversity volume . Further evaluation two widely-adopted object detection algorithm based deep learning ( YOLO v3/ YOLO v4 ) also illustrates feasibility dataset typical construction scenario achieving maximum mAP 81.47 % . In manner research contributes large-scale image dataset development deep learning-based object detection method construction industry set performance benchmark evaluation corresponding algorithm area .
One biggest challenge development deployment spoken dialogue system design spoken language generation module . This challenge arises need generator adapt many feature dialogue domain user population dialogue context . A promising approach trainable generation us general-purpose linguistic knowledge automatically adapted feature interest application domain individual user user group . In paper present evaluate trainable sentence planner providing restaurant information MATCH dialogue system . We show trainable sentence planning produce complex information presentation whose quality comparable output template-based generator tuned domain . We also show method easily support adapting sentence planner individual individualized sentence planner generally perform better model trained tested population individual . Previous work documented utilized individual preference content selection knowledge result provide first demonstration individual preference sentence planning operation affecting content order discourse structure sentence structure system response . Finally evaluate contribution different feature set show application n-gram feature often well feature based higher-level linguistic representation .
For graphical user interface ( UI ) design important understand attracts visual attention . While previous work saliency focused desktop web-based UIs mobile app UIs differ several respect . We present finding controlled study 30 participant 193 mobile UIs . The result speak role expectation guiding user look . Strong bias toward top-left corner display text image evident bottom-up feature color size affected saliency less . Classic parameter-free saliency model showed weak fit data data-driven model improved significantly trained specifically dataset ( e.g . NSS rose 0.66 0.84 ) . We also release first annotated dataset investigating visual saliency mobile UIs .
Explainability AI system critical user take informed action . Understanding `` `` open black-box AI important opening . We conduct mixed-methods study two different group -- people without AI background -- perceive different type AI explanation . Quantitatively share user perception along five dimension . Qualitatively describe AI background influence interpretation elucidating difference lens appropriation cognitive heuristic . We find ( 1 ) group showed unwarranted faith number different reason ( 2 ) group found value different explanation beyond intended design . Carrying critical implication field XAI finding showcase AI generated explanation negative consequence despite best intention could lead harmful manipulation trust . We propose design intervention mitigate .
Images handwritten digit different natural image orientation digit well similarity feature different digit make confusion . On hand deep convolutional neural network achieving huge success computer vision problem especially image classification . BDNet densely connected deep convolutional neural network model used classify ( recognize ) Bengali handwritten numeral digit . It end-to-end trained using ISI Bengali handwritten numeral dataset . During training untraditional data preprocessing augmentation technique used trained model work different dataset . The model achieved test accuracy 99.775 % ( baseline 99.40 % ) test dataset ISI Bengali handwritten numeral . So BDNet model give 62.5 % error reduction compared previous state-of-the-art model . Here also created dataset 1000 image Bengali handwritten numeral test trained model giving promising result . Codes trained model dataset available : { http : //github.com/Sufianlab/BDNet } .
In paper provide insight skill representation skill representation seen essential part skill assessment stage Computational Red Teaming process . Skill representation demonstrated context Sudoku puzzle real human skill used Sudoku solving along acquisition represented computationally cognitively plausible manner using feed-forward neural network back-propagation supervised learning . The neural network based skill coupled hard-coded constraint propagation computational Sudoku solver solving sequence kept hard-coded skill represented neural network . The paper demonstrates modified solver achieve different level proficiency depending amount skill acquired neural network . Results encouraging developing complex skill skill acquisition model usable general framework related skill assessment aspect Computational Red Teaming .
We present integrate Design Sprints project-based learning introductory visualization course . A design sprint unique process based rapid prototyping user testing define goal validate idea starting costly development . The well-defined interactive time-constrained design cycle make design sprint promising option teaching project-based active-learning-centered course increase student engagement hands-on experience . Over past five year adjusted design sprint methodology teaching range visualization course . We present detailed guide incorporating design sprint large undergraduate small professional development course online on-campus setting . Design sprint result including quantitative qualitative student feedback show design sprint engage student help practice apply visualization design skill . We provide design sprint teaching material show example student-created work discus limitation lesson learned .
Adversarial example input deliberately perturbed imperceptible change induce model error raised serious concern reliability security deep neural network ( DNNs ) . While adversarial attack extensively studied continuous data domain image discrete nature text present unique challenge . In paper propose Irony-based Adversarial Examples ( IAE ) method transforms straightforward sentence ironic one create adversarial text . This approach exploit rhetorical device irony intended meaning opposite literal interpretation requiring deeper understanding context detect . The IAE method particularly challenging due need accurately locate evaluation word substitute appropriate collocation expand text suitable ironic element maintaining semantic coherence . Our research make following key contribution : ( 1 ) We introduce IAE strategy generating textual adversarial example using irony . This method rely pre-existing irony corpus making versatile tool creating adversarial text various NLP task . ( 2 ) We demonstrate performance several state-of-the-art deep learning model sentiment analysis task significantly deteriorates subjected IAE attack . This finding underscore susceptibility current NLP system adversarial manipulation irony . ( 3 ) We compare impact IAE human judgment versus NLP system revealing human less susceptible effect irony text .
Accurate battery lifetime prediction important preventative maintenance warranty improved cell design manufacturing . However manufacturing variability usage-dependent degradation make life prediction challenging . Here investigate new feature derived capacity-voltage data early life predict lifetime cell cycled widely varying charge rate discharge rate depth discharge . Features extracted regularly scheduled reference performance test ( i.e . low rate full cycle ) cycling . The early-life feature capture cell 's state health rate change component-level degradation mode correlate strongly cell lifetime . Using newly generated dataset 225 nickel-manganese-cobalt/graphite Li-ion cell aged wide range condition demonstrate lifetime prediction in-distribution cell 15.1 % mean absolute percentage error using first 15 % data cell . Further testing using hierarchical Bayesian regression model show improved performance extrapolation achieving 21.8 % mean absolute percentage error out-of-distribution cell . Our approach highlight importance using domain knowledge lithium-ion battery degradation mode inform feature engineering . Further provide community new publicly available battery aging dataset cell cycled beyond 80 % rated capacity .
The AdaBoost algorithm superiority resisting overfitting . Understanding mystery phenomenon fascinating fundamental theoretical problem . Many study devoted explaining statistical view margin theory . In paper illustrate feature learning viewpoint propose AdaBoost+SVM algorithm explain resistant overfitting AdaBoost directly easily understand . Firstly adopt AdaBoost algorithm learn base classifier . Then instead directly weighted combination base classifier regard feature input SVM classifier . With new coefficient bias obtained used construct final classifier . We explain rationality illustrate theorem dimension feature increase performance SVM would worse explain resistant overfitting AdaBoost .
Affect often expressed via non-verbal body language actions/gestures vital indicator human behavior . Recent study recognition fine-grained actions/gestures monocular image mainly focused modeling spatial configuration body part representing body pose human-objects interaction variation local appearance . The result show brittle approach since relies accurate body parts/objects detection . In work argue exist local discriminative semantic region whose `` informativeness `` evaluated attention mechanism inferring fine-grained gestures/actions . To end propose novel end-to-end \textbf { Regional Attention Network ( RAN ) } fully Convolutional Neural Network ( CNN ) combine multiple contextual region attention mechanism focusing part image relevant given task . Our region consist one consecutive cell adapted strategy used computing HOG ( Histogram Oriented Gradient ) descriptor . The model extensively evaluated ten datasets belonging 3 different scenario : 1 ) head pose recognition 2 ) driver state recognition 3 ) human action facial expression recognition . The proposed approach outperforms state-of-the-art considerable margin different metric .
Harmony level prediction receiving increasing attention nowadays . Color play crucial role affecting human aesthetic response . In paper explore color harmony using fuzzy-based color model address question universality . For experiment utilize dataset containing attractive image five different domain : fashion art nature interior design brand logo . We aim identify harmony pattern dominant color palette within image using fuzzy approach . It well-suited task handle inherent subjectivity contextual variability associated aesthetic color harmony evaluation . Our experimental result suggest color harmony largely universal . Additionally finding reveal color harmony solely influenced hue relationship color wheel also saturation intensity color . In palette high harmony level observed prevalent adherence color wheel principle maintaining moderate level saturation intensity . These finding contribute ongoing research color harmony underlying principle offering valuable insight designer artist researcher field aesthetic .
Graph-structured data ubiquitous world model complex relationship object enabling various Web application . Daily influx unlabeled graph data Web offer immense potential application . Graph self-supervised algorithm achieved significant success acquiring generic knowledge abundant unlabeled graph data . These pre-trained model applied various downstream Web application saving training time improving downstream ( target ) performance . However different graph even across seemingly similar domain differ significantly term attribute semantics posing difficulty infeasibility transferring pre-trained model downstream task . Concretely speaking example additional task-specific node information downstream task ( specificity ) usually deliberately omitted pre-trained representation ( transferability ) leveraged . The trade-off termed `` transferability-specificity dilemma `` work . To address challenge introduce innovative deployment module coined GraphControl motivated ControlNet realize better graph domain transfer learning . Specifically leveraging universal structural pre-trained model GraphControl align input space across various graph incorporate unique characteristic target data conditional input . These condition progressively integrated model fine-tuning prompt tuning ControlNet facilitating personalized deployment . Extensive experiment show method significantly enhances adaptability pre-trained model target attributed datasets achieving 1.4-3x performance gain . Furthermore outperforms training-from-scratch method target data comparable margin exhibit faster convergence .
Accurate continuous reliable positioning critical component achieving autonomous driving . However complex urban canyon environment vulnerability stand-alone sensor non-line-of-sight ( NLOS ) caused high building tree elevated structure seriously affect positioning result . To address challenge sky-view image segmentation algorithm based Fully Convolutional Network ( FCN ) proposed GNSS NLOS detection . Building upon novel NLOS detection mitigation algorithm ( named S-NDM ) extended tightly coupled Global Navigation Satellite Systems ( GNSS ) Inertial Measurement Units ( IMU ) visual feature system called Sky-GVIO aim achieving continuous accurate positioning urban canyon environment . Furthermore system harmonizes Single Point Positioning ( SPP ) Real-Time Kinematic ( RTK ) methodology bolster operational versatility resilience . In urban canyon environment positioning performance S-NDM algorithm proposed paper evaluated different tightly coupled SPP-related RTK-related model . The result exhibit Sky-GVIO system achieves meter-level accuracy SPP mode sub-decimeter precision RTK surpassing performance GNSS/INS/Vision framework devoid S-NDM . Additionally sky-view image dataset inclusive training evaluation subset made publicly accessible scholarly exploration http : //github.com/whuwangjr/sky-view-images .
In paper summarize several application based thermal imaging . We emphasize importance emissivity adjustment proper temperature measurement . A new set face image acquired different emissivity value step 0.01 also presented distributed free research purpose . Among utility mention : ) possibility apply correction image acquired wrong emissivity value possible acquire new one ; b ) privacy protection thermal image obtained low emissivity factor still suitable several application hide identity user ; c ) image processing improving temperature detection scene containing object different emissivity .
The outbreak coronavirus disease ( COVID-19 ) swept across 180 country territory since late January 2020 . As worldwide emergency response government implemented various measure policy self-quarantine travel restriction work home regional lockdown control spread epidemic . These countermeasure seek restrict human mobility COVID-19 highly contagious disease spread human-to-human transmission . Medical expert policymakers expressed urgency effectively evaluate outcome human restriction policy aid big data information technology . Thus based big human mobility data city POI data interactive visual analytics system called Epidemic Mobility ( EpiMob ) designed study . The system interactively simulates change human mobility infection status response implementation certain restriction policy combination policy ( e.g . regional lockdown telecommuting screening ) . Users conveniently designate spatial temporal range different mobility restriction policy . Then result reflecting infection situation different policy dynamically displayed flexibly compared analyzed depth . Multiple case study consisting interview domain expert conducted largest metropolitan area Japan ( i.e . Greater Tokyo Area ) demonstrate system provide insight effect different human mobility restriction policy epidemic control measurement comparison .
Plagiarism one growing issue academia always concern Universities academic institution . The situation becoming even worse availability ample resource web . This paper focus creating effective fast tool plagiarism detection text based electronic assignment . Our plagiarism detection tool named AntiPlag developed using tri-gram sequence matching technique . Three set text based assignment tested AntiPlag result compared existing commercial plagiarism detection tool . AntiPlag showed better result term false positive compared commercial tool due pre-processing step performed AntiPlag . In addition improve detection latency AntiPlag applies data clustering technique making four time faster commercial tool considered . AntiPlag could used isolate plagiarized text based assignment non-plagiarised assignment easily . Therefore present AntiPlag fast effective tool plagiarism detection text based electronic assignment .
Bag-of-Visual-Words ( BoVW ) approach widely used recent year image classification purpose . However limitation regarding optimal feature selection clustering technique lack spatial organization data weighting visual word crucial . These factor affect stability model reduce performance . We propose develop algorithm based BoVW facial expression analysis go beyond limitation . Thus visual codebook built using k-Means++ method avoid poor clustering . To exploit reliable low level feature search best feature detector avoids locating large number keypoints contribute classification process . Then propose compute relative conjunction matrix order preserve spatial order data coding relationship among visual word . In addition weighting scheme reflects important visual word respect given image introduced . We speed learning process using histogram intersection kernel Support Vector Machine learn discriminative classifier . The efficiency proposed algorithm compared standard bag visual word method bag visual word method spatial pyramid . Extensive experiment CK+ MMI JAFFE database show good average recognition rate . Likewise ability recognize spontaneous non-basic expressive state investigated using DynEmo database .
Despite tremendous achievement deep convolutional neural network ( CNNs ) many computer vision task understanding actually work remains significant challenge . In paper propose novel two-step understanding method namely Salient Relevance ( SR ) map aim shed light deep CNNs recognize image learn feature area referred attention area therein . Our proposed method start layer-wise relevance propagation ( LRP ) step estimate pixel-wise relevance map input image . Following construct context-aware saliency map SR map LRP-generated map predicts area close focus attention instead isolated pixel LRP reveals . In human visual system information region important pixel recognition . Consequently proposed approach closely simulates human recognition . Experimental result using ILSVRC2012 validation dataset conjunction two well-established deep CNN model AlexNet VGG-16 clearly demonstrate proposed approach concisely identifies key pixel also attention area contribute underlying neural network 's comprehension given image . As proposed SR map constitutes convenient visual interface unveils visual attention network reveals type object model learned recognize training . The source code available http : //github.com/Hey1Li/Salient-Relevance-Propagation .
We introduce Reflective Hamiltonian Monte Carlo ( ReHMC ) HMC-based algorithm sample log-concave distribution restricted convex body . We prove starting warm start walk mix log-concave target distribution $ \pi ( x ) \propto e^ { -f ( x ) } $ $ f $ $ L $ -smooth $ $ -strongly-convex within accuracy $ \varepsilon $ $ \widetilde O ( \kappa d^2 \ell^2 \log ( 1 / \varepsilon ) ) $ step well-rounded convex body $ \kappa = L / $ condition number negative log-density $ $ dimension $ \ell $ upper bound number reflection $ \varepsilon $ accuracy parameter . We also developed efficient open source implementation ReHMC performed experimental study various high-dimensional data-sets . The experiment suggest ReHMC outperfroms Hit-and-Run Coordinate-Hit-and-Run regarding time need produce independent sample introduces practical truncated sampling thousand dimension .
Noise important factor get added image reduces quality appearance . So order enhance image quality removed preserving textural information structural feature image . There different type noise exist corrupt image . Selection denoising algorithm application dependent . Hence necessary knowledge noise present image select appropriate denoising algorithm . Objective paper present brief account type noise type different noise removal algorithm . In first section type noise basis additive multiplicative nature discussed . In second section precise classification analysis different potential image denoising algorithm presented . At end paper comparative study algorithm context performance evaluation done concluded several promising direction future research work .
Recent work shown potential using Mixed Integer Programming ( MIP ) solver optimize certain aspect neural network ( NNs ) . However intriguing approach training NNs MIP solver under-explored . State-of-the-art-methods train NNs typically gradient-based require significant data computation GPUs extensive hyper-parameter tuning . In contrast training MIP solver require GPUs heavy hyper-parameter tuning currently handle anything small amount data . This article build recent advance train binarized NNs using MIP solver . We go beyond current work formulating new MIP model improve training efficiency train important class integer-valued neural network ( INNs ) . We provide two novel method potential significance using MIP train NNs . The first method optimizes number neuron NN training . This reduces need deciding network architecture training . The second method address amount training data MIP feasibly handle : provide batch training method dramatically increase amount data MIP solver use train . We thus provide promising step towards using much data training NNs using MIP model . Experimental result two real-world data-limited datasets demonstrate approach strongly outperforms previous state art training NN MIP term accuracy training time amount data . Our methodology proficient training NNs minimal training data available training minimal memory requirement -- potentially valuable deploying low-memory device .
In data analysis latent variable play central role help provide powerful insight wide variety phenomenon ranging biological human science . The latent tree model particular type probabilistic graphical model deserves attention . Its simple structure - tree - allows simple efficient inference latent variable capture complex relationship . In past decade latent tree model subject significant theoretical methodological development . In review propose comprehensive study model . First summarize key idea underlying model . Second explain efficiently learned data . Third illustrate use within three type application : latent structure discovery multidimensional clustering probabilistic inference . Finally conclude give promising direction future research field .
The rapid development musical AI technology expanded creative potential various musical activity ranging music style transformation music generation . However little research investigated musical AIs support music therapist urgently need new technology support . This study used mixed method including semi-structured interview participatory design approach . By collaborating music therapist explored design opportunity musical AIs music therapy . We presented co-design outcome involving integration musical AIs music therapy process developed theoretical framework rooted emotion-focused therapy . After concluded benefit concern surrounding music AIs perspective music therapist . Based finding discussed opportunity design implication applying musical AIs music therapy . Our work offer valuable insight developing human-AI collaborative music system therapy involving complex procedure specific requirement .
Meta learning us information base learner ( e.g . classifier estimator ) well information learning problem improve upon performance single base learner . For example Bayes error rate given feature space known used aid choosing classifier well feature selection model selection base classifier meta classifier . Recent work field f-divergence functional estimation led development simple rapidly converging estimator used estimate various bound Bayes error . We estimate multiple bound Bayes error using estimator applies meta learning slowly converging plug-in estimator obtain parametric convergence rate . We compare estimated bound empirically simulated data estimate tighter bound feature extracted image patch analysis sunspot continuum magnetogram image .
Interacting pedestrian understandably efficiently one toughest challenge faced autonomous vehicle ( AVs ) due limitation current algorithm external human-machine interface ( eHMIs ) . In paper design eHMIs based gesture inspired popular method interaction pedestrian human driver . Eight common gesture selected convey AVs ' yielding non-yielding intention uncontrolled crosswalk previous literature . Through VR experiment ( N1 = 31 ) following online survey ( N2 = 394 ) discovered significant difference usability gesture-based eHMIs compared current eHMIs . Good gesture-based eHMIs increase efficiency pedestrian-AV interaction ensuring safety . Poor gesture however cause misinterpretation . The underlying reason explored : ambiguity regarding recipient signal whether gesture precise polite familiar pedestrian . Based empirical evidence discus potential opportunity provide valuable insight developing comprehensible gesture-based eHMIs future support better interaction AVs road user .
We consider reinforcement learning ( RL ) Markov Decision Processes agent repeatedly interacts environment modeled controlled Markov process . At time step $ $ earns reward also incurs cost-vector consisting $ M $ cost . We design model-based RL algorithm maximize cumulative reward earned time horizon $ T $ time-steps simultaneously ensuring average value $ M $ cost expenditure bounded agent-specified threshold $ c^ { ub } _i i=12 \ldots M $ . In order measure performance reinforcement learning algorithm satisfies average cost constraint define $ M+1 $ dimensional regret vector composed reward regret $ M $ cost regret . The reward regret measure sub-optimality cumulative reward $ $ -th component cost regret vector difference $ $ -th cumulative cost expense expected cost expenditure $ Tc^ { ub } _i $ . We prove expected value regret vector UCRL-CMDP upper-bounded $ \tilde { O } \left ( T^ { 2\slash 3 } \right ) $ $ T $ time horizon . We show reduce regret desired subset $ M $ cost expense increasing regret reward remaining cost . To best knowledge work considers non-episodic RL average cost constraint derive algorithm can~\emph { tune regret vector } according agent 's requirement cost regret .
Manipulation defines many experience consumer including subtle nudge overt advertising campaign seek gain attention money . With advent digital service continuously optimize online experience favor stakeholder requirement increasingly designer developer make use `` dark pattern `` -- -forms manipulation prey human psychology -- -to encourage certain behavior discourage others way present unequal value end user . In paper provide account end user perception manipulation build extends notion dark pattern . We report result survey user conducted English Mandarin Chinese ( n=169 ) including follow-up interview nine survey respondent . We used card sorting method support thematic analysis response cultural context identifying qualitatively-supported insight describe end user ' felt experience manipulative product continuum manipulation . We support analysis quantitative analysis survey result presentation vignette interview . We conclude implication future research consideration public policy guidance empower give user autonomy experience digital service .
Most machine learning model static world dynamic increasing online deployment learned model give increasing urgency development efficient effective mechanism address learning context non-stationary distribution commonly called concept drift . However key issue characterizing different type drift occur previously subjected rigorous definition analysis . In particular qualitative drift categorization proposed formally defined quantitative description required precise objective understanding learner performance existed . We present first comprehensive framework quantitative analysis drift . This support development first comprehensive set formal definition type concept drift . The formal definition clarify ambiguity identify gap previous definition giving rise new comprehensive taxonomy concept drift type solid foundation research mechanism detect address concept drift .
Object detection main task computer vision . Template matching reference method detecting object arbitrary template . However template matching computational complexity depends rotation accuracy limiting factor large 3D image ( tomograms ) . Here implement new algorithm called tensorial template matching based mathematical framework represents rotation template tensor field . Contrary standard template matching computational complexity presented algorithm independent rotation accuracy . Using synthetic real data tomography demonstrate tensorial template matching much faster template matching potential improve accuracy
Motivated practical demand simplification data towards consistent human thinking problem solving well tolerance uncertainty information granule becoming important entity data processing different level data abstraction . This paper proposes method construct classifier multi-resolution hierarchical granular representation ( MRHGRC ) using hyperbox fuzzy set . The proposed approach form series granular inference hierarchically many level abstraction . An attractive characteristic classifier maintain relatively high accuracy low degree granularity based reusing knowledge learned lower level abstraction . In addition approach reduce data size significantly well handling uncertainty incompleteness associated data real-world application . The construction process classifier consists two phase . The first phase formulate model greatest level granularity later stage aim reduce complexity constructed model deduce data higher abstraction level . Experimental outcome conducted comprehensively synthetic real datasets indicated efficiency method term training time predictive performance comparison type fuzzy min-max neural network common machine learning algorithm .
In enterprise email search setting search engine often power multiple enterprise various industry : technology education manufacturing etc . However using global ranking model across different enterprise may result suboptimal search quality due corpus difference distinct information need . On hand training individual ranking model enterprise may infeasible especially smaller institution limited data . To address data challenge paper propose domain adaptation approach fine-tunes global model individual enterprise . In particular propose novel application Maximum Mean Discrepancy ( MMD ) approach information retrieval attempt bridge gap global data distribution data distribution given individual enterprise . We conduct comprehensive set experiment large-scale email search engine demonstrate MMD approach consistently improves search quality multiple individual domain comparison global ranking model well several competitive domain adaptation baseline including adversarial learning method .
Convolutional Neural Networks become standard image classification task however architecture invariant translation input image . This lack invariance attributed use stride ignores sampling theorem fully connected layer lack spatial reasoning . We show stride greatly benefit translation invariance given combined sufficient similarity neighbouring pixel characteristic refer local homogeneity . We also observe characteristic dataset-specific dictate relationship pooling kernel size stride required translation invariance . Furthermore find trade-off exists generalization translation invariance case pooling kernel size larger kernel size lead better invariance poorer generalization . Finally explore efficacy solution proposed namely global average pooling anti-aliasing data augmentation empirically lens local homogeneity .
This paper address challenging task reconstructing pose multiple individual engaged close interaction captured multiple calibrated camera . The difficulty arises noisy false 2D keypoint detection due inter-person occlusion heavy ambiguity associating keypoints individual due close interaction scarcity training data collecting annotating motion data crowded scene resource-intensive . We introduce novel system address challenge . Our system integrates learning-based pose estimation component corresponding training inference strategy . The pose estimation component take multi-view 2D keypoint heatmaps input reconstructs pose individual using 3D conditional volumetric network . As network n't need image input leverage known camera parameter test scene large quantity existing motion capture data synthesize massive training data mimic real data distribution test scene . Extensive experiment demonstrate approach significantly surpasses previous approach term pose accuracy generalizable across various camera setup population size . The code available project page : http : //github.com/zju3dv/CloseMoCap .
Hyperdimensional ( HD ) computing built upon unique data type referred hypervectors . The dimension hypervectors typically range ten thousand . Proposed solve cognitive task HD computing aim calculating similarity among data . Data transformation realized three operation including addition multiplication permutation . Its ultra-wide data representation introduces redundancy noise . Since information evenly distributed every bit hypervectors HD computing inherently robust . Additionally due nature three operation HD computing lead fast learning ability high energy efficiency acceptable accuracy learning classification task . This paper introduces background HD computing review data representation data transformation similarity measurement . The orthogonality high dimension present opportunity flexible computing . To balance tradeoff accuracy efficiency strategy include limited encoding retraining binarization hardware acceleration . Evaluations indicate HD computing show great potential addressing problem using data form letter signal image . HD computing especially show significant promise replace machine learning algorithm light-weight classifier field internet thing ( IoTs ) .
This letter proposes estimate low-rank matrix formulating convex optimization problem non-convex regularization . We employ parameterized non-convex penalty function estimate non-zero singular value accurately nuclear norm . A closed-form solution global optimum proposed objective function ( sum data fidelity non-convex regularizer ) also derived . The solution reduces singular value thresholding method special case . The proposed method demonstrated image denoising .
The basic concept Neural Machine Translation ( NMT ) train large Neural Network maximizes translation performance given parallel corpus . NMT using simple left-to-right beam-search decoder generate new translation approximately maximize trained conditional probability . The current beam search strategy generates target sentence word word left-to- right keeping fixed amount active candidate time step . First simple search less adaptive also expands candidate whose score much worse current best . Secondly expand hypothesis within best scoring candidate even score close best one . The latter one avoided increasing beam size performance improvement observed . While reach better performance draw- back slower decoding speed . In paper concentrate speeding decoder applying flexible beam search strategy whose candidate size may vary time step depending candidate score . We speed original decoder 43 % two language pair German-English Chinese-English without losing translation quality .
This work present advancement multi-class vehicle detection using UAV camera development spatiotemporal object detection model . The study introduces Spatio-Temporal Vehicle Detection Dataset ( STVD ) containing 6 600 annotated sequential frame image captured UAVs enabling comprehensive training evaluation algorithm holistic spatiotemporal perception . A YOLO-based object detection algorithm enhanced incorporate temporal dynamic resulting improved performance single frame model . The integration attention mechanism spatiotemporal model shown enhance performance . Experimental validation demonstrates significant progress best spatiotemporal model exhibiting 16.22 % improvement single frame model demonstrated attention mechanism hold potential additional performance gain .
Road accident significant economic societal cost small number severe accident accounting large portion cost . Predicting accident severity help proactive approach road safety identifying potential unsafe road condition taking well-informed action reduce number severe accident . This study investigates effectiveness Random Forest machine learning algorithm predicting severity accident . The model trained dataset accident record large metropolitan area evaluated using various metric . Hyperparameters feature selection optimized improve model 's performance . The result show Random Forest model effective tool predicting accident severity accuracy 80 % . The study also identifies top six important variable model include wind speed pressure humidity visibility clear condition cloud cover . The fitted model Area Under Curve 80 % recall 79.2 % precision 97.1 % F1 score 87.3 % . These result suggest proposed model higher performance explaining target variable accident severity class . Overall study provides evidence Random Forest model viable reliable tool predicting accident severity used help reduce number fatality injury due road accident United States
State art Symbolic Regression ( SR ) method currently build specialized model application Large Language Models ( LLMs ) remains largely unexplored . In work introduce first comprehensive framework utilizes LLMs task SR. We propose In-Context Symbolic Regression ( ICSR ) SR method iteratively refines functional form LLM determines coefficient external optimizer . ICSR leverage LLMs ' strong mathematical prior propose initial set possible function given observation refine based error . Our finding reveal LLMs able successfully find symbolic equation fit given data matching outperforming overall performance best SR baseline four popular benchmark yielding simpler equation better distribution generalization .
Fact-centric information need rarely one-shot ; user typically ask follow-up question explore topic . In conversational setting user 's input often incomplete entity predicate left ungrammatical phrase . This pose huge challenge question answering ( QA ) system typically rely cue full-fledged interrogative sentence . As solution develop CONVEX : unsupervised method answer incomplete question knowledge graph ( KG ) maintaining conversation context using entity predicate seen far automatically inferring missing ambiguous piece follow-up question . The core method graph exploration algorithm judiciously expands frontier find candidate answer current question . To evaluate CONVEX release ConvQuestions crowdsourced benchmark 11200 distinct conversation five different domain . We show CONVEX : ( ) add conversational support stand-alone QA system ( ii ) outperforms state-of-the-art baseline question completion strategy .
Existing deep clustering method rely either contrastive non-contrastive representation learning downstream clustering task . Contrastive-based method thanks negative pair learn uniform representation clustering negative pair however may inevitably lead class collision issue consequently compromise clustering performance . Non-contrastive-based method hand avoid class collision issue resulting non-uniform representation may cause collapse clustering . To enjoy strength world paper present novel end-to-end deep clustering method prototype scattering positive sampling termed ProPos . Specifically first maximize distance prototypical representation named prototype scattering loss improves uniformity representation . Second align one augmented view instance sampled neighbor another view -- assumed truly positive pair embedding space -- improve within-cluster compactness termed positive sampling alignment . The strength ProPos avoidable class collision issue uniform representation well-separated cluster within-cluster compactness . By optimizing ProPos end-to-end expectation-maximization framework extensive experimental result demonstrate ProPos achieves competing performance moderate-scale clustering benchmark datasets establishes new state-of-the-art performance large-scale datasets . Source code available \url { http : //github.com/Hzzone/ProPos } .
While public claim concern privacy frequently appear overlook . This disparity concern behaviour known Privacy Paradox . Such issue particularly prevalent wearable device . These product store personal data text message contact detail . However owner rarely use protective feature . Educational game effective encouraging change behaviour . Therefore developed first privacy game ( Android ) Wear OS watch . 10 participant used smartwatches two month allowing high-level setting monitored . Five individual randomly assigned treatment group played dynamically-customised privacy-themed game . To minimise confounding variable five received app lacking privacy topic . The treatment group improved protection usage screen lock significantly increasing ( p = 0.043 ) . In contrast 80 % control group continued never restrict setting . After posttest phase evaluated behavioural rationale semi-structured interview . Privacy concern became nuanced treatment group opinion aligning behaviour . Actions appeared influenced primarily three factor : convenience privacy salience data sensitivity . This first smartwatch game encourage privacy-protective behaviour .
Machine learning ( ML ) help fight pandemic like COVID-19 enabling rapid screening large volume image . To perform data analysis maintaining patient privacy create ML model satisfy Differential Privacy ( DP ) . Previous work exploring private COVID-19 model part based small datasets provide weaker unclear privacy guarantee investigate practical privacy . We suggest improvement address open gap . We account inherent class imbalance evaluate utility-privacy trade-off extensively stricter privacy budget . Our evaluation supported empirically estimating practical privacy black-box Membership Inference Attacks ( MIAs ) . The introduced DP help limit leakage threat posed MIAs practical analysis first test hypothesis COVID-19 classification task . Our result indicate needed privacy level might differ based task-dependent practical threat MIAs . The result suggest increasing DP guarantee empirical privacy leakage improves marginally DP therefore appears limited impact practical MIA defense . Our finding identify possibility better utility-privacy trade-off believe empirical attack-specific privacy estimation play vital role tuning practical privacy .
Detecting segmenting salient object natural scene often referred salient object detection attracted great interest computer vision . While many model proposed several application emerged deep understanding achievement issue remains lacking . We aim provide comprehensive review recent progress salient object detection situate field among closely related area generic scene segmentation object proposal generation saliency fixation prediction . Covering 228 publication survey ) root key concept task ii ) core technique main modeling trend iii ) datasets evaluation metric salient object detection . We also discus open problem evaluation metric dataset bias model performance suggest future research direction .
Vision-based deep learning ( DL ) method made great progress learning autonomous driving model large-scale crowd-sourced video datasets . They trained predict instantaneous driving behavior video data captured on-vehicle camera . In paper develop geo-context aware visualization system study Autonomous Driving Model ( ADM ) prediction together large-scale ADM video data . The visual study seamlessly integrated geographical environment combining DL model performance geospatial visualization technique . Model performance measure studied together set geospatial attribute map view . Users also discover compare prediction behavior multiple DL model city-wide street-level analysis together road image video content . Therefore system provides new visual exploration platform DL model designer autonomous driving . Use case domain expert evaluation show utility effectiveness visualization system .
This paper introduces novel computational method mapping indoor luminance value facade open workplace improve daylight performance . 180-degree fisheye rendering different indoor location view position time year created . These rendering transformed two-dimensional ( 2D ) image three-dimensional ( 3D ) hemisphere . High luminance value filtered projected hemisphere facade surface . This framework highlight area facade allow much light penetration interior environment . The flexible workflow allows occupant centric lighting analysis computes multiple design parameter synthesizes result localized facade optimization daylight design .
Male infertility disease affect approximately 7 % men . Sperm morphology analysis ( SMA ) one main diagnosis method problem . Manual SMA inexact subjective non-reproducible hard teach process . As result paper introduce novel automatic SMA based neural architecture search algorithm termed Genetic Neural Architecture Search ( GeNAS ) . For purpose used collection image called MHSMA dataset contains 1540 sperm image collected 235 patient infertility problem . GeNAS genetic algorithm act meta-controller explores constrained search space plain convolutional neural network architecture . Every individual genetic algorithm convolutional neural network trained predict morphological deformity different segment human sperm ( head vacuole acrosome ) fitness calculated novel proposed method named GeNAS-WF especially designed noisy low resolution imbalanced datasets . Also hashing method used save trained neural architecture fitness could reuse fitness evaluation speed algorithm . Besides term running time computation power proposed architecture search method far efficient existing neural architecture search algorithm . Additionally proposed method evaluated balanced datasets whereas GeNAS built specifically noisy low quality imbalanced datasets common field medical imaging . In experiment best neural architecture found GeNAS reached accuracy 91.66 % 77.33 % 77.66 % vacuole head acrosome abnormality detection respectively . In comparison proposed algorithm MHSMA dataset GeNAS achieved state-of-the-art result .
Multi-label image classification ( MLIC ) fundamental practical task aim assign multiple possible label image . In recent year many deep convolutional neural network ( CNN ) based approach proposed model label correlation discover semantics label learn semantic representation image . This paper advance research direction improving modeling label correlation learning semantic representation . On one hand besides local semantics label propose explore global semantics shared multiple label . On hand existing approach mainly learn semantic representation last convolutional layer CNN . But noted image representation different layer CNN capture different level scale feature different discriminative ability . We thus propose learn semantic representation multiple convolutional layer . To end paper design Multi-layered Semantic Representation Network ( MSRN ) discovers local global semantics label modeling label correlation utilizes label semantics guide semantic representation learning multiple layer attention mechanism . Extensive experiment four benchmark datasets including VOC 2007 COCO NUS-WIDE Apparel show competitive performance proposed MSRN state-of-the-art model .
Dimensionality reduction ( DR ) method attracted extensive attention provide discriminative information reduce computational burden hyperspectral image ( HSI ) classification . However DR method face many challenge due limited training sample high dimensional spectrum . To address issue graph-based spatial spectral regularized local scaling cut ( SSRLSC ) DR HSI data proposed . The underlying idea proposed method utilize information spectral spatial domain achieve better classification accuracy spectral domain counterpart . In SSRLSC guided filter initially used smoothen homogenize pixel HSI data order preserve pixel consistency . This followed generation between-class within-class dissimilarity matrix spectral spatial domain regularized local scaling cut ( RLSC ) neighboring pixel local scaling cut ( NPLSC ) respectively . Finally obtain projection matrix optimizing updated spatial-spectral between-class total-class dissimilarity . The effectiveness proposed DR algorithm illustrated two popular real-world HSI datasets .
The task dialogue generation aim automatically provide response given previous utterance . Tracking dialogue state important ingredient dialogue generation estimating user ' intention . However \emph { expensive nature state labeling } \emph { weak interpretability } make dialogue state tracking challenging problem task-oriented non-task-oriented dialogue generation : For generating response task-oriented dialogue state tracking usually learned manually annotated corpus human annotation expensive training ; generating response non-task-oriented dialogue existing work neglect explicit state tracking due unlimited number dialogue state . In paper propose \emph { semi-supervised explicit dialogue state tracker } ( SEDST ) neural dialogue generation . To end approach two core ingredient : \emph { CopyFlowNet } \emph { posterior regularization } . Specifically propose encoder-decoder architecture named \emph { CopyFlowNet } represent explicit dialogue state probabilistic distribution vocabulary space . To optimize training procedure apply posterior regularization strategy integrate indirect supervision . Extensive experiment conducted task-oriented non-task-oriented dialogue corpus demonstrate effectiveness proposed model . Moreover find proposed semi-supervised dialogue state tracker achieves comparable performance state-of-the-art supervised learning baseline state tracking procedure .
Objective : Evictions important social behavioral determinant health . Evictions associated cascade negative event lead unemployment housing insecurity/homelessness long-term poverty mental health problem . In study developed natural language processing system automatically detect eviction status electronic health record ( EHR ) note . Materials Methods : We first defined eviction status ( eviction presence eviction period ) annotated eviction status 5000 EHR note Veterans Health Administration ( VHA ) . We developed novel model KIRESH shown substantially outperform state-of-the-art model fine-tuning pre-trained language model like BioBERT BioClinicalBERT . Moreover designed novel prompt improve model performance using intrinsic connection two sub-tasks eviction presence period prediction . Finally used Temperature Scaling-based Calibration KIRESH-Prompt method avoid over-confidence issue arising imbalance dataset . Results : KIRESH-Prompt substantially outperformed strong baseline model including fine-tuning BioClinicalBERT model achieve 0.74672 MCC 0.71153 Macro-F1 0.83396 Micro-F1 predicting eviction period 0.66827 MCC 0.62734 Macro-F1 0.7863 Micro-F1 predicting eviction presence . We also conducted additional experiment benchmark social determinant health ( SBDH ) dataset demonstrate generalizability method . Conclusion Future Work : KIRESH-Prompt substantially improved eviction status classification . We plan deploy KIRESH-Prompt VHA EHRs eviction surveillance system help address US Veterans ' housing insecurity .
Despite recent improvement computer vision artificial visual system ' design still daunting since explanation visual computing algorithm remains elusive . Salient object detection one problem still open due difficulty understanding brain 's inner working . Progress research area follows traditional path hand-made design using neuroscience knowledge . In recent year two different approach based genetic programming appear enhance technique . One follows idea combining previous hand-made method genetic programming fuzzy logic . The approach consists improving inner computational structure basic hand-made model artificial evolution . This research work proposes expanding artificial dorsal stream using recent proposal solve salient object detection problem . This approach us benefit two main aspect research area : fixation prediction detection salient object . We decided apply fusion visual saliency image segmentation algorithm template . The proposed methodology discovers several critical structure template artificial evolution . We present result benchmark designed expert outstanding result comparison state-of-the-art .
As AI technology progress social acceptance AI agent including intelligent virtual agent robot becoming even important application AI human society . One way improve relationship human anthropomorphic agent human empathize agent . By empathizing human act positively kindly toward agent make easier accept agent . In study focus self-disclosure agent human order increase empathy felt human toward anthropomorphic agent . We experimentally investigate possibility self-disclosure agent facilitates human empathy . We formulate hypothesis experimentally analyze discus condition human empathy toward agent . Experiments conducted three-way mixed plan factor agent ' appearance ( human robot ) self-disclosure ( high-relevance self-disclosure low-relevance self-disclosure self-disclosure ) empathy before/after video stimulus . An analysis variance ( ANOVA ) performed using data 918 participant . We found appearance factor main effect self-disclosure highly relevant scenario used facilitated human empathy statistically significant difference . We also found self-disclosure suppressed empathy.These result support hypothesis . This study reveals self-disclosure represents important characteristic anthropomorphic agent help human accept .
Video anomaly detection aim discover abnormal event video principal object target object people vehicle . Each target video data rich spatio-temporal context information . Most existing method focus temporal context ignoring role spatial context anomaly detection . The spatial context information represents relationship detection target surrounding target . Anomaly detection make lot sense . To end video anomaly detection algorithm based target spatio-temporal context fusion proposed . Firstly target video frame extracted target detection network reduce background interference . Then optical flow map two adjacent frame calculated . Motion feature used multiple target video frame construct spatial context simultaneously re-encoding target appearance motion feature finally reconstructing feature spatio-temporal dual-stream network using reconstruction error represent abnormal score . The algorithm achieves frame-level AUCs 98.5 % 86.3 % UCSDped2 Avenue datasets respectively . On UCSDped2 dataset spatio-temporal dual-stream network improves frame 5.1 % 0.3 % respectively compared temporal spatial stream network . After using spatial context encoding frame-level AUC enhanced 1 % verifies method 's effectiveness .
General Continual Learning ( GCL ) aim learning non independent identically distributed stream data without catastrophic forgetting old task n't rely task boundary training testing stage . We reveal relation feature deviation crucial problem catastrophic forgetting relation deviation refers deficiency relationship among class knowledge distillation feature deviation refers indiscriminative feature representation . To end propose Complementary Calibration ( CoCa ) framework mining complementary model 's output feature alleviate two deviation process GCL . Specifically propose new collaborative distillation approach addressing relation deviation . It distills model 's output utilizing ensemble dark knowledge new model 's output reserved output maintains performance old task well balancing relationship among class . Furthermore explore collaborative self-supervision idea leverage pretext task supervised contrastive learning addressing feature deviation problem learning complete discriminative feature class . Extensive experiment four popular datasets show CoCa framework achieves superior performance state-of-the-art method . Code available http : //github.com/lijincm/CoCa .
Data-driven decision making related individual become increasingly pervasive issue concerning potential discrimination raised recent study . In response researcher made effort propose implement fairness measure algorithm effort translated real-world practice data-driven decision making . As still urgent need create viable tool facilitate fair decision making . We propose FairSight visual analytic system address need ; designed achieve different notion fairness ranking decision identifying required action -- understanding measuring diagnosing mitigating bias -- together lead fairer decision making . Through case study user study demonstrate proposed visual analytic diagnostic module system effective understanding fairness-aware decision pipeline obtaining fair outcome .
We revisit problem fair clustering first introduced Chierichetti et al . requires protected attribute approximately equal representation every cluster ; i.e . balance property . Existing solution fair clustering either scalable achieve optimal trade-off clustering objective fairness . In paper propose new notion fairness call $ tau $ -fair fairness strictly generalizes balance property enables fine-grained efficiency vs. fairness trade-off . Furthermore show simple greedy round-robin based algorithm achieve trade-off efficiently . Under general setting multi-valued protected attribute rigorously analyze theoretical property algorithm . Our experimental result suggest proposed solution outperforms state-of-the-art algorithm work exceptionally well even large number cluster .
While image segmentation crucial various computer vision application autonomous driving grasping robot navigation annotating object pixel-level training nearly impossible . Therefore study unsupervised image segmentation method essential . In paper present pixel-level clustering framework segmenting image region without using ground truth annotation . The proposed framework includes feature embedding module attention mechanism feature statistic computing module image reconstruction superpixel segmentation achieve accurate unsupervised segmentation . Additionally propose training strategy utilizes intra-consistency within superpixel inter-similarity/dissimilarity neighboring superpixels structural similarity image . To avoid potential over-segmentation caused superpixel-based loss also propose post-processing method . Furthermore present extension proposed method unsupervised semantic segmentation . We conducted experiment three publicly available datasets ( Berkeley segmentation dataset PASCAL VOC 2012 dataset COCO-Stuff dataset ) demonstrate effectiveness proposed framework . The experimental result show proposed framework outperforms previous state-of-the-art method .
In contrast traditional camera whose pixel common exposure time event-based camera novel bio-inspired sensor whose pixel work independently asynchronously output intensity change ( called `` event `` ) microsecond resolution . Since event caused apparent motion object event-based camera sample visual information based scene dynamic therefore natural fit traditional camera acquire motion especially high speed traditional camera suffer motion blur . However distinguishing event caused different moving object camera 's ego-motion challenging task . We present first per-event segmentation method splitting scene independently moving object . Our method jointly estimate event-object association ( i.e . segmentation ) motion parameter object ( background ) maximization objective function build upon recent result event-based motion-compensation . We provide thorough evaluation method public dataset outperforming state-of-the-art much 10 % . We also show first quantitative evaluation segmentation algorithm event camera yielding around 90 % accuracy 4 pixel relative displacement .
In era big data advancement improvement application algorithm academic research played important role promoting development different discipline . Academic paper various discipline especially computer science contain large number algorithm . Identifying algorithm full-text content paper determine popular classical algorithm specific field help scholar gain comprehensive understanding algorithm even field . To end article take field natural language processing ( NLP ) example identifies algorithm academic paper field . A dictionary algorithm constructed manually annotating content paper sentence containing algorithm dictionary extracted dictionary-based matching . The number article mentioning algorithm used indicator analyze influence algorithm . Our result reveal algorithm highest influence NLP paper show classification algorithm represent largest proportion among high-impact algorithm . In addition evolution influence algorithm reflects change research task topic field change influence different algorithm show different trend . As preliminary exploration paper conduct analysis impact algorithm mentioned academic text result used training data automatic extraction large-scale algorithm future . The methodology paper domain-independent applied domain .
Junctions play important role characterization local geometric structure image detection longstanding challenging task . Existing junction detector usually focus identifying junction location orientation junction branch ignoring scale ; however scale also contain rich geometric information . This paper present novel approach junction detection characterization exploit locally anisotropic geometry junction estimate scale geometry using \emph { contrario } model . The output junction anisotropic scale -- - i.e . branch junction associated independent scale parameter -- - thus termed anisotropic-scale junction ( ASJs ) . We apply newly detected ASJs matching indoor image may dramatic change viewpoint detected local visual feature e.g . key-points usually insufficiently distinctive . We propose use anisotropic geometry junction improve matching precision indoor image . Matching result obtained set indoor image demonstrate approach achieves state-of-the-art performance indoor image matching .
This paper introduces use single layer deep convolutional network remote sensing data analysis . Direct application multi- hyper-spectral imagery supervised ( shallow deep ) convolutional network challenging given high input data dimensionality relatively small amount available labeled data . Therefore propose use greedy layer-wise unsupervised pre-training coupled highly efficient algorithm unsupervised learning sparse feature . The algorithm rooted sparse representation enforces population lifetime sparsity extracted feature simultaneously . We successfully illustrate expressive power extracted representation several scenario : classification aerial scene well land-use classification high resolution ( VHR ) land-cover classification multi- hyper-spectral image . The proposed algorithm clearly outperforms standard Principal Component Analysis ( PCA ) kernel counterpart ( kPCA ) well current state-of-the-art algorithm aerial classification extremely computationally efficient learning representation data . Results show single layer convolutional network extract powerful discriminative feature receptive field account neighboring pixel preferred classification requires high resolution detailed result . However deep architecture significantly outperform single layer variant capturing increasing level abstraction complexity throughout feature hierarchy .
Graph Convolutional Network ( GCN ) experienced great success graph analysis task . It work smoothing node feature across graph . The current GCN model overwhelmingly assume node feature information complete . However real-world graph data often incomplete containing missing feature . Traditionally people estimate fill unknown feature based imputation technique apply GCN . However process feature filling graph learning separated resulting degraded unstable performance . This problem becomes serious large number feature missing . We propose approach adapts GCN graph containing missing feature . In contrast traditional strategy approach integrates processing missing feature graph learning within neural network architecture . Our idea represent missing data Gaussian Mixture Model ( GMM ) calculate expected activation neuron first hidden layer GCN keeping layer network unchanged . This enables u learn GMM parameter network weight parameter end-to-end manner . Notably approach increase computational complexity GCN consistent GCN feature complete . We demonstrate extensive experiment approach significantly outperforms imputation-based method node classification link prediction task . We show performance approach case low level missing feature even superior GCN case complete feature .
Question classification ( QC ) prime constituent automated question answering system . The work presented demonstrates combination multiple model achieve better classification performance obtained existing individual model question classification task Bengali . We exploited state-of-the-art multiple model combination technique i.e . ensemble stacking voting increase QC accuracy . Lexical syntactic semantic feature Bengali question used four well-known classifier namely Na\ `` { \i } Bayes kernel Na\ `` { \i } Bayes Rule Induction Decision Tree serve base learner . Single-layer question-class taxonomy 8 coarse-grained class extended two-layer taxonomy adding 69 fine-grained class . We carried experiment single-layer two-layer taxonomy . Experimental result confirmed classifier combination approach outperform single classifier classification approach 4.02 % coarse-grained question class . Overall stacking approach produce best result fine-grained classification achieves 87.79 % accuracy . The approach presented could used Indo-Aryan Indic language develop question answering system .
Writer identification based small amount text challenging problem . In paper propose new benchmark study writer identification based word text block image approximately contain one word . In order extract powerful feature word image deep neural network named FragNet proposed . The FragNet two pathway : feature pyramid used extract feature map fragment pathway trained predict writer identity based fragment extracted input image feature map feature pyramid . We conduct experiment four benchmark datasets show proposed method generate efficient robust deep representation writer identification based word page image .
Time-series data arises many real-world application ( e.g . mobile health ) deep neural network ( DNNs ) shown great success solving . Despite success little known robustness adversarial attack . In paper propose novel adversarial framework referred Time-Series Attacks via STATistical Features ( TSA-STAT ) } . To address unique challenge time-series domain TSA-STAT employ constraint statistical feature time-series data construct adversarial example . Optimized polynomial transformation used create attack effective ( term successfully fooling DNNs ) based additive perturbation . We also provide certified bound norm statistical feature constructing adversarial example . Our experiment diverse real-world benchmark datasets show effectiveness TSA-STAT fooling DNNs time-series domain improving robustness . The source code TSA-STAT algorithm available http : //github.com/tahabelkhouja/Time-Series-Attacks-via-STATistical-Features
With increasing reliance small Unmanned Aerial Systems ( sUAS ) Emergency Response Scenarios Search Rescue integration computer vision capability become key factor mission success . Nevertheless computer vision performance detecting human severely degrades shifting ground aerial view . Several aerial datasets created mitigate problem however none specifically addressed issue occlusion critical component Emergency Response Scenarios . Natural Occluded Multi-scale Aerial Dataset ( NOMAD ) present benchmark human detection occluded aerial view five different aerial distance rich imagery variance . NOMAD composed 100 different Actors performing sequence walking laying hiding . It includes 42825 frame extracted 5.4k resolution video manually annotated bounding box label describing 10 different visibility level categorized according percentage human body visible inside bounding box . This allows computer vision model evaluated detection performance across different range occlusion . NOMAD designed improve effectiveness aerial search rescue enhance collaboration sUAS human providing new benchmark dataset human detection occluded aerial view . Full dataset found : http : //github.com/ArtRuss/NOMAD .
Vertical Federated Learning ( VFL ) federated learning setting multiple party different feature set user jointly train machine learning model without exposing raw data model parameter . Motivated rapid growth VFL research real-world application provide comprehensive review concept algorithm VFL well current advance challenge various aspect including effectiveness efficiency privacy . We provide exhaustive categorization VFL setting privacy-preserving protocol comprehensively analyze privacy attack defense strategy protocol . In end propose unified framework termed VFLow considers VFL problem communication computation privacy well effectiveness fairness constraint . Finally review recent advance industrial application highlighting open challenge future direction VFL .
Graph neural network ( GNNs ) achieved great success many graph-based application . However enormous size high sparsity level graph hinder application industrial scenario . Although scalable GNNs proposed large-scale graph adopt fixed $ K $ -hop neighborhood node thus facing over-smoothing issue adopting large propagation depth node within sparse region . To tackle issue propose new GNN architecture -- Graph Attention Multi-Layer Perceptron ( GAMLP ) capture underlying correlation different scale graph knowledge . We deployed GAMLP Tencent Angel platform evaluate GAMLP real-world datasets large-scale industrial datasets . Extensive experiment 14 graph datasets demonstrate GAMLP achieves state-of-the-art performance enjoying high scalability efficiency . Specifically outperforms GAT 1.3\ % regarding predictive accuracy large-scale Tencent Video dataset achieving $ 50\times $ training speedup . Besides rank top-1 leaderboards largest homogeneous heterogeneous graph ( i.e . ogbn-papers100M ogbn-mag ) Open Graph Benchmark .
The current research focusing area Opinion Mining also called sentiment analysis due sheer volume opinion rich web resource discussion forum review site blog available digital form . One important problem sentiment analysis product review produce summary opinion based product feature . We surveyed analyzed paper various technique developed key task opinion mining . We provided overall picture involved developing software system opinion mining basis survey analysis .
Challenges faced formerly incarcerated individual United States raise question society 's ability truly provide second chance . This paper present outcome ongoing collaboration non-profit organization dedicated reentry support . We highlight multifaceted challenge individual face reentry journey including support program prioritize supervision service unresponsive support system limited access resource financial struggle exacerbated restricted employment opportunity technological barrier . In face complex social challenge work aim facilitate partner organization 's ongoing effort promote digital literacy web application integrated existing process . We share initial feedback stakeholder draw four implication : supporting continuity care promoting reflection slow technology building flexibility reconfiguring toward existing infrastructure conclude reflection role partner side .
Item-to-item collaborative filtering ( aka . item-based CF ) long used building recommender system industrial setting owing interpretability efficiency real-time personalization . It build user 's profile historically interacted item recommending new item similar user 's profile . As key item-based CF method estimation item similarity . Early approach use statistical measure cosine similarity Pearson coefficient estimate item similarity less accurate since lack tailored optimization recommendation task . In recent year several work attempt learn item similarity data expressing similarity underlying model estimating model parameter optimizing recommendation-aware objective function . While extensive effort made use shallow linear model learning item similarity relatively less work exploring nonlinear neural network model item-based CF . In work propose neural network model named Neural Attentive Item Similarity model ( NAIS ) item-based CF . The key design NAIS attention network capable distinguishing historical item user profile important prediction . Compared state-of-the-art item-based CF method Factored Item Similarity Model ( FISM ) NAIS stronger representation power additional parameter brought attention network . Extensive experiment two public benchmark demonstrate effectiveness NAIS . This work first attempt design neural network model item-based CF opening new research possibility future development neural recommender system .
Inspired authorship controversy Dream Red Chamber application machine learning study literary stylometry develop rigorous new method mathematical analysis authorship testing so-called chrono-divide writing style . Our method incorporates latest advance study authorship attribution particularly technique support vector machine . By introducing notion relative frequency feature ranking metric method prof highly effective robust . Applying method Cheng-Gao version Dream Red Chamber led convincing irrefutable evidence first $ 80 $ chapter last $ 40 $ chapter book written two different author . Furthermore analysis unexpectedly provided strong support hypothesis Chapter 67 work Cao Xueqin either . We also tested method three Great Classical Novels Chinese . As expected chrono-divides found . This provides evidence robustness method .
Nowadays major challenge machine learning Big Data challenge . The big data problem due large number data point large number feature data point training model become slow . The training time two major component : Time access data time process ( learn ) data . So far research focused second part i.e . learning data . In paper proposed one possible solution handle big data problem machine learning . The idea reduce training time reducing data access time proposing systematic sampling cyclic/sequential sampling select mini-batches dataset . To prove effectiveness proposed sampling technique used Empirical Risk Minimization commonly used machine learning problem strongly convex smooth case . The problem solved using SAG SAGA SVRG SAAG-II MBSGD ( Mini-batched SGD ) using two step determination technique namely constant step size backtracking line search method . Theoretical result prove convergence systematic sampling cyclic sampling widely used random sampling technique expectation . Experimental result bench marked datasets prove efficacy proposed sampling technique show six time faster training .
Interruption dialogue occurs listener begin speech current speaker finish speaking . Interruptions broadly divided two group : cooperative ( listener want support speaker ) competitive ( listener try take control conversation speaker 's ) . A system automatically classifies interruption used call center specifically task customer satisfaction monitoring agent monitoring . In study developed text-based interruption classification model preparing in-house dataset consisting ASR-transcribed customer support telephone dialogue Russian . We fine-tuned Conversational RuBERT dataset optimized hyperparameters model performed well . With improvement proposed model applied automatic monitoring system .
A change detection system take input two image region captured two different time predicts pixel region undergone change time period . Since pixel-based analysis erroneous due noise illumination difference factor contextual information usually used determine class pixel ( changed ) . This contextual information taken account considering pixel difference image along neighborhood . With help ground truth information labeled pattern generated . Finally Broad Learning classifier used get prediction class pixel . Results show Broad Learning classify data set significantly higher F-Score Multilayer Perceptron . Performance comparison also made popular classifier namely Multilayer Perceptron Random Forest .
Large language model ( LLMs ) made significant advancement natural language processing ( NLP ) . Broad corpus capture diverse pattern introduce irrelevance focused corpus enhance reliability reducing misleading information . Training LLMs focused corpus pose computational challenge . An alternative approach use retrieval-augmentation ( RetA ) method tested specific domain . To evaluate LLM performance OpenAI 's GPT-3 GPT-4 Bing 's Prometheus custom RetA model compared using 19 question diffuse large B-cell lymphoma ( DLBCL ) disease . Eight independent reviewer assessed response based accuracy relevance readability ( rated 1-3 ) . The RetA model performed best accuracy ( 12/19 3-point score total=47 ) relevance ( 13/19 50 ) followed GPT-4 ( 8/19 43 ; 11/19 49 ) . GPT-4 received highest readability score ( 17/19 55 ) followed GPT-3 ( 15/19 53 ) RetA model ( 11/19 47 ) . Prometheus underperformed accuracy ( 34 ) relevance ( 32 ) readability ( 38 ) . Both GPT-3.5 GPT-4 hallucination 19 response compared RetA model Prometheus . Hallucinations mostly associated non-existent reference fabricated efficacy data . These finding suggest RetA model supplemented domain-specific corpus may outperform general-purpose LLMs accuracy relevance within specific domain . However evaluation limited specific question metric may capture challenge semantic search NLP task . Further research explore different LLM architecture RetA methodology evaluation method assess strength limitation comprehensively .
Over year datasets developed various object detection task . Object detection maritime domain essential safety navigation ship . However still lack publicly available large-scale datasets maritime domain . To overcome challenge present KOLOMVERSE open large-scale image dataset object detection maritime domain KRISO ( Korea Research Institute Ships Ocean Engineering ) . We collected 5845 hour video data captured 21 territorial water South Korea . Through elaborate data quality assessment process gathered around 2151470 4K resolution image video data . This dataset considers various environment : weather time illumination occlusion viewpoint background wind speed visibility . The KOLOMVERSE consists five class ( ship buoy fishnet buoy lighthouse wind farm ) maritime object detection . The dataset image 3840 $ \times $ 2160 pixel knowledge far largest publicly available dataset object detection maritime domain . We performed object detection experiment evaluated dataset several pre-trained state-of-the-art architecture show effectiveness usefulness dataset . The dataset available : \url { http : //github.com/MaritimeDataset/KOLOMVERSE } .
Uncertainty quantification important task machine learning - task standardneural network ( NNs ) traditionally excelled . This limitation safety-critical application uncertainty-aware method like Gaussian process Bayesian linear regression often preferred . Bayesian neural network approach address limitation . They assume probability distribution parameter yield distributed prediction . However training inference typically intractable approximation must employed . A promising approximation NNs Bayesian last layer ( BLL ) . They assume distributed weight linear output layer yield normally distributed prediction . To approximate intractable Bayesian neural network point estimate distributed weight last layer obtained maximizing marginal likelihood . This previously challenging marginal likelihood expensive evaluate setting . We present reformulation log-marginal likelihood NN BLL allows efficient training using backpropagation . Furthermore address challenge uncertainty quantification extrapolation point . We provide metric quantify degree extrapolation derive method improve uncertainty quantification point . Our method derived multivariate case demonstrated simulation study . In comparison Bayesian linear regression fixed feature Bayesian neural network trained variational inference proposed method achieves highest log-predictive density test data .
Student mobility academic mobility involves student moving institution post-secondary education one challenging task process assess transfer credit offered incoming student . In general process involves domain expert comparing learning outcome course decide offering transfer credit incoming student . This manual implementation labor-intensive also influenced undue bias administrative complexity . The proposed research article focus identifying model exploit advancement field Natural Language Processing ( NLP ) effectively automate process . Given unique structure domain specificity complexity learning outcome ( LOs ) need designing tailor-made model arises . The proposed model us clustering-inspired methodology based knowledge-based semantic similarity measure assess taxonomic similarity LOs transformer-based semantic similarity model assess semantic similarity LOs . The similarity LOs aggregated form course course similarity . Due lack quality benchmark datasets new benchmark dataset containing seven course-to-course similarity measure proposed . Understanding inherent need flexibility decision-making process aggregation part model offer tunable parameter accommodate different scenario . While providing efficient model assess similarity course existing resource research work steer future research attempt apply NLP field articulation ideal direction highlighting persisting research gap .
Motor imagery ( MI ) based brain-computer interface ( BCIs ) enable direct control external device imagined movement various body part . Unlike previous system used fixed-length EEG trial MI decoding asynchronous BCIs aim detect user 's MI without explicit trigger . They challenging implement algorithm need first distinguish resting-states MI trial classify MI trial correct task without trigger . This paper proposes sliding window prescreening classification ( SWPC ) approach MI-based asynchronous BCIs consists two module : prescreening module screen MI trial resting-state classification module MI classification . Both module trained supervised learning followed self-supervised learning refines feature extractor . Within-subject cross-subject asynchronous MI classification four different EEG datasets validated effectiveness SWPC i.e . always achieved highest average classification accuracy outperformed best state-of-the-art baseline dataset 2 % .
Recent advance deep learning method natural language processing ( NLP ) created new business opportunity made NLP research critical industry development . As one big player field NLP together government university important track influence industry research . In study seek quantify characterize industry presence NLP community time . Using corpus comprehensive metadata 78187 NLP publication 701 resume NLP publication author explore industry presence field since early 90 . We find industry presence among NLP author steady steep increase past five year ( 180 % growth 2017 2022 ) . A company account publication provide funding academic researcher grant internship . Our study show presence impact industry natural language processing research significant fast-growing . This work call increased transparency industry influence field .
We propose adapt segmentation network constrained formulation embeds domain-invariant prior knowledge segmentation region . Such knowledge may take form simple anatomical information e.g . structure size shape estimated source sample known priori . Our method imposes domain-invariant inequality constraint network output unlabeled target sample . It implicitly match prediction statistic target source domain permitted uncertainty prior knowledge . We address constrained problem differentiable penalty fully suited standard stochastic gradient descent approach removing need computationally expensive Lagrangian optimization dual projection . Unlike current two-step adversarial training formulation based single loss single network simplifies adaptation avoiding extra adversarial step improving convergence quality training . The comparison approach state-of-the-art adversarial method reveals substantially better performance challenging task adapting spine segmentation across different MRI modality . Our result also show robustness imprecision size prior approaching accuracy fully supervised model trained directly target domain.Our method readily used various constraint segmentation problem .
With increased focus visual attention ( VA ) last decade large number computational visual saliency method developed past year . These model traditionally evaluated using performance evaluation metric quantify match predicted saliency fixation data obtained eye-tracking experiment human observer . Though considerable number metric proposed literature notable problem . In work discus shortcoming existing metric illustrative example propose new metric us local weight based fixation density overcomes flaw . To compare performance proposed metric assessing quality saliency prediction existing metric construct ground-truth subjective database saliency map obtained 17 different VA model evaluated 16 human observer 5-point categorical scale term visual resemblance corresponding ground-truth fixation density map obtained eye-tracking data . The metric evaluated correlating metric score human subjective rating . The correlation result show proposed evaluation metric outperforms popular existing metric . Additionally constructed database corresponding subjective rating provide insight existing metric future metric better estimating quality saliency prediction used benchmark .
This paper proposes reconfigurable model recognize detect multiclass ( multiview ) object large variation appearance . Compared well acknowledged hierarchical model study two advanced capability hierarchy object modeling : ( ) `` switch `` variable ( i.e . or-nodes ) specifying alternative composition ( ii ) making local classifier ( i.e . leaf-nodes ) shared among different class . These capability enable u account well structural variability preserving model compact . Our model form And-Or Graph comprises four layer : batch leaf-nodes collaborative edge bottom localizing object part ; or-nodes bottom activate child leaf-nodes ; and-nodes classify object whole ; one root-node top switching multiclass classification also or-node . For model training present EM-type algorithm namely dynamical structural optimization ( DSO ) iteratively determine structural configuration ( e.g . leaf-node generation associated parent or-nodes shared across class ) along optimizing multi-layer parameter . The proposed method valid challenging database e.g . PASCAL VOC 2007 UIUC-People achieves state-of-the-arts performance .
In many application domain medicine information retrieval cybersecurity social medium etc . datasets used inducing classification model often unequal distribution instance class . This situation known imbalanced data classification cause low predictive performance minority class example . Thus prediction model unreliable although overall model accuracy acceptable . Oversampling undersampling technique well-known strategy deal problem balancing number example class . However effectiveness depends several factor mainly related data intrinsic characteristic imbalance ratio dataset size dimensionality overlapping class borderline example . In work impact factor analyzed comprehensive comparative study involving 40 datasets different application area . The objective obtain model automatic selection best resampling strategy dataset based characteristic . These model allow u check several factor simultaneously considering wide range value since induced varied datasets cover broad spectrum condition . This differs study focus individual analysis characteristic cover small range value . In addition study encompasses basic advanced resampling strategy evaluated mean eight different performance metric including new measure specifically designed imbalanced data classification . The general nature proposal allows choice appropriate method regardless domain avoiding search special purpose technique could valid target data .
Most Machine Learning research evaluates best solution term performance . However race best performing model many important aspect often overlooked contrary carefully considered . In fact sometimes gap performance different approach neglectable whereas factor production cost energy consumption carbon footprint must take consideration . Large Language Models ( LLMs ) extensively adopted address NLP problem academia industry . In work present detailed quantitative comparison LLM traditional approach ( e.g . SVM ) LexGLUE benchmark take account performance ( standard index ) alternative metric timing power consumption cost word : carbon-footprint . In analysis considered prototyping phase ( model selection training-validation-test iteration ) in-production phase separately since follow different implementation procedure also require different resource . The result indicate often simplest algorithm achieve performance close large LLMs low power consumption lower resource demand . The result obtained could suggest company include additional evaluation choice Machine Learning ( ML ) solution .
Denoising diffusion probabilistic model currently becoming leading paradigm generative modeling many important data modality . Being prevalent computer vision community diffusion model also recently gained attention domain including speech NLP graph-like data . In work investigate framework diffusion model advantageous general tabular problem datapoints typically represented vector heterogeneous feature . The inherent heterogeneity tabular data make quite challenging accurate modeling since individual feature completely different nature i.e . continuous discrete . To address data type introduce TabDDPM -- diffusion model universally applied tabular dataset handle type feature . We extensively evaluate TabDDPM wide set benchmark demonstrate superiority existing GAN/VAE alternative consistent advantage diffusion model field . Additionally show TabDDPM eligible privacy-oriented setup original datapoints publicly shared .
While long short-term memory ( LSTM ) model demonstrated stellar performance streamflow prediction major risk applying model contiguous region gauge prediction ungauged region ( PUR ) problem . However softer data flow duration curve ( FDC ) may already available nearby station may become available . Here demonstrate sparse FDC data migrated assimilated LSTM-based network via encoder . A stringent region-based holdout test showed median Kling-Gupta efficiency ( KGE ) 0.62 US dataset substantially higher previous state-of-the-art global-scale ungauged basin test . The baseline model without FDC already competitive ( median KGE 0.56 ) integrating FDCs substantial value . Because inaccurate representation input baseline model might sometimes produce catastrophic result . However model generalizability meaningfully improved compiling ensemble based model different input selection .
Deep neural network good success record thus viewed best architecture choice complex application . Their main shortcoming long time vanishing gradient prevented numerical optimization algorithm acceptable convergence . A breakthrough achieved concept residual connection -- identity mapping parallel conventional layer . This concept applicable stack layer dimension substantially alleviates vanishing gradient problem . A stack residual connection layer expressed expansion term similar Taylor expansion . This expansion suggests possibility truncating higher-order term receiving architecture consisting single broad layer composed initially stacked layer parallel . In word sequential deep architecture substituted parallel shallow one . Prompted theory investigated performance capability parallel architecture comparison sequential one . The computer vision datasets MNIST CIFAR10 used train architecture total 6912 combination varying number convolutional layer number filter kernel size meta parameter . Our finding demonstrate surprising equivalence deep ( sequential ) shallow ( parallel ) architecture . Both layout produced similar result term training validation set loss . This discovery implies wide shallow architecture potentially replace deep network without sacrificing performance . Such substitution potential simplify network architecture improve optimization efficiency accelerate training process .
With leap machine learning technique applicationon Earth observation challenge unlocked unprecedented performance across domain . While development method previously limited availability volume sensor data computing resource lack adequate reference data constituting new bottleneck . Since creating ground-truth information expensive error-prone task new way must devised source reliable high-quality reference data large scale . As example showcase E URO C ROPS reference dataset crop type classification aggregate harmonizes administrative data surveyed different country goal transnational interoperability .
Sentiment Analysis currently vital area research . With advancement use internet creation social medium website blog opinion rating etc . increased rapidly . People express feedback emotion social medium post form like dislike comment etc . The rapid growth volume viewer-generated user-generated data content YouTube led increase YouTube sentiment analysis . Due analyzing public reaction become essential need information extraction data visualization technical domain . This research predicts YouTube Ad view sentiment using Deep Learning Machine Learning algorithm like Linear Regression ( LR ) Support Vector Machine ( SVM ) Decision Tree ( DT ) Random Forest ( RF ) Artificial Neural Network ( ANN ) . Finally comparative analysis done based experimental result acquired different model .
Data clustering received lot attention numerous method algorithm software package available . Among technique parametric finite-mixture model play central role due interesting mathematical property existence maximum-likelihood estimator based expectation-maximization ( EM ) . In paper propose new mixture model associate weight observed point . We introduce weighted-data Gaussian mixture derive two EM algorithm . The first one considers fixed weight observation . The second one treat weight random variable following gamma distribution . We propose model selection method based minimum message length criterion provide weight initialization strategy validate proposed algorithm comparing several state art parametric non-parametric clustering technique . We also demonstrate effectiveness robustness proposed clustering technique presence heterogeneous data namely audio-visual scene analysis .
The use Deep Learning ( DL ) algorithm improved performance vision-based space application recent year . However generating large amount annotated data training DL algorithm proven challenging . While synthetically generated image used DL model trained synthetic data often susceptible performance degradation tested real-world environment . In context Interdisciplinary Center Security Reliability Trust ( SnT ) University Luxembourg developed 'SnT Zero-G Lab ' training validating vision-based space algorithm condition emulating real-world space environment . An important aspect SnT Zero-G Lab development equipment selection . From lesson learned lab development article present systematic approach combining market survey experimental analysis equipment selection . In particular article focus image acquisition equipment space lab : background material camera illumination lamp . The result experiment analysis show market survey complimented experimental analysis required effective equipment selection space lab development project .
We present medical crowdsourcing visual analytics platform called C { $ ^2 $ } A visualize classify filter crowdsourced clinical data . More specifically C $ ^2 $ A used build consensus clinical diagnosis visualizing crowd response filtering anomalous activity . Crowdsourcing medical application recently shown promise non-expert user ( crowd ) able achieve accuracy similar medical expert . This potential reduce interpretation/reading time possibly improve accuracy building consensus finding beforehand letting medical expert make final diagnosis . In paper focus virtual colonoscopy ( VC ) application clinical technician target user radiologist acting consultant classifying segment benign malignant . In particular C $ ^2 $ A used analyze explore crowd response video segment created fly-throughs virtual colon . C $ ^2 $ A provides several interactive visualization component build crowd consensus video segment detect anomaly crowd data VC video segment finally improve non-expert user 's work quality performance A/B testing optimal crowdsourcing platform application-specific parameter . Case study domain expert feedback demonstrate effectiveness framework improving worker ' output quality potential reduce radiologist ' interpretation time hence potential improve traditional clinical workflow marking majority video segment benign based crowd consensus .
Thermal signal explored HCI emotion-elicitation enhancing two-person communication showing temperature invokes social emotional signal individual . Yet extending finding group communication missing . We investigated thermal signal used communicate group affective state hybrid meeting scenario help people feel connected distance . We conducted lab study ( N=20 participant ) explored wrist-worn thermal feedback communicate audience emotion . Our result show thermal feedback effective method conveying audience engagement without increasing workload help presenter feel tune audience . We outline design implication real-world wearable social thermal feedback system virtual in-person communication support group affect communication social connectedness . Thermal feedback potential connect people across distance facilitate effective dynamic communication multiple context .
With ever increasing size web relevant information extraction Internet query formed keywords become big challenge . Query Expansion ( QE ) play crucial role improving search Internet . Here user 's initial query reformulated adding additional meaningful term similar significance . QE -- part information retrieval ( IR ) -- long attracted researcher ' attention . It become influential field personalized social document question answering cross-language IR information filtering multimedia IR . Research QE gained prominence IR dedicated conference TREC ( Text Information Retrieval Conference ) CLEF ( Conference Labs Evaluation Forum ) . This paper survey QE technique IR 1960 2017 respect core technique data source used weighting ranking methodology user participation application -- bringing similarity difference .
Tensor completion recovers multi-dimensional array limited number measurement . Using recently proposed tensor ring ( TR ) decomposition paper show d-order tensor dimensional size n TR rank r exactly recovered high probability solving convex optimization program given n^ { d/2 } r^2 ln^7 ( n^ { d/2 } ) sample . The proposed TR incoherence condition result hold similar matrix incoherence condition . The experiment synthetic data verify recovery guarantee TR completion . Moreover experiment real-world data show method improves recovery performance compared state-of-the-art method .
After tremendous development neural network trained backpropagation good time develop algorithm training neural network gain insight network . In paper propose new algorithm training feedforward neural network fairly faster backpropagation . This method based projection reconstruction every layer projected data reconstructed label forced similar weight tuned accordingly layer layer . The proposed algorithm used input feature space named backprojection kernel backprojection respectively . This algorithm give insight network projection-based perspective . The experiment synthetic datasets show effectiveness proposed method .
Attention model widely used Vision-language ( V-L ) task perform visual-textual correlation . Humans perform correlation strong linguistic understanding visual world . However even best performing attention model V-L task lack high-level linguistic understanding thus creating semantic gap modality . In paper propose attention mechanism - Linguistically-aware Attention ( LAT ) - leverage object attribute obtained generic object detector along pre-trained language model reduce semantic gap . LAT represents visual textual modality common linguistically-rich space thus providing linguistic awareness attention process . We apply demonstrate effectiveness LAT three V-L task : Counting-VQA VQA Image captioning . In Counting-VQA propose novel counting-specific VQA model predict intuitive count achieve state-of-the-art result five datasets . In VQA Captioning show generic nature effectiveness LAT adapting various baseline consistently improving performance .
Long-term availability mineral industrial material necessary condition sustainable development constituent manufacturing product . To enhance efficiency material management define computer-vision-enabled material measurement system provide review work relevant development particular emphasis foundation . A network system wide-area material stock monitoring also covered . Finally challenge future research direction discussed . As first article bridging industrial ecology advanced computer vision review intended support research community towards sustainable manufacturing .
We propose novel neural architecture search algorithm via reinforcement learning decoupling structure operation search process . Our approach sample candidate model multinomial distribution policy vector defined two search space independently . The proposed technique improves efficiency architecture search process significantly compared conventional method based reinforcement learning RNN controller achieving competitive accuracy model size target task . Our policy vector easily interpretable throughout training procedure allows analyze search progress discovered architecture ; black-box characteristic RNN controller hamper understanding training progress term policy parameter update . Our experiment demonstrate outstanding performance compared state-of-the-art method fraction search cost .
Jitter inevitable by-product gaze detection . Because gaze typing tends slow frustrating process . In paper propose SliceType soft keyboard optimized gaze input . Our main design objective use screen area efficiently allocating larger area target key . We achieve determining key used next input allocating space adjacent key merging animation . Larger key faster navigate towards easy dwell presence eye tracking jitter . As result user type faster comfortably . In addition employ word completion scheme complement gaze typing mechanic . A character related prediction displayed key . Dwelling key enters character double-dwelling enters prediction . While dwelling key enter character user read related prediction effortlessly . The improvement provided feature quantified using Fitts ' law . The performance proposed keyboard compared two soft keyboard designed gaze typing Dasher GazeTalk . 37 novice user gaze-typed piece text using three keyboard . The result experiment show proposed keyboard allows faster typing preferred user .
Recent research established possibility deducing soft-biometric attribute age gender race individual 's face image high accuracy . However raise privacy concern especially face image collected biometric recognition purpose used attribute analysis without person 's consent . To address problem develop technique imparting soft biometric privacy face image via image perturbation methodology . The image perturbation undertaken using GAN-based Semi-Adversarial Network ( SAN ) - referred PrivacyNet - modifies input face image used face matcher matching purpose reliably used attribute classifier . Further PrivacyNet allows person choose specific attribute obfuscated input face image ( e.g . age race ) allowing type attribute extracted ( e.g . gender ) . Extensive experiment using multiple face matcher multiple age/gender/race classifier multiple face datasets demonstrate generalizability proposed multi-attribute privacy enhancing method across multiple face attribute classifier .
Convolutional sparse representation form sparse representation dictionary structure equivalent convolution set linear filter . While effective algorithm recently developed convolutional sparse coding problem corresponding dictionary learning problem substantially challenging . Furthermore although number different approach proposed absence thorough comparison make difficult determine represents current state art . The present work address deficiency proposes new approach outperform existing one certain context . A thorough set performance comparison indicates wide range performance difference among existing proposed method clearly identifies effective .
With system acquiring 3D surface data evermore commonplace become important reliably extract specific shape acquired data . In presence noise occlusion done use statistical shape model learned database clean example shape question . In paper review analyze compare different statistical model : analyze variation geometry globally analyze variation geometry locally . We first review different type model used literature proceed define model analyze theoretically term statistical computational aspect . We perform extensive experimental comparison task model fitting give intuition type model better application . Due wide availability database high-quality data use human face specific shape wish extract corrupted data .
Most current multi-object tracker focus short-term tracking based deep complex system often operate real-time making impractical video-surveillance . In paper present long-term multi-face tracking architecture conceived working crowded context face often visible part person . Our system benefit advance field face detection face recognition achieve long-term tracking particularly unconstrained motion occlusion people . It follows tracking-by-detection approach combining fast short-term visual tracker novel online tracklet reconnection strategy grounded rank-based face verification . The proposed rank-based constraint favour higher inter-class distance among tracklets reduces propagation error due wrong reconnections . Additionally correction module included correct past assignment extra computational cost . We present series experiment introducing novel specialized metric evaluation long-term tracking capability publicly release video dataset 10 manually annotated video total length 8 ' 54 `` . Our finding validate robustness proposed module demonstrate challenging context approach yield 50 % longer track state-of-the-art deep learning tracker .
Using evolutionary computation algorithm solve multiple task knowledge sharing promising approach . Image feature learning considered multitask problem different task may similar feature space . Genetic programming ( GP ) successfully applied image feature learning classification . However existing GP method solve one task independently using sufficient training data . No multitask GP method developed image feature learning . Therefore paper develops multitask GP approach image feature learning classification limited training data . Owing flexible representation GP new knowledge sharing mechanism based new individual representation developed allow GP automatically learn share across two task improve learning performance . The shared knowledge encoded common tree represent common/general feature two task . With new individual representation task solved using feature extracted common tree task-specific tree representing task-specific feature . To learn best common task-specific tree new evolutionary process new fitness function developed . The performance proposed approach examined six multitask problem 12 image classification datasets limited training data compared three GP 14 non-GP-based competitive method . Experimental result show new approach outperforms compared method almost comparison . Further analysis reveals new approach learns simple yet effective common tree high effectiveness transferability .
We study expressive power deep ReLU neural network approximating function dilated shift-invariant space widely used signal processing image processing communication . Approximation error bound estimated respect width depth neural network . The network construction based bit extraction data-fitting capacity deep neural network . As application main result approximation rate classical function space Sobolev space Besov space obtained . We also give lower bound $ L^p ( 1\le p \le \infty ) $ approximation error Sobolev space show construction neural network asymptotically optimal logarithmic factor .
Gated recurrent unit ( GRUs ) specialized memory element building recurrent neural network . Despite incredible success various task including extracting dynamic underlying neural data little understood specific dynamic representable GRU network . As result difficult know priori successful GRU network perform given task also capacity mimic underlying behavior biological counterpart . Using continuous time analysis gain intuition inner working GRU network . We restrict presentation low dimension allowing comprehensive visualization . We found surprisingly rich repertoire dynamical feature includes stable limit cycle ( nonlinear oscillation ) multi-stable dynamic various topology homoclinic bifurcation . At time unable train GRU network produce continuous attractor hypothesized exist biological neural network . We contextualize usefulness different kind observed dynamic support claim experimentally .
Saliency integration attracted much attention unifying saliency map multiple saliency model . Previous offline integration method usually face two challenge : 1. candidate saliency model misjudge saliency image integration result lean heavily inferior candidate model ; 2. unawareness ground truth saliency label brings difficulty estimating expertise candidate model . To address problem paper propose arbitrator model ( AM ) saliency integration . Firstly incorporate consensus multiple saliency model external knowledge reference map effectively rectify misleading candidate model . Secondly quest way estimating expertise saliency model without ground truth label give rise two distinct online model-expertise estimation method . Finally derive Bayesian integration framework reconcile saliency model varying expertise reference map . To extensively evaluate proposed AM model test twenty-seven state-of-the-art saliency model covering traditional deep learning one various combination four datasets . The evaluation result show AM model improves performance substantially compared existing state-of-the-art integration method regardless chosen candidate saliency model .
We exploring design implementation artificial expression kinetic audio-visual representation real-time physiological data reflect emotional cognitive state . In work demonstrate prototype Enactive Mandala map real-time EEG signal modulate ambient music animated visual music . Transparent real-time audio-visual feedback brainwave quality support intuitive insight connection thought physiological state .
Multi-scale architecture attention module shown effectiveness many deep learning-based image de-raining method . However manually designing integrating two component neural network requires bulk labor extensive expertise . In article high-performance multi-scale attentive neural architecture search ( MANAS ) framework technically developed image deraining . The proposed method formulates new multi-scale attention search space multiple flexible module favorite image de-raining task . Under search space multi-scale attentive cell built used construct powerful image de-raining network . The internal multiscale attentive architecture de-raining network searched automatically gradient-based search algorithm avoids daunting procedure manual design extent . Moreover order obtain robust image de-raining model practical effective multi-to-one training strategy also presented allow de-raining network get sufficient background information multiple rainy image background scene meanwhile multiple loss function including external loss internal loss architecture regularization loss model complexity loss jointly optimized achieve robust de-raining performance controllable model complexity . Extensive experimental result synthetic realistic rainy image well down-stream vision application ( i.e . objection detection segmentation ) consistently demonstrate superiority proposed method . The code publicly available http : //github.com/lcai-gz/MANAS .
In many research area scientific progress accelerated multidisciplinary access image data interdisciplinary annotation . However keeping track annotation ensure high-quality multi-purpose data set challenging labour intensive task . We developed open-source online platform EXACT ( EXpert Algorithm Collaboration Tool ) enables collaborative interdisciplinary analysis image different domain online offline . EXACT support multi-gigapixel medical whole slide image well image series thousand image . The software utilises flexible plugin system adapted diverse application counting mitotic figure screening mode finding false annotation novel validation view using latest deep learning image analysis technology . This combined version control system make possible keep track change data set example link result deep learning experiment specific data set version . EXACT freely available already successfully applied broad range annotation task including highly diverse application like deep learning supported cytology scoring interdisciplinary multi-centre whole slide image tumour annotation highly specialised whale sound spectroscopy clustering .
This paper proposes supervised classification algorithm capable continual learning utilizing Adaptive Resonance Theory ( ART ) -based growing self-organizing clustering algorithm . The ART-based clustering algorithm theoretically capable continual learning proposed algorithm independently applies class training data generating classifier . Whenever additional training data set new class given new ART-based clustering defined different learning space . Thanks above-mentioned feature proposed algorithm realizes continual learning capability . Simulation experiment showed proposed algorithm superior classification performance compared state-of-the-art clustering-based classification algorithm capable continual learning .
In discounted reward Markov Decision Process ( MDP ) objective find optimal value function i.e . value function corresponding optimal policy . This problem reduces solving functional equation known Bellman equation fixed point iteration scheme known value iteration utilized obtain solution . In literature successive over-relaxation based value iteration scheme proposed speed-up computation optimal value function . The speed-up achieved constructing modified Bellman equation ensures faster convergence optimal value function . However many practical application model information known resort Reinforcement Learning ( RL ) algorithm obtain optimal policy value function . One popular algorithm Q-learning . In paper propose Successive Over-Relaxation ( SOR ) Q-learning . We first derive modified fixed point iteration SOR Q-values utilize stochastic approximation derive learning algorithm compute optimal value function optimal policy . We prove almost sure convergence SOR Q-learning SOR Q-values . Finally numerical experiment show SOR Q-learning faster compared standard Q-learning algorithm .
Nowadays ubiquitous usage mobile device network raised concern loss control personal data research advance towards trade-off privacy utility scenario combine exchange communication big database distributed collaborative ( P2P ) Machine Learning technique . On hand although Federated Learning ( FL ) provides level privacy retaining data local node executes local training enrich global model scenario still susceptible privacy breach membership inference attack . To provide stronger level privacy research deploys experimental environment FL Differential Privacy ( DP ) using benchmark datasets . The obtained result show election parameter technique DP central aforementioned trade-off privacy utility mean classification example .
For Pretrained Language Models ( PLMs ) susceptibility noise recently linked subword segmentation . However unclear aspect segmentation affect understanding . This study assesses robustness PLMs various disrupted segmentation caused noise . An evaluation framework subword segmentation named Contrastive Lexical Semantic ( CoLeS ) probe proposed . It provides systematic categorization segmentation corruption noise evaluation protocol generating contrastive datasets canonical-noisy word pair . Experimental result indicate PLMs unable accurately compute word meaning noise introduces completely different subwords small subword fragment large number additional subwords particularly inserted within subwords .
Recommendation system crucial importance variety modern apps web service news feed social network e-commerce search etc . To achieve peak prediction accuracy modern recommendation model combine deep learning terabyte-scale embedding table obtain fine-grained representation underlying data . Traditional inference serving architecture require deploying whole model standalone server infeasible massive scale . In paper provide insight intriguing challenging inference domain online recommendation system . We propose HugeCTR Hierarchical Parameter Server ( HPS ) industry-leading distributed recommendation inference framework combine high-performance GPU embedding cache hierarchical storage architecture realize low-latency retrieval embeddings online model inference task . Among thing HPS feature ( 1 ) redundant hierarchical storage system ( 2 ) novel high-bandwidth cache accelerate parallel embedding lookup NVIDIA GPUs ( 3 ) online training support ( 4 ) light-weight APIs easy integration existing large-scale recommendation workflow . To demonstrate capability conduct extensive study using synthetically engineered public datasets . We show HPS dramatically reduce end-to-end inference latency achieving 5~62x speedup ( depending batch size ) CPU baseline implementation popular recommendation model . Through multi-GPU concurrent deployment HPS also greatly increase inference QPS .
This paper present key aspect trade-off designer Human-Computer Interaction practitioner might encounter designing multimodal interaction older adult . The paper gather literature multimodal interaction assistive technology describes set design challenge specific older user . Building main design challenge four trade-off design multimodal technology target group presented discussed . To highlight relevance trade-off design process multimodal technology older adult two four reported trade-off illustrated two user study explored mid-air speech-based interaction tablet device . The first study investigates design trade-off related redundant multimodal command older middle-aged younger adult whereas second one investigates design choice related definition set mid-air one-hand gesture voice input command . Further reflection highlight design trade-off consideration bring process presenting overview design choice involved potential consequence .
In paper investigate moving object detected image impacted atmospheric turbulence . We present geometric spatio-temporal point view problem show possible distinguish movement due turbulence vs. moving object . To perform task propose extension 2D cartoon+texture decomposition algorithm 3D vector field . Our algorithm based curvelet space permit better characterize movement flow geometry . We present experiment real data illustrate efficiency proposed method .
In paper propose movie genre recommendation system based imbalanced survey data unequal classification cost small medium-sized enterprise ( SMEs ) need data-based analytical approach stock favored movie target marketing young people . The dataset maintains detailed personal profile predictor including demographic behavioral preference information user well imbalanced genre preference . These predictor include information actor director . The paper applies Gentle boost Adaboost Bagged tree ensemble well SVM machine learning algorithm learn classification one thousand observation predict movie genre preference adjusted classification cost . The proposed recommendation system also selects important predictor avoid overfitting shorten training time . This paper compare test error among above-mentioned algorithm used recommend different movie genre . The prediction power also indicated comparison precision recall state-of-the-art recommendation system . The proposed movie genre recommendation system solves problem small dataset imbalanced response unequal classification cost .
At present time Optical Coherence Tomography ( OCT ) among commonly used non-invasive imaging method acquisition large volumetric scan human retinal tissue vasculature . To resolve decisive information extracted OCT volume make applicable diagnostic analysis exact identification retinal layer thickness serf essential task done patient separately . However manual examination multiple OCT scan row demanding time consuming task result lengthy qualification process frequently confounded presence tissue-dependent speckle noise . Therefore elaboration automated segmentation model become important task field medical image processing . We propose novel purely data driven \textit { geometric approach order-constrained 3D OCT retinal cell layer segmentation } take input data metric space come along basic operation effectively computed parallel . As opposed many established retina detection method presented formulation avoids use shape prior accomplishes natural order retina purely geometric way . This make approach unbiased hence suited detection local anatomical change retinal tissue structure . To demonstrate robustness proposed approach compare two different choice feature data set manually annotated 3D OCT volume healthy human retina . The quality computed segmentation compared state art term mean absolute error Dice similarity coefficient . The result indicate great potential applying method classification diseased retina open new research direction regarding joint segmentation retinal cell layer blood vessel structure .
This paper present approach estimating continuous 6-DoF pose object single RGB image . The approach combine semantic keypoints predicted convolutional network ( convnet ) deformable shape model . Unlike prior investigator agnostic whether object textured textureless convnet learns optimal representation available training-image data . Furthermore approach applied instance- class-based pose recovery . Additionally accompany main pipeline technique semi-automatic data generation unlabeled video . This procedure allows u train learnable component method minimal manual intervention labeling process . Empirically show approach accurately recover 6-DoF object pose instance- class-based scenario even cluttered background . We apply approach several existing large-scale datasets - including PASCAL3D+ LineMOD-Occluded YCB-Video TUD-Light - using labeling pipeline new dataset novel object class introduce . Extensive empirical evaluation show approach able provide pose estimation result comparable state art .
Autonomous perception requires high-quality environment sensing form 3D bounding box dynamic object . The primary sensor used automotive system light-based camera LiDARs . However known fail adverse weather condition . Radars potentially solve problem barely affected adverse weather condition . However specular reflection wireless signal cause poor performance radar point cloud . We introduce Pointillism system combine data multiple spatially separated radar optimal separation mitigate problem . We introduce novel concept Cross Potential Point Clouds us spatial diversity induced multiple radar solves problem noise sparsity radar point cloud . Furthermore present design RP-net novel deep learning architecture designed explicitly radar 's sparse data distribution enable accurate 3D bounding box estimation . The spatial technique designed proposed paper fundamental radar point cloud distribution would benefit radar sensing application .
Confidence region prediction practically useful extension commonly studied pattern recognition problem . Instead predicting single label constraint relaxed allow prediction subset label given desired confidence level 1-delta . Ideally effective region prediction ( 1 ) well calibrated - predictive region confidence level 1-delta err relative frequency delta ( 2 ) narrow ( certain ) possible . We present simple technique generate confidence region prediction conditional probability estimate ( probability forecast ) . We use 'conversion ' technique generate confidence region prediction probability forecast output standard machine learning algorithm tested 15 multi-class datasets . Our result show approximately 44 % experiment demonstrate well-calibrated confidence region prediction K-Nearest Neighbour algorithm tending perform consistently well across data . Our result illustrate practical benefit effective confidence region prediction respect medical diagnostics guarantee capturing true disease label given .
The detection similar pattern time series commonly called motif received continuous increasing attention diverse scientific community . In particular recent approach discovering similar motif different length proposed . In work show variable-length similarity-based motif directly compared hence ranked normalized dissimilarity . Specifically find length-normalized motif dissimilarity still intrinsic dependency motif length lowest dissimilarity particularly affected dependency . Moreover find dependency generally non-linear change considered data set dissimilarity measure . Based finding propose solution rank motif measure significance . This solution relies compact accurate model dissimilarity space using beta distribution three parameter depend motif length non-linear way . We believe incomparability variable-length dissimilarity could go beyond field time series similar modeling strategy one used could help broad context .
We present novel approach data-driven modeling time-domain induced polarization ( IP ) phenomenon using variational autoencoders ( VAE ) . VAEs Bayesian neural network aim learn latent statistical distribution encode extensive data set lower dimension representation . We collected 1 600 319 IP decay curve various region Canada United States Kazakhstan compiled train deep VAE . The proposed deep learning approach strictly unsupervised data-driven : require manual processing ground truth labeling IP data . Moreover VAE approach avoids pitfall IP parametrization empirical Cole-Cole Debye decomposition model simple power-law model sophisticated mechanistic model . We demonstrate four application VAEs model process IP data : ( 1 ) representative synthetic data generation ( 2 ) unsupervised Bayesian denoising data uncertainty estimation ( 3 ) quantitative evaluation signal-to-noise ratio ( 4 ) automated outlier detection . We also interpret IP compilation 's latent representation reveal strong correlation first dimension average chargeability IP decay . Finally experiment varying VAE latent space dimension demonstrate single real-valued scalar parameter contains sufficient information encode extensive IP data compilation . This new finding suggests modeling time-domain IP data using mathematical model governed one free parameter ambiguous whereas modeling average chargeability justified . A pre-trained implementation model -- readily applicable new IP data geolocation -- available open-source Python code applied geophysics community .
Despite improvement perception accuracy brought via deep learning developing system combining accurate visual perception ability reason visual percept remains extremely challenging . A particular application area interest accessibility perspective reasoning statistical chart bar pie chart . To end formulate problem reasoning statistical chart classification task using MAC-Networks give answer predefined vocabulary generic answer . Additionally enhance capability MAC-Networks give chart-specific answer open-ended question replacing classification layer regression layer localize textual answer present image . We call network ChartNet demonstrate efficacy predicting vocabulary vocabulary answer . To test method generated dataset statistical chart image corresponding question answer pair . Results show ChartNet consistently outperform state-of-the-art method reasoning question may viable candidate application containing image statistical chart .
In last year various type machine learning algorithm Support Vector Machine ( SVM ) Support Vector Regression ( SVR ) Non-negative Matrix Factorization ( NMF ) introduced . The kernel approach effective method increasing classification accuracy machine learning algorithm . This paper introduces family one-parameter kernel function improving accuracy SVM classification . The proposed kernel function consists trigonometric term differs existing kernel function . We show function positive definite kernel function . Finally evaluate SVM method based new trigonometric kernel Gaussian kernel polynomial kernel convex combination new kernel function Gaussian kernel function various type datasets . Empirical result show SVM based new trigonometric kernel function mixed kernel function achieve best classification accuracy . Moreover numerical result performing SVR based new trigonometric kernel function mixed kernel function presented .
We examine prosodic entrainment cooperative game dialog new feature set describing register pitch accent shape rhythmic aspect utterance . For well established feature present entrainment profile detect within- across-dialog entrainment speaker ' gender role game . It turned feature set undergo entrainment different quantitative qualitative way partly attributed different function . Furthermore interaction speaker gender role ( describer vs. follower ) suggest gender-dependent strategy cooperative solution-oriented interaction : female describers entrain male describers least . Our data suggests slight advantage latter strategy task success .
The emergence single-chip polarized color sensor allows simultaneously capturing chromatic polarimetric information scene monochromatic image plane . However unlike usual camera embedded demosaicing method latest polarized color camera delivered in-built demosaicing tool . For demosaicing user down-sample captured image use traditional interpolation technique . Neither perform well since polarization color interdependent . Therefore joint chromatic polarimetric demosaicing key obtaining high-quality polarized color image . In paper propose joint chromatic polarimetric demosaicing model address challenging problem . Instead mechanically demosaicing multi-channel polarized color image present sparse representation-based optimization strategy utilizes chromatic information polarimetric information jointly optimize model . To avoid interaction color polarization demosaicing separately construct corresponding dictionary . We also build optical data acquisition system collect dataset contains various source polarization illumination reflectance birefringence . Results qualitative quantitative experiment shown method capable faithfully recovering full RGB information four polarization angle pixel single mosaic input image . Moreover proposed method perform well synthetic data real captured data .
Non-negative Matrix Factorisation ( NMF ) extensively used machine learning data analytics application . Most existing variation NMF consider row/column vector factorised matrix shaped ignore relationship among pairwise row column . In many case pairwise relationship enables better factorisation example image clustering recommender system . In paper propose algorithm named Relative Pairwise Relationship constrained Non-negative Matrix Factorisation ( RPR-NMF ) place constraint relative pairwise distance amongst feature imposing penalty triplet form . Two distance measure squared Euclidean distance Symmetric divergence used exponential hinge loss penalty adopted two measure respectively . It well known so-called `` multiplicative update rule `` result much faster convergence gradient descend matrix factorisation . However applying update rule RPR-NMF also proving convergence straightforward . Thus use reasonable approximation relax complexity brought penalty practically verified . Experiments synthetic datasets real datasets demonstrate algorithm advantage gaining close approximation satisfying high proportion expected constraint achieving superior performance compared algorithm .
Long Short-Term Memory Networks ( LSTMs ) applied daily discharge prediction remarkable success . Many practical scenario however require prediction granular timescales . For instance accurate prediction short extreme flood peak make life-saving difference yet peak may escape coarse temporal resolution daily prediction . Naively training LSTM hourly data however entail long input sequence make learning hard computationally expensive . In study propose two Multi-Timescale LSTM ( MTS-LSTM ) architecture jointly predict multiple timescales within one model process long-past input single temporal resolution branch individual timescale recent input step . We test model 516 basin across continental United States benchmark US National Water Model . Compared naive prediction distinct LSTM per timescale multi-timescale architecture computationally efficient loss accuracy . Beyond prediction quality multi-timescale LSTM process different input variable different timescales especially relevant operational application lead time meteorological forcings depends temporal resolution .
Federated learning ( FL ) received significant attention recent year advantage efficient training machine learning model across distributed client without disclosing user-sensitive data . Specifically federated edge learning ( FEEL ) system time-varying nature wireless channel introduces inevitable system dynamic communication process thereby affecting training latency energy consumption . In work consider streaming data scenario new training data sample randomly generated time edge device . Our goal develop dynamic scheduling resource allocation algorithm address inherent randomness data arrival resource availability long-term energy constraint . To achieve formulate stochastic network optimization problem use Lyapunov drift-plus-penalty framework obtain dynamic resource management design . Our proposed algorithm make adaptive decision device scheduling computational capacity adjustment allocation bandwidth transmit power every round . We provide convergence analysis considered setting heterogeneous data time-varying objective function support rationale behind proposed scheduling design . The effectiveness scheme verified simulation result demonstrating improved learning performance energy efficiency compared baseline scheme .
Recent advancement area deep learning shown effectiveness large neural network several application . However deep neural network continue grow size becomes difficult configure many parameter obtain good result . Presently analyst must experiment many different configuration parameter setting labor-intensive time-consuming . On hand capacity fully automated technique neural network architecture search limited without domain knowledge human expert . To deal problem formulate task neural network architecture optimization graph space exploration based one-shot architecture search technique . In approach super-graph candidate architecture trained one-shot optimal neural network identified sub-graph . In paper present framework allows analyst effectively build solution sub-graph space guide network search injecting domain knowledge . Starting network architecture space composed basic neural network component analyst empowered effectively select promising component via one-shot search scheme . Applying technique iterative manner allows analyst converge best performing neural network architecture given application . During exploration analyst use domain knowledge aided cue provided scatterplot visualization search space edit different component guide search faster convergence . We designed interface collaboration several deep learning researcher final effectiveness evaluated user study two case study .
Human speech processing inherently multimodal visual cue ( lip movement ) help better understand speech noise . Lip-reading driven speech enhancement significantly outperforms benchmark audio-only approach low signal-to-noise ratio ( SNRs ) . However high SNRs low level background noise visual cue become fairly less effective speech enhancement . Therefore optimal context-aware audio-visual ( AV ) system required contextually utilises visual noisy audio feature effectively account different noisy condition . In paper introduce novel contextual AV switching component contextually exploit AV cue respect different operating condition estimate clean audio without requiring SNR estimation . The switching module switch visual-only ( V-only ) audio-only ( A-only ) AV cue low high moderate SNR level respectively . The contextual AV switching component developed integrating convolutional neural network long-short-term memory network . For testing estimated clean audio feature utilised developed novel enhanced visually derived Wiener filter clean audio power spectrum estimation . The contextual AV speech enhancement method evaluated real-world scenario using benchmark Grid ChiME3 corpus . For objective testing perceptual evaluation speech quality used evaluate quality restored speech . For subjective testing standard mean-opinion-score method used . The critical analysis comparative study demonstrate outperformance proposed contextual AV approach A-only V-only spectral subtraction log-minimum mean square error based speech enhancement method low high SNRs revealing capability tackle spectro-temporal variation real-world noisy condition .
Performing real-time accurate instrument segmentation video great significance improving performance robotic-assisted surgery . We identify two important clue surgical instrument perception including local temporal dependency adjacent frame global semantic correlation long-range duration . However existing work perform segmentation purely using visual cue single frame . Optical flow used model motion two frame brings heavy computational cost . We propose novel dual-memory network ( DMNet ) wisely relate global local spatio-temporal knowledge augment current feature boosting segmentation performance retaining real-time prediction capability . We propose one hand efficient local memory taking complementary advantage convolutional LSTM non-local mechanism towards relating reception field . On hand develop active global memory gather global semantic correlation long temporal range current one gather informative frame derived model uncertainty frame similarity . We extensively validated method two public benchmark surgical video datasets . Experimental result demonstrate method largely outperforms state-of-the-art work segmentation accuracy maintaining real-time speed .
Virtual reality ( VR ) rapidly growing potential change way create consume content . In VR user integrate multimodal sensory information receive create unified perception virtual world . In survey review body work addressing multimodality VR role benefit user experience together different application leverage multimodality many discipline . These work thus encompass several field research demonstrate multimodality play fundamental role VR ; enhancing experience improving overall performance yielding unprecedented ability skill knowledge transfer .
Graph clustering process grouping vertex densely connected set called cluster . We tailor two mathematical programming formulation literature problem . In obtain heuristic approximation intra-cluster density maximization problem . We use two variation Boltzmann machine heuristic obtain numerical solution . For benchmarking purpose compare solution quality computational performance obtained using commercial solver Gurobi . We also compare clustering quality cluster obtained using popular Louvain modularity maximization method . Our initial result clearly demonstrate superiority problem formulation . They also establish superiority Boltzmann machine traditional exact solver . In case smaller less complex graph Boltzmann machine provide solution Gurobi solution time order magnitude lower . In case larger complex graph Gurobi fails return meaningful result within reasonable time frame . Finally also note clustering formulation distance minimization $ K $ -medoids yield cluster superior quality obtained Louvain algorithm .
Globally distributed group require collaborative system support work . Besides able support teamwork system also promote well-being maximize human potential lead engaging system joyful experience . Designing system significant challenge requires thorough understanding group work . We used field theory lens view essential aspect group motivation utilized collaboration persona analyze element group work . We integrated well-being determinant engagement factor develop group-centered framework digital collaboration global setting . Based outcome proposed conceptual framework design engaging collaborative system recommend system value used evaluate system
Manifold ranking successfully applied query-oriented multi-document summarization . It make use relationship among sentence also relationship given query sentence . However information original query often insufficient . So present query expansion method combined manifold ranking resolve problem . Our method utilizes information query term knowledge base WordNet expand synonym also us information document set expand query various way ( mean expansion variance expansion TextRank expansion ) . Compared previous query expansion method method combine multiple query expansion method better represent query information time make useful attempt manifold ranking . In addition use degree word overlap proximity word calculate similarity sentence . We performed experiment datasets DUC 2006 DUC2007 evaluation result show proposed query expansion method significantly improve system performance make system comparable state-of-the-art system .
Feature selection powerful dimension reduction technique selects subset relevant feature model construction . Numerous feature selection method proposed fail high-dimensional low-sample size ( HDLSS ) setting due challenge overfitting . In paper present deep learning-based method - GRAph Convolutional nEtwork feature Selector ( GRACES ) - select important feature HDLSS data . We demonstrate empirical evidence GRACES outperforms feature selection method synthetic real-world datasets .
Motor imagery ( MI ) classical paradigm electroencephalogram ( EEG ) based brain-computer interface ( BCIs ) . Online accurate fast decoding important successful application . This paper proposes simple yet effective front-end replication dynamic window ( FRDW ) algorithm purpose . Dynamic window enable classification based test EEG trial shorter used training improving decision speed ; front-end replication fill short test EEG trial length used training improving classification accuracy . Within-subject cross-subject online MI classification experiment three public datasets three different classifier three different data augmentation approach demonstrated FRDW significantly increase information transfer rate MI decoding . Additionally FR also used training data augmentation . FRDW helped win national champion China BCI Competition 2022 .
Human pose transfer ( HPT ) emerging research topic huge potential fashion design medium production online advertising virtual reality . For application visual realism fine-grained appearance detail crucial production quality user engagement . However existing HPT method often suffer three fundamental issue : detail deficiency content ambiguity style inconsistency severely degrade visual quality realism generated image . Aiming towards real-world application develop challenging yet practical HPT setting termed Fine-grained Human Pose Transfer ( FHPT ) higher focus semantic fidelity detail replenishment . Concretely analyze potential design flaw existing method via illustrative example establish core FHPT methodology combing idea content synthesis feature transfer together mutually-guided fashion . Thereafter substantiate proposed methodology Detail Replenishing Network ( DRN ) corresponding coarse-to-fine model training scheme . Moreover build complete suite fine-grained evaluation protocol address challenge FHPT comprehensive manner including semantic analysis structural detection perceptual quality assessment . Extensive experiment DeepFashion benchmark dataset verified power proposed benchmark start-of-the-art work 12\ % -14\ % gain top-10 retrieval recall 5\ % higher joint localization accuracy near 40\ % gain face identity preservation . Moreover evaluation result offer insight subject matter could inspire many promising future work along direction .
Retrieving video particular person face image query via hashing technique many important application . While face image typically represented vector Euclidean space characterizing face video robust set modeling technique ( e.g . covariance matrix exploited study reside Riemannian manifold ) recently shown appealing advantage . This hence result thorny heterogeneous space matching problem . Moreover hashing handcrafted feature done many existing work clearly inadequate achieve desirable performance task . To address problem present end-to-end Deep Heterogeneous Hashing ( DHH ) method integrates three stage including image feature learning video modeling heterogeneous hashing single framework learn unified binary code face image video . To tackle key challenge hashing manifold well-studied Riemannian kernel mapping employed project data ( i.e . covariance matrix ) Euclidean space thus enables embed two heterogeneous representation common Hamming space intra-space discriminability inter-space compatibility considered . To perform network optimization gradient kernel mapping innovatively derived via structured matrix backpropagation theoretically principled way . Experiments three challenging datasets show method achieves quite competitive performance compared existing hashing method .
Information retrieval system retrieves relevant document based query submitted user . The document initially indexed word document assigned weight using weighting technique called TFIDF product Term Frequency ( TF ) Inverse Document Frequency ( IDF ) . TF represents number occurrence term document . IDF measure whether term common rare across document . It computed dividing total number document system number document containing term computing logarithm quotient . By default use base 10 calculate logarithm . In paper going test weighting technique using range log base 0.1 100.0 calculate IDF . Testing different log base vector model weighting technique highlight importance understanding performance system different weighting value . We use document MED CRAN NPL LISA CISI test collection scientist assembled explicitly experiment data information retrieval system .
Radial correction distortion applied in-camera out-camera software/firmware alters supporting grid image hamper PRNU-based camera attribution . Existing solution deal problem try invert/estimate correction using radial transformation parameterized variable order restrain computational load ; however ever prevalent complex distortion correction performance unsatisfactory . In paper propose adaptive algorithm dividing image concentric annulus able deal sophisticated correction like applied out-camera third party software like Adobe Lightroom Photoshop Gimp PT-Lens . We also introduce statistic called cumulative peak correlation energy ( CPCE ) allows efficient early stopping strategy . Experiments large dataset in-camera out-camera radially corrected image show solution improves state art term accuracy computational cost .
African language still lag advance Natural Language Processing technique one reason lack representative data technique transfer information language help mitigate lack data problem . This paper train Setswana Sepedi monolingual word vector us VecMap create cross-lingual embeddings Setswana-Sepedi order cross-lingual transfer . Word embeddings word vector represent word continuous floating number semantically similar word mapped nearby point n-dimensional space . The idea word embeddings based distribution hypothesis state semantically similar word distributed similar context ( Harris 1954 ) . Cross-lingual embeddings leverage monolingual embeddings learning shared vector space two separately trained monolingual vector word similar meaning represented similar vector . In paper investigate cross-lingual embeddings Setswana-Sepedi monolingual word vector . We use unsupervised cross lingual embeddings VecMap train Setswana-Sepedi cross-language word embeddings . We evaluate quality Setswana-Sepedi cross-lingual word representation using semantic evaluation task . For semantic similarity task translated WordSim SimLex task Setswana Sepedi . We release dataset part work researcher . We evaluate intrinsic quality embeddings determine improvement semantic representation word embeddings .
In paper survey method concept developed evaluation dialogue system . Evaluation crucial part development process . Often dialogue system evaluated mean human evaluation questionnaire . However tends cost time intensive . Thus much work put finding method allow reduce involvement human labour . In survey present main concept method . For differentiate various class dialogue system ( task-oriented dialogue system conversational dialogue system question-answering dialogue system ) . We cover class introducing main technology developed dialogue system presenting evaluation method regarding class .
Knowledge Graphs ( KGs ) serving semantic network prove highly effective managing complex interconnected data different domain offering unified contextualized structured representation flexibility allows easy adaptation evolving knowledge . Processing complex Human Resources ( HR ) data KGs help different HR function like recruitment job matching identifying learning gap enhancing employee retention . Despite potential limited effort made implement practical HR knowledge graph . This study address gap presenting framework effectively developing HR knowledge graph document using Large Language Models . The resulting KG used variety downstream task including job matching identifying employee skill gap many . In work showcase instance HR KGs prove instrumental precise job matching yielding advantage employer employee . Empirical evidence experiment information propagation KGs Graph Neural Nets along case study underscore effectiveness KGs task job employee recommendation job area classification . Code data available : http : //github.com/azminewasi/HRGraph
Large-scale training semantic segmentation challenging due expense obtaining training data task relative vision task . We propose novel training approach address difficulty . Given cheaply-obtained sparse image labelings propagate sparse label produce guessed dense labelings . A standard CNN-based segmentation network trained mimic labelings . The label-propagation process defined via random-walk hitting probability lead differentiable parameterization uncertainty estimate incorporated loss . We show learning label-propagator jointly segmentation predictor able effectively learn semantic edge given direct edge supervision . Experiments also show training segmentation network way outperforms naive approach .
With novel fast advance area deep neural network several challenging image-based task recently approached researcher pattern recognition computer vision . In paper address one task match image content natural language description sometimes referred multimodal content retrieval . Such task particularly challenging considering must find semantic correspondence caption respective image challenge computer vision natural language processing area . For propose novel multimodal approach based solely convolutional neural network aligning image caption directly convolving raw character . Our proposed character-based textual embeddings allow replacement word-embeddings recurrent neural network text understanding saving processing time requiring fewer learnable parameter . Our method based idea projecting visual textual information common embedding space . For training embeddings optimize contrastive loss function computed minimize order-violations image respective description . We achieve state-of-the-art performance largest well-known image-text alignment dataset namely Microsoft COCO method conceptually much simpler possesses considerably fewer parameter current approach .
Image Super Resolution ( SR ) find application area image need closely inspected observer extract enhanced information . One focused application offline forensic analysis surveillance feed . Due limitation camera hardware camera pose limited bandwidth varying illumination condition occlusion quality surveillance feed significantly degraded time thereby compromising monitoring behavior activity sporadic information scene . For proposed research work inspected effectiveness four conventional yet effective SR algorithm three deep learning-based SR algorithm seek finest method executes well surveillance environment limited training data op-tions . These algorithm generate enhanced resolution output image sin-gle low-resolution ( LR ) input image . For performance analysis subset 220 image six surveillance datasets used consisting individual varying distance camera changing illumination condition complex background . The performance algorithm evaluated compared using qualitative quantitative metric . These SR algo-rithms also compared based face detection accuracy . By analyzing comparing performance algorithm Convolutional Neural Network ( CNN ) based SR technique using external dictionary proved best achieving robust face detection accuracy scoring optimal quantitative metric result different surveillance condition . This CNN layer progressively learn complex feature using external dictionary .
The maximum entropy principle largely used thresholding segmentation image . Among several formulation principle effectively applied based Tsallis non-extensive entropy . Here discus role entropic index determining threshold . When index spanning interval ( 01 ) image value threshold large leap . In manner observe abrupt transition appearance corresponding bi-level multi-level image . These gray-level image transition analogous order texture transition observed physical system transition driven temperature physical quantity .
Twin Support Vector Machines ( TWSVMs ) emerged efficient alternative Support Vector Machines ( SVM ) learning imbalanced datasets . The TWSVM learns two non-parallel classifying hyperplanes solving couple smaller sized problem . However unsuitable large datasets involves matrix operation . In paper discus Twin Neural Network ( Twin NN ) architecture learning large unbalanced datasets . The Twin NN also learns optimal feature map allowing better discrimination class . We also present extension network architecture multiclass datasets . Results presented paper demonstrate Twin NN generalizes well scale well large unbalanced datasets .
Machine learning expected fuel significant improvement medical care . To ensure fundamental principle beneficence respect human autonomy prevention harm justice privacy transparency respected medical machine learning system must developed responsibly . Many high-level declaration ethical principle put forth purpose severe lack technical guideline explicating practical consequence medical machine learning . Similarly currently considerable uncertainty regarding exact regulatory requirement placed upon medical machine learning system . This survey provides overview technical procedural challenge involved creating medical machine learning system responsibly conformity existing regulation well possible solution address challenge . First brief review existing regulation affecting medical machine learning provided showing property safety robustness reliability privacy security transparency explainability nondiscrimination demanded already existing law regulation - albeit many case uncertain degree . Next key technical obstacle achieving desirable property discussed well important technique overcome obstacle medical context . We notice distribution shift spurious correlation model underspecification uncertainty quantification data scarcity represent severe challenge medical context . Promising solution approach include use large representative datasets federated learning mean end careful exploitation domain knowledge use inherently transparent model comprehensive out-of-distribution model testing verification well algorithmic impact assessment .
TOTTA outline spatial position rotation guidance real/virtual tool ( TO ) towards real/virtual target ( TA ) key task Mixed Reality application . The task error critical consequence regarding safety performance quality surgical implantology industrial maintenance scenario . The TOTTA problem lack dedicated study scattered across different domain isolated design . This work contributes systematic review TOTTA visual widget studying 70 unique design 24 paper . TOTTA commonly guided visual overlap intuitive pre-attentive 'collimation ' feedback simple-shaped widget : Box 3D Axes 3D Model 2D Crosshair Globe Tetrahedron Line Plane . Our research discovers TO TA often represented shape . They distinguished topological element ( e.g . edge vertex face ) color transparency level added shape widget quantity size . Meanwhile design provide continuous 'during manipulation feedback ' relative distance TO TA text dynamic color sonification amplified graphical visualization . Some approach trigger discrete 'TA reached feedback ' color alteration added sound TA shape change added text . We found lack golden standard including testing procedure current one limited partial set different incomparable setup ( different target configuration avatar background etc . ) . We also found bias participant : right-handed young male non-color impaired .
We introduce novel technique associated high resolution dataset aim precisely evaluate wireless signal based indoor positioning algorithm . The technique implement augmented reality ( AR ) based positioning system used annotate wireless signal parameter data sample high precision position data . We track position practical low cost navigable setup camera Bluetooth Low Energy ( BLE ) beacon area decorated AR marker . We maximize performance AR-based localization using redundant number marker . Video stream captured camera subjected series marker recognition subset selection filtering operation yield highly precise pose estimation . Our result show reduce positional error AR localization system rate 0.05 meter . The position data used annotate BLE data captured simultaneously sensor stationed environment hence constructing wireless signal data set ground truth allows wireless signal based localization system evaluated accurately .
It longstanding goal computer vision describe 3D physical space term parameterized volumetric model would allow autonomous machine understand interact surroundings . Such model typically motivated human visual perception aim represents element physical word ranging individual object complex scene using small set parameter . One de facto stadards approach problem superquadrics - volumetric model define various 3D shape primitive fitted actual 3D data ( either form point cloud range image ) . However existing solution superquadric recovery involve costly iterative fitting procedure limit applicability technique practice . To alleviate problem explore paper possibility recover superquadrics range image without time consuming iterative parameter estimation technique using contemporary deep-learning model specifically convolutional neural network ( CNNs ) . We pose superquadric recovery problem regression task develop CNN regressor able estimate parameter superquadric model given range image . We train regressor large set synthetic range image containing single ( unrotated ) superquadric shape evaluate learned model comparaitve experiment current state-of-the-art . Additionally also present qualitative analysis involving dataset real-world object . The result experiment show proposed regressor outperforms existing state-of-the-art also ensures 270x faster execution time .
Diabetic Retinopathy medical condition retina damaged fluid leak blood vessel retina . The presence hemorrhage retina earliest symptom diabetic retinopathy . The number shape hemorrhage used indicate severity disease . Early automated hemorrhage detection help reduce incidence blindness . This paper introduced new method depending hemorrhage shape detect dot hemorrhage ( DH ) number size early stage achieved reducing retinal image detail . Detection recognize DH following three sequential step removing fovea removing vasculature recognize DH determining circularity object image finally determine shape factor related DH recognition stage strengthens recognition process . The proposed method recognizes separate DH .
Knot diagram among common visual tool topology . Computer program make possible draw manipulate render digitally prof useful knot theory teaching research . Still openly available tool manipulate knot diagram real-time interactive way yet developed . We introduce method operating geometry knot diagram without underlying three-dimensional structure underpin application . This allows u directly interact vector graphic knot diagram time computing knot invariant way proposed previous work . An implementation method provided .
Session-based recommendation ( SBR ) challenging task aim recommending item based anonymous behavior sequence . Almost existing solution SBR model user preference based current session without exploiting session may contain relevant irrelevant item-transitions current session . This paper proposes novel approach called Global Context Enhanced Graph Neural Networks ( GCE-GNN ) exploit item transition session subtle manner better inferring user preference current session . Specifically GCE-GNN learns two level item embeddings session graph global graph respectively : ( ) Session graph learn session-level item embedding modeling pairwise item-transitions within current session ; ( ii ) Global graph learn global-level item embedding modeling pairwise item-transitions session . In GCE-GNN propose novel global-level item representation learning layer employ session-aware attention mechanism recursively incorporate neighbor ' embeddings node global graph . We also design session-level item representation learning layer employ GNN session graph learn session-level item embeddings within current session . Moreover GCE-GNN aggregate learnt item representation two level soft attention mechanism . Experiments three benchmark datasets demonstrate GCE-GNN outperforms state-of-the-art method consistently .
As part SMILK Joint Lab studied use Natural Language Processing : ( 1 ) enrich knowledge base link data web conversely ( 2 ) use linked data contribute improvement text analysis annotation textual content support knowledge extraction . The evaluation focused brand-related information retrieval field cosmetic . This article describes step approach : creation ProVoc ontology describe product brand ; automatic population knowledge base mainly based ProVoc heterogeneous textual resource ; evaluation application take form browser plugin providing additional knowledge user browsing web .
Support Vector Machines ( SVMs ) primarily designed 2-class classification . But extended N-class classification also based requirement multiclasses practical application . Although N-class classification using SVM considerable research attention getting minimum number classifier time training testing still continuing research . We propose new algorithm CBTS-SVM ( Centroid based Binary Tree Structured SVM ) address issue . In build binary tree SVM model based similarity class label finding distance corresponding centroid root level . The experimental result demonstrates comparable accuracy CBTS OVO reasonable gamma cost value . On hand CBTS compared OVA give better accuracy reduced training time testing time . Furthermore CBTS also scalable able handle large data set .
Transformer-based NLP model trained using hundred million even billion parameter limiting applicability computationally constrained environment . While number parameter generally correlate performance clear whether entire network required downstream task . Motivated recent work pruning distilling pre-trained model explore strategy drop layer pre-trained model observe effect pruning downstream GLUE task . We able prune BERT RoBERTa XLNet model 40 % maintaining 98 % original performance . Additionally show pruned model par built using knowledge distillation term size performance . Our experiment yield interesting observation ( ) lower layer critical maintain downstream task performance ( ii ) task paraphrase detection sentence similarity robust dropping layer ( iii ) model trained using different objective function exhibit different learning pattern w.r.t layer dropping .
The problem reducing Hidden Markov Model ( HMM ) one smaller dimension exactly reproduces marginals tackled using system-theoretic approach . Realization theory tool extended HMMs leveraging suitable algebraic representation probability space . We propose two algorithm return coarse-grained equivalent HMMs obtained stochastic projection operator : first return model exactly reproduce single-time distribution given output process second full ( multi-time ) distribution preserved . The reduction method exploit structure observed output also initial condition whenever latter known belongs given subclass . Optimal algorithm derived class HMM namely observable one .
Traditional human-in-the-loop-based annotation time-series data like inertial data often requires access alternate modality like video audio environment . These alternate source provide necessary information human annotator raw numeric data often obfuscated even expert . However traditional approach many concern surrounding overall cost efficiency storage additional modality time scalability privacy . Interestingly recent large language model ( LLMs ) also trained vast amount publicly available alphanumeric data allows comprehend perform well task beyond natural language processing . Naturally open potential avenue explore LLMs virtual annotator LLMs directly provided raw sensor data annotation instead relying alternate modality . Naturally could mitigate problem traditional human-in-the-loop approach . Motivated observation perform detailed study paper assess whether state-of-the-art ( SOTA ) LLMs used virtual annotator labeling time-series physical sensing data . To perform principled manner segregate study two major phase . In first phase investigate challenge LLM like GPT-4 face comprehending raw sensor data . Considering observation phase 1 next phase investigate possibility encoding raw sensor data using SOTA SSL approach utilizing projected time-series data get annotation LLM . Detailed evaluation four benchmark HAR datasets show SSL-based encoding metric-based guidance allow LLM make reasonable decision provide accurate annotation without requiring computationally expensive fine-tuning sophisticated prompt engineering .
Hundreds popular mobile apps today market tie mindfulness . What activity apps support benefit claim ? How mindfulness teacher domain expert view apps ? We first conduct exploratory review 370 mindfulness-related apps Google Play finding mindfulness presented primarily tool relaxation stress reduction . We interviewed 15 U.S. mindfulness teacher therapeutic Buddhist Yogic tradition perspective apps . Teachers expressed concern apps introduce mindfulness tool relaxation neglect full potential . We draw upon experience teacher suggest design implication linking mindfulness contemplative practice like cultivation compassion . Our finding speak importance coherence design : metaphor mechanism technology align underlying principle follows .
Generative model inferential autoencoders mostly make use $ \ell_2 $ norm optimization objective . In order generate perceptually better image short paper theoretically discusses use Structural Similarity Index ( SSIM ) generative model inferential autoencoders . We first review SSIM SSIM distance metric SSIM kernel . We show SSIM kernel universal kernel thus used unconditional conditional generated moment matching network . Then explain use SSIM distance variational adversarial autoencoders unconditional conditional Generative Adversarial Networks ( GANs ) . Finally propose use SSIM distance rather $ \ell_2 $ norm least square GAN .
Integrating knowledge across different domain essential feature human learning . Learning paradigm transfer learning meta-learning multi-task learning reflect human learning process exploiting prior knowledge new task encouraging faster learning good generalization new task . This article give detailed view learning paradigm comparative analysis . The weakness one learning algorithm turn strength another thus merging prevalent trait literature . Numerous research paper focus learning paradigm separately provide comprehensive overview . However article review research study combine ( two ) learning algorithm . This survey describes technique combined solve problem many different field research including computer vision natural language processing hyper-spectral imaging many supervised setting . Based knowledge accumulated literature hypothesize generic task-agnostic model-agnostic learning network - ensemble meta-learning transfer learning multi-task learning termed Multi-modal Multi-task Meta Transfer Learning . We also present open research question limitation future research direction proposed network . The aim article spark interest among scholar effectively merging existing learning algorithm intention advancing research field . Instead presenting experimental result invite reader explore contemplate technique merging algorithm navigating limitation .
This paper introduces device algorithm graphical user interface obtain anthropometric measurement foot . Presented device facilitates obtaining scale image image processing taking one image side foot underfoot simultaneously . Introduced image processing algorithm minimizes noise criterion suitable object detection single object image outperforms famous image thresholding method lighting condition poor . Performance image-based method compared manual method . Image-based measurement underfoot average 4mm less actual measure . Mean absolute error underfoot length 1.6mm however length obtained side foot 4.4mm mean absolute error . Furthermore based t-test f-test result significant difference manual image-based anthropometry observed . In order maintain anthropometry process performance different situation user interface designed handling change light condition altering speed algorithm .
Biometric signature verification traditionally performed pen-based office-like scenario using device specifically designed acquiring handwriting . However high deployment device smartphones tablet given rise new thriving scenario signature biometrics handwriting performed using pen stylus also finger via touch interaction . Some preliminary study highlighted challenge new scenario necessity research topic . The main contribution work propose new on-line signature verification architecture adapted signature complexity order tackle new challenging scenario . Additionally exhaustive comparative analysis pen- touch-based scenario using proposed methodology carried along review relevant recent study field . Significant improvement biometric verification performance practical insight extracted application signature verification real scenario .
Sharing live telepresence experience teleconferencing remote collaboration receives increasing interest recent progress capturing AR/VR technology . Whereas impressive telepresence system proposed top on-the-fly scene capture data transmission visualization system restricted immersion single low number user respective scenario . In paper direct attention immersing significantly larger group people live-captured scene required education entertainment collaboration scenario . For purpose rather abandoning previous approach present range optimization involved reconstruction streaming component allow immersion group 24 user within scene - factor 6 higher previous work - without introducing latency changing involved consumer hardware setup . We demonstrate optimized system capable generating high-quality scene reconstruction well providing immersive viewing experience large group people within live-captured scene .
The article explores new way written language aided AI technology like GPT-2 GPT-3 . The question stated paper whether novel technology eventually replace authored book relate contextualize publication kind new tool process idea behind . For purpose new concept synthetic book introduced article . It stand publication created deploying AI technology precisely autoregressive language model able generate human-like text . Supported case study value reasoning synthetic book discussed . The paper emphasizes artistic quality issue come AI-generated content . The article introduces project demonstrate interactive input artist and/or audience combined deep-learning-based language model . In end paper focus understanding neural aesthetic written language art context .
Temperature monitoring life time heat source component engineering system becomes essential guarantee normal work working life component . However prior method mainly use interpolate estimation reconstruct temperature field limited monitoring point require large amount temperature tensor accurate estimation . This may decrease availability reliability system sharply increase monitoring cost . To solve problem work develops novel physics-informed deep reversible regression model temperature field reconstruction heat-source system ( TFR-HSS ) better reconstruct temperature field limited monitoring point unsupervisedly . First define TFR-HSS task mathematically numerically model task hence transform task image-to-image regression problem . Then work develops deep reversible regression model better learn physical information especially boundary . Finally considering physical characteristic heat conduction well boundary condition work proposes physics-informed reconstruction loss including four training loss jointly learns deep surrogate model loss unsupervisedly . Experimental study conducted typical two-dimensional heat-source system demonstrate effectiveness proposed method .
Research investigating cognitive aspect information system often dependent detail-rich data . Eye-trackers promise provide respective data associated cost often beyond researcher ' budget . Recently eye-trackers entered market promise eye-tracking support reasonable price . In work explore whether eye-trackers use information system research explore accuracy low-cost eye-tracker ( Gazepoint GP3 ) empirical study . The result show Gazepoint GP3 well suited respective research given experimental material acknowledges limit eye-tracker . To foster replication comparison result data experimental material well source code developed study made available online .
Shadow detection general photo nontrivial problem due complexity real world . Though recent shadow detector already achieved remarkable performance various benchmark data performance still limited general real-world situation . In work collected shadow image multiple scenario compiled new dataset 10500 shadow image labeled ground-truth mask supporting shadow detection complex world . Our dataset cover rich variety scene category diverse shadow size location contrast type . Further comprehensively analyze complexity dataset present fast shadow detection network detail enhancement module harvest shadow detail demonstrate effectiveness method detect shadow general situation .
The present paper show solution problem automatic distress detection precisely detection hole paved road . To proposed solution us weightless neural network known Wisard decide whether image road kind crack . In addition proposed architecture also show use transfer learning able improve overall accuracy decision system . As verification step research experiment carried using image street Federal University Tocantins Brazil . The architecture developed solution present result 85.71 % accuracy dataset proving superior approach state-of-the-art .
While recent advance deep learning significantly advanced state art vessel detection color fundus ( CF ) image success detecting vessel fluorescein angiography ( FA ) stymied due lack labeled ground truth datasets . We propose novel pipeline detect retinal vessel FA image using deep neural network reduces effort required generating labeled ground truth data combining two key component : cross-modality transfer human-in-the-loop learning . The cross-modality transfer exploit concurrently captured CF fundus FA image . Binary vessel map first detected CF image pre-trained neural network geometrically registered transferred FA image via robust parametric chamfer alignment preliminary FA vessel detection obtained unsupervised technique . Using transferred vessel initial ground truth label deep learning human-in-the-loop approach progressively improves quality ground truth labeling iterating deep-learning labeling . The approach significantly reduces manual labeling effort increasing engagement . We highlight several important consideration proposed methodology validate performance three datasets . Experimental result demonstrate proposed pipeline significantly reduces annotation effort resulting deep learning method outperform prior existing FA vessel detection method significant margin . A new public dataset RECOVERY-FA19 introduced includes high-resolution ultra-widefield image accurately labeled ground truth binary vessel map .
Time series classification ( TSC ) home number algorithm group utilise different kind discriminatory pattern . One group describes classifier predict using phase dependant interval . The time series forest ( TSF ) classifier one well known interval method demonstrated strong performance well relative speed training prediction . However recent advance approach left TSF behind . TSF originally summarises interval using three simple summary statistic . The ` catch22 ' feature set 22 time series feature recently proposed aid time series analysis concise set diverse informative descriptive characteristic . We propose combining TSF catch22 form new classifier Canonical Interval Forest ( CIF ) . We outline additional enhancement training procedure extend classifier include multivariate classification capability . We demonstrate large significant improvement accuracy TSF catch22 show par top performer algorithmic class . By upgrading interval-based component TSF CIF also demonstrate significant improvement hierarchical vote collective transformation-based ensemble ( HIVE-COTE ) combine different time series representation . HIVE-COTE using CIF significantly accurate UCR archive classifier aware represents new state art TSC .
Time-sync comment reveal new way extracting online video tag . However time-sync comment lot noise due user ' diverse comment introducing great challenge accurate fast video tag extraction . In paper propose unsupervised video tag extraction algorithm named Semantic Weight-Inverse Document Frequency ( SW-IDF ) . Specifically first generate corresponding semantic association graph ( SAG ) using semantic similarity timestamps time-sync comment . Second propose two graph cluster algorithm i.e . dialogue-based algorithm topic center-based algorithm deal video different density comment . Third design graph iteration algorithm assign weight comment based degree clustered subgraphs differentiate meaningful comment noise . Finally gain weight word combining Semantic Weight ( SW ) Inverse Document Frequency ( IDF ) . In way video tag extracted automatically unsupervised way . Extensive experiment shown SW-IDF ( dialogue-based algorithm ) achieves 0.4210 F1-score 0.4932 MAP ( Mean Average Precision ) high-density comment 0.4267 F1-score 0.3623 MAP low-density comment ; SW-IDF ( topic center-based algorithm ) achieves 0.4444 F1-score 0.5122 MAP high-density comment 0.4207 F1-score 0.3522 MAP low-density comment . It better performance state-of-the-art unsupervised algorithm F1-score MAP .
Small device frequently used IoT smart-city application perform periodic dedicated task soft deadline . This work focus developing method derive efficient power-management method periodic task small device . We first study limitation existing Linux built-in method used small device . We illustrate three typical workload/system pattern challenging manage Linux 's built-in solution . We develop reinforcement-learning-based technique temporal encoding derive effective DVFS governor even presence three system pattern . The derived governor us one performance counter built-in Linux mechanism require explicit task model workload . We implemented prototype system Nvidia Jetson Nano Board experimented six application including two self-designed four benchmark application . Under different deadline constraint approach quickly derive DVFS governor adapt performance requirement outperform built-in Linux approach energy saving . On Mibench workload performance slack ranging 0.04 0.4 proposed method save 3 % - 11 % energy compared Ondemand . AudioReg FaceReg application tested 5 % - 14 % energy-saving improvement . We open-sourced implementation in-kernel quantized neural network engine . The codebase found : http : //github.com/coladog/tinyagent .
The spread Coronavirus disease-2019 epidemic caused many course exam conducted online . The cheating behavior detection model examination invigilation system play pivotal role guaranteeing equality long-distance examination . However cheating behavior rare researcher comprehensively take account feature head posture gaze angle body posture background information task cheating behavior detection . In paper develop present CHEESE CHEating detection framework via multiplE inStancE learning . The framework consists label generator implement weak supervision feature encoder learn discriminative feature . In addition framework combine body posture background feature extracted 3D convolution eye gaze head posture facial feature captured OpenFace 2.0 . These feature fed spatio-temporal graph module stitching analyze spatio-temporal change video clip detect cheating behavior . Our experiment three datasets UCF-Crime ShanghaiTech Online Exam Proctoring ( OEP ) prove effectiveness method compared state-of-the-art approach obtain frame-level AUC score 87.58 % OEP dataset .
In paper perform exhaustive evaluation different representation address intent classification problem Spoken Language Understanding ( SLU ) setup . We benchmark three type system perform SLU intent detection task : 1 ) text-based 2 ) lattice-based novel 3 ) multimodal approach . Our work provides comprehensive analysis could achievable performance different state-of-the-art SLU system different circumstance e.g . automatically- vs. manually-generated transcript . We evaluate system publicly available SLURP spoken language resource corpus . Our result indicate using richer form Automatic Speech Recognition ( ASR ) output namely word-consensus-networks allows SLU system improve comparison 1-best setup ( 5.5 % relative improvement ) . However crossmodal approach i.e . learning acoustic text embeddings obtains performance similar oracle setup relative improvement 17.8 % 1-best configuration recommended alternative overcome limitation working automatically generated transcript .
In contrast standard closed-set domain adaptation task partial domain adaptation setup caters realistic scenario relaxing identical label set assumption . The fact source label set subsuming target label set however introduces additional obstacle training private source category sample thwart relevant knowledge transfer mislead classification process . To mitigate issue devise mechanism strategic selection highly-confident target sample essential estimation class-importance weight . Furthermore capture class-discriminative domain-invariant feature coupling process achieving compact distinct class distribution adversarial objective . Experimental finding numerous cross-domain classification task demonstrate potential proposed technique deliver superior comparable accuracy existing method .
Visualizing large matrix involves many formidable problem . Various popular solution problem involve sampling clustering projection feature selection reduce size complexity original task . An important aspect method preserve relative distance point higher-dimensional space reducing row column fit lower dimensional space . This aspect important conclusion based faulty visual reasoning harmful . Judging dissimilar point similar similar point dissimilar basis visualization lead false conclusion . To ameliorate bias make visualization large datasets feasible introduce two new algorithm respectively select subset row column rectangular matrix . This selection designed preserve relative distance closely possible . We compare matrix sketch traditional alternative variety artificial real datasets .
Event-based camera bio-inspired vision sensor whose pixel work independently respond asynchronously brightness change microsecond resolution . Their advantage make possible tackle challenging scenario robotics high-speed high dynamic range scene . We present solution problem visual odometry data acquired stereo event-based camera rig . Our system follows parallel tracking-and-mapping approach novel solution subproblem ( 3D reconstruction camera pose estimation ) developed two objective mind : principled efficient real-time operation commodity hardware . To end seek maximize spatio-temporal consistency stereo event-based data using simple efficient representation . Specifically mapping module build semi-dense 3D map scene fusing depth estimate multiple local viewpoint ( obtained spatio-temporal consistency ) probabilistic fashion . The tracking module recovers pose stereo rig solving registration problem naturally arises due chosen map event data representation . Experiments publicly available datasets recording demonstrate versatility proposed method natural scene general 6-DoF motion . The system successfully leverage advantage event-based camera perform visual odometry challenging illumination condition low-light high dynamic range running real-time standard CPU . We release software dataset open source licence foster research emerging topic event-based SLAM .
This paper develops compositional vector-based semantics subject object relative pronoun within categorical framework . Frobenius algebra used formalise operation required model semantics relative pronoun including passing information relative clause modified noun phrase well copying combining discarding part relative clause . We develop two instantiation abstract semantics one based truth-theoretic approach one based corpus statistic .
Video capsule endoscopy ( VCE ) used widely nowadays visualizing gastrointestinal ( GI ) tract . Capsule endoscopy exam prescribed usually additional monitoring mechanism help identifying polyp bleeding etc . To analyze large scale video data produced VCE exam automatic image processing computer vision learning algorithm required . Recently automatic polyp detection algorithm proposed various degree success . Though polyp detection colonoscopy traditional endoscopy procedure based image becoming mature field due unique imaging characteristic detecting polyp automatically VCE hard problem . We review different polyp detection approach VCE imagery provide systematic analysis challenge faced standard image processing computer vision method .
Large language model ( LLMs ) ChatGPT GPT4 making new wave field natural language processing artificial intelligence due emergent ability generalizability . However LLMs black-box model often fall short capturing accessing factual knowledge . In contrast Knowledge Graphs ( KGs ) Wikipedia Huapu example structured knowledge model explicitly store rich factual knowledge . KGs enhance LLMs providing external knowledge inference interpretability . Meanwhile KGs difficult construct evolving nature challenge existing method KGs generate new fact represent unseen knowledge . Therefore complementary unify LLMs KGs together simultaneously leverage advantage . In article present forward-looking roadmap unification LLMs KGs . Our roadmap consists three general framework namely 1 ) KG-enhanced LLMs incorporate KGs pre-training inference phase LLMs purpose enhancing understanding knowledge learned LLMs ; 2 ) LLM-augmented KGs leverage LLMs different KG task embedding completion construction graph-to-text generation question answering ; 3 ) Synergized LLMs + KGs LLMs KGs play equal role work mutually beneficial way enhance LLMs KGs bidirectional reasoning driven data knowledge . We review summarize existing effort within three framework roadmap pinpoint future research direction .
Recently learning-based model enhanced performance single-image super-resolution ( SISR ) . However applying SISR successively video frame lead lack temporal coherency . Convolutional neural network ( CNNs ) outperform traditional approach term image quality metric peak signal noise ratio ( PSNR ) structural similarity ( SSIM ) . However generative adversarial network ( GANs ) offer competitive advantage able mitigate issue lack finer texture detail usually seen CNNs super-resolving large upscaling factor . We present iSeeBetter novel GAN-based spatio-temporal approach video super-resolution ( VSR ) render temporally consistent super-resolution video . iSeeBetter extract spatial temporal information current neighboring frame using concept recurrent back-projection network generator . Furthermore improve `` naturality `` super-resolved image eliminating artifact seen traditional algorithm utilize discriminator super-resolution generative adversarial network ( SRGAN ) . Although mean squared error ( MSE ) primary loss-minimization objective improves PSNR/SSIM metric may capture fine detail image resulting misrepresentation perceptual quality . To address use four-fold ( MSE perceptual adversarial total-variation ( TV ) ) loss function . Our result demonstrate iSeeBetter offer superior VSR fidelity surpasses state-of-the-art performance .
Change detection basic task remote sensing image processing . The research objective identity change information interest filter irrelevant change information interference factor . Recently rise deep learning provided new tool change detection yielded impressive result . However available method focus mainly difference information multitemporal remote sensing image lack robustness pseudo-change information . To overcome lack resistance current method pseudo-changes paper propose new method namely dual attentive fully convolutional Siamese network ( DASNet ) change detection high-resolution image . Through dual-attention mechanism long-range dependency captured obtain discriminant feature representation enhance recognition performance model . Moreover imbalanced sample serious problem change detection i.e . unchanged sample much changed sample one main reason resulting pseudo-changes . We put forward weighted double margin contrastive loss address problem punishing attention unchanged feature pair increase attention changed feature pair . The experimental result method change detection dataset ( CDD ) building change detection dataset ( BCDD ) demonstrate compared baseline method proposed method realizes maximum improvement 2.1\ % 3.6\ % respectively F1 score . Our Pytorch implementation available http : //github.com/lehaifeng/DASNet .
Trustfulness -- one 's general tendency confidence unknown people situation -- predicts many important real-world outcome mental health likelihood cooperate others clinician . While data-driven measure interpersonal trust previously introduced develop first language-based assessment personality trait trustfulness fitting one 's language accepted questionnaire-based trust score . Further using trustfulness type case study explore role questionnaire size well word count developing language-based predictive model user ' psychological trait . We find leveraging longer questionnaire yield greater test set accuracy training find beneficial include user took smaller questionnaire offer observation training . Similarly noting decrease individual prediction error word count increased found word count-weighted training scheme helpful user first place .
It conventional wisdom machine learning data mining logical model rule set interpretable model among rule-based model simpler model interpretable complex one . In position paper question latter assumption focusing one particular aspect interpretability namely plausibility model . Roughly speaking equate plausibility model likeliness user accepts explanation prediction . In particular argue thing equal longer explanation may convincing shorter one predominant bias shorter model typically necessary learning powerful discriminative model may suitable come user acceptance learned model . To end first recapitulate evidence postulate report result evaluation crowd-sourcing study based 3.000 judgment . The result reveal strong preference simple rule whereas observe weak preference longer rule domain . We relate result well-known cognitive bias conjunction fallacy representative heuristic recogition heuristic investigate relation rule length plausibility .
Nowadays many research article prefaced research highlight summarize main finding paper . Highlights help researcher precisely quickly identify contribution paper also enhance discoverability article via search engine . We aim automatically construct research highlight given certain segment research paper . We use pointer-generator network coverage mechanism contextual embedding layer input encodes input token SciBERT embeddings . We test model benchmark dataset CSPubSum also present MixSub new multi-disciplinary corpus paper automatic research highlight generation . For CSPubSum MixSub observed proposed model achieves best performance compared related variant model proposed literature . On CSPubSum dataset model achieves best performance input abstract paper opposed segment paper . It produce ROUGE-1 ROUGE-2 ROUGE-L F1-scores 38.26 14.26 35.51 respectively METEOR score 32.62 BERTScore F1 86.65 outperform baseline . On new MixSub dataset abstract input proposed model ( trained whole training corpus without distinguishing subject category ) achieves ROUGE-1 ROUGE-2 ROUGE-L F1-scores 31.78 9.76 29.3 respectively METEOR score 24.00 BERTScore F1 85.25 .
Multispectral pedestrian detection important task many around-the-clock application since visible thermal modality provide complementary information especially low light condition . Due presence two modality misalignment modality imbalance significant issue multispectral pedestrian detection . In paper propose M ulti S pectral pedestrian DE tection TR ansformer ( MS-DETR ) fix issue . MS-DETR consists two modality-specific backbone Transformer encoders followed multi-modal Transformer decoder visible thermal feature fused multi-modal Transformer decoder . To well resist misalignment multi-modal image design loosely coupled fusion strategy sparsely sampling keypoints multi-modal feature independently fusing adaptively learned attention weight . Moreover based insight different modality also different pedestrian instance tend different confidence score final detection propose instance-aware modality-balanced optimization strategy preserve visible thermal decoder branch aligns predicted slot instance-wise dynamic loss . Our end-to-end MS-DETR show superior performance challenging KAIST CVC-14 LLVIP benchmark datasets . The source code available http : //github.com/YinghuiXing/MS-DETR .
Background subtraction fundamental low-level processing task numerous computer vision application . The vast majority algorithm process image pixel-by-pixel basis independent decision made pixel . A general limitation processing rich contextual information taken account . We propose block-based method capable dealing noise illumination variation dynamic background still obtaining smooth contour foreground object . Specifically image sequence analysed overlapping block-by-block basis . A low-dimensional texture descriptor obtained block passed adaptive classifier cascade stage handle distinct problem . A probabilistic foreground mask generation approach exploit block overlap integrate interim block-level decision final pixel-level foreground segmentation . Unlike many pixel-based method ad-hoc post-processing foreground mask required . Experiments difficult Wallflower I2R datasets show proposed approach obtains average better result ( qualitatively quantitatively ) several prominent method . We furthermore propose use tracking performance unbiased approach assessing practical usefulness foreground segmentation method show proposed approach lead considerable improvement tracking accuracy CAVIAR dataset .
Current approach paraphrase generation detection heavily rely single general similarity score ignoring intricate linguistic property language . This paper introduces two new task address shortcoming considering paraphrase type - specific linguistic perturbation particular text position . We name task Paraphrase Type Generation Paraphrase Type Detection . Our result suggest current technique perform well binary classification scenario i.e . paraphrased inclusion fine-grained paraphrase type pose significant challenge . While approach good generating detecting general semantic similar content fail understand intrinsic linguistic variable manipulate . Models trained generating identifying paraphrase type also show improvement task without . In addition scaling model improves ability understand paraphrase type . We believe paraphrase type unlock new paradigm developing paraphrase model solving task future .
In order mitigate high communication cost distributed federated learning various vector compression scheme quantization sparsification dithering become popular . In designing compression method one aim communicate bit possible minimizes cost per communication round time attempting impart little distortion ( variance ) communicated message possible minimizes adverse effect compression overall number communication round . However intuitively two goal fundamentally conflict : compression allow distorted message become . We formalize intuition prove { \em uncertainty principle } randomized compression operator thus quantifying limitation mathematically { \em effectively providing asymptotically tight lower bound might achievable communication compression } . Motivated development call search optimal compression operator . In attempt take first step direction consider unbiased compression method inspired Kashin representation vector call { \em Kashin compression ( KC ) } . In contrast previously proposed compression mechanism KC enjoys { \em dimension independent } variance bound derive explicit formula even regime bit need communicate per vector entry .
Classification predicts class object using knowledge learned training phase . This process requires learning labeled sample . However labeled sample usually limited . Annotation process annoying tedious expensive requires human expert . Meanwhile unlabeled data available almost free . Semi-supervised learning approach make use labeled unlabeled data . This paper introduces cluster label approach using PSO semi-supervised classification . PSO competitive traditional clustering algorithm . A new local best PSO presented cluster unlabeled data . The available labeled data guide learning process . The experiment conducted using four state-of-the-art datasets different domain . The result compared Label Propagation popular semi-supervised classifier two state-of-the-art supervised classification model namely k-nearest neighbor decision tree . The experiment show efficiency proposed model .
3D semantic occupancy prediction pivotal task field autonomous driving . Recent approach made great advance 3D semantic occupancy prediction single modality . However multi-modal semantic occupancy prediction approach encountered difficulty dealing modality heterogeneity modality misalignment insufficient modality interaction arise fusion different modality data may result loss important geometric semantic information . This letter present novel multi-modal i.e . LiDAR-camera 3D semantic occupancy prediction framework dubbed Co-Occ couple explicit LiDAR-camera feature fusion implicit volume rendering regularization . The key insight volume rendering feature space proficiently bridge gap 3D LiDAR sweep 2D image serving physical regularization enhance LiDAR-camera fused volumetric representation . Specifically first propose Geometric- Semantic-aware Fusion ( GSFusion ) module explicitly enhance LiDAR feature incorporating neighboring camera feature K-nearest neighbor ( KNN ) search . Then employ volume rendering project fused feature back image plane reconstructing color depth map . These map supervised input image camera depth estimation derived LiDAR respectively . Extensive experiment popular nuScenes SemanticKITTI benchmark verify effectiveness Co-Occ 3D semantic occupancy prediction . The project page available http : //rorisis.github.io/Co-Occ_project-page/ .
Ensemble classifier refers group individual classifier cooperatively trained data set supervised classification problem . In paper present review commonly used ensemble classifier literature . Some ensemble classifier also developed targeting specific application . We also present application driven ensemble classifier paper .
We propose topic-dependent attention model sentiment classification topic extraction . Our model assumes global topic embedding shared across document employ attention mechanism derive local topic embedding word sentence . These subsequently incorporated modified Gated Recurrent Unit ( GRU ) sentiment classification extraction topic bearing different sentiment polarity . Those topic emerge word ' local topic embeddings learned internal attention GRU cell context multi-task learning framework . In paper present hierarchical architecture new GRU unit experiment conducted user ' review demonstrate classification performance par state-of-the-art methodology sentiment classification topic coherence outperforming current approach supervised topic extraction . In addition model able extract coherent aspect-sentiment cluster despite using aspect-level annotation training .
Semantic segmentation key technique involved automatic interpretation high-resolution remote sensing ( HRS ) imagery drawn much attention remote sensing community . Deep convolutional neural network ( DCNNs ) successfully applied HRS imagery semantic segmentation task due hierarchical representation ability . However heavy dependency large number training data dense annotation sensitiveness variation data distribution severely restrict potential application DCNNs semantic segmentation HRS imagery . This study proposes novel unsupervised domain adaptation semantic segmentation network ( MemoryAdaptNet ) semantic segmentation HRS imagery . MemoryAdaptNet construct output space adversarial learning scheme bridge domain distribution discrepancy source domain target domain narrow influence domain shift . Specifically embed invariant feature memory module store invariant domain-level context information feature obtained adversarial learning tend represent variant feature current limited input . This module integrated category attention-driven invariant domain-level context aggregation module current pseudo invariant feature augmenting pixel representation . An entropy-based pseudo label filtering strategy used update memory module high-confident pseudo invariant feature current target image . Extensive experiment three cross-domain task indicate proposed MemoryAdaptNet remarkably superior state-of-the-art method .
Deep reinforcement learning combination reinforcement learning ( RL ) deep learning . This field research able solve wide range complex decision-making task previously reach machine . Thus deep RL open many new application domain healthcare robotics smart grid finance many . This manuscript provides introduction deep reinforcement learning model algorithm technique . Particular focus aspect related generalization deep RL used practical application . We assume reader familiar basic machine learning concept .
Anomaly detection a.k.a . outlier detection novelty detection lasting yet active research area various research community several decade . There still unique problem complexity challenge require advanced approach . In recent year deep learning enabled anomaly detection i.e . deep anomaly detection emerged critical direction . This paper survey research deep anomaly detection comprehensive taxonomy covering advancement three high-level category 11 fine-grained category method . We review key intuition objective function underlying assumption advantage disadvantage discus address aforementioned challenge . We discus set possible future opportunity new perspective addressing challenge .
Safety critical autonomous driving one aspect improving safety accurately capture uncertainty perception system especially knowing unknown . Different providing deterministic probabilistic result e.g . probabilistic object detection provide partial information perception scenario propose complete probabilistic model named GevBEV . It interprets 2D driving space probabilistic Bird 's Eye View ( BEV ) map point-based spatial Gaussian distribution one draw evidence parameter categorical Dirichlet distribution new sample point continuous driving space . The experimental result show GevBEV provides reliable uncertainty quantification also outperforms previous work benchmark OPV2V V2V4Real BEV map interpretation cooperative perception simulated real-world driving scenario respectively . A critical factor cooperative perception data transmission size communication channel . GevBEV help reduce communication overhead selecting important information share learned uncertainty reducing average information communicated 87 % slight performance drop . Our code published http : //github.com/YuanYunshuang/GevBEV .
The present paper deal online convex optimization involving time-varying loss function time-varying constraint . The loss function fully accessible learner instead function value ( a.k.a . bandit feedback ) revealed queried point . The constraint revealed making decision instantaneously violated yet must satisfied long term . This setting fit nicely emerging online network task fog computing Internet-of-Things ( IoT ) online decision must flexibly adapt changing user preference ( loss function ) temporally unpredictable availability resource ( constraint ) . Tailored human-in-the-loop system loss function hard model family bandit online saddle-point ( BanSaP ) scheme developed adaptively adjust online operation based ( possibly multiple ) bandit feedback loss function changing environment . Performance assessed : ) dynamic regret generalizes widely used static regret ; ii ) fit capture accumulated amount constraint violation . Specifically BanSaP proved simultaneously yield sub-linear dynamic regret fit provided best dynamic solution vary slowly time . Numerical test fog computation offloading task corroborate proposed BanSaP approach offer competitive performance relative existing approach based gradient feedback .
In work present review state art information theoretic feature selection method . The concept feature relevance redundance complementarity ( synergy ) clearly defined well Markov blanket . The problem optimal feature selection defined . A unifying theoretical framework described retrofit successful heuristic criterion indicating approximation made method . A number open problem field presented .
Monitoring spread disease-carrying mosquito first necessary step control severe disease dengue chikungunya Zika yellow fever . Previous citizen science project able obtain large image datasets linked geo-tracking information . As number international collaborator grows manual annotation expert entomologist large amount data gathered user becomes time demanding unscalable posing strong need automated classification mosquito specie image . We introduce application two Deep Convolutional Neural Networks comparative study automate classification task . We use transfer learning principle train two state-of-the-art architecture data provided Mosquito Alert project obtaining testing accuracy 94 % . In addition applied explainable model based Grad-CAM algorithm visualise discriminant region classified image coincide white band stripe located leg abdomen thorax mosquito Aedes albopictus specie . The model allows u analyse classification error . Visual Grad-CAM model show linked poor acquisition condition strong image occlusion .
From non-central panorama 3D line recovered geometric reasoning . However sensitivity noise complex geometric modeling required led panorama little investigated . In work present novel approach 3D layout recovery indoor environment using single non-central panorama . We obtain boundary structural line room non-central panorama using deep learning exploit property non-central projection system new geometrical processing recover scaled layout . We solve problem Manhattan environment handling occlusion also Atlanta environment unified method . The experiment performed improve state-of-the-art method 3D layout recovery single panorama . Our approach first work using deep learning non-central panorama recovering scale single panorama layout .
Lexicon-free speech recognition naturally deal problem out-of-vocabulary ( OOV ) word . In paper show character-based language model ( LM ) perform well word-based LMs speech recognition word error rate ( WER ) even without restricting decoding lexicon . We study character-based LMs show convolutional LMs effectively leverage large ( character ) context key good speech recognition performance downstream . We specifically show lexicon-free decoding performance ( WER ) utterance OOV word using character-based LMs better lexicon-based decoding character word-based LMs .
Our objective paper review application feedback idea area additive manufacturing . Both application feedback control 3D printing process application feedback theory enable user interact better machine reviewed . Where appropriate opportunity future work highlighted .
Today text classification becomes critical task concerned individual numerous purpose . Hence several research conducted develop automatic text classification national international language . However need automatic text categorization system local language felt . The main aim study establish Pashto automatic text classification system . In order pursue work built Pashto corpus collection Pashto document due unavailability public datasets Pashto text document . Besides study compare several model containing statistical neural network machine learning technique including Multilayer Perceptron ( MLP ) Support Vector Machine ( SVM ) K Nearest Neighbor ( KNN ) decision tree gaussian na\ `` ive Bayes multinomial na\ `` ive Bayes random forest logistic regression discover effective approach . Moreover investigation evaluates two different feature extraction method including unigram Time Frequency Inverse Document Frequency ( IFIDF ) . Subsequently research obtained average testing accuracy rate 94 % using MLP classification algorithm TFIDF feature extraction method context .
We propose explainable approach relation extraction mitigates tension generalization explainability jointly training two goal . Our approach us multi-task learning architecture jointly train classifier relation extraction sequence model label word context relation explain decision relation classifier . We also convert model output rule bring global explanation approach . This sequence model trained using hybrid strategy : supervised supervision pre-existing pattern available semi-supervised otherwise . In latter situation treat sequence model 's label latent variable learn best assignment maximizes performance relation classifier . We evaluate proposed approach two datasets show sequence model provides label serve accurate explanation relation classifier 's decision importantly joint training generally improves performance relation classifier . We also evaluate performance generated rule show new rule great add-on manual rule bring rule-based system much closer neural model .
Legal case matching automatically construct model estimate similarity source target case played essential role intelligent legal system . Semantic text matching model applied task source target legal case considered long-form text document . These general-purpose matching model make prediction solely based text legal case overlooking essential role law article legal case matching . In real world matching result ( e.g . relevance label ) dramatically affected law article content judgment legal case radically formed basis law . From causal sense matching decision affected mediation effect cited law article legal case direct effect key circumstance ( e.g . detailed fact description ) legal case . In light observation paper proposes model-agnostic causal learning framework called Law-Match legal case matching model learned respecting corresponding law article . Given pair legal case related law article Law-Match considers embeddings law article instrumental variable ( IVs ) embeddings legal case treatment . Using IV regression treatment decomposed law-related law-unrelated part respectively reflecting mediation direct effect . These two part combined different weight collectively support final matching prediction . We show framework model-agnostic number legal case matching model applied underlying model . Comprehensive experiment show Law-Match outperform state-of-the-art baseline three public datasets .
A robust reliable system detecting spam review cry need today world order purchase product without cheated online site . In many online site option posting review thus creating scope fake paid review untruthful review . These concocted review mislead general public put perplexity whether believe review . Prominent machine learning technique introduced solve problem spam review detection . The majority current research concentrated supervised learning method require labeled data - inadequacy come online review . Our focus article detect deceptive text review . In order achieve worked labeled unlabeled data proposed deep learning method spam review detection includes Multi-Layer Perceptron ( MLP ) Convolutional Neural Network ( CNN ) variant Recurrent Neural Network ( RNN ) Long Short-Term Memory ( LSTM ) . We also applied traditional machine learning classifier Nave Bayes ( NB ) K Nearest Neighbor ( KNN ) Support Vector Machine ( SVM ) detect spam review finally shown performance comparison traditional deep learning classifier .
The success supervised classification remotely sensed image acquired large geographical area short time interval strongly depends representativity sample used train classification algorithm define model . When training sample collected image ( spatial region ) different one used mapping spectral shift two distribution likely make model fail . Such shift generally due difference acquisition atmospheric condition change nature object observed . In order design classification method robust data-set shift recent remote sensing literature considered solution based domain adaptation ( DA ) approach . Inspired machine learning literature several DA method proposed solve specific problem remote sensing data classification . This paper provides critical review recent advance DA remote sensing present overview method divided four category : ) invariant feature selection ; ii ) representation matching ; iii ) adaptation classifier iv ) selective sampling . We provide overview recent methodology well example application considered technique real remote sensing image characterized high spatial spectral resolution . Finally propose guideline selection method use real application scenario .
Graph Neural Networks ( GNNs ) made rapid development recent year . Due great ability modeling graph-structured data GNNs vastly used various application including high-stakes scenario financial analysis traffic prediction drug discovery . Despite great potential benefiting human real world recent study show GNNs leak private information vulnerable adversarial attack inherit magnify societal bias training data lack interpretability risk causing unintentional harm user society . For example existing work demonstrate attacker fool GNNs give outcome desire unnoticeable perturbation training graph . GNNs trained social network may embed discrimination decision process strengthening undesirable societal bias . Consequently trustworthy GNNs various aspect emerging prevent harm GNN model increase user ' trust GNNs . In paper give comprehensive survey GNNs computational aspect privacy robustness fairness explainability . For aspect give taxonomy related method formulate general framework multiple category trustworthy GNNs . We also discus future research direction aspect connection aspect help achieve trustworthiness .
Deep learning driven great progress natural biological image processing . However material science engineering often flaw indistinctions material microscopic image induced complex sample preparation even due material hindering detection target object . In work propose WPU-net redesigns architecture weighted loss U-Net force network integrate information adjacent slice pay attention topology boundary detection task . Then WPU-net applied typical material example i.e . grain boundary detection polycrystalline material . Experiments demonstrate proposed method achieves promising performance outperforms state-of-the-art method . Besides propose new method object tracking adjacent slice effectively reconstruct 3D structure whole material . Finally present material microscopic image dataset goal advancing state-of-the-art image processing material science .
Crop yield highly complex trait determined multiple factor genotype environment interaction . Accurate yield prediction requires fundamental understanding functional relationship yield interactive factor reveal relationship requires comprehensive datasets powerful algorithm . In 2018 Syngenta Crop Challenge Syngenta released several large datasets recorded genotype yield performance 2267 maize hybrid planted 2247 location 2008 2016 asked participant predict yield performance 2017 . As one winning team designed deep neural network ( DNN ) approach took advantage state-of-the-art modeling solution technique . Our model found superior prediction accuracy root-mean-square-error ( RMSE ) 12 % average yield 50 % standard deviation validation dataset using predicted weather data . With perfect weather data RMSE would reduced 11 % average yield 46 % standard deviation . We also performed feature selection based trained DNN model successfully decreased dimension input space without significant drop prediction accuracy . Our computational result suggested model significantly outperformed popular method Lasso shallow neural network ( SNN ) regression tree ( RT ) . The result also revealed environmental factor greater effect crop yield genotype .
Active learning improves performance machine learning method judiciously selecting limited number unlabeled data point query label aim maximally improving underlying classifier 's performance . Recent gain made using sequential active learning synthetic aperture radar ( SAR ) data arXiv:2204.00005 . In iteration sequential active learning selects query set size one batch active learning selects query set multiple datapoints . While batch active learning method exhibit greater efficiency challenge lie maintaining model accuracy relative sequential active learning method . We developed novel two-part approach batch active learning : Dijkstra 's Annulus Core-Set ( DAC ) core-set generation LocalMax batch sampling . The batch active learning process combine DAC LocalMax achieves nearly identical accuracy sequential active learning efficient proportional batch size . As application pipeline built based transfer learning feature embedding graph learning DAC LocalMax classify FUSAR-Ship OpenSARShip datasets . Our pipeline outperforms state-of-the-art CNN-based method .
Discourse parsing crucial task natural language processing aim reveal higher-level relation text . Despite growing interest cross-lingual discourse parsing challenge persist due limited parallel data inconsistency Rhetorical Structure Theory ( RST ) application across language corpus . To address introduce parallel Russian annotation large diverse English GUM RST corpus . Leveraging recent advance end-to-end RST parser achieves state-of-the-art result English Russian corpus . It demonstrates effectiveness monolingual bilingual setting successfully transferring even limited second-language annotation . To best knowledge work first evaluate potential cross-lingual end-to-end RST parsing manually annotated parallel corpus .
Implant prosthesis appropriate treatment dentition defect dentition loss usually involves surgical guide design process decide implant position . However design heavily relies subjective experience dentist . In paper transformer-based Implant Position Regression Network ImplantFormer proposed automatically predict implant position based oral CBCT data . We creatively propose predict implant position using 2D axial view tooth crown area fit centerline implant obtain actual implant position tooth root . Convolutional stem decoder designed coarsely extract image feature operation patch embedding integrate multi-level feature map robust prediction respectively . As long-range relationship local feature involved approach better represent global information achieves better location performance . Extensive experiment dental implant dataset five-fold cross-validation demonstrated proposed ImplantFormer achieves superior performance existing method .
AI researcher posited Dungeons Dragons ( D & D ) challenge problem test system various language-related capability . In paper frame D & D specifically dialogue system challenge task generate next conversational turn game predict state game given dialogue history . We create gameplay dataset consisting nearly 900 game total 7000 player 800000 dialogue turn 500000 dice roll 58 million word . We automatically annotate data partial state information game play . We train large language model ( LM ) generate next game turn conditioning different information . The LM respond particular character player run game -- i.e . Dungeon Master ( DM ) . It trained produce dialogue either in-character ( roleplaying fictional world ) out-of-character ( discussing rule strategy ) . We perform human evaluation determine factor make generated output plausible interesting . We perform automatic evaluation determine well model predict game state given history examine well tracking game state improves ability produce plausible conversational output .
Feature selection vital technique machine learning reduce computational complexity improve model performance mitigate risk overfitting . However increasing complexity dimensionality datasets pose significant challenge selection feature . Focusing challenge paper proposes cascaded two-stage feature clustering selection algorithm fuzzy decision system . In first stage reduce search space clustering relevant feature addressing inter-feature redundancy . In second stage clustering-based sequentially forward selection method explores global local structure data presented . We propose novel metric assessing significance feature considers global separability local consistency . Global separability measure degree intra-class cohesion inter-class separation based fuzzy membership providing comprehensive understanding data separability . Meanwhile local consistency leverage fuzzy neighborhood rough set model capture uncertainty fuzziness data . The effectiveness proposed algorithm evaluated experiment conducted 18 public datasets real-world schizophrenia dataset . The experiment result demonstrate algorithm 's superiority benchmarking algorithm classification accuracy number selected feature .
Signature synthesis computation technique generates artificial specimen support decision making automatic signature verification . A lot work dedicated subject centre synthesizing dynamic static two-dimensional handwriting canvas . This paper proposes framework generate synthetic 3D on-air signature exploiting lognormality principle mimic complex neuromotor control process play fingertip move . Addressing usual case involving development artificial individual duplicated sample paper contributes synthesis : ( 1 ) trajectory velocity entirely 3D new signature ; ( 2 ) kinematic information 3D trajectory signature known ( 3 ) duplicate sample 3D real signature . Validation conducted generating synthetic 3D signature database mimicking real one showing automatic signature verification genuine skilled forgery report performance similar real synthetic database . We also observed training 3D automatic signature verifier duplicate reduce error . We demonstrated proposal also valid synthesizing 3D air writing gesture . Finally perception test confirmed human likeness generated specimen . The database generated publicly available research purpose .
In Time Series Classification ( TSC ) temporal pooling method consider sequential information proposed . However found temporal pooling distinct mechanism perform better worse depending time series data . We term fixed pooling mechanism single perspective temporal poolings . In paper propose novel temporal pooling method diverse perspective learning : Selection Multiple Temporal Poolings ( SoM-TP ) . SoM-TP dynamically selects optimal temporal pooling among multiple method data attention . The dynamic pooling selection motivated ensemble concept Multiple Choice Learning ( MCL ) selects best among multiple output . The pooling selection SoM-TP 's attention enables non-iterative pooling ensemble within single classifier . Additionally define perspective loss Diverse Perspective Learning Network ( DPLN ) . The loss work regularizer reflect pooling perspective DPLN . Our perspective analysis using Layer-wise Relevance Propagation ( LRP ) reveals limitation single perspective ultimately demonstrates diverse perspective learning SoM-TP . We also show SoM-TP outperforms CNN model based temporal poolings state-of-the-art model TSC extensive UCR/UEA repository .
Recent year seen vast potential Graph Neural Networks ( GNN ) many field data structured graph ( e.g . chemistry recommender system ) . In particular GNNs becoming increasingly popular field networking graph intrinsically present many level ( e.g . topology routing ) . The main novelty GNNs ability generalize network unseen training essential feature developing practical Machine Learning ( ML ) solution networking . However implementing functional GNN prototype currently cumbersome task requires strong skill neural network programming . This pose important barrier network engineer often necessary ML expertise . In article present IGNNITION novel open-source framework enables fast prototyping GNNs networking system . IGNNITION based intuitive high-level abstraction hide complexity behind GNNs still offering great flexibility build custom GNN architecture . To showcase versatility performance framework implement two state-of-the-art GNN model applied different networking use case . Our result show GNN model produced IGNNITION equivalent term accuracy performance native implementation TensorFlow .
With increasing computing capability modern supercomputer size data generated scientific simulation growing rapidly . As result application scientist need effective data summarization technique reduce large-scale multivariate spatiotemporal data set preserving important data property reduced data answer domain-specific query involving multiple variable sufficient accuracy . While analyzing complex scientific event domain expert often analyze visualize two variable together obtain better understanding characteristic data feature . Therefore data summarization technique required analyze multi-variable relationship detail perform data reduction important feature involving multiple variable preserved reduced data . To achieve work propose data sub-sampling algorithm performing statistical data summarization leverage pointwise information theoretic measure quantify statistical association data point considering multiple variable generates sub-sampled data preserve statistical association among multi-variables . Using reduced sampled data show multivariate feature query analysis done effectively . The efficacy proposed multivariate association driven sampling algorithm presented applying several scientific data set .
Image denoising fundamental problem computational photography achieving high perception low distortion highly demanding . Current method either struggle perceptual quality suffer significant distortion . Recently emerging diffusion model achieved state-of-the-art performance various task demonstrates great potential image denoising . However stimulating diffusion model image denoising straightforward requires solving several critical problem . For one thing input inconsistency hinders connection diffusion model image denoising . For another content inconsistency generated image desired denoised image introduces distortion . To tackle problem present novel strategy called Diffusion Model Image Denoising ( DMID ) understanding rethinking diffusion model denoising perspective . Our DMID strategy includes adaptive embedding method embeds noisy image pre-trained unconditional diffusion model adaptive ensembling method reduces distortion denoised image . Our DMID strategy achieves state-of-the-art performance distortion-based perception-based metric Gaussian real-world image denoising.The code available http : //github.com/Li-Tong-621/DMID .
In paper describe problem painter classification propose novel approach based deep convolutional autoencoder neural network . While previous approach relied image processing manual feature extraction painting approach operates raw pixel level without preprocessing manual feature extraction . We first train deep convolutional autoencoder dataset painting subsequently use initialize supervised convolutional neural network classification phase . The proposed approach substantially outperforms previous method improving previous state-of-the-art 3-painter classification problem 90.44 % accuracy ( previous state-of-the-art ) 96.52 % accuracy i.e . 63 % reduction error rate .
Labeling training data increasingly largest bottleneck deploying machine learning system . We present Snorkel first-of-its-kind system enables user train state-of-the-art model without hand labeling training data . Instead user write labeling function express arbitrary heuristic unknown accuracy correlation . Snorkel denoises output without access ground truth incorporating first end-to-end implementation recently proposed machine learning paradigm data programming . We present flexible interface layer writing labeling function based experience past year collaborating company agency research lab . In user study subject matter expert build model 2.8x faster increase predictive performance average 45.5 % versus seven hour hand labeling . We study modeling tradeoff new setting propose optimizer automating tradeoff decision give 1.8x speedup per pipeline execution . In two collaboration U.S. Department Veterans Affairs U.S. Food Drug Administration four open-source text image data set representative deployment Snorkel provides 132 % average improvement predictive performance prior heuristic approach come within average 3.60 % predictive performance large hand-curated training set .
Humans possess remarkable capability make fast intuitive decision also self-reflect i.e . explain oneself efficiently learn explanation others . This work provides first step toward mimicking process capitalizing explanation generated based existing explanation method i.e . Grad-CAM . Learning explanation combined conventional labeled data yield significant improvement classification term accuracy training time .
As one popular generative model Variational Autoencoder ( VAE ) approximates posterior latent variable based amortized variational inference . However decoder network sufficiently expressive VAE may lead posterior collapse ; uninformative latent representation may learned . To end paper propose alternative model DU-VAE learning Diverse less Uncertain latent space thus representation learned meaningful compact manner . Specifically first theoretically demonstrate result better latent space high diversity low uncertainty awareness controlling distribution posterior 's parameter across whole data accordingly . Then without introduction new loss term modifying training strategy propose exploit Dropout variance Batch-Normalization mean simultaneously regularize distribution implicitly . Furthermore evaluate generalization effect also exploit DU-VAE inverse autoregressive flow based-VAE ( VAE-IAF ) empirically . Finally extensive experiment three benchmark datasets clearly show approach outperform state-of-the-art baseline likelihood estimation underlying classification task .
The Aviation Safety Reporting System collect voluntarily submitted report aviation safety incident facilitate research work aiming reduce incident . To effectively reduce incident vital accurately identify incident occurred . More precisely given set possible cause shaping factor task cause identification involves identifying shaping factor responsible incident described report . We investigate two approach cause identification . Both approach exploit information provided semantic lexicon automatically constructed via Thelen Riloffs Basilisk framework augmented linguistic algorithmic modification . The first approach label report using simple heuristic look word phrase acquired semantic lexicon learning process report . The second approach recasts cause identification text classification problem employing supervised transductive text classification algorithm learn model incident report labeled shaping factor using model label unseen report . Our experiment show heuristic-based approach learning-based approach ( given sufficient training data ) outperform baseline system significantly .
Camera calibration method usually consist capturing image known calibration pattern using detected correspondence optimize parameter assumed camera model . A meaningful evaluation method relies availability realistic synthetic data . In previous work concerned conventional camera synthetic data mainly created rendering perfect image pinhole camera subsequently adding distortion aberration rendering correspondence according assumed camera model . This method bias evaluation since every camera perfectly complies assumed model . Furthermore field plenoptic camera calibration synthetic ground truth data available . We address problem proposing method based backward ray tracing create realistic ground truth data used unbiased evaluation calibration method type camera .
Linear principal component analysis ( PCA ) extended nonlinear PCA using artificial neural network . But benefit curved component requires careful control model complexity . Moreover standard technique model selection including cross-validation generally use independent test set fail applied nonlinear PCA inherent unsupervised characteristic . This paper present new approach validating complexity nonlinear PCA model using error missing data estimation criterion model selection . It motivated idea model optimal complexity able predict missing value highest accuracy . While standard test set validation usually favour over-fitted nonlinear PCA model proposed model validation approach correctly selects optimal model complexity .
Physics-informed neural network ( PINNs ) attracted lot attention scientific computing functional representation partial differential equation ( PDE ) solution offer flexibility accuracy feature . However training cost limited practical use real alternative classic numerical method . Thus propose incorporate multi-resolution hash encoding PINNs improve training efficiency encoding offer locally-aware ( multi resolution ) coordinate input neural network . Borrowed neural representation field community ( NeRF ) investigate robustness calculating derivative hash encoded neural network respect input coordinate often needed PINN loss term . We propose replace automatic differentiation finite-difference calculation derivative address discontinuous nature derivative . We also share appropriate range hash encoding hyperparameters obtain robust derivative . We test proposed method three problem including Burgers equation Helmholtz equation Navier-Stokes equation . The proposed method admits 10-fold improvement efficiency vanilla PINN implementation .
The timely identification significant memory concern ( SMC ) crucial proactive cognitive health management especially aging population . Detecting SMC early enables timely intervention personalized care potentially slowing cognitive disorder progression . This study present state-of-the-art review followed comprehensive evaluation machine learning model within randomized neural network ( RNNs ) hyperplane-based classifier ( HbCs ) family investigate SMC diagnosis thoroughly . Utilizing Alzheimer 's Disease Neuroimaging Initiative 2 ( ADNI2 ) dataset 111 individual SMC 111 healthy older adult analyzed based T1W magnetic resonance imaging ( MRI ) scan extracting rich feature . This analysis based baseline structural MRI ( sMRI ) scan extracting rich feature gray matter ( GM ) white matter ( WM ) Jacobian determinant ( JD ) cortical thickness ( CT ) measurement . In RNNs deep random vector functional link ( dRVFL ) ensemble dRVFL ( edRVFL ) emerge best classifier term performance metric identification SMC . In HbCs Kernelized pinball general twin support vector machine ( Pin-GTSVM-K ) excels CT WM feature whereas Linear Pin-GTSVM ( Pin-GTSVM-L ) Linear intuitionistic fuzzy TSVM ( IFTSVM-L ) performs well JD GM feature set respectively . This comprehensive evaluation emphasizes critical role feature selection model choice attaining effective classifier SMC diagnosis . The inclusion statistical analysis reinforces credibility result affirming rigor analysis . The performance measure exhibit suitability framework aiding researcher automated accurate assessment SMC . The source code algorithm datasets used study available http : //github.com/mtanveer1/SMC .
Compared unsupervised domain adaptation semi-supervised domain adaptation ( SSDA ) aim significantly improve classification performance generalization capability model leveraging presence small amount labeled data target domain . Several SSDA approach developed enable semantic-aligned feature confusion labeled ( pseudo labeled ) sample across domain ; nevertheless owing scarcity semantic label information target domain arduous fully realize potential . In study propose novel SSDA approach named Graph-based Adaptive Betweenness Clustering ( G-ABC ) achieving categorical domain alignment enables cross-domain semantic alignment mandating semantic transfer labeled data source target domain unlabeled target sample . In particular heterogeneous graph initially constructed reflect pairwise relationship labeled sample domain unlabeled one target domain . Then degrade noisy connectivity graph connectivity refinement conducted introducing two strategy namely Confidence Uncertainty based Node Removal Prediction Dissimilarity based Edge Pruning . Once graph refined Adaptive Betweenness Clustering introduced facilitate semantic transfer using across-domain betweenness clustering within-domain betweenness clustering thereby propagating semantic label information labeled sample across domain unlabeled target data . Extensive experiment three standard benchmark datasets namely DomainNet Office-Home Office-31 indicated method outperforms previous state-of-the-art SSDA approach demonstrating superiority proposed G-ABC algorithm .
Most existing point cloud instance semantic segmentation method rely heavily strong supervision signal require point-level label every point scene . However strong supervision suffers large annotation cost arousing need study efficient annotating . In paper discover location instance matter instance semantic 3D scene segmentation . By fully taking advantage location design weakly-supervised point cloud segmentation method requires clicking one point per instance indicate location annotation . With over-segmentation pre-processing extend location annotation segment seg-level label . We design segment grouping network ( SegGroup ) generate point-level pseudo label seg-level label hierarchically grouping unlabeled segment relevant nearby labeled segment existing point-level supervised segmentation model directly consume pseudo label training . Experimental result show seg-level supervised method ( SegGroup ) achieves comparable result fully annotated point-level supervised method . Moreover outperforms recent weakly-supervised method given fixed annotation budget . Code available http : //github.com/AnTao97/SegGroup .
We propose novel federated learning paradigm model data variability among heterogeneous client multi-centric study . Our method expressed hierarchical Bayesian latent variable model client-specific parameter assumed realization global distribution master level turn estimated account data bias variability across client . We show framework effectively optimized expectation maximization ( EM ) latent master 's distribution client ' parameter . We also introduce formal differential privacy ( DP ) guarantee compatibly EM optimization scheme . We tested method analysis multi-modal medical imaging data clinical score distributed clinical datasets patient affected Alzheimer 's disease . We demonstrate method robust data distributed either iid non-iid manner even local parameter perturbation included provide DP guarantee . Moreover variability data view center quantified interpretable manner guaranteeing high-quality data reconstruction compared state-of-the-art autoencoding model federated learning scheme . The code available http : //gitlab.inria.fr/epione/federated-multi-views-ppca .
The light field ( LF ) reconstruction mainly confronted two challenge large disparity non-Lambertian effect . Typical approach either address large disparity challenge using depth estimation followed view synthesis eschew explicit depth information enable non-Lambertian rendering rarely solve challenge unified framework . In paper revisit classic LF rendering framework address challenge incorporating advanced deep learning technique . First analytically show essential issue behind large disparity non-Lambertian challenge aliasing problem . Classic LF rendering approach typically mitigate aliasing reconstruction filter Fourier domain however intractable implement within deep learning pipeline . Instead introduce alternative framework perform anti-aliasing reconstruction image domain analytically show comparable efficacy aliasing issue . To explore full potential embed anti-aliasing framework deep neural network design integrated architecture trainable parameter . The network trained end-to-end optimization using peculiar training set including regular LFs unstructured LFs . The proposed deep learning pipeline show substantial superiority solving large disparity non-Lambertian challenge compared state-of-the-art approach . In addition view interpolation LF also show proposed pipeline also benefit light field view extrapolation .
Deep matrix factorization ( deep MFs ) recent unsupervised data mining technique inspired constrained low-rank approximation . They aim extract complex hierarchy feature within high-dimensional datasets . Most loss function proposed literature evaluate quality deep MF model underlying optimization framework consistent different loss used different layer . In paper introduce two meaningful loss function deep MF present generic framework solve corresponding optimization problem . We illustrate effectiveness approach integration various constraint regularization sparsity nonnegativity minimum-volume . The model successfully applied synthetic real data namely hyperspectral unmixing extraction facial feature .
The high temporal resolution asymmetric spatial activation essential attribute electroencephalogram ( EEG ) underlying emotional process brain . To learn temporal dynamic spatial asymmetry EEG towards accurate generalized emotion recognition propose TSception multi-scale convolutional neural network classify emotion EEG . TSception consists dynamic temporal asymmetric spatial high-level fusion layer learn discriminative representation time channel dimension simultaneously . The dynamic temporal layer consists multi-scale 1D convolutional kernel whose length related sampling rate EEG learns dynamic temporal frequency representation EEG . The asymmetric spatial layer take advantage asymmetric EEG pattern emotion learning discriminative global hemisphere representation . The learned spatial representation fused high-level fusion layer . Using generalized cross-validation setting proposed method evaluated two publicly available datasets DEAP MAHNOB-HCI . The performance proposed network compared prior reported method SVM KNN FBFgMDM FBTSC Unsupervised learning DeepConvNet ShallowConvNet EEGNet . TSception achieves higher classification accuracy F1 score method experiment . The code available http : //github.com/yi-ding-cs/TSception
The location fiducial facial landmark point around facial component facial contour capture rigid non-rigid facial deformation due head movement facial expression . They hence important various facial analysis task . Many facial landmark detection algorithm developed automatically detect key point year paper perform extensive review . We classify facial landmark detection algorithm three major category : holistic method Constrained Local Model ( CLM ) method regression-based method . They differ way utilize facial appearance shape information . The holistic method explicitly build model represent global facial appearance shape information . The CLMs explicitly leverage global shape model build local appearance model . The regression-based method implicitly capture facial shape appearance information . For algorithm within category discus underlying theory well difference . We also compare performance controlled wild benchmark datasets varying facial expression head pose occlusion . Based evaluation point respective strength weakness . There also separate section review latest deep learning-based algorithm . The survey also includes listing benchmark database existing software . Finally identify future research direction including combining method different category leverage respective strength solve landmark detection `` in-the-wild `` .
Controlling fish feeding machine challenging problem experienced fisherman adequately control based assumption . To build robust method reasonable application propose automatic controlling fish feeding machine based computer vision using combination counting nutriment estimating ripple behavior using regression textural feature respectively . To count number nutriment apply object detection tracking method acknowledge nutriment moving sea surface . Recently object tracking active research challenging problem computer vision . Unfortunately robust tracking method multiple small object dense complex relationship unsolved problem aquaculture field appearance creature . Based number nutriment ripple behavior control fish feeding machine consistently performs well real environment . Proposed method present agreement automatic controlling fish feeding activation graph textural feature ripple behavior . Our tracking method precisely track nutriment next frame comparing method . Based computational time proposed method reach 3.86 fps method spend lower 1.93 fps . Quantitative evaluation promise proposed method valuable aquaculture fish farm widely applied real environment .
Recent year seen surge machine learning approach aimed reducing disparity model output across different subgroup . In many setting training data may used multiple downstream application different user mean may effective intervene training data . In work present FairWASP novel pre-processing approach designed reduce disparity classification datasets without modifying original data . FairWASP return sample-level weight reweighted dataset minimizes Wasserstein distance original dataset satisfying ( empirical version ) demographic parity popular fairness criterion . We show theoretically integer weight optimal mean method equivalently understood duplicating eliminating sample . FairWASP therefore used construct datasets fed classification method method accept sample weight . Our work based reformulating pre-processing task large-scale mixed-integer program ( MIP ) propose highly efficient algorithm based cutting plane method . Experiments demonstrate proposed optimization algorithm significantly outperforms state-of-the-art commercial solver solving MIP linear program relaxation . Further experiment highlight competitive performance FairWASP reducing disparity preserving accuracy downstream classification setting .
We present improved model theory time-causal time-recursive spatio-temporal receptive field obtained combination Gaussian receptive field spatial domain first-order integrator equivalently truncated exponential filter coupled cascade temporal domain . Compared previous spatio-temporal scale-space formulation term non-enhancement local extremum scale invariance receptive field based different scale-space axiomatics time ensuring non-creation new local extremum zero-crossings increasing temporal scale . Specifically extension presented parameterizing intermediate temporal scale level analysing resulting temporal dynamic transferring theory discrete implementation term recursive filter time .
Multiple object tracking critical task autonomous driving . Existing work primarily focus heuristic design neural network obtain high accuracy . As tracking accuracy improves however neural network become increasingly complex posing challenge practical application real driving scenario due high level latency . In paper explore use neural architecture search ( NAS ) method search efficient architecture tracking aiming low real-time latency maintaining relatively high accuracy . Another challenge object tracking unreliability single sensor therefore propose multi-modal framework improve robustness . Experiments demonstrate algorithm run edge device within lower latency constraint thus greatly reducing computational requirement multi-modal object tracking keeping lower latency .
Time-of-flight ( TOF ) camera sensor measure depth scene-points illuminating scene controlled laser LED source analyzing reflected light . In paper first describe underlying measurement principle time-of-flight camera including : ( ) pulsed-light camera measure directly time taken light pulse travel device object back ( ii ) continuous-wave modulated-light camera measure phase difference emitted received signal hence obtain travel time indirectly . We review main existing design including prototype well commercially available device . We also review relevant camera calibration principle applied TOF device . Finally discus benefit challenge combined TOF color camera system .
Objective : Target identification brain-computer interface ( BCI ) speller refers electroencephalogram ( EEG ) classification predicting target character subject intends spell . When visual stimulus character tagged distinct frequency EEG record steady-state visually evoked potential ( SSVEP ) whose spectrum dominated harmonic target frequency . In setting address target identification propose novel deep neural network ( DNN ) architecture . Method : The proposed DNN process multi-channel SSVEP convolution across sub-bands harmonic channel time classifies fully connected layer . We test two publicly available large scale ( benchmark BETA ) datasets consisting total 105 subject 40 character . Our first stage training learns global model exploiting statistical commonality among subject second stage fine tune subject separately exploiting individuality . Results : Our DNN achieves impressive information transfer rate ( ITRs ) datasets 265.23 bits/min 196.59 bits/min respectively 0.4 second stimulation . The code available reproducibility http : //github.com/osmanberke/Deep-SSVEP-BCI . Conclusion : The presented DNN strongly outperforms state-of-the-art technique accuracy ITR rate highest ever reported performance result datasets . Significance : Due unprecedentedly high speller ITRs flawless applicability general SSVEP system technique great potential various biomedical engineering setting BCIs communication rehabilitation control .
Breast cancer one common prevalent type cancer mainly affect woman population . chance effective treatment increase early diagnosis . Mammography considered one effective proven technique early diagnosis breast cancer . Tissues around mass look identical mammogram make automatic detection process challenging task . They indistinguishable surrounding parenchyma . In paper present efficient automated approach segment mass mammogram . The proposed method us hierarchical clustering isolate salient area feature extracted reject false detection . We applied method two popular publicly available datasets ( mini-MIAS DDSM ) . A total 56 image mini-mias database 76 image DDSM randomly selected . Results explained in-terms ROC ( Receiver Operating Characteristics ) curve compared technique . Experimental result demonstrate efficiency advantage proposed system automatic mass identification mammogram .
Estimating human pose video critical human-computer interaction . Joints cooperate rather move independently human movement . There spatial temporal correlation joint . Despite positive result previous approach focus modeling spatial correlation joint straightforwardly integrating feature along temporal dimension ignoring temporal correlation joint . In work propose plug-and-play kinematics modeling module ( KMM ) explicitly model temporal correlation joint across different frame calculating temporal similarity . In way KMM capture motion cue current joint relative joint different time . Besides formulate video-based human pose estimation Markov Decision Process design novel kinematics modeling network ( KIMNet ) simulate Markov Chain allowing KIMNet locate joint recursively . Our approach achieves state-of-the-art result two challenging benchmark . In particular KIMNet show robustness occlusion . The code released http : //github.com/YHDang/KIMNet .
Image Fusion process core information set component image merged form single image informative complete component input image quality appearance . This paper present fast effective image fusion method creating high quality fused image merging component image . In proposed method input image broken two-scale image representation base layer large scale variation intensity detail layer containing small scale detail . Here fusion base detail layer implemented mean Local Edge preserving filtering based technique . The proposed method efficient image fusion technique noise component low quality resultant image high used application like medical image processing requiring accurate edge preserved image . Performance tested calculating PSNR SSIM image . The benefit proposed method remove noise without altering underlying structure image . This paper also present image zooming technique using bilinear interpolation portion input image cropped bilinear interpolation applied . Experimental result showed PSNR value calculated noise found low resultant image portion .
Objective : After year research Twitter post recognized important source patient-generated data providing unique insight population health . A fundamental step incorporating Twitter data pharmacoepidemiological research automatically recognize medication mention tweet . Given lexical search medication name may fail due misspelling ambiguity common word propose advanced method recognize . Methods : We present Kusuri Ensemble Learning classifier able identify tweet mentioning drug product dietary supplement . Kusuri ( `` medication `` Japanese ) composed two module . First four different classifier ( lexicon-based spelling-variant-based pattern-based one based weakly-trained neural network ) applied parallel discover tweet potentially containing medication name . Second ensemble deep neural network encoding morphological semantical long-range dependency important word tweet discovered used make final decision . Results : On balanced ( 50-50 ) corpus 15005 tweet Kusuri demonstrated performance close human annotator 93.7 % F1-score best score achieved thus far corpus . On corpus made tweet posted 113 Twitter user ( 98959 tweet 0.26 % mentioning medication ) Kusuri obtained 76.3 % F1-score . There prior drug extraction system compare running extremely unbalanced dataset . Conclusion : The system identifies tweet mentioning drug name performance high enough ensure usefulness ready integrated larger natural language processing system .
An intrinsic problem classifier based machine learning ( ML ) method learning time grows size complexity training dataset increase . For reason important efficient computational method algorithm applied large datasets still possible complete machine learning task reasonable time . In context present paper accurate simple process speed ML method . An unsupervised clustering algorithm combined Expectation Maximization ( EM ) algorithm develop efficient Hidden Markov Model ( HMM ) training . The idea proposed process consists two step . In first step training instance similar input clustered weight factor represents frequency instance assigned representative cluster . Dynamic Time Warping technique used dissimilarity function cluster similar example . In second step formula classical HMM training algorithm ( EM ) associated number training instance modified include weight factor appropriate term . This process significantly accelerates HMM training maintaining initial transition emission probability matrix obtained classical HMM training algorithm . Accordingly classification accuracy preserved . Depending size training set speedup 2200 time possible size 100.000 instance . The proposed approach limited training HMMs employed large variety MLs method .
Media coverage substantial effect public perception event . Nevertheless medium outlet often biased . One way bias news article altering word choice . The automatic identification bias word choice challenging primarily due lack gold standard data set high context dependency . This paper present BABE robust diverse data set created trained expert medium bias research . We also analyze expert labeling essential within domain . Our data set offer better annotation quality higher inter-annotator agreement existing work . It consists 3700 sentence balanced among topic outlet containing medium bias label word sentence level . Based data also introduce way detect bias-inducing sentence news article automatically . Our best performing BERT-based model pre-trained larger corpus consisting distant label . Fine-tuning evaluating model proposed supervised data set achieve macro F1-score 0.804 outperforming existing method .
Conventional tracking solution feasible handling abrupt motion based smooth motion assumption accurate motion model . Abrupt motion subject motion continuity smoothness . To assuage deem tracking optimisation problem propose novel abrupt motion tracker based swarm intelligence - SwaTrack . Unlike existing swarm-based filtering method first introduce optimised swarm-based sampling strategy tradeoff exploration exploitation search space search optimal proposal distribution . Secondly propose Dynamic Acceleration Parameters ( DAP ) allow fly tuning best mean variance distribution sampling . Such innovating idea combining strategy ingenious way PSO framework handle abrupt motion far existing work found . Experimental result quantitative qualitative shown effectiveness proposed method tracking abrupt motion .
Studies writing revision rarely focus revision quality . To address issue introduce corpus between-draft revision student argumentative essay annotated whether revision improves essay quality . We demonstrate potential usage annotation developing machine learning model predict revision improvement . With goal expanding training data also extract revision dataset edited expert proofreader . Our result indicate blending expert non-expert revision increase model performance expert data particularly important predicting low-quality revision .
We study problem synthesizing number likely future frame single input image . In contrast traditional method tackled problem deterministic non-parametric way propose model future frame probabilistic manner . Our probabilistic model make possible u sample synthesize many possible future frame single input image . To synthesize realistic movement object propose novel network structure namely Cross Convolutional Network ; network encodes image motion information feature map convolutional kernel respectively . In experiment model performs well synthetic data 2D shape animated game sprite real-world video frame . We present analysis learned network representation showing implicitly learning compact encoding object appearance motion . We also demonstrate application including visual analogy-making video extrapolation .
An open research question deep reinforcement learning focus policy learning key decision within sparse domain . This paper emphasizes combining advantage inputoutput hidden Markov model reinforcement learning towards interpretable maintenance decision . We propose novel hierarchical-modeling methodology high level detects interprets root cause failure well health degradation turbofan engine low level provides optimal replacement policy . It outperforms baseline performance deep reinforcement learning method applied directly raw data using hidden Markov model without specialized hierarchy . It also provides comparable performance prior work however additional benefit interpretability .
Learning reliably perceive understand scene integral enabler robot operate real-world . This problem inherently challenging due multitude object type well appearance change caused varying illumination weather condition . Leveraging complementary modality enable learning semantically richer representation resilient perturbation . Despite tremendous progress recent year multimodal convolutional neural network approach directly concatenate feature map individual modality stream rendering model incapable focusing relevant complementary information fusion . To address limitation propose mutimodal semantic segmentation framework dynamically adapts fusion modality-specific feature sensitive object category spatial location scene context self-supervised manner . Specifically propose architecture consisting two modality-specific encoder stream fuse intermediate encoder representation single decoder using proposed self-supervised model adaptation fusion mechanism optimally combine complementary feature . As intermediate representation aligned across modality introduce attention scheme better correlation . In addition propose computationally efficient unimodal segmentation architecture termed AdapNet++ incorporates new encoder multiscale residual unit efficient atrous spatial pyramid pooling larger effective receptive field 10x fewer parameter complemented strong decoder multi-resolution supervision scheme recovers high-resolution detail . Comprehensive empirical evaluation several benchmark demonstrate unimodal multimodal architecture achieve state-of-the-art performance .
Automated story generation problem automatically selecting sequence event action word told story . We seek develop system generate story learning everything need know textual story corpus . To date recurrent neural network learn language model character word sentence level little success generating coherent story . We explore question event representation provide mid-level abstraction word sentence order retain semantic information original data minimizing event sparsity . We present technique preprocessing textual story data event sequence . We present technique automated story generation whereby decompose problem generation successive event ( event2event ) generation natural language sentence event ( event2sentence ) . We give empirical result comparing different event representation effect event successor generation translation event natural language .
In work consider medical concept normalization problem i.e . problem mapping health-related entity mention free-form text concept controlled vocabulary usually standard thesaurus Unified Medical Language System ( UMLS ) . This challenging task since medical terminology different coming health care professional general public form social medium text . We approach sequence learning problem powerful neural network recurrent neural network contextualized word representation model trained obtain semantic representation social medium expression . Our experimental evaluation three different benchmark show neural architecture leverage semantic meaning entity mention significantly outperform existing state art model .
This article summarizes principle idea emerging area applying \textit { conditional computation } method design neural network . In particular focus neural network dynamically activate de-activate part computational graph conditionally input . Examples include dynamic selection e.g . input token layer ( set layer ) sub-modules inside layer ( e.g . channel convolutional filter ) . We first provide general formalism describe technique uniform way . Then introduce three notable implementation principle : mixture-of-experts ( MoEs ) network token selection mechanism early-exit neural network . The paper aim provide tutorial-like introduction growing field . To end analyze benefit modular design term efficiency explainability transfer learning focus emerging applicative area ranging automated scientific discovery semantic communication .
In paper discus generation symbol ( alphabet ) based specific user requirement ( medium priority type information need conveyed ) . A framework generation alphabet proposed use generation shorthand writing system explored . We discus possible use machine learning genetic algorithm gather input generation alphabet optimization already generated one . The alphabet generated using method may used different field creation synthetic language constructed script creation sensible command multimodal interaction Human-Computer Interfaces mouse gesture touchpads body gesture eye-tracking camera brain-computing Interfaces especially application elderly care people disability .
Glaucoma common eye disease lead irreversible blindness unless timely detected . Hence glaucoma detection early stage utmost importance better treatment plan ultimately saving vision . The recent literature shown prominence CNN-based method detect glaucoma retinal fundus image . However method mainly focus solving binary classification task thoroughly explored detection different glaucoma stage relatively challenging due minute lesion size variation high inter-class similarity . This paper proposes global self-attention based network called GS-Net efficient multi-stage glaucoma classification . We introduce global self-attention module ( GSAM ) consisting two parallel attention module channel attention module ( CAM ) spatial attention module ( SAM ) learn global feature dependency across channel spatial dimension . The GSAM encourages extracting discriminative class-specific feature fundus image . The experimental result publicly available dataset demonstrate GS-Net outperforms state-of-the-art method . Also GSAM achieves competitive performance popular attention module .
Obtaining standardized crowdsourced benchmark computational method major issue data science community . Dedicated framework enabling fair benchmarking unified environment yet developed . Here introduce Codabench open-source community-driven platform benchmarking algorithm software agent versus datasets task . A public instance Codabench ( http : //www.codabench.org/ ) open everyone free charge allows benchmark organizer compare fairly submission setting ( software hardware data algorithm ) custom protocol data format . Codabench unique feature facilitating organization benchmark flexibly easily reproducibly possibility re-using template benchmark supplying compute resource on-demand . Codabench used internally externally various application receiving 130 user 2500 submission . As illustrative use case introduce 4 diverse benchmark covering Graph Machine Learning Cancer Heterogeneity Clinical Diagnosis Reinforcement Learning .
The extraction understanding temporal event relation major challenge natural language processing . Processing text sentence-by-sentence expression-by-expression basis often fails part due challenge capturing global consistency text . We present ensemble method reconciles output multiple classifier temporal expression across text using integer programming . Computational experiment show ensemble improves upon best individual result two recent challenge SemEval-2013 TempEval-3 ( Temporal Annotation ) SemEval-2016 Task 12 ( Clinical TempEval ) .
Random Forest ensemble decision tree based bagging random subspace concept . As suggested Breiman strength unstable learner diversity among ensemble model ' core strength . In paper propose two approach known oblique rotation double random forest . In first approach propose rotation based double random forest . In rotation based double random forest transformation rotation feature space generated node . At node different random feature subspace chosen evaluation hence transformation node different . Different transformation result better diversity among base learner hence better generalization performance . With double random forest base learner data node transformed via two different transformation namely principal component analysis linear discriminant analysis . In second approach propose oblique double random forest . Decision tree random forest double random forest univariate result generation axis parallel split fails capture geometric structure data . Also standard random forest may grow sufficiently large decision tree resulting suboptimal performance . To capture geometric property grow decision tree sufficient depth propose oblique double random forest . The oblique double random forest model multivariate decision tree . At non-leaf node multisurface proximal support vector machine generates optimal plane better generalization performance . Also different regularization technique employed tackling small sample size problem decision tree oblique double random forest .
Multimodal learning framework building model make prediction based different type modality . Important challenge multimodal learning inference shared representation arbitrary modality cross-modal generation via representation ; however achieving requires taking heterogeneous nature multimodal data account . In recent year deep generative model i.e . generative model distribution parameterized deep neural network attracted much attention especially variational autoencoders suitable accomplishing challenge consider heterogeneity infer good representation data . Therefore various multimodal generative model based variational autoencoders called multimodal deep generative model proposed recent year . In paper provide categorized survey study multimodal deep generative model .
Experience replay ( ER ) used ( deep ) reinforcement learning considered applicable off-policy algorithm . However case ER applied on-policy algorithm suggesting off-policyness might sufficient condition applying ER . This paper reconsiders strict `` experience replayable condition `` ( ERC ) proposes way modifying existing algorithm satisfy ERC . In light postulated instability policy improvement represents pivotal factor ERC . The instability factor revealed viewpoint metric learning ) repulsive force negative sample ii ) replay inappropriate experience . Accordingly corresponding stabilization trick derived . As result confirmed numerical simulation proposed stabilization trick make ER applicable advantage actor-critic on-policy algorithm . Moreover learning performance comparable soft actor-critic state-of-the-art off-policy algorithm .
Audio-Visual Emotion Recognition ( AVER ) garnered increasing attention recent year critical role creating emotion-ware intelligent machine . Previous effort area dominated supervised learning paradigm . Despite significant progress supervised learning meeting bottleneck due longstanding data scarcity issue AVER . Motivated recent advance self-supervised learning propose Hierarchical Contrastive Masked Autoencoder ( HiCMAE ) novel self-supervised framework leverage large-scale self-supervised pre-training vast unlabeled audio-visual data promote advancement AVER . Following prior art self-supervised audio-visual representation learning HiCMAE adopts two primary form self-supervision pre-training namely masked data modeling contrastive learning . Unlike focus exclusively top-layer representation neglecting explicit guidance intermediate layer HiCMAE develops three-pronged strategy foster hierarchical audio-visual feature learning improve overall quality learned representation . To verify effectiveness HiCMAE conduct extensive experiment 9 datasets covering categorical dimensional AVER task . Experimental result show method significantly outperforms state-of-the-art supervised self-supervised audio-visual method indicates HiCMAE powerful audio-visual emotion representation learner . Codes model publicly available http : //github.com/sunlicai/HiCMAE .
The inability automated edge detection method inspired primal sketch model accurately calculate object edge influence pixel noise open problem . Extending principle image perception i.e . Weber-Fechner law Sheperd similarity law propose new edge detection method formulation use perceived brightness neighbourhood similarity calculation determination robust object edge . The robustness detected edge benchmark Sobel SIS Kirsch Prewitt edge detection method example face recognition problem showing statistically significant improvement recognition accuracy pixel noise tolerance .
We propose new efficient architecture semantic segmentation based `` Waterfall `` Atrous Spatial Pooling architecture achieves considerable accuracy increase decreasing number network parameter memory footprint . The proposed Waterfall architecture leverage efficiency progressive filtering cascade architecture maintaining multiscale fields-of-view comparable spatial pyramid configuration . Additionally method rely postprocessing stage Conditional Random Fields reduces complexity required training time . We demonstrate Waterfall approach ResNet backbone robust efficient architecture semantic segmentation obtaining state-of-the-art result significant reduction number parameter Pascal VOC dataset Cityscapes dataset .
To ensure safety railroad operation important monitor forecast track geometry irregularity . A higher safety requires forecasting higher spatiotemporal frequency turn requires capturing spatial correlation . Additionally track geometry irregularity influenced multiple exogenous factor . In study method proposed forecast one type track geometry irregularity vertical alignment incorporating spatial exogenous factor calculation . The proposed method embeds exogenous factor capture spatiotemporal correlation using convolutional long short-term memory . The proposed method also experimentally compared method term forecasting performance . Additionally ablation study exogenous factor conducted examine individual contribution forecasting performance . The result reveal spatial calculation maintenance record data improve forecasting vertical alignment .
Learning idiomatic expression seen one challenging stage second language learning unpredictable meaning . A similar situation hold identification within natural language processing application machine translation parsing . The lack high-quality usage sample exacerbates challenge human also artificial intelligence system . This article introduces gamified crowdsourcing approach collecting language learning material idiomatic expression ; messaging bot designed asynchronous multiplayer game native speaker compete providing idiomatic nonidiomatic usage example rating player ' entry . As opposed classical crowdprocessing annotation effort field first time literature crowdcreating & crowdrating approach implemented tested idiom corpus construction . The approach language independent evaluated two language comparison traditional data preparation technique field . The reaction crowd monitored different motivational mean ( namely gamification affordances monetary reward ) . The result reveal proposed approach powerful collecting targeted material although explicit crowdsourcing approach found entertaining useful crowd . The approach shown potential speed construction idiom corpus different natural language used second language learning material training data supervised idiom identification system sample lexicographic study .
Transformer-based language model ( LMs ) inefficient long context . We propose Dodo solution context compression . Instead one vector per token standard transformer model Dodo represents text dynamic number hidden state layer reducing cost self-attention fraction typical time space . Moreover off-the-shelf model LLaMA adapted Dodo efficient parameter tuning method LoRA . In use Dodo act either autoregressive LM context compressor downstream task . We demonstrate experiment language modeling question answering summarization Dodo retains capability task drastically reducing overhead decoding . For example autoencoding task Dodo shrink context 20x compression ratio BLEU score 98 % reconstruction achieving nearly lossless encoding .
Photo-realistic avatar modern term referring digital asset represents human computer graphic advanced system video game simulation tool . These avatar utilize advance graphic technology software hardware aspect . While photo-realistic avatar increasingly used industrial simulation representing human factor human worker psychophysiological state remains challenge . This article contributes resolving issue introducing novel concept MetaStates digitization representation psychophysiological state human worker digital world . The MetaStates influence physical representation performance digital human worker performing task . To demonstrate concept study present development photo-realistic avatar enhanced multi-level graphical representation psychophysiological state relevant Industry 5.0 . This approach represents major step forward use digital human industrial simulation allowing company better leverage benefit Industrial Metaverse daily operation simulation keeping human worker center system .
We present method classify object video stream using brain-inspired Hierarchical Temporal Memory ( HTM ) algorithm . Object classification challenging task human still significantly outperform machine learning algorithm due unique capability . We implemented system achieves promising performance term recognition accuracy . Unfortunately conducting advanced experiment computationally demanding ; trial run standard CPU may take long several day 960x540 video stream frame . Therefore decided accelerate selected part system using OpenCL . In particular seek determine extent porting selected computationally demanding part core may speed calculation . The classification accuracy system examined series experiment performance given term F1 score function number column synapsis $ min\_overlap $ $ winners\_set\_size $ . The system achieves highest F1 score 0.95 0.91 $ min\_overlap=4 $ 256 synapsis respectively . We also conduced series experiment different hardware setup measured CPU/GPU acceleration . The best kernel speed-up 632x 207x reached 256 synapsis 1024 column . However overall acceleration including transfer time significantly lower amounted 6.5x 3.2x setup .
The inherent nature patient data pose several challenge . Prevalent case amass substantial longitudinal data owing patient volume consistent follow-up however longitudinal laboratory data renowned irregularity temporality absenteeism sparsity ; In contrast recruitment rare specific case often constrained due limited patient size episodic observation . This study employed self-supervised learning ( SSL ) pretrain generalized laboratory progress ( GLP ) model capture overall progression six common laboratory marker prevalent cardiovascular case intention transferring knowledge aid detection specific cardiovascular event . GLP implemented two-stage training approach leveraging information embedded within interpolated data amplify performance SSL . After GLP pretraining transferred TVR detection . The proposed two-stage training improved performance pure SSL transferability GLP exhibited distinctiveness . After GLP processing classification exhibited notable enhancement averaged accuracy rising 0.63 0.90 . All evaluated metric demonstrated substantial superiority ( p < 0.01 ) compared prior GLP processing . Our study effectively engages translational engineering transferring patient progression cardiovascular laboratory parameter one patient group another transcending limitation data availability . The transferability disease progression optimized strategy examination treatment improves patient prognosis using commonly available laboratory parameter . The potential expanding approach encompass disease hold great promise .
Landuse characterization important urban planning . It traditionally performed field survey manual photo interpretation two practice time-consuming labor-intensive . Therefore aim automate landuse mapping urban-object level deep learning approach based data multiple source ( modality ) . We consider two image modality : overhead imagery Google Maps ensemble ground-based picture ( side-views ) per urban-object Google Street View ( GSV ) . These modality bring complementary visual information pertaining urban-objects . We propose end-to-end trainable model us OpenStreetMap annotation label . The model accommodate variable number GSV picture ground-based branch also function absence ground picture prediction time . We test effectiveness model area \^Ile-de-France France test generalization ability set urban-objects city Nantes France . Our proposed multimodal Convolutional Neural Network achieves considerably higher accuracy method use single image modality making suitable automatic landuse map update . Additionally approach could easily scaled multiple city based data source available many city worldwide .
A systematic review machine-learning strategy improving generalizability ( cross-subjects cross-sessions ) electroencephalography ( EEG ) based emotion classification realized . In context non-stationarity EEG signal critical issue lead Dataset Shift problem . Several architecture method proposed address issue mainly based transfer learning method . 418 paper retrieved Scopus IEEE Xplore PubMed database search query focusing modern machine learning technique generalization EEG-based emotion assessment . Among paper 75 found eligible based relevance problem . Studies lacking specific cross-subject cross-session validation strategy making use biosignals support excluded . On basis selected paper ' analysis taxonomy study employing Machine Learning ( ML ) method proposed together brief discussion different ML approach involved . The study best result term average classification accuracy identified supporting transfer learning method seem perform better approach . A discussion proposed impact ( ) emotion theoretical model ( ii ) psychological screening experimental sample classifier performance .
Embodied agent vision navigation coupled deep neural network attracted increasing attention . However deep neural network shown vulnerable malicious adversarial noise may potentially cause catastrophic failure Embodied Vision Navigation . Among different adversarial noise universal adversarial perturbation ( UAP ) i.e . constant image-agnostic perturbation applied every input frame agent play critical role Embodied Vision Navigation since computation-efficient application-practical attack . However existing UAP method ignore system dynamic Embodied Vision Navigation might sub-optimal . In order extend UAP sequential decision setting formulate disturbed environment universal noise $ \delta $ $ \delta $ -disturbed Markov Decision Process ( $ \delta $ -MDP ) . Based formulation analyze property $ \delta $ -MDP propose two novel Consistent Attack method named Reward UAP Trajectory UAP attacking Embodied agent consider dynamic MDP calculate universal noise estimating disturbed distribution disturbed Q function . For various victim model Consistent Attack cause significant drop performance PointGoal task Habitat different datasets different scene . Extensive experimental result indicate exist serious potential risk applying Embodied Vision Navigation method real world .
Sometimes simple fast algorithm required detect human presence movement low error rate controlled environment security purpose . Here light weight algorithm presented generates alert detection human presence movement towards certain direction . The algorithm us fixed angle CCTV camera image taken time relies upon skeleton transformation successive image calculation difference coordinate .
Email triage involves going unhandled email deciding . This familiar process become increasingly challenging number unhandled email grows . During triage session user commonly defer handling email immediately deal later . These deferred email often related task postponed user time right information deal . In paper qualitative interview large-scale log analysis study enterprise email user tend defer . We found user likely defer email handling involves replying reading carefully clicking link attachment . We also learned decision defer email depends many factor user 's workload importance sender . Our qualitative result suggested deferring common quantitative log analysis confirms 12 % triage session 16 % daily active user least one deferred email weekday . We also discus several deferral strategy marking email unread flagging reported interviewee illustrate pattern also observed user log . Inspired characteristic deferred email contextual factor involved deciding email deferred train classifier predicting whether recently triaged email actually deferred . Our experimental result suggests deferral classified modest effectiveness . Overall work provides novel insight user handle email deferral modeled .
Video skimming also known dynamic video summarization generates temporally abridged version given video . Skimming achieved identifying significant component either uni-modal multi-modal feature extracted video . Being dynamic nature video skimming temporal connectivity allows better understanding video summary . Having obvious advantage recently video skimming drawn focus many researcher benefiting easy availability required computing resource . In paper provide comprehensive survey video skimming focusing substantial amount literature past decade . We present taxonomy video skimming approach discus evolution highlighting key advance . We also provide study component required evaluation video skimming performance .
This paper considers outdoor terrain mapping using RGB image obtained aerial vehicle . While feature-based localization mapping technique deliver real-time vehicle odometry sparse keypoint depth reconstruction dense model environment geometry semantics ( vegetation building etc . ) usually recovered offline significant computation storage . This paper develops joint 2D-3D learning approach reconstruct local metric-semantic mesh camera keyframe maintained visual odometry algorithm . Given estimated camera trajectory local mesh assembled global environment model capture terrain topology semantics online operation . A local mesh reconstructed using initialization refinement stage . In initialization stage estimate mesh vertex elevation solving least square problem relating vertex barycentric coordinate sparse keypoint depth measurement . In refinement stage associate 2D image semantic feature 3D mesh vertex using camera projection apply graph convolution refine mesh vertex spatial coordinate semantic feature based joint 2D 3D supervision . Quantitative qualitative evaluation using real aerial image show potential method support environmental monitoring surveillance application .
In recent year generative adversarial network ( GAN ) -based image generation technique design generator stacking multiple residual block . The residual block generally contains shortcut \ie skip connection effectively support information propagation network . In paper propose novel shortcut method called gated shortcut embrace strength point residual block also boost GAN performance . More specifically based gating mechanism proposed method lead residual block keep ( remove ) information relevant ( irrelevant ) image generated . To demonstrate proposed method brings significant improvement GAN performance paper provides extensive experimental result various standard datasets CIFAR-10 CIFAR-100 LSUN tiny-ImageNet . Quantitative evaluation show gated shortcut achieves impressive GAN performance term Frechet inception distance ( FID ) Inception score ( IS ) . For instance proposed method improves FID IS score tiny-ImageNet dataset 35.13 27.90 20.23 23.42 respectively .
We propose novel deep multi-modality neural network restoring low bit rate video talking head . Such video content common social medium teleconferencing distance education tele-medicine etc . often need transmitted limited bandwidth . The proposed CNN method exploit correlation among three modality video audio emotion state speaker remove video compression artifact caused spatial sampling quantization . The deep learning approach turn ideally suited video restoration task complex non-linear cross-modality correlation difficult model analytically explicitly . The new method video post processor significantly boost perceptual quality aggressively compressed talking head video fully compatible existing video compression standard .
The availability abundance knowledge source spurred large amount effort development enhancement Information Retrieval technique . Users information need expressed natural language successful retrieval much dependent effective communication intended purpose . Natural language query consist multiple linguistic feature serve represent intended search goal . Linguistic characteristic cause semantic ambiguity misinterpretation query well additional factor lack familiarity search environment affect user ability accurately represent information need coined concept intention gap . The latter directly affect relevance returned search result may user satisfaction therefore major issue impacting effectiveness information retrieval system . Central discussion identification significant constituent characterize query intent enrichment addition meaningful term phrase even latent representation either manually automatically capture intended meaning . Specifically discus technique achieve enrichment particular utilizing information gathered statistical processing term dependency within document corpus external knowledge source ontology . We lay anatomy generic linguistic based query expansion framework propose module-based decomposition covering topical issue query processing information retrieval computational linguistics ontology engineering . For module review state-of-the-art solution literature categorized analyzed light technique used .
The optimal power flow ( OPF ) problem critical component power system operation becomes increasingly difficult solve due variability intermittency unpredictability renewable energy brought power system . Although traditional optimization technique stochastic robust optimization approach could leveraged address OPF problem face renewable energy uncertainty i.e . dynamic coefficient optimization model effectiveness dealing large-scale problem remains limited . As result deep learning technique neural network recently developed improve computational efficiency solving OPF problem utilization data . However feasibility optimality solution may guaranteed system dynamic properly addressed well . In paper propose optimization model-informed generative adversarial network ( MI-GAN ) framework solve OPF uncertainty . The main contribution summarized three aspect : ( 1 ) ensure feasibility improve optimality generated solution three important layer proposed : feasibility filter layer comparison layer gradient-guided layer ; ( 2 ) GAN-based framework efficient model-informed selector incorporating three new layer established ; ( 3 ) new recursive iteration algorithm also proposed improve solution optimality handle system dynamic . The numerical result IEEE test system show proposed method effective promising .
Background : Although noticed depressed patient show difference processing emotion precise neural modulation mechanism positive negative emotion remain elusive . FMRI cutting-edge medical imaging technology renowned high spatial resolution dynamic temporal information making particularly suitable neural dynamic depression research . Methods : To address gap study firstly leveraged fMRI delineate activated region associated positive negative emotion healthy individual resulting creation positive emotion atlas ( PEA ) negative emotion atlas ( NEA ) . Subsequently examined neuroimaging change depression patient using atlas evaluated diagnostic performance based machine learning . Results : Our finding demonstrate classification accuracy depressed patient based PEA NEA exceeded 0.70 notable improvement compared whole-brain atlas . Furthermore ALFF analysis unveiled significant difference depressed patient healthy control eight functional cluster NEA focusing left cuneus cingulate gyrus superior parietal lobule . In contrast PEA revealed pronounced difference across fifteen cluster involving right fusiform gyrus parahippocampal gyrus inferior parietal lobule . Limitations : Due limited sample size subtypes depressed patient efficacy may need validation future . Conclusions : These finding emphasize complex interplay emotion modulation depression showcasing significant alteration PEA NEA among depression patient . This research enhances understanding emotion modulation depression implication diagnosis treatment evaluation .
Convolutional neural network ( CNN ) ability feature learning nonlinear mapping demonstrated effectiveness prognostic health management ( PHM ) . However explanation physical meaning CNN architecture rarely studied . In paper novel wavelet driven deep neural network termed WaveletKernelNet ( WKN ) presented continuous wavelet convolutional ( CWConv ) layer designed replace first convolutional layer standard CNN . This enables first CWConv layer discover meaningful filter . Furthermore scale parameter translation parameter directly learned raw data CWConv layer . This provides effective way obtain customized filter bank specifically tuned extracting defect-related impact component embedded vibration signal . In addition three experimental verification using data laboratory environment carried verify effectiveness proposed method mechanical fault diagnosis . The result show importance designed CWConv layer output CWConv layer interpretable . Besides found WKN fewer parameter higher fault classification accuracy faster convergence speed standard CNN .
One common obstacle learning causal model data high-order conditional independence ( CI ) relationship random variable difficult estimate . Since CI test conditioning set low order performed accurately even small number observation reasonable approach determine casual structure base merely low-order CIs . Recent research confirmed e.g . case sparse true causal model structure learned even zero- first-order conditional independency yield good approximation model . However challenging task provide method faithfully explain given set low-order CIs . In paper propose algorithm given set conditional independency order less equal $ k $ $ k $ small fixed number computes faithful graphical representation given set . Our result complete generalize previous work learning pairwise marginal independency . Moreover enable improve upon 0-1 graph model e.g . heavily used estimation genome network .
The majority traditional text-to-video retrieval system operate static environment i.e . interaction user agent beyond initial textual query provided user . This sub-optimal initial query ambiguity would lead many falsely retrieved video . To overcome limitation propose novel framework Video Retrieval using Dialog ( ViReD ) enables user interact AI agent via multiple round dialog user refines retrieved result answering question generated AI agent . Our novel multimodal question generator learns ask question maximize subsequent video retrieval performance using ( ) video candidate retrieved last round interaction user ( ii ) text-based dialog history documenting previous interaction generate question incorporate visual linguistic cue relevant video retrieval . Furthermore generate maximally informative question propose Information-Guided Supervision ( IGS ) guide question generator ask question would boost subsequent video retrieval accuracy . We validate effectiveness interactive ViReD framework AVSD dataset showing interactive method performs significantly better traditional non-interactive video retrieval system . We also demonstrate proposed approach generalizes real-world setting involve interaction real human thus demonstrating robustness generality framework
With modern infotainment system driver increasingly tempted engage secondary task driving . Since distracted driving already one main cause fatal accident in-vehicle touchscreen Human-Machine Interfaces ( HMIs ) must little distracting possible . To ensure system safe use undergo elaborate expensive empirical testing requiring fully functional prototype . Thus early-stage method informing designer implication design may driver distraction great value . This paper present machine learning method based anticipated usage scenario predicts visual demand in-vehicle touchscreen interaction provides local global explanation factor influencing driver ' visual attention allocation . The approach based large-scale natural driving data continuously collected production line vehicle employ SHapley Additive exPlanation ( SHAP ) method provide explanation leveraging informed design decision . Our approach accurate related work identifies interaction long glance occur 68 % accuracy predicts total glance duration mean error 2.4 s. Our explanation replicate result various recent study provide fast easily accessible insight effect UI element driving automation vehicle speed driver distraction . The system help designer evaluate current design also help better anticipate understand implication design decision might future design .
Currently deep learning-based visual inspection highly successful help supervised learning method . However real industrial scenario scarcity defect sample cost annotation lack priori knowledge defect may render supervised-based method ineffective . In recent year unsupervised anomaly localization algorithm become widely used industrial inspection task . This paper aim help researcher field comprehensively surveying recent achievement unsupervised anomaly localization industrial image using deep learning . The survey review 120 significant publication covering different aspect anomaly localization mainly covering various concept challenge taxonomy benchmark datasets quantitative performance comparison method reviewed . In reviewing achievement date paper provides detailed prediction analysis several future research direction . This review provides detailed technical information researcher interested industrial anomaly localization wish apply localization anomaly field .
In work study impact noise training object detection network medical domain mitigated improving training procedure . Annotating large medical datasets training data-hungry deep learning model expensive time consuming . Leveraging information already collected clinical practice form text report bookmark lesion measurement would substantially reduce cost . Obtaining precise lesion bounding box automatic mining procedure however difficult . We provide quantitative evaluation effect bounding box coordinate noise performance Faster R-CNN object detection network breast mass detection . Varying degree noise simulated randomly modifying bounding box : experiment bounding box could enlarged six time original size . The noise injected CBIS-DDSM collection well curated public mammography dataset accurate lesion location available . We show due imperfect matching ground truth network bounding box proposal noise propagated training reduces ability network correctly classify lesion background . When using standard Intersection Union criterion area FROC curve decrease 9 % . A novel matching criterion proposed improve tolerance noise .
Optical sensor learning algorithm autonomous vehicle dramatically advanced past year . Nonetheless reliability today 's autonomous vehicle hindered limited line-of-sight sensing capability brittleness data-driven method handling extreme situation . With recent development telecommunication technology cooperative perception vehicle-to-vehicle communication become promising paradigm enhance autonomous driving dangerous emergency situation . We introduce COOPERNAUT end-to-end learning model us cross-vehicle perception vision-based cooperative driving . Our model encodes LiDAR information compact point-based representation transmitted message vehicle via realistic wireless channel . To evaluate model develop AutoCastSim network-augmented driving simulation framework example accident-prone scenario . Our experiment AutoCastSim suggest cooperative perception driving model lead 40 % improvement average success rate egocentric driving model challenging driving situation 5 time smaller bandwidth requirement prior work V2VNet . COOPERNAUT AUTOCASTSIM available http : //ut-austin-rpl.github.io/Coopernaut/ .
Light field become popular representation three dimensional scene interest processing resampling compression . As operation often result loss quality need quantify . In work collect new dataset dense reference distorted light field well corresponding quality score scaled perceptual unit . The score acquired subjective experiment using interactive light-field viewing setup . The dataset contains typical artifact occur light-field processing chain due light-field reconstruction multi-view compression limitation automultiscopic display . We test number existing objective quality metric determine well predict quality light field . We find existing image quality metric provide good measure light-field quality require dense reference light- field optimal performance . For complex task comparing two distorted light field performance drop significantly reveals need new light-field-specific metric .
Blind image deblurring algorithm improving steadily past year . Most state-of-the-art algorithm however still perform perfectly challenging case especially large blur setting . In paper focus estimate good kernel estimate single blurred image based image structure . We found image detail caused blurring could adversely affect kernel estimation especially blur kernel large . One effective way eliminate detail apply image denoising model based Total Variation ( TV ) . First developed novel method computing image structure based TV model structure undermining kernel estimation removed . Second mitigate possible adverse effect salient edge improve robustness kernel estimation applied gradient selection method . Third proposed novel kernel estimation method capable preserving continuity sparsity kernel reducing noise . Finally developed adaptive weighted spatial prior purpose preserving sharp edge latent image restoration . The effectiveness method demonstrated experiment various kind challenging example .
Mobile task automation emerging field leverage AI streamline optimize execution routine task mobile device thereby enhancing efficiency productivity . Traditional method Programming By Demonstration ( PBD ) limited due dependence predefined task susceptibility app update . Recent advancement utilized view hierarchy collect UI information employed Large Language Models ( LLM ) enhance task automation . However view hierarchy accessibility issue face potential problem like missing object description misaligned structure . This paper introduces VisionTasker two-stage framework combining vision-based UI understanding LLM task planning mobile task automation step-by-step manner . VisionTasker firstly convert UI screenshot natural language interpretation using vision-based UI understanding approach eliminating need view hierarchy . Secondly adopts step-by-step task planning method presenting one interface time LLM . The LLM identifies relevant element within interface determines next action enhancing accuracy practicality . Extensive experiment show VisionTasker outperforms previous method providing effective UI representation across four datasets . Additionally automating 147 real-world task Android smartphone VisionTasker demonstrates advantage human task human show unfamiliarity show significant improvement integrated PBD mechanism . VisionTasker open-source available http : //github.com/AkimotoAyako/VisionTasker .
Hilberg ( 1990 ) supposed finite-order excess entropy random human text proportional square root text length . Assuming Hilberg 's hypothesis true derive Guiraud 's law state number word type text greater proportional square root text length . Our derivation based mathematical conjecture coding theory several experiment suggesting word defined approximately nonterminals shortest context-free grammar text . Such operational definition word applied even text deprived space allow Mandelbrot 's `` intermittent silence `` explanation Zipf 's Guiraud 's law . In contrast Mandelbrot 's model assumes probabilistic long-memory effect human narration might capable explaining Menzerath 's law .
In work present Densely Connected Temporal Convolutional Network ( DC-TCN ) lip-reading isolated word . Although Temporal Convolutional Networks ( TCN ) recently demonstrated great potential many vision task receptive field dense enough model complex temporal dynamic lip-reading scenario . To address problem introduce dense connection network capture robust temporal feature . Moreover approach utilises Squeeze-and-Excitation block light-weight attention mechanism enhance model 's classification power . Without bell whistle DC-TCN method achieved 88.36 % accuracy Lip Reading Wild ( LRW ) dataset 43.65 % LRW-1000 dataset surpassed baseline method new state-of-the-art datasets .
Deep-learning based computer vision model proved ground-breaking approach human activity recognition ( HAR ) . However existing work dedicated improve prediction accuracy either creating new model architecture increasing model complexity refining model parameter training larger datasets . Here propose alternative idea differing existing work increase model accuracy also shape model prediction align human understanding automatically creating higher-level summarizing label similar group human activity . First argue importance feasibility constructing hierarchical labeling system human activity recognition . Then utilize prediction black box HAR model identify similarity different activity . Finally tailor hierarchical clustering method automatically generate hierarchical tree activity conduct experiment . In system activity label level designed magnitude accuracy reflect specific amount activity detail . This strategy enables trade-off extent detail recognized activity user privacy masking sensitive prediction ; also provides possibility use formerly prohibited invasive model privacy-concerned scenario . Since hierarchy generated machine 's perspective prediction upper level provide better accuracy especially useful detailed label training set rather trivial final prediction goal . Moreover analysis structure tree reveal bias prediction model guide future data collection strategy .
In paper propose data intensive approach inferring sentence-internal temporal relation . Temporal inference relevant practical NLP application either extract synthesize temporal information ( e.g . summarisation question answering ) . Our method bypass need manual coding exploiting presence marker like `` overtly signal temporal relation . We first show model trained main subordinate clause connected temporal marker achieve good performance pseudo-disambiguation task simulating temporal inference ( testing temporal marker treated unseen model must select right marker set possible candidate ) . Secondly assess whether proposed approach hold promise semi-automatic creation temporal annotation . Specifically use model trained noisy approximate data ( i.e . main subordinate clause ) predict intra-sentential relation present TimeBank corpus annotated rich temporal information . Our experiment compare contrast several probabilistic model differing feature space linguistic assumption data requirement . We evaluate performance gold standard corpus also human subject .
Misinformation considered threat democratic value principle . The spread content social medium polarizes society undermines public discourse distorting public perception generating social unrest lacking rigor traditional journalism . Transformers transfer learning proved state-of-the-art method multiple well-known natural language processing task . In paper propose MisRoB { \AE } RTa novel transformer-based deep neural ensemble architecture misinformation detection . MisRoB { \AE } RTa take advantage two transformer ( BART \ & RoBERTa ) improve classification performance . We also benchmarked evaluated performance multiple transformer task misinformation detection . For training testing used large real-world news article dataset labeled 10 class addressing two shortcoming current research : increasing size dataset small large moving focus fake news detection binary classification multi-class classification . For dataset manually verified content news article ensure correctly labeled . The experimental result show accuracy transformer misinformation detection problem significantly influenced method employed learn context dataset size vocabulary dimension . We observe empirically best accuracy performance among classification model use one transformer obtained BART DistilRoBERTa obtains best accuracy least amount time required fine-tuning training . The proposed MisRoB { \AE } RTa outperforms transformer model task misinformation detection . To arrive conclusion performed ample ablation sensitivity testing MisRoB { \AE } RTa two datasets .
Recent advance artificial intelligence ( AI ) significantly intensified research geoscience remote sensing ( RS ) field . AI algorithm especially deep learning-based one developed applied widely RS data analysis . The successful application AI cover almost aspect Earth observation ( EO ) mission low-level vision task like super-resolution denoising inpainting high-level vision task like scene classification object detection semantic segmentation . While AI technique enable researcher observe understand Earth accurately vulnerability uncertainty AI model deserve attention considering many geoscience RS task highly safety-critical . This paper review current development AI security geoscience RS field covering following five important aspect : adversarial attack backdoor attack federated learning uncertainty explainability . Moreover potential opportunity trend discussed provide insight future research . To best author ' knowledge paper first attempt provide systematic review AI security-related research geoscience RS community . Available code datasets also listed paper move vibrant field research forward .
Global climate change drastic impact environment . Previous study showed pest disaster occured global climate change may cause tremendous number tree died inevitably became factor forest fire . An important portent forest fire condition forest . Aerial image-based forest analysis give early detection dead tree living tree . In paper applied synthetic method enlarge imagery dataset present new framework automated dead tree detection aerial image using re-trained Mask RCNN ( Mask Region-based Convolutional Neural Network ) approach transfer learning scheme . We apply framework aerial imagery datasets compare eight fine-tuned model . The mean average precision score ( mAP ) best model reach 54 % . Following automated detection able automatically produce calculate number dead tree mask label dead tree image indicator forest health could linked causal analysis environmental change predictive likelihood forest fire .
Feature selection intractable problem therefore practical algorithm often trade solution accuracy computation time . In paper propose novel multi-stage feature selection framework utilizing multiple level approximation surrogate . Such framework allows using wrapper approach much computationally efficient way significantly increasing quality feature selection solution achievable especially large datasets . We design evaluate Surrogate-Assisted Genetic Algorithm ( SAGA ) utilizes concept guide evolutionary search early phase exploration . SAGA switch evaluating original function final exploitation phase . We prove run-time upper bound SAGA surrogate-assisted stage worse equal wrapper GA scale better induction algorithm high order complexity number instance . We demonstrate using 14 datasets UCI ML repository practice SAGA significantly reduces computation time compared baseline wrapper Genetic Algorithm ( GA ) converging solution significantly higher accuracy . Our experiment show SAGA arrive near-optimal solution three time faster wrapper GA average . We also showcase importance evolution control approach designed prevent surrogate misleading evolutionary search towards false optimum .
Four-variable-independent-regression localization loss Smooth- $ \ell_1 $ Loss used default modern detector . Nevertheless kind loss oversimplified inconsistent final evaluation metric intersection union ( IoU ) . Directly employing standard IoU also infeasible since constant-zero plateau case non-overlapping box non-zero gradient minimum may make trainable . Accordingly propose systematic method address problem . Firstly propose new metric extended IoU ( EIoU ) well-defined two box overlapping reduced standard IoU overlapping . Secondly present convexification technique ( CT ) construct loss basis EIoU guarantee gradient minimum zero . Thirdly propose steady optimization technique ( SOT ) make fractional EIoU loss approaching minimum steadily smoothly . Fourthly fully exploit capability EIoU based loss introduce interrelated IoU-predicting head boost localization accuracy . With proposed contribution new method incorporated Faster R-CNN ResNet50+FPN backbone yield \textbf { 4.2 mAP } gain VOC2007 \textbf { 2.3 mAP } gain COCO2017 baseline Smooth- $ \ell_1 $ Loss almost \textbf { training inferencing computational cost } . Specifically stricter metric notable gain improving \textbf { 8.2 mAP } VOC2007 \textbf { 5.4 mAP } COCO2017 metric $ AP_ { 90 } $ .
Areas computational mechanic uncertainty quantification optimization usually involve repeated evaluation numerical model represent behavior engineering system . In case complex nonlinear system however model tend expensive evaluate making surrogate model quite valuable . Artificial neural network approximate system well taking advantage inherent information given training data . In context paper investigates improvement training process including sensitivity information partial derivative w.r.t . input outlined Sobolev training . In computational mechanic sensitivity applied neural network expanding training loss function additional loss term thereby improving training convergence resulting lower generalisation error . This improvement shown two example linear non-linear material behavior . More specifically Sobolev designed loss function expanded residual weight adjusting effect loss training step . Residual weighting given scaling different training data case response sensitivity . These residual weight optimized adaptive scheme whereby varying objective function explored showing improvement accuracy precision general training convergence .
Geometric scattering recently gained recognition graph representation learning recent work shown integrating scattering feature graph convolution network ( GCNs ) alleviate typical oversmoothing feature node representation learning . However scattering often relies handcrafted design requiring careful selection frequency band via cascade wavelet transforms well effective weight sharing scheme combine low- band-pass information . Here introduce new attention-based architecture produce adaptive task-driven node representation implicitly learning node-wise weight combining multiple scattering GCN channel network . We show resulting geometric scattering attention network ( GSAN ) outperforms previous network semi-supervised node classification also enabling spectral study extracted information examining node-wise attention weight .
Autonomous vehicle rely LiDAR sensor perceive environment . Adverse weather condition like rain snow fog negatively affect sensor reducing reliability introducing unwanted noise measurement . In work tackle problem proposing novel approach detecting adverse weather effect LiDAR data . We reformulate problem outlier detection task use energy-based framework detect outlier point cloud . More specifically method learns associate low energy score inlier point high energy score outlier allowing robust detection adverse weather effect . In extensive experiment show method performs better adverse weather detection higher robustness unseen weather effect previous state-of-the-art method . Furthermore show method used perform simultaneous outlier detection semantic segmentation . Finally help expand research field LiDAR perception adverse weather release SemanticSpray dataset contains labeled vehicle spray data highway-like scenario . The dataset available http : //semantic-spray-dataset.github.io .
Learning dictionary suitable sparse coding instead using engineered base proven effective variety image processing task . This paper study optimization dictionary image data representation enforced explicitly sparse respect smooth normalized sparseness measure . This involves computation Euclidean projection onto level set sparseness measure . While previous algorithm optimization problem least quasi-linear time complexity first algorithm linear time complexity constant space complexity proposed . The key mathematically rigorous derivation characterization projection 's result based soft-shrinkage function . This theory applied original algorithm called Easy Dictionary Learning ( EZDL ) learns dictionary simple fast-to-compute Hebbian-like learning rule . The new algorithm efficient expressive particularly simple implement . It demonstrated despite simplicity proposed learning algorithm able generate rich variety dictionary particular topographic organization atom separable atom . Further dictionary expressive benchmark learning algorithm term reproduction quality entire image result equivalent denoising performance . EZDL learns approximately 30 % faster already efficient Online Dictionary Learning algorithm therefore eligible rapid data set analysis problem vast quantity learning sample .
The enormous use sarcastic text form communication social medium physiological effect target user . Each user different approach misusing recognising sarcasm . Sarcasm detection difficult even user depend many thing perspective context special symbol . So challenging task machine differentiate sarcastic sentence non-sarcastic sentence . There exact rule based model accurately detect sarcasm many text corpus current situation . So one need focus optimistic forthcoming approach sarcasm detection domain . This paper discusses various sarcasm detection technique concludes approach related datasets optimal feature researcher 's challenge .
A fall abnormal activity occurs rarely ; however missing identify fall serious health safety implication individual . Due rarity occurrence fall may insufficient training data available . Therefore standard supervised machine learning method may directly applied handle problem . In paper present taxonomy study fall detection perspective availability fall data . The proposed taxonomy independent type sensor used specific feature extraction/selection method . The taxonomy identifies different category classification method study fall detection based availability data training classifier . Then present comprehensive literature review within category identify approach treating fall abnormal activity plausible research direction . We conclude paper discussing several open research problem field pointer future research .
One major challenge machine learning nowadays provide prediction high accuracy also user-friendly explanation . Although recent year witnessed increasingly popular use deep neural network sequence modeling still challenging explain rationale behind model output essential building trust supporting domain expert validate critique refine model . We propose ProSeNet interpretable steerable deep sequence model natural explanation derived case-based reasoning . The prediction obtained comparing input prototype exemplar case problem domain . For better interpretability define several criterion constructing prototype including simplicity diversity sparsity propose learning objective optimization procedure . ProSeNet also provides user-friendly approach model steering : domain expert without knowledge underlying model parameter easily incorporate intuition experience manually refining prototype . We conduct experiment wide range real-world application including predictive diagnostics automobile ECG protein sequence classification sentiment analysis text . The result show ProSeNet achieve accuracy par state-of-the-art deep learning model . We also evaluate interpretability result concrete case study . Finally user study Amazon Mechanical Turk ( MTurk ) demonstrate model selects high-quality prototype align well human knowledge interactively refined better interpretability without loss performance .
In quantum mechanic norm squared wave function interpreted probability density describes likelihood particle measured given position momentum . This statistical property core fuzzy structure microcosmos . Recently hybrid neural structure raised intense attention resulting various intelligent system far-reaching influence . Here propose probability-density-based deep learning paradigm fuzzy design functional meta-structures . In contrast inverse design method probability-density-based neural network efficiently evaluate accurately capture plausible meta-structures high-dimensional parameter space . Local maximum probability density distribution correspond likely candidate meet desired performance . We verify universally adaptive approach limited acoustic designing multiple meta-structures targeted transmission spectrum experiment unequivocally demonstrating effectiveness generalization inverse design .
In paper focus unsupervised learning Video Object Segmentation ( VOS ) learns visual correspondence ( i.e . similarity pixel-level feature ) unlabeled video . Previous method mainly based contrastive learning paradigm optimize either image level pixel level . Image-level optimization ( e.g . spatially pooled feature ResNet ) learns robust high-level semantics sub-optimal since pixel-level feature optimized implicitly . By contrast pixel-level optimization explicit however sensitive visual quality training data robust object deformation . To complementarily perform two level optimization unified framework propose In-aNd-Out ( INO ) generative learning purely generative perspective help naturally designed class token patch token Vision Transformer ( ViT ) . Specifically image-level optimization force out-view imagination local global view class token help capture high-level semantics name out-generative learning . As pixel-level optimization perform in-view masked image modeling patch token recovers corrupted part image via inferring fine-grained structure term in-generative learning . To discover temporal information better additionally force inter-frame consistency feature affinity matrix level . Extensive experiment DAVIS-2017 val YouTube-VOS 2018 val show INO outperforms previous state-of-the-art method significant margin . Code available : http : //github.com/pansanity666/INO_VOS
Due increasingly need automatic traffic monitoring vehicle license plate detection high interest perform automatic toll collection traffic law enforcement parking lot access control among others . In paper sliding window approach based Histogram Oriented Gradients ( HOG ) feature used Brazilian license plate detection . This approach consists scanning whole image multiscale fashion license plate located precisely . The main contribution work consists deep study best setup HOG descriptor detection Brazilian license plate HOG never applied . We also demonstrate reliability method ensured recall higher 98 % ( precision higher 78 % ) publicly available data set .
The following paper reproducibility report `` Social NCE : Contrastive Learning Socially-aware Motion Representations `` { \cite { liu2020snce } } published ICCV 2021 part ML Reproducibility Challenge 2021 . The original code made available author \footnote { \href { http : //github.com/vita-epfl/social-nce } { http : //github.com/vita-epfl/social-nce } } . We attempted verify result claimed author reimplemented code PyTorch Lightning .
Complicated image registration key issue medical image analysis deep learning-based method achieved better result traditional method . The method include ConvNet-based Transformer-based method . Although ConvNets effectively utilize local information reduce redundancy via small neighborhood convolution limited receptive field result inability capture global dependency . Transformers establish long-distance dependency via self-attention mechanism ; however intense calculation relationship among token lead high redundancy . We propose novel unsupervised image registration method named unified Transformer superresolution ( UTSRMorph ) network enhance feature representation learning encoder generate detailed displacement field decoder overcome problem . We first propose fusion attention block integrate advantage ConvNets Transformers insert ConvNet-based channel attention module multihead self-attention module . The overlapping attention block novel cross-attention method us overlapping window obtain abundant correlation match information pair image . Then block flexibly stacked new powerful encoder . The decoder generation process high-resolution deformation displacement field low-resolution feature considered superresolution process . Specifically superresolution module employed replace interpolation upsampling overcome feature degradation . UTSRMorph compared state-of-the-art registration method 3D brain MR ( OASIS IXI ) MR-CT datasets . The qualitative quantitative result indicate UTSRMorph achieves relatively better performance . The code datasets publicly available http : //github.com/Runshi-Zhang/UTSRMorph .
Unsupervised Domain Adaptive Object Detection ( UDA-OD ) us unlabelled data improve reliability robotic vision system open-world environment . Previous approach UDA-OD based self-training effective overcoming change general appearance image . However shift robot 's deployment environment also impact likelihood different object occur termed class distribution shift . Motivated propose framework explicitly addressing class distribution shift improve pseudo-label reliability self-training . Our approach us domain invariance contextual understanding pre-trained joint vision language model predict class distribution unlabelled data . By aligning class distribution pseudo-labels prediction provide weak supervision pseudo-label accuracy . To account low quality pseudo-labels early self-training propose approach dynamically adjust number pseudo-labels per image based model confidence . Our method outperforms state-of-the-art approach several benchmark including 4.7 mAP improvement facing challenging class distribution shift .
Object selection refers mechanism extracting object interest ignoring object background given visual scene . It fundamental issue many computer vision image analysis technique still challenging task artificial visual system . Chaotic phase synchronization take place case involving almost identical dynamical system mean phase difference system kept bounded time amplitude remain chaotic may uncorrelated . Instead complete synchronization phase synchronization believed mechanism neural integration brain . In paper object selection model proposed . Oscillators network representing salient object given scene phase synchronized phase synchronization occurs background object . In way salient object extracted . In model shift mechanism also introduced change attention one object another . Computer simulation show model produce result similar observed natural vision system .
Transformers revolutionized various real-world application natural language processing computer vision . However traditional von-Neumann computing paradigm face memory bandwidth limitation accelerating transformer owing massive model size . To end In-memory Computing ( IMC ) crossbar based Non-volatile Memories ( NVMs ) due ability perform highly parallelized Matrix-Vector-Multiplications ( MVMs ) high energy-efficiencies emerged promising solution accelerating transformer . However analog MVM operation crossbar introduce non-idealities stochastic read & write noise affect inference accuracy deployed transformer . Specifically find pre-trained Vision Transformers ( ViTs ) vulnerable crossbar due impact write noise dynamically-generated Key ( K ) Value ( V ) matrix attention layer effect accounted prior study . We thus propose ClipFormer transformation K V matrix inference boost non-ideal accuracy pre-trained ViT model . ClipFormer requires additional hardware training overhead amenable transformer deployed memristive crossbar platform . Our experiment Imagenet-1k dataset using pre-trained DeiT-S transformer subjected standard training variation-aware-training show > 10-40 % higher non-ideal accuracy high write noise regime applying ClipFormer .
We present PAC-Bayesian analysis lifelong learning . In lifelong learning problem sequence learning task observed one-at-a-time goal transfer information acquired previous task new learning task . We consider case learning task multi-armed bandit problem . We derive lower bound expected average reward would obtained given multi-armed bandit algorithm run new task particular prior set number step . We propose lifelong learning algorithm use new bound learning objective . Our proposed algorithm evaluated several lifelong multi-armed bandit problem found perform better baseline method use generalisation bound .
Fine-grained visual classification ( FGVC ) challenging computer vision problem task automatically recognise object subordinate category . One main difficulty capturing discriminative inter-class variance among visually similar class . Recently method Vision Transformer ( ViT ) demonstrated noticeable achievement FGVC generally employing self-attention mechanism additional resource-consuming technique distinguish potentially discriminative region disregarding rest . However approach may struggle effectively focus truly discriminative region due relying inherent self-attention mechanism resulting classification token likely aggregating global information less-important background patch . Moreover due immense lack datapoints classifier may fail find helpful inter-class distinguishing feature since unrelated distinctive background region may falsely recognised valuable . To end introduce simple yet effective Salient Mask-Guided Vision Transformer ( SM-ViT ) discriminability standard ViT ` attention map boosted salient masking potentially discriminative foreground region . Extensive experiment demonstrate standard training procedure SM-ViT achieves state-of-the-art performance popular FGVC benchmark among existing ViT-based approach requiring fewer resource lower input image resolution .
Finger vein recognition technology become one primary solution high-security identification system . However still information leakage problem seriously jeopardizes user privacy anonymity cause great security risk . In addition work consider fully integrated secure finger vein recognition system . So different previous system integrate preprocessing template protection integrated deep learning model . We propose end-to-end cancelable finger vein network ( CFVNet ) used design secure finger vein recognition system.It includes plug-and-play BWR-ROIAlign unit consists three sub-modules : Localization Compression Transformation . The localization module achieves automated localization stable unique finger vein ROI . The compression module losslessly remove spatial channel redundancy . The transformation module us proposed BWR method introduce unlinkability irreversibility revocability system . BWR-ROIAlign directly plug model introduce feature DCNN-based finger vein recognition system . We perform extensive experiment four public datasets study performance cancelable biometric attribute CFVNet-based recognition system . The average accuracy EERs Dsys four datasets 99.82 % 0.01 % 0.025 respectively achieves competitive performance compared state-of-the-arts .
We performed cough detection based measurement accelerometer attached patient 's bed . This form monitoring less intrusive body-attached accelerometer sensor sidestep privacy concern encountered using audio cough detection . For experiment compiled manually-annotated dataset containing acceleration signal approximately 6000 cough 68000 non-cough event 14 adult male patient tuberculosis clinic . As classifier considered convolutional neural network ( CNN ) long-short-term-memory ( LSTM ) network residual neural network ( Resnet50 ) . We find classifier able distinguish acceleration signal due coughing due activity including sneezing throat-clearing movement bed high accuracy . The Resnet50 performs best achieving area ROC curve ( AUC ) exceeding 0.98 cross-validation experiment . We conclude high-accuracy cough monitoring based measurement accelerometer consumer smartphone possible . Since need gather audio avoided therefore privacy inherently protected since accelerometer attached bed worn form monitoring may represent convenient readily accepted method long-term patient cough monitoring .
Coaching technology wearable exergames provide quantitative feedback based measured activity little evidence qualitative feedback aid technique improvement . To achieve personalised qualitative feedback demonstrated proof-of-concept prototype combining kinesiology computational intelligence could help improving tennis swing technique utilising three-dimensional tennis motion data acquired multi-camera video . Expert data labelling relied virtual 3D stick figure replay . Diverse assessment criterion novice intermediate skill level configurable coaching scenario matched variety tennis swing ( 22 backhand 21 forehand ) included good technique common error . A set selected coaching rule transferred adaptive assessment module able learn data evolve internal structure produce autonomous personalised feedback including verbal cue virtual camera 3D replay end-of-session progress report . The prototype demonstrated autonomous assessment future data based learning prior example aligned skill level flexible coaching scenario coaching rule . The generated intuitive diagnostic feedback consisted element safety performance tennis swing technique swing sample compared expert . For safety aspect relative swing width prototype showed improved assessment ...
Large pre-trained neural network ubiquitous critical success many downstream task natural language processing computer vision . However within field web information retrieval stark contrast lack similarly flexible powerful pre-trained model properly parse webpage . Consequently believe common machine learning task like content extraction information mining webpage low-hanging gain yet remain untapped . We aim close gap introducing agnostic deep graph neural network feature extractor ingest webpage structure pre-train self-supervised massive unlabeled data fine-tune arbitrary task webpage effectually . Finally show pre-trained model achieves state-of-the-art result using multiple datasets two different benchmark : webpage boilerplate removal genre classification thus lending support potential application diverse downstream task .
We propose extend concept private information retrieval allowing distortion retrieval process relaxing perfect privacy requirement time . In particular study trade-off download rate distortion user privacy leakage show limit large file size trade-off captured via novel information-theoretical formulation datasets known distribution . Moreover scenario statistic dataset unknown propose new deep learning framework leveraging generative adversarial network approach allows user learn efficient scheme data . We evaluate performance scheme synthetic Gaussian dataset well MNIST CIFAR-10 LSUN datasets . For MNIST CIFAR-10 LSUN datasets data-driven approach significantly outperforms nonlearning-based scheme combine source coding download multiple file .
Mixed data comprises numeric categorical feature mixed datasets occur frequently many domain health finance marketing . Clustering often applied mixed datasets find structure group similar object analysis . However clustering mixed data challenging difficult directly apply mathematical operation summation averaging feature value datasets . In paper present taxonomy study mixed data clustering algorithm identifying five major research theme . We present state-of-the-art review research work within research theme . We analyze strength weakness method pointer future research direction . Lastly present in-depth analysis overall challenge field highlight open research question discus guideline make progress field .
As deep learning technique expanded real-world recommendation task many deep neural network based Collaborative Filtering ( CF ) model developed project user-item interaction latent feature space based various neural architecture multi-layer perceptron auto-encoder graph neural network . However majority existing collaborative filtering system well designed handle missing data . Particularly order inject negative signal training phase solution largely rely negative sampling unobserved user-item interaction simply treating negative instance brings recommendation performance degradation . To address issue develop Collaborative Reflection-Augmented Autoencoder Network ( CRANet ) capable exploring transferable knowledge observed unobserved user-item interaction . The network architecture CRANet formed integrative structure reflective receptor network information fusion autoencoder module endows recommendation framework ability encoding implicit user 's pairwise preference interacted non-interacted item . Additionally parametric regularization-based tied-weight scheme designed perform robust joint training two-stage CRANet model . We finally experimentally validate CRANet four diverse benchmark datasets corresponding two recommendation task show debiasing negative signal user-item interaction improves performance compared various state-of-the-art recommendation technique . Our source code available http : //github.com/akaxlh/CRANet .
Reliable microaneurysm detection digital fundus image still open issue medical image processing . We propose ensemble-based framework improve microaneurysm detection . Unlike well-known approach considering output multiple classifier propose combination internal component microaneurysm detector namely preprocessing method candidate extractor . We evaluated approach microaneurysm detection online competition algorithm currently ranked first also two database . Since microaneurysm detection decisive diabetic retinopathy grading also tested proposed method task publicly available Messidor database promising AUC 0.90 0.01 uncertainty achieved 'DR/non-DR'-type classification based presence absence microaneurysms .
In letter contribute multi-language handwritten digit recognition dataset named MNIST-MIX largest dataset type term language data sample . With data format MNIST MNIST-MIX seamlessly applied existing study handwritten digit recognition . By introducing digit 10 different language MNIST-MIX becomes challenging dataset imbalanced classification requires better design model . We also present result applying LeNet model pre-trained MNIST baseline .
Siamese neural network powerful architecture feature extraction metric learning . It usually consists several network share weight . The Siamese concept topology-agnostic use neural network backbone . The two popular loss function training network triplet contrastive loss function . In paper propose two novel loss function named Fisher Discriminant Triplet ( FDT ) Fisher Discriminant Contrastive ( FDC ) . The former us anchor-neighbor-distant triplet latter utilizes pair anchor-neighbor anchor-distant sample . The FDT FDC loss function designed based statistical formulation Fisher Discriminant Analysis ( FDA ) linear subspace learning method . Our experiment MNIST two challenging publicly available histopathology datasets show effectiveness proposed loss function .
It well-known box filter efficiently computed using pre-integrations local finite-differences [ Crow1984 Heckbert1986 Viola2001 ] . By generalizing idea combining non-standard variant Central Limit Theorem constant-time O ( 1 ) algorithm proposed [ Chaudhury2010 ] allowed one perform space-variant filtering using Gaussian-like kernel . The algorithm based observation isotropic anisotropic Gaussians could approximated using certain bivariate spline called box spline . The attractive feature algorithm allowed one continuously control shape size ( covariance ) filter fixed computational cost per pixel irrespective size filter . The algorithm however offered limited control covariance accuracy Gaussian approximation . In work propose improvement appropriately modifying algorithm [ Chaudhury2010 ] .
Clustering non-Euclidean data difficult one used algorithm besides hierarchical clustering popular algorithm Partitioning Around Medoids ( PAM ) also simply referred k-medoids . In Euclidean geometry mean-as used k-means-is good estimator cluster center hold arbitrary dissimilarity . PAM us medoid instead object smallest dissimilarity others cluster . This notion centrality used ( dis- ) similarity thus high relevance many domain biology require use Jaccard Gower complex distance . A key issue PAM high run time cost . We propose modification PAM algorithm achieve O ( k ) -fold speedup second SWAP phase algorithm still find result original PAM algorithm . If slightly relax choice swap performed ( comparable quality ) accelerate algorithm performing k swap iteration . With substantially faster SWAP also explore alternative strategy choosing initial medoids . We also show CLARA CLARANS algorithm benefit modification . It easily combined earlier approach use PAM CLARA big data ( use PAM subroutine hence immediately benefit improvement ) performance high k becomes increasingly important . In experiment real data k=100 observed 200-fold speedup compared original PAM SWAP algorithm making PAM applicable larger data set long afford compute distance matrix particular higher k ( k=2 new SWAP 1.5 time faster speedup expected increase k ) .
The long-tailed distribution common phenomenon real world . Extracted large scale image datasets inevitably demonstrate long-tailed property model trained imbalanced data obtain high performance over-represented category struggle under-represented category leading biased prediction performance degradation . To address challenge propose novel de-biasing method named Inverse Image Frequency ( IIF ) . IIF multiplicative margin adjustment transformation logits classification layer convolutional neural network . Our method achieves stronger performance similar work especially useful downstream task long-tailed instance segmentation produce fewer false positive detection . Our extensive experiment show IIF surpasses state art many long-tailed benchmark ImageNet-LT CIFAR-LT Places-LT LVIS reaching 55.8 % top-1 accuracy ResNet50 ImageNet-LT 26.2 % segmentation AP MaskRCNN LVIS . Code available http : //github.com/kostas1515/iif
Although Deep Neural Networks ( DNN ) become backbone technology several ubiquitous application deployment resource-constrained machine e.g . Internet Things ( IoT ) device still challenging . To satisfy resource requirement paradigm collaborative deep inference IoT synergy introduced . However distribution DNN network suffers severe data leakage . Various threat presented including black-box attack malicious participant recover arbitrary input fed device . Although many countermeasure designed achieve privacy-preserving DNN result additional computation lower accuracy . In paper present approach target security collaborative deep inference via re-thinking distribution strategy without sacrificing model performance . Particularly examine different DNN partition make model susceptible black-box threat derive amount data allocated per device hide propriety original input . We formulate methodology optimization establish trade-off latency co-inference privacy-level data . Next relax optimal solution shape approach Reinforcement Learning ( RL ) design support heterogeneous device well multiple DNNs/datasets .
We introduce model-based deep learning architecture termed MoDL-MUSSELS correction phase error multishot diffusion-weighted echo-planar MRI image . The proposed algorithm generalization existing MUSSELS algorithm similar performance significantly reduced computational complexity . In work show iterative re-weighted least-squares implementation MUSSELS alternate multichannel filter bank enforcement data consistency . The multichannel filter bank project data signal subspace thus exploiting phase relation shot . Due high computational complexity self-learned filter bank propose replace convolutional neural network ( CNN ) whose parameter learned exemplary data . The proposed CNN hybrid model involving multichannel CNN k-space another CNN image space . The k-space CNN exploit phase relation shot image image domain network used project data image manifold . The experiment show proposed scheme yield reconstruction comparable state art method offering several order magnitude reduction run-time .
What happened machine learning lately mean future medical image analysis ? Machine learning witnessed tremendous amount attention last year . The current boom started around 2009 so-called deep artificial neural network began outperforming established model number important benchmark . Deep neural network state-of-the-art machine learning model across variety area image analysis natural language processing widely deployed academia industry . These development huge potential medical imaging technology medical data analysis medical diagnostics healthcare general slowly realized . We provide short overview recent advance associated challenge machine learning applied medical image processing image analysis . As become broad fast expanding field survey entire landscape application put particular focus deep learning MRI . Our aim threefold : ( ) give brief introduction deep learning pointer core reference ; ( ii ) indicate deep learning applied entire MRI processing chain acquisition image retrieval segmentation disease prediction ; ( iii ) provide starting point people interested experimenting perhaps contributing field machine learning medical imaging pointing good educational resource state-of-the-art open-source code interesting source data problem related medical imaging .
We present adversarial framework craft perturbation mislead classifier accounting image content semantics label . The proposed framework combine structure loss semantic adversarial loss multi-task objective function train fully convolutional neural network . The structure loss help generate perturbation whose type magnitude defined target image processing filter . The semantic adversarial loss considers group ( semantic ) label craft perturbation prevent filtered image { } classified label group . We validate framework three different target filter namely detail enhancement log transformation gamma correction filter ; evaluate adversarially filtered image three classifier ResNet50 ResNet18 AlexNet pre-trained ImageNet . We show proposed framework generates filtered image high success rate robustness transferability unseen classifier . We also discus objective subjective evaluation adversarial perturbation .
The goal co-clustering simultaneously identify clustering row well column two dimensional data matrix . A number co-clustering technique proposed including information-theoretic co-clustering minimum sum-squared residue co-clustering method . However existing co-clustering algorithm designed find pairwise disjoint exhaustive co-clusters many real-world datasets contain large overlap co-clusters also outlier belong co-cluster . In paper formulate problem Non-Exhaustive Overlapping Co-Clustering row column cluster allowed overlap outlier dimension data matrix assigned cluster . To solve problem propose intuitive objective function develop efficient iterative algorithm call NEO-CC algorithm . We theoretically show NEO-CC algorithm monotonically decrease proposed objective function . Experimental result show NEO-CC algorithm able effectively capture underlying co-clustering structure real-world data thus outperforms state-of-the-art clustering co-clustering method . This manuscript includes extended analysis [ 21 ] .
The fourth industrial revolution creates ubiquitous sensor data production plant . To generate maximum value data reliable precise time series-based machine learning method like temporal neural network needed . This paper proposes novel sequence-to-sequence deep learning architecture time series segmentation called PrecTime try combine concept advantage sliding window dense labeling approach . The general-purpose architecture evaluated real-world industry dataset containing End-of-Line testing sensor data hydraulic pump . We able show PrecTime outperforms five implemented state-of-the-art baseline network based multiple metric . The achieved segmentation accuracy around 96 % show PrecTime achieve result close human intelligence operational state segmentation within testing cycle .
The interpretability deep neural network attracted increasing attention recent year several method created interpret `` black box `` model . Fundamental limitation remain however impede pace understanding network especially extraction understandable semantic space . In work introduce framework semantic explainable AI ( S-XAI ) utilizes row-centered principal component analysis obtain common trait best combination superpixels discovered genetic algorithm extract understandable semantic space basis discovered semantically sensitive neuron visualization technique . Statistical interpretation semantic space also provided concept semantic probability proposed first time . Our experimental result demonstrate S-XAI effective providing semantic interpretation CNN offer broad usage including trustworthiness assessment semantic sample searching .
Spatial transformer network ( STNs ) designed enable convolutional neural network ( CNNs ) learn invariance image transformation . STNs originally proposed transform CNN feature map well input image . This enables use complex feature predicting transformation parameter . However since STNs perform purely spatial transformation general case ability align feature map transformed image original . STNs therefore unable support invariance transforming CNN feature map . We present simple proof study practical implication showing inability coupled decreased classification accuracy . We therefore investigate alternative STN architecture make use complex feature . We find deeper localization network difficult train localization network share parameter classification network remain stable grow deeper allows higher classification accuracy difficult datasets . Finally explore interaction localization network complexity iterative image alignment .
Event camera novel bio-inspired sensor measure per-pixel brightness difference asynchronously . Recovering brightness event appealing since reconstructed image inherit high dynamic range ( HDR ) high-speed property event ; hence used many robotic vision application generate slow-motion HDR video . However state-of-the-art method tackle problem training event-to-image Recurrent Neural Network ( RNN ) lack explainability difficult tune . In work show first time tackling combined problem motion brightness estimation lead u formulate event-based image reconstruction linear inverse problem solved without training image reconstruction RNN . Instead classical learning-based regularizers used solve problem remove artifact reconstructed image . The experiment show proposed approach generates image visual quality par state-of-the-art method despite using data short time interval . State-of-the-art result achieved using image denoising Convolutional Neural Network ( CNN ) regularization function . The proposed regularized formulation solver unifying character applied also reconstruct brightness second derivative . Additionally formulation attractive naturally combined super-resolution motion-segmentation color demosaicing . Code available http : //github.com/tub-rip/event_based_image_rec_inverse_problem
In recent year several research article published field corona-virus caused disease like severe acute respiratory syndrome ( SARS ) middle east respiratory syndrome ( MERS ) COVID-19 . In presence numerous research article extracting best-suited article time-consuming manually impractical . The objective paper extract activity trend corona-virus related research article using machine learning approach . The COVID-19 open research dataset ( CORD-19 ) used experiment whereas several target-tasks along explanation defined classification based domain knowledge . Clustering technique used create different cluster available article later task assignment performed using parallel one-class support vector machine ( OCSVMs ) . Experiments original reduced feature validate performance approach . It evident k-means clustering algorithm followed parallel OCSVMs outperforms method original reduced feature space .
Finding solution classical transportation problem great importance since optimization problem arises many engineering computer science application . Especially Earth Mover 's Distance used plethora application ranging content-based image retrieval shape matching fingerprint recognition object tracking phishing web page detection computing color difference linguistics biology . Our starting point well-known revised simplex algorithm iteratively improves feasible solution optimality . The Shortlist Method propose substantially reduces number candidate inspected improving solution time balancing number pivot required . Tests simulated benchmark demonstrate considerable reduction computation time new method compared usual revised simplex algorithm implemented state-of-the-art initialization pivot strategy . As consequence Shortlist Method facilitates computation large scale transportation problem viable time . In addition describe novel method finding initial feasible solution coin Modified Russell 's Method .
This paper considers problem signal denoising using sparse tight-frame analysis prior . The L1 norm extensively used regularizer promote sparsity ; however tends under-estimate non-zero value underlying signal . To accurately estimate non-zero value propose use non-convex regularizer chosen ensure convexity objective function . The convexity objective function ensured constraining parameter non-convex penalty . We use ADMM obtain solution show guarantee ADMM converges global optimum objective function . We illustrate proposed method 1D 2D signal denoising .
Marine debris problem health marine environment human health since tiny piece plastic called `` microplastics `` resulting debris decomposition time entering food chain level . For marine debris detection removal autonomous underwater vehicle ( AUVs ) potential solution . In letter focus efficiency AUV vision real-time low-light object detection . First improved efficiency class state-of-the-art object detector namely EfficientDets 1.5 % AP D0 2.6 % AP D1 1.2 % AP D2 1.3 % AP D3 without increasing GPU latency . Subsequently created made publicly available dataset detection in-water plastic bag bottle trained improved EfficientDets another dataset marine debris detection . Finally investigated detector performance affected low-light condition compared two low-light underwater image enhancement strategy term accuracy latency . Source code dataset publicly available .
Kubelka-Munk ( K-M ) theory successfully used estimate pigment concentration pigment mixture modern painting spectral imagery . In study single-constant K-M theory utilized classification green pigment Selden Map China navigational map South China Sea likely created early seventeenth century . Hyperspectral data map collected Bodleian Library University Oxford used estimate pigment diversity spatial distribution within map . This work seek assess utility analyzing data K/S space Kubelka-Munk theory opposed traditional reflectance domain . We estimate dimensionality data extract endmembers reflectance domain . Then perform linear unmixing estimate abundance K/S space following Bai et al . ( 2017 ) perform classification abundance space . Finally due lack ground truth label classification accuracy estimated computing mean spectrum class representative signature class calculating root mean squared error pixel class create spatial representation error . This highlight magnitude spatial pattern error indicating particular pigment well modeled approach .
File type identification file type clustering may difficult task increasingly importance field computer network security . Classical method file type detection including considering file extension magic byte easily spoofed . Content-based file type detection newer way taken account recently . In paper new content-based method purpose file type detection file type clustering proposed based PCA neural network . The proposed method good accuracy fast enough .
Quantification minimization uncertainty important task design electromagnetic device come high computational effort . We propose hybrid approach combining reliability accuracy Monte Carlo analysis efficiency surrogate model based Gaussian Process Regression . We present two optimization approach . An adaptive Newton-MC reduce impact uncertainty genetic multi-objective approach optimize performance robustness time . For dielectrical waveguide used benchmark problem proposed method outperform classic approach .
Chatbot technology increasingly emerging virtual assistant . Chatbots could allow individual organization accomplish objective currently fully optimized collaboration across intergenerational context . This paper explores preference chatbots companion intergenerational innovation . The Q methodology used investigate different type collaborator determine different choice occur collaborator merge problem solution domain chatbots ' design within intergenerational setting . The study 's finding reveal various chatbot design priority diverse among younger adult senior adult . Additionally research outline principle chatbot design chatbots support generation . This research first step towards cultivating deeper understanding different age group ' subjective design preference chatbots functioning companion workplace . Moreover study demonstrates Q methodology guide technological development shifting approach age-focused design common goal-oriented design within multigenerational context .
The social medium network phenomenon lead massive amount valuable data available online easy access . Many user share image video comment review news opinion different social network site Twitter one popular one . Data collected Twitter highly unstructured extracting useful information tweet challenging task . Twitter huge number Arabic user mostly post write tweet using Arabic language . While lot research sentiment analysis English amount research datasets Arabic language limited . This paper introduces Arabic language dataset opinion health service collected Twitter . The paper first detail process collecting data Twitter also process filtering pre-processing annotating Arabic text order build big sentiment analysis dataset Arabic . Several Machine Learning algorithm ( Naive Bayes Support Vector Machine Logistic Regression ) alongside Deep Convolutional Neural Networks utilized experiment sentiment analysis health dataset .
Fine-tuning pre-trained language model ( PLMs ) demonstrated effectiveness various downstream NLP task recently . However many low-resource scenario conventional fine-tuning strategy sufficiently capture important semantic feature downstream task . To address issue introduce novel framework ( named `` CSS-LM `` ) improve fine-tuning phase PLMs via contrastive semi-supervised learning . Specifically given specific task retrieve positive negative instance large-scale unlabeled corpus according domain-level class-level semantic relatedness task . We perform contrastive semi-supervised learning retrieved unlabeled original labeled instance help PLMs capture crucial task-related semantic feature . The experimental result show CSS-LM achieves better result conventional fine-tuning strategy series downstream task few-shot setting outperforms latest supervised contrastive fine-tuning strategy . Our datasets source code available provide detail .
We extend previous work Inductive Conformal Prediction ( ICP ) multi-label text classification present novel approach addressing computational inefficiency Label Powerset ( LP ) ICP arrising dealing high number unique label . We present experimental result using original proposed efficient LP-ICP two English one Czech language data-sets . Specifically apply LP-ICP three deep Artificial Neural Network ( ANN ) classifier two type : one based contextualised ( bert ) two non-contextualised ( word2vec ) word-embeddings . In LP-ICP setting assign nonconformity score label-sets corresponding p-values prediction-sets determined . Our approach deal increased computational burden LP eliminating consideration significant number label-sets surely p-values specified significance level . This reduces dramatically computational complexity approach fully respecting standard CP guarantee . Our experimental result show contextualised-based classifier surpasses non-contextualised-based one obtains state-of-the-art performance data-sets examined . The good performance underlying classifier carried ICP counterpart without significant accuracy loss added benefit ICP i.e . confidence information encapsulated prediction set . We experimentally demonstrate resulting prediction set tight enough practically useful even though set possible label-sets contains $ 1e+16 $ combination . Additionally empirical error rate obtained prediction-sets confirm output well-calibrated .
Continual learning deep neural network key requirement scaling complex applicative scenario achieving real lifelong learning architecture . Previous approach problem considered either progressive increase size network tried regularize network behavior equalize respect previously observed task . In latter case essential understand type information best represents past behavior . Common technique include regularizing past output gradient individual weight . In work propose new relatively simple efficient method perform continual learning regularizing instead network internal embeddings . To make approach scalable also propose dynamic sampling strategy reduce memory footprint required external storage . We show method performs favorably respect state-of-the-art approach literature requiring significantly less space memory computational time . In addition inspired inspired recent work evaluate impact selecting flexible model activation function inside network evaluating impact catastrophic forgetting activation function .
Applications like disaster management industrial inspection often require expert enter contaminated place . To circumvent need physical presence desirable generate fully immersive individual live teleoperation experience . However standard video-based approach suffer limited degree immersion situation awareness due restriction camera view impact navigation . In paper present novel VR-based practical system immersive robot teleoperation scene exploration . While operated scene robot capture RGB-D data streamed SLAM-based live multi-client telepresence system . Here global 3D model already captured scene part reconstructed streamed individual remote user client rendering e.g . head-mounted display device ( HMDs ) performed . We introduce novel lightweight robot client component transmits robot-specific data enables quick integration existing robotic system . This way contrast first-person exploration system operator explore navigate remote site completely independent current position view capturing robot complementing traditional input device teleoperation . We provide proof-of-concept implementation demonstrate capability well performance system regarding interactive object measurement bandwidth-efficient data streaming visualization . Furthermore show benefit purely video-based teleoperation user study revealing higher degree situation awareness precise navigation challenging environment .
We present new approach video-driven animation high-quality neural 3D head model addressing challenge person-independent animation video input . Typically high-quality generative model learned specific individual multi-view video footage resulting person-specific latent representation drive generation process . In order achieve person-independent animation video input introduce LSTM-based animation network capable translating person-independent expression feature personalized animation parameter person-specific 3D head model . Our approach combine advantage personalized head model ( high quality realism ) convenience video-driven animation employing multi-person facial performance capture . We demonstrate effectiveness approach synthesized animation high quality based different source video well ablation study .
With advance seen deep learning voice-based application burgeoning ranging personal assistant affective computing remote disease diagnostics . As voice contains linguistic para-linguistic information ( e.g . vocal pitch intonation speech rate loudness ) growing interest voice anonymization preserve speaker privacy identity . Voice privacy challenge emerged last year focus placed removing speaker identity keeping linguistic content intact . For affective computing disease monitoring application however para-linguistic content may critical . Unfortunately effect anonymization may system still largely unknown . In paper fill gap focus one particular health monitoring application : speech-based COVID-19 diagnosis . We test three anonymization method impact five different state-of-the-art COVID-19 diagnostic system using three public datasets . We validate effectiveness anonymization method compare computational complexity quantify impact across different testing scenario within- across-dataset condition . Additionally provided comprehensive evaluation importance different speech aspect diagnostics showed affected different type anonymizers . Lastly show benefit using anonymized external data data augmentation tool help recover COVID-19 diagnostic accuracy loss seen anonymization .
Machine learning based system reaching society large many aspect everyday life . This phenomenon accompanied concern ethical issue may arise adoption technology . ML fairness recently established area machine learning study ensure bias data model inaccuracy lead model treat individual unfavorably basis characteristic e.g . race gender disability sexual political orientation . In manuscript discus limitation present current reasoning fairness method deal describe work done author address . More specifically show causal Bayesian network play important role reason deal fairness especially complex unfairness scenario . We describe optimal transport theory used develop method impose constraint full shape distribution corresponding different sensitive attribute overcoming limitation approach approximate fairness desideratum imposing constraint lower order moment function distribution . We present unified framework encompasses method deal different setting fairness criterion enjoys strong theoretical guarantee . We introduce approach learn fair representation generalize unseen task . Finally describe technique account legal restriction use sensitive attribute .
Cross-domain pedestrian detection aim generalize pedestrian detector one label-rich domain another label-scarce domain crucial various real-world application . Most recent work focus domain alignment train domain-adaptive detector either instance level image level . From practical point view one-stage detector faster . Therefore concentrate designing cross-domain algorithm rapid one-stage detector lack instance-level proposal perform image-level feature alignment . However pure image-level feature alignment cause foreground-background misalignment issue arise i.e . foreground feature source domain image falsely aligned background feature target domain image . To address issue systematically analyze importance foreground background image-level cross-domain alignment learn background play critical role image-level cross-domain alignment . Therefore focus cross-domain background feature alignment minimizing influence foreground feature cross-domain alignment stage . This paper proposes novel framework namely background-focused distribution alignment ( BFDA ) train domain adaptive onestage pedestrian detector . Specifically BFDA first decouples background feature whole image feature map aligns via novel long-short-range discriminator .
A recently introduced classifier called SS3 shown well suited deal early risk detection ( ERD ) problem text stream . It obtained state-of-the-art performance early depression anorexia detection Reddit CLEF 's eRisk open task . SS3 created deal ERD problem naturally since : support incremental training classification text stream visually explain rationale . However SS3 process input using bag-of-word model lacking ability recognize important word sequence . This aspect could negatively affect classification performance also reduces descriptiveness visual explanation . In standard document classification field common use word n-grams try overcome limitation . Unfortunately working text stream using n-grams trivial since system must learn recognize n-grams important `` fly `` . This paper introduces t-SS3 extension SS3 allows recognize useful pattern text stream dynamically . We evaluated model eRisk 2017 2018 task early depression anorexia detection . Experimental result suggest t-SS3 able improve current result richness visual explanation .
Given lack word delimiters written Japanese word segmentation generally considered crucial first step processing Japanese text . Typical Japanese segmentation algorithm rely either lexicon syntactic analysis pre-segmented data ; labor-intensive lexico-syntactic technique vulnerable unknown word problem . In contrast introduce novel robust statistical method utilizing unsegmented training data . Despite simplicity algorithm yield performance long kanji sequence comparable sometimes surpassing state-of-the-art morphological analyzer variety error metric . The algorithm also outperforms another mostly-unsupervised statistical algorithm previously proposed Chinese . Additionally present two-level annotation scheme Japanese incorporate multiple segmentation granularity introduce two novel evaluation metric based notion compatible bracket account multiple granularity simultaneously .
A framework proposed generative model basis digital twin mirror structure . The proposal based premise deterministic model account uncertainty present structural modelling application . Two different type generative model considered . The first physics-based model based stochastic finite element ( SFE ) method widely used modelling structure material loading uncertainty imposed . Such model calibrated according data structure would expected outperform model modelling accurately capture true underlying physic structure . The potential use SFE model digital mirror illustrated via application linear structure stochastic material property . For situation physical formulation model suffice data-driven framework proposed using machine learning conditional generative adversarial network ( cGANs ) . The latter algorithm used learn distribution quantity interest structure material nonlinearities uncertainty . For example considered work data-driven cGANs model outperform physics-based approach . Finally example shown two method coupled hybrid model approach demonstrated .
Social norm support coordination cooperation society . With social robot becoming increasingly involved society also need follow social norm society . This paper present computational framework learning context social norm present context online manner robot . The paper utilizes recent state-of-the-art approach incremental learning adapts online learning scene ( context ) . The paper utilizes Dempster-Schafer theory model context-specific norm . After learning scene ( context ) use active learning learn related norm . We test approach Pepper robot taking different scene location . Our result show Pepper learn different scene related norm simply communicating human partner online manner .
Although agreement annotator studied past statistical viewpoint little work attempted quantify extent phenomenon affect evaluation computer vision ( CV ) object detection algorithm . Many researcher utilise ground truth ( GT ) experiment often GT derived one annotator 's opinion . How difference opinion affect algorithm 's evaluation ? Four example typical CV problem chosen methodology applied quantify inter-annotator variance offer insight mechanism behind agreement use GT . It found detecting linear object annotator agreement low . The agreement object position linear otherwise partially explained basic image property . Automatic object detector compared annotator agreement found clear relationship exists . Several method calculating GTs number annotation applied resulting difference performance object detector quantified . It found rank detector highly dependent upon method used form GT . It also found although STAPLE LSML GT estimation method appear represent mean performance measured using individual annotation annotation large variance estimate tend degrade . Furthermore one commonly adopted annotation combination method -- consensus voting -- accentuates obvious feature result overestimation algorithm 's performance . Finally concluded datasets may possible state confidence one algorithm outperforms another evaluating upon one GT method calculating confidence bound discussed .
Breast lesion localization using tactile imaging new developing direction medical science . To achieve goal proper image reconstruction image registration valuable asset . In paper new approach segmentation-based image surface reconstruction algorithm used reconstruct surface breast phantom . In breast tissue sub-dermal vein network used distinguishable pattern reconstruction . The proposed image capturing device contact surface phantom surface deformation occur due applied force time scanning . A novel force based surface rectification system used reconstruct deformed surface image original structure . For construction full surface rectified image advanced affine scale-invariant feature transform ( A-SIFT ) proposed reduce affine effect time data capturing . Camera position based image stitching approach applied construct final original non-rigid surface . The proposed model validated theoretical model real scenario demonstrate advantage respect competing method . The result proposed method applied path reconstruction end positioning accuracy 99.7 %
The development unmanned aerial vehicle ( UAVs ) gaining momentum recent year owing technological advance significant reduction cost . UAV technology used wide range domain including communication agriculture security transportation . It may useful group UAVs clusters/flocks certain domain various challenge associated UAV usage alleviated clustering . Several computational challenge arise UAV flock management solved using machine learning ( ML ) method . In survey describe basic term relating UAVS modern ML method provide overview related tutorial survey . We subsequently consider different challenge appear UAV flock . For issue survey several machine learning-based method suggested literature handle associated challenge . Thereafter describe various open issue ML applied solve different challenge flock suggest mean using ML method purpose . This comprehensive review may useful researcher developer providing wide view various aspect state-of-the-art ML technology applicable flock management .
In paper work intra-variable handwriting writing sample individual vary significantly . Such within-writer variation throw challenge automatic writer inspection state-of-the-art method perform well . To deal intra-variability analyze idiosyncrasy individual handwriting . We identify/verify writer highly idiosyncratic text-patches . Such patch detected using deep recurrent reinforcement learning-based architecture . An idiosyncratic score assigned every patch predicted employing deep regression analysis . For writer identification propose deep neural architecture make final decision idiosyncratic score-induced weighted average patch-based decision . For writer verification propose two algorithm patch-fed deep feature aggregation assist authentication using triplet network . The experiment performed two database obtained encouraging result .
Task-oriented dialogue system ( TODS ) continuing rise popularity various industry find way effectively harness capability saving time money . However even state-of-the-art TODS yet reaching full potential . TODS typically primary design focus completing task hand metric task-resolution take priority . Other conversational quality attribute may point success otherwise dialogue may ignored . This cause interaction human dialogue system leave user dissatisfied frustrated . This paper explores literature evaluative framework dialogue system role conversational quality attribute dialogue system looking utilised examining correlation performance dialogue system .
The goal Author Profiling ( AP ) identify demographic aspect ( e.g . age gender ) given set author analyzing written text . Recently AP task gained interest many problem related computer forensics psychology marketing specially related social medium exploitation . As known social medium data shared wide range modality ( e.g . text image audio ) representing valuable information exploited extracting valuable insight user . Nevertheless current work AP using social medium data devoted analyze textual information work started exploring gender identification using visual information . Contrastingly paper focus exploiting visual modality perform age gender identification social medium specifically Twitter . Our goal evaluate pertinence using visual information solving AP task . Accordingly extended Twitter corpus PAN 2014 incorporating posted image user making distinction tweeted retweeted image . Performed experiment provide interesting evidence usefulness visual information comparison traditional textual representation AP task .
In training neural network common practice use partial gradient computed batch mostly small subset training set . This approach motivated argument partial gradient close true one precision growing square root batch size . A theoretical justification help stochastic approximation theory . However condition validity theory satisfied usual learning rate schedule . Batch processing also difficult combine efficient second-order optimization method . This proposal based another hypothesis : loss minimum training set expected well-approximated minimum subset . Such subset minimum computed fraction time necessary optimizing whole training set . This hypothesis tested help MNIST CIFAR-10 CIFAR-100 image classification benchmark optionally extended training data augmentation . The experiment confirmed result equivalent conventional training reached . In summary even small subset representative overdetermination ratio given model parameter set sufficiently exceeds unity . The computing expense reduced tenth less .
Intra-class compactness inter-class separability crucial indicator measure effectiveness model produce discriminative feature intra-class compactness indicates close feature label inter-class separability indicates far away feature different label . In work investigate intra-class compactness inter-class separability feature learned convolutional network propose Gaussian-based softmax ( $ \mathcal { G } $ -softmax ) function effectively improve intra-class compactness inter-class separability . The proposed function simple implement easily replace softmax function . We evaluate proposed $ \mathcal { G } $ -softmax function classification datasets ( i.e . CIFAR-10 CIFAR-100 Tiny ImageNet ) multi-label classification datasets ( i.e . MS COCO NUS-WIDE ) . The experimental result show proposed $ \mathcal { G } $ -softmax function improves state-of-the-art model across evaluated datasets . In addition analysis intra-class compactness inter-class separability demonstrates advantage proposed function softmax function consistent performance improvement . More importantly observe high intra-class compactness inter-class separability linearly correlated average precision MS COCO NUS-WIDE . This implies improvement intra-class compactness inter-class separability would lead improvement average precision .
We study involuntary micro-movements eye biometric identification . While prior study extract lower-frequency macro-movements output video-based eye-tracking system engineer explicit feature macro-movements develop deep convolutional architecture process raw eye-tracking signal . Compared prior work network attains lower error rate one order magnitude faster two order magnitude : identifies user accurately within second .
The collection analysis kidney stone morphological criterion essential aetiological diagnosis stone disease . However in-situ LASER-based fragmentation urinary stone established chirurgical intervention may destroy morphology targeted stone . In current study assess performance added value processing complete digital endoscopic video sequence automatic recognition stone morphological feature standard-of-care intra-operative session . To end computer-aided video classifier developed predict in-situ morphology stone using intra-operative digital endoscopic video acquired clinical setting . The proposed technique evaluated pure ( i.e . include one morphology ) mixed ( i.e . include least two morphology ) stone involving `` Ia/Calcium Oxalate Monohydrate ( COM ) `` `` IIb/ Calcium Oxalate Dihydrate ( COD ) `` `` IIIb/Uric Acid ( UA ) `` morphology . 71 digital endoscopic video ( 50 exhibited one morphological type 21 displayed two ) analyzed using proposed video classifier ( 56840 frame processed total ) . Using proposed approach diagnostic performance ( averaged pure mixed stone type ) follows : balanced accuracy=88 % sensitivity=80 % specificity=95 % precision=78 % F1-score=78 % . The obtained result demonstrate AI applied digital endoscopic video sequence promising tool collecting morphological information time-course stone fragmentation process without resorting human intervention stone delineation selection good quality steady frame . To end irrelevant image information must removed prediction process frame pixel level feasible thanks use AI-dedicated network .
Person identification based eye movement getting attention anti-spoofing resistant useful continuous authentication . Therefore noteworthy researcher know relevant field including author journal conference institution . This paper present comprehensive quantitative overview field eye movement biometrics using bibliometric approach . All data analysis based document written English published 2004 2019 . Scopus used perform information retrieval . This research focused temporal evolution leading author cited paper leading journal competition collaboration network .
The aquaculture sector New Zealand experiencing rapid expansion particular emphasis mussel export . As demand mussel farming operation continue evolve integration artificial intelligence computer vision technique intelligent object detection emerging effective approach enhance operational efficiency . This study delf advancing buoy detection leveraging deep learning methodology intelligent mussel farm monitoring management . The primary objective center improving accuracy robustness detecting buoy across spectrum real-world scenario . A diverse dataset sourced mussel farm captured labeled training encompassing imagery taken camera mounted floating platform traversing vessel capturing various lighting weather condition . To establish effective deep learning model buoy detection limited number labeled data employ transfer learning technique . This involves adapting pre-trained object detection model create specialized deep learning buoy detection model . We explore different pre-trained model including YOLO variant alongside data diversity investigate effect model performance . Our investigation demonstrates significant enhancement buoy detection performance deep learning accompanied improved generalization across diverse weather condition highlighting practical effectiveness approach .
We introduce method modeling configuration object 2D 3D image using mathematical `` skeletal linking structure `` simultaneously capture individual shape feature object positional information relative one another . The object may either smooth boundary disjoint others share common portion boundary object piecewise smooth manner . These structure include special class `` Blum medial linking structure `` intrinsically associated configuration build upon Blum medial ax individual object . We give classification property Blum linking structure generic configuration . The skeletal linking structure add increased flexibility modeling configuration object relaxing Blum condition extend minimal way individual `` skeletal structure `` previously used modeling individual object capturing geometric property . This allows mathematical method introduced single object significantly extended entire configuration object . These method capture internal shape structure individual object also external structure neighboring region object .
A robust efficient anomaly detection technique proposed capable dealing crowded scene traditional tracking based approach tend fail . Initial foreground segmentation input frame confines analysis foreground object effectively ignores irrelevant background dynamic . Input frame split non-overlapping cell followed extracting feature based motion size texture cell . Each feature type independently analysed presence anomaly . Unlike method refined estimate object motion achieved computing optical flow foreground pixel . The motion size feature modelled approximated version kernel density estimation computationally efficient even large training datasets . Texture feature modelled adaptively grown codebook number entry codebook selected online fashion . Experiments recently published UCSD Anomaly Detection dataset show proposed method obtains considerably better result three recent approach : MPPCA social force mixture dynamic texture ( MDT ) . The proposed method also several order magnitude faster MDT next best performing method .
Security incident targeted distributed denial service ( DDoS ) attack power grid hacking factory industrial control system ( ICS ) increase . This paper unpacks emerging security risk lie industrial internet thing drawing technical regulatory perspective . Legal change ushered European Union ( EU ) Network Information Security ( NIS ) Directive 2016 General Data Protection Regulation 2016 ( GDPR ) ( enforced May 2018 ) . We use case study emergent smart energy supply chain frame scope consolidate breadth security concern play regulatory response . We argue industrial IoT brings four security concern fore namely : appreciating shift offline online infrastructure ; managing temporal dimension security ; addressing implementation gap best practice ; engaging infrastructural complexity . Our goal surface risk foster dialogue avoid emergence Internet Insecure Industrial Things
Cost-Sensitive Online Classification drawn extensive attention recent year main approach directly online optimize two well-known cost-sensitive metric : ( ) weighted sum sensitivity specificity ; ( ii ) weighted misclassification cost . However previous existing method considered first-order information data stream . It insufficient practice since many recent study proved incorporating second-order information enhances prediction performance classification model . Thus propose family cost-sensitive online classification algorithm adaptive regularization paper . We theoretically analyze proposed algorithm empirically validate effectiveness property extensive experiment . Then better trade performance efficiency introduce sketching technique algorithm significantly accelerates computational speed quite slight performance loss . Finally apply algorithm tackle several online anomaly detection task real world . Promising result prove proposed algorithm effective efficient solving cost-sensitive online classification problem various real-world domain .
Knowledge graph ( KGs ) structured form knowledge representation widely applied real world . Recently few-shot knowledge graph completion ( FKGC ) aim predict missing fact unseen relation few-shot associated fact attracted increasing attention practitioner researcher . However existing FKGC method based metric learning meta-learning often suffer out-of-distribution overfitting problem . Meanwhile incompetent estimating uncertainty prediction critically important model prediction could unreliable few-shot setting . Furthermore handle complex relation ignore path information KGs largely limit performance . In paper propose normalizing flow-based neural process few-shot knowledge graph completion ( NP-FKGC ) . Specifically unify normalizing flow neural process model complex distribution KG completion function . This offer novel way predict fact few-shot relation estimating uncertainty . Then propose stochastic ManifoldE decoder incorporate neural process handle complex relation few-shot setting . To improve performance introduce attentive relation path-based graph neural network capture path information KGs . Extensive experiment three public datasets demonstrate method significantly outperforms existing FKGC method achieves state-of-the-art performance . Code available http : //github.com/RManLuo/NP-FKGC.git .
Recently pre-trained language representation model bidirectional encoder representation transformer ( BERT ) performing well commonsense question answering ( CSQA ) . However problem model directly use explicit information knowledge source existing outside . To augment additional method knowledge-aware graph network ( KagNet ) multi-hop graph relation network ( MHGRN ) proposed . In study propose use latest pre-trained language model lite bidirectional encoder representation transformer ( ALBERT ) knowledge graph information extraction technique . We also propose applying novel method schema graph expansion recent language model . Then analyze effect applying knowledge graph-based knowledge extraction technique recent pre-trained language model confirm schema graph expansion effective extent . Furthermore show proposed model achieve better performance existing KagNet MHGRN model CommonsenseQA dataset .
Pharmaceutical company relying often external source innovation boost discovery research productivity . However in-depth knowledge external innovation may translate successful product launch still required order better understand best leverage innovation ecosystem . We analyzed pre-approval publication history FDA-approved new molecular entity ( NMEs ) new biologic entity ( NBEs ) launched 13 top research pharma company last decade ( 2006-2016 ) . We found academic institution contributed majority pre-approval publication publication subject matter closely aligned strength respective innovator . We found also true candidate drug terminated Phase 3 volume literature molecule substantially less approved drug . This may suggest approved drug often associated robust dataset provided large number institute . Collectively result analysis support hypothesis collaborative research innovation environment spanning across academia industry government highly conducive successful drug approval .
Digital agent considered general-purpose technology . They spread quickly private organizational context including education . Yet research lack conceptual framing describe interaction agent holistic manner . While focusing interaction pedagogical agent i.e . digital agent capable natural-language interaction learner propose model learning activity based activity theory . We use model review prior research digital agent education analyze various characteristic activity including feature pedagogical agent learner influence learning outcome . The analysis lead identification IS research direction guidance developer pedagogical agent digital agent general . We conclude extending activity theory-based model beyond context education show help designer researcher ask right question creating digital agent .
Magnitude-based pruning technique used optimise deep learning model edge inference . We achieved 75 % model size reduction higher accuracy original multi-output regression model head-pose estimation .
Humans learn language interaction environment listening human . It also possible computational model learn language directly speech far approach require text . We improve existing neural network approach create visually grounded embeddings spoken utterance . Using combination multi-layer GRU importance sampling cyclic learning rate ensembling vectorial self-attention result show remarkable increase image-caption retrieval performance previous work . Furthermore investigate layer model learn recognise word input . We find deeper network layer better encoding word presence although final layer slightly lower performance . This show visually grounded sentence encoder learns recognise word input even though explicitly trained word recognition .
It difficult find optimal sparse solution manifold learning based dimensionality reduction algorithm . The lasso elastic net penalized manifold learning based dimensionality reduction directly lasso penalized least square problem thus least angle regression ( LARS ) ( Efron et al . \cite { LARS } ) one popular algorithm sparse learning applied . Therefore current approach take indirect way strict setting inconvenient application . In paper proposed manifold elastic net MEN short . MEN incorporates merit manifold learning based dimensionality reduction sparse learning based dimensionality reduction . By using series equivalent transformation show MEN equivalent lasso penalized least square problem thus LARS adopted obtain optimal sparse solution MEN . In particular MEN following advantage subsequent classification : 1 ) local geometry sample well preserved low dimensional data representation 2 ) margin maximization classification error minimization considered sparse projection calculation 3 ) projection matrix MEN improves parsimony computation 4 ) elastic net penalty reduces over-fitting problem 5 ) projection matrix MEN interpreted psychologically physiologically . Experimental evidence face recognition various popular datasets suggests MEN superior top level dimensionality reduction algorithm .
We study neural network compress uninformative input space model data lie $ $ dimension whose label vary within linear manifold dimension $ d_\parallel < $ . We show one-hidden layer network initialized infinitesimal weight ( i.e . feature learning regime ) trained gradient descent first layer weight evolve become nearly insensitive $ d_\perp=d-d_\parallel $ uninformative direction . These effectively compressed factor $ \lambda\sim \sqrt { p } $ $ p $ size training set . We quantify benefit compression test error $ \epsilon $ . For large initialization weight ( lazy training regime ) compression occurs regular boundary separating label find $ \epsilon \sim p^ { -\beta } $ $ \beta_\text { Lazy } = / ( 3d-2 ) $ . Compression improves learning curve $ \beta_\text { Feature } = ( 2d-1 ) / ( 3d-2 ) $ $ d_\parallel = 1 $ $ \beta_\text { Feature } = ( + d_\perp/2 ) / ( 3d-2 ) $ $ d_\parallel > 1 $ . We test prediction stripe model boundary parallel interface ( $ d_\parallel=1 $ ) well cylindrical boundary ( $ d_\parallel=2 $ ) . Next show compression shape Neural Tangent Kernel ( NTK ) evolution time top eigenvectors become informative display larger projection label . Consequently kernel learning frozen NTK end training outperforms initial NTK . We confirm prediction one-hidden layer FC network trained stripe model 16-layers CNN trained MNIST also find $ \beta_\text { Feature } > \beta_\text { Lazy } $ .
Generating high fidelity identity-preserving face different facial attribute wide range application . Although number generative model developed tackle problem still much room improvement.In paticular current solution usually ignore perceptual information image argue benefit output high-quality image preserving identity information especially facial attribute learning area.To end propose train GAN iteratively via regularizing min-max process integrated loss includes per-pixel loss also perceptual loss . In contrast existing method deal either image generation transformation proposed iterative architecture achieve . Experiments multi-label facial dataset CelebA demonstrate proposed model excellent performance recognizing multiple attribute generating high-quality image transforming image controllable attribute .
In work propose novel technique obtaining descriptor gray-level texture image . The descriptor provided applying multiscale transform fractal dimension image estimated probability ( Voss ) method . The effectiveness descriptor verified classification task using benchmark texture datasets . The result obtained demonstrate efficiency proposed method tool description discrimination texture image .
Colorectal polyp important precursor colon cancer major health problem . Colon capsule endoscopy ( CCE ) safe minimally invasive examination procedure image intestine obtained via digital camera board small capsule ingested patient . The video sequence analyzed presence polyp . We propose algorithm relief labor human operator analyzing frame video sequence . The algorithm act binary classifier label frame either containing polyp based geometrical analysis texture content frame . The geometrical analysis based segmentation image help mid-pass filter . The feature extracted segmentation procedure classified according assumption polyp characterized protrusion mostly round shape . Thus use best fit ball radius decision parameter binary classifier . We present statistical study performance approach data set containing 18900 frame endoscopic video sequence five adult patient . The algorithm demonstrates solid performance achieving 47 % sensitivity per frame 81 % sensitivity per polyp specificity level 90 % . On average video sequence length 3747 frame 367 false positive frame need inspected human operator .
Autonomous game design generating game algorithmically longtime goal within technical game research field . However existing autonomous game design system relied large part human-authoring game design knowledge fitness function search-based method . In paper describe experiment attempt learn human-like fitness function autonomous game design adversarial manner . While experimental work meet expectation present analysis system result hope informative future autonomous game design research .
Quaternion space brought several benefit traditional Euclidean space : Quaternions ( ) consist real three imaginary component encouraging richer representation ; ( ii ) utilize Hamilton product better encodes inter-latent interaction across multiple Quaternion component ; ( iii ) result model smaller degree freedom less prone overfitting . Unfortunately current recommender system rely real-valued representation Euclidean space model either user 's long-term short-term interest . In paper fully utilize Quaternion space model user 's long-term short-term preference . We first propose QUaternion-based self-Attentive Long term user Encoding ( QUALE ) study user 's long-term intent . Then propose QUaternion-based self-Attentive Short term user Encoding ( QUASE ) learn user 's short-term interest . To enhance model ' capability propose fuse QUALE QUASE one model namely QUALSE using Quaternion-based gating mechanism . We develop Quaternion-based Adversarial learning along Bayesian Personalized Ranking ( QABPR ) improve model 's robustness . Extensive experiment six real-world datasets show fused QUALSE model outperformed 11 state-of-the-art baseline improving 8.43 % HIT @ 1 10.27 % NDCG @ 1 average compared best baseline .
Recently video-based action recognition method using convolutional neural network ( CNNs ) achieve remarkable recognition performance . However still lack understanding generalization mechanism action recognition model . In paper suggest action recognition model rely motion information less expected thus robust randomization frame order . Furthermore find motion monotonicity remaining randomization also contributes robustness . Based observation develop novel defense method using temporal shuffling input video adversarial attack action recognition model . Another observation enabling defense method adversarial perturbation video sensitive temporal destruction . To best knowledge first attempt design defense method without additional training 3D CNN-based video action recognition model .
Safe operation machine learning model requires architecture explicitly delimit operational range . We evaluate ability anomaly detection algorithm provide indicator correlated degraded model performance . By placing acceptance threshold indicator hard boundary formed define model 's coverage . As use case consider extraction exoplanetary spectrum transit light curve specifically within context ESA 's upcoming Ariel mission . Isolation Forests shown effectively identify context prediction model likely fail . Coverage/error trade-off evaluated condition data concept drift . The best performance seen Isolation Forests model projection prediction model 's explainability SHAP value .
In paper performance three deep learning method predicting short-term evolution reproducing long-term statistic multi-scale spatio-temporal Lorenz 96 system examined . The method : echo state network ( type reservoir computing RC-ESN ) deep feed-forward artificial neural network ( ANN ) recurrent neural network long short-term memory ( RNN-LSTM ) . This Lorenz 96 system three tier nonlinearly interacting variable representing slow/large-scale ( $ X $ ) intermediate ( $ Y $ ) fast/small-scale ( $ Z $ ) process . For training testing $ X $ available ; $ Y $ $ Z $ never known used . We show RC-ESN substantially outperforms ANN RNN-LSTM short-term prediction e.g . accurately forecasting chaotic trajectory hundred numerical solver 's time step equivalent several Lyapunov timescales . The RNN-LSTM ANN show prediction skill well ; RNN-LSTM best ANN . Furthermore even losing trajectory data predicted RC-ESN RNN-LSTM probability density function ( PDFs ) closely match true PDF even tail . The PDF data predicted using ANN however deviate true PDF . Implications caveat application data-driven data-assisted surrogate modeling complex nonlinear dynamical system weather/climate discussed .
Accurate prediction crop yield harvest great importance crop logistics market planning food distribution around world . Yield prediction requires monitoring phenological climatic characteristic extended time period model complex relation involved crop development . Remote sensing satellite image provided various satellite circumnavigating world cheap reliable way obtain data yield prediction . The field yield prediction currently dominated Deep Learning approach . While accuracy reached approach promising needed amount data `` black-box `` nature restrict application Deep Learning method . The limitation overcome proposing pipeline process remote sensing image feature-based representation allow employment Extreme Gradient Boosting ( XGBoost ) yield prediction . A comparative evaluation soybean yield prediction within United States show promising prediction accuracy compared state-of-the-art yield prediction system based Deep Learning . Feature importance expose near-infrared spectrum light important feature within model . The reported result hint capability XGBoost yield prediction encourage future experiment XGBoost yield prediction crop region around world .
Image compression fundamental technology Internet communication engineering . However high compression rate general method may degrade image resulting unreadable text . In paper propose image compression method maintaining text quality . We developed scene text image quality assessment model assess text quality compressed image . The assessment model iteratively search best-compressed image holding high-quality text . Objective subjective result showed proposed method superior existing method . Furthermore proposed assessment model outperformed deep-learning regression model .
Web Data Extraction important problem studied mean different scientific tool broad range application . Many approach extracting data Web designed solve specific problem operate ad-hoc domain . Other approach instead heavily reuse technique algorithm developed field Information Extraction . This survey aim providing structured comprehensive overview literature field Web Data Extraction . We provided simple classification framework existing Web Data Extraction application grouped two main class namely application Enterprise level Social Web level . At Enterprise level Web Data Extraction technique emerge key tool perform data analysis Business Competitive Intelligence system well business process re-engineering . At Social Web level Web Data Extraction technique allow gather large amount structured data continuously generated disseminated Web 2.0 Social Media Online Social Network user offer unprecedented opportunity analyze human behavior large scale . We discus also potential cross-fertilization i.e . possibility re-using Web Data Extraction technique originally designed work given domain domain .
This paper proposes simple yet effective method learn hierarchical object shape model consisting local contour fragment represents category shape form And-Or tree . This model extends traditional hierarchical tree structure introducing `` switch `` variable ( i.e . or-nodes ) explicitly specify production rule capture shape variation . We thus define model three layer : leaf-nodes detecting local contour fragment or-nodes specifying selection leaf-nodes root-node encoding holistic distortion . In training stage optimization And-Or tree learning extend concave-convex procedure ( CCCP ) embedding structural clustering iterative learning step . The inference shape detection consistent model optimization integrates local testing via leaf-nodes or-nodes global verification via root-node . The advantage approach validated challenging shape database ( i.e . ETHZ INRIA Horse ) summarized follows . ( 1 ) The proposed method able accurately localize shape contour unreliable edge detection edge tracing . ( 2 ) The And-Or tree model enables u well capture intraclass variance .
Distance function main metric measuring affinity two data point machine learning . Extant distance function often provide unreachable distance value real application . This lead incorrect measure affinity data point . This paper proposes reachable distance function KNN classification . The reachable distance function geometric direct-line distance two data point . It give consideration class attribute training dataset measuring affinity data point . Concretely speaking reachable distance data point includes class center distance real distance . Its shape look like `` Z `` also call Z distance function . In way affinity data point class always stronger different class . Or intraclass data point always closer interclass data point . We evaluated reachable distance experiment demonstrated proposed distance function achieved better performance KNN classification .
Co-creative Procedural Content Generation via Machine Learning ( PCGML ) refers system PCGML agent human work together produce output content . One limitation co-creative PCGML requires co-creative training data PCGML agent learn interact human . However acquiring data difficult time-consuming process . In work propose approximating human-AI interaction data employing transfer learning adapt learned co-creative knowledge one game different game . We explore approach co-creative Zelda dungeon room generation .
The protection private information crucial issue data-driven research business context . Typically technique like anonymisation ( selective ) deletion introduced order allow data sharing e. g. case collaborative research endeavour . For use anonymisation technique $ k $ -anonymity criterion one popular numerous scientific publication different algorithm metric . Anonymisation technique often require changing data thus necessarily affect result machine learning model trained underlying data . In work conduct systematic comparison detailed investigation effect different $ k $ -anonymisation algorithm result machine learning model . We investigate set popular $ k $ -anonymisation algorithm different classifier evaluate different real-world datasets . Our systematic evaluation show increasingly strong $ k $ -anonymity constraint classification performance generally degrades varying degree strongly depending dataset anonymisation method . Furthermore Mondrian considered method appealing property subsequent classification .
Biomedical research yield wealth information much accessible literature . Consequently literature search essential tool building prior knowledge clinical biomedical research . Although recent improvement artificial intelligence expanded functionality beyond keyword-based search advance may unfamiliar clinician researcher . In response present survey literature search tool tailored general specific information need biomedicine objective helping reader efficiently fulfill information need . We first examine widely used PubMed search engine discussing recent improvement continued challenge . We describe literature search tool catering five specific information need : 1 . Identifying high-quality clinical research evidence-based medicine . 2 . Retrieving gene-related information precision medicine genomics . 3 . Searching meaning including natural language question . 4 . Locating related article literature recommendation . 5 . Mining literature discover association concept disease genetic variant . Additionally cover practical consideration best practice choosing using tool . Finally provide perspective future literature search engine considering recent breakthrough large language model ChatGPT . In summary survey provides comprehensive view biomedical literature search functionality 36 publicly available tool .
Patient hand-off triage two fundamental problem health care . Often doctor must painstakingly summarize complex finding efficiently communicate specialist quickly make decision patient urgent case . In pursuit challenge present ( 1 ) model state-of-art radiology report summarization performance using ( 2 ) novel method augmenting medical data ( 3 ) analysis model limitation radiology knowledge gain . We also provide data processing pipeline future model developed MIMIC CXR dataset . Our best performing model fine-tuned BERT-to-BERT encoder-decoder 58.75/100 ROUGE-L F1 outperformed specialized checkpoint sophisticated attention mechanism . We investigate aspect work .
Hashing recently sparked great revolution cross-modal retrieval low storage cost high query speed . Recent cross-modal hashing method often learn unified equal-length hash code represent multi-modal data make intuitively comparable . However unified equal-length hash representation could inherently sacrifice representation scalability data different modality may one-to-one correspondence could encoded efficiently different hash code unequal length . To mitigate problem paper exploit related relatively unexplored problem : encode heterogeneous data varying hash length generalize cross-modal retrieval various challenging scenario . To end generalized flexible cross-modal hashing framework termed Matrix Tri-Factorization Hashing ( MTFH ) proposed work seamlessly various setting including paired unpaired multi-modal data equal varying hash length encoding scenario . More specifically MTFH exploit efficient objective function flexibly learn modality-specific hash code different length setting synchronously learning two semantic correlation matrix semantically correlate different hash representation heterogeneous data comparable . As result derived hash code semantically meaningful various challenging cross-modal retrieval task . Extensive experiment evaluated public benchmark datasets highlight superiority MTFH various retrieval scenario show competitive performance state-of-the-arts .
This document develops general concept useful extracting knowledge embedded large graph datasets pair-wise relationship cause-effect-type relation . Almost underlying assumption made data presented term pair-wise relationship objects/events . This assumption used mine pattern dataset defining reduced graph dataset boils-down concentrate information compact form . The resulting extracted structure set pattern manifestly symbolic nature capture encode graph structure dataset term ( generative ) grammar . This structure identified formal mathematical structure sheaf . In essence paper introduces basic concept sheaf theory domain graphical datasets .
Deep learning ( DL ) unprecedented success entering scientific computing full force . However current DL method typically suffer instability even universal approximation property guarantee existence stable neural network ( NNs ) . We address paradox demonstrating basic well-conditioned problem scientific computing one prove existence NNs great approximation quality however exist algorithm even randomised train ( compute ) NN . For positive integer $ K > 2 $ $ L $ case simultaneously : ( ) randomised training algorithm compute NN correct $ K $ digit probability greater $ 1/2 $ ( b ) exists deterministic training algorithm computes NN $ K-1 $ correct digit ( even randomised ) algorithm need arbitrarily many training data ( c ) exists deterministic training algorithm computes NN $ K-2 $ correct digit using $ L $ training sample . These result imply classification theory describing condition ( stable ) NNs given accuracy computed algorithm . We begin theory establishing sufficient condition existence algorithm compute stable NNs inverse problem . We introduce Fast Iterative REstarted NETworks ( FIRENETs ) prove numerically verify stable . Moreover prove $ \mathcal { O } ( |\log ( \epsilon ) | ) $ layer needed $ \epsilon $ -accurate solution inverse problem .
Recently Segment Anything Model ( SAM ) become research hotspot field multimedia computer vision exhibit powerful yet versatile capability various ( un ) conditional image segmentation task . Although SAM support different type segmentation prompt note compared point- box-guided segmentation performs much worse text-instructed task e.g . referring image segmentation ( RIS ) . In paper argue deep text instruction tuning key mitigate shortcoming caused shallow fusion scheme default light-weight mask decoder . To address issue propose two simple yet effective deep instruction tuning ( DIT ) method SAM one end-to-end layer-wise . With minimal modification DITs directly transform image encoder SAM stand-alone vision-language learner contrast building another deep fusion branch maximizing benefit superior segmentation capability . Extensive experiment three highly competitive benchmark datasets RIS show simple end-to-end DIT improve SAM large margin layer-wise DIT boost performance state-of-the-art much less data training expenditure . Our code released : http : //github.com/wysnzzzz/DIT .
We introduce Dagma-DCE interpretable model-agnostic scheme differentiable causal discovery . Current non- over-parametric method differentiable causal discovery use opaque proxy `` independence `` justify inclusion exclusion causal relationship . We show theoretically empirically proxy may arbitrarily different actual causal strength . Juxtaposed existing differentiable causal discovery algorithm \textsc { Dagma-DCE } us interpretable measure causal strength define weighted adjacency matrix . In number simulated datasets show method achieves state-of-the-art level performance . We additionally show \textsc { Dagma-DCE } allows principled thresholding sparsity penalty domain-experts . The code method available open-source http : //github.com/DanWaxman/DAGMA-DCE easily adapted arbitrary differentiable model .
Deep convolutional network ( CNN ) achieve impressive result RGB scene recognition thanks large datasets Places . In contrast RGB-D scene recognition still underdeveloped comparison due two limitation RGB-D data address paper . The first limitation lack depth data training deep learning model . Rather fine tuning transferring RGB-specific feature address limitation proposing architecture two-step training approach directly learns effective depth-specific feature using weak supervision via patch . The resulting RGB-D model also benefit complementary multimodal feature . Another limitation short range depth sensor ( typically 0.5m 5.5m ) resulting depth image capturing distant object scene RGB image . We show limitation addressed using RGB-D video comprehensive depth information accumulated camera travel across scene . Focusing scenario introduce ISIA RGB-D video dataset evaluate RGB-D scene recognition video . Our video recognition architecture combine convolutional recurrent neural network ( RNNs ) trained three step increasingly complex data learn effective feature ( i.e . patch frame sequence ) . Our approach obtains state-of-the-art performance RGB-D image ( NYUD2 SUN RGB-D ) video ( ISIA RGB-D ) scene recognition .
The development analytical software big Earth observation data face several challenge . Designers need balance conflicting factor . Solutions efficient specific hardware architecture used environment . Packages work generic hardware open standard performance dedicated solution . Software assumes user computer programmer flexible may difficult learn wide audience . This paper describes sits open-source R package satellite image time series analysis using machine learning . To allow expert use satellite imagery fullest extent sits adopts time-first space-later approach . It support complete cycle data analysis land classification . Its API provides simple powerful set function . The software work different cloud computing environment . Satellite image time series input machine learning classifier result post-processed using spatial smoothing . Since machine learning method need accurate training data sits includes method quality assessment training sample . The software also provides method validation accuracy measurement . The package thus comprises production environment big EO data analysis . We show approach produce high accuracy land use land cover map case study Cerrado biome one world 's fast moving agricultural frontier year 2018 .
In 3D reconstruction recovery calibration parameter camera paramount since provides metric information observed scene e.g . measure angle ratio distance . Autocalibration enables estimation camera parameter without using calibration device enforcing simple constraint camera parameter . In absence information internal camera parameter focal length principal point knowledge camera pixel shape usually available constraint . Given projective reconstruction rigid scene address problem autocalibration minimal set camera known pixel shape otherwise arbitrarily varying intrinsic extrinsic parameter . We propose algorithm requires 5 camera ( theoretical minimum ) thus halving number camera required previous algorithm based constraint . To purpose introduce basic geometric tool six-line conic variety ( SLCV ) consisting set plane intersecting six given line 3D space point conic . We show set solution Euclidean upgrading problem three camera known pixel shape parameterized computationally efficient way . This parameterization used solve autocalibration five camera reducing three-dimensional search space two-dimensional one . We provide experiment real image showing good performance technique .
In work propose deep learning network deformable image registration ( DIRNet ) . The DIRNet consists convolutional neural network ( ConvNet ) regressor spatial transformer resampler . The ConvNet analyzes pair fixed moving image output parameter spatial transformer generates displacement vector field enables resampler warp moving image fixed image . The DIRNet trained end-to-end unsupervised optimization similarity metric input image pair . A trained DIRNet applied perform registration unseen image pair one pas thus non-iteratively . Evaluation performed registration image handwritten digit ( MNIST ) cardiac cine MR scan ( Sunnybrook Cardiac Data ) . The result demonstrate registration DIRNet accurate conventional deformable image registration method substantially shorter execution time .
IoT Edge intelligence requires Convolutional Neural Network ( CNN ) inference take place edge device . ARM big.LITTLE architecture heart prevalent commercial edge device . It comprises single-ISA heterogeneous core grouped multiple homogeneous cluster enable power performance trade-off . All core expected simultaneously employed inference attain maximal throughput . However high communication overhead involved parallelization computation convolution kernel across cluster detrimental throughput . We present alternative framework called Pipe-it employ pipelined design split convolutional layer across cluster limiting parallelization respective kernel assigned cluster . We develop performance-prediction model utilizes convolutional layer descriptor predict execution time layer individually permitted core configuration ( type count ) . Pipe-it exploit prediction create balanced pipeline using efficient design space exploration algorithm . Pipe-it average result 39 % higher throughput highest antecedent throughput .
The approach analyzing polarimetric scattering matrix polarimetric synthetic aperture radar ( PolSAR ) data always focus PolSAR image classification . Generally polarization coherent matrix covariance matrix obtained polarimetric scattering matrix show limited number polarimetric information . In order solve problem propose sparse scattering coding way deal polarimetric scattering matrix obtain close complete feature . This encoding mode also maintain polarimetric information scattering matrix completely . At time view encoding way design corresponding classification algorithm based convolution network combine feature . Based sparse scattering coding convolution neural network polarimetric convolutional network proposed classify PolSAR image making full use polarimetric information . We perform experiment PolSAR image acquired AIRSAR RADARSAT-2 verify proposed method . The experimental result demonstrate proposed method get better result huge potential PolSAR data classification . Source code sparse scattering coding available http : //github.com/liuxuvip/Polarimetric-Scattering-Coding .
In paper propose unsupervised feature extraction method capture temporal information monocular video detect encode subject interest frame leverage contrastive self-supervised ( CSS ) learning extract rich latent vector . Instead simply treating latent feature nearby frame positive pair temporally-distant one negative pair CSS approach explicitly disentangle latent vector time-variant component time-invariant one . We show applying contrastive loss time-variant feature encouraging gradual transition nearby away frame also reconstructing input extract rich temporal feature well-suited human pose estimation . Our approach reduces error 50 % compared standard CSS strategy outperforms unsupervised single-view method match performance multi-view technique . When 2D pose available approach extract even richer latent feature improve 3D pose estimation accuracy outperforming state-of-the-art weakly supervised method .
Training Restricted Boltzmann Machines ( RBMs ) challenging long time due difficulty computing precisely log-likelihood gradient . Over past decade many work proposed less successful training recipe without studying crucial quantity problem : mixing time i.e . number Monte Carlo iteration needed sample new configuration model . In work show mixing time play crucial role dynamic stability trained model RBMs operate two well-defined regime namely equilibrium out-of-equilibrium depending interplay mixing time model number step $ k $ used approximate gradient . We show empirically mixing time increase learning often implies transition one regime another soon $ k $ becomes smaller time . In particular show using popular $ k $ ( persistent ) contrastive divergence approach $ k $ small dynamic learned model extremely slow often dominated strong out-of-equilibrium effect . On contrary RBMs trained equilibrium display faster dynamic smooth convergence dataset-like configuration sampling . Finally discus exploit practice regime depending task one aim fulfill : ( ) short $ k $ used generate convincing sample short learning time ( ii ) large $ k $ ( increasingly large ) needed learn correct equilibrium distribution RBM . Finally existence two operational regime seems general property energy based model trained via likelihood maximization .
Object detection one active topic computer vision past year . Recent work mainly focused pushing state-of-the-art general-purpose COCO benchmark . However use detection framework specific application autonomous driving yet area addressed . This study present enhanced 2D object detector based Faster R-CNN better suited context autonomous vehicle . Two main aspect improved : anchor generation procedure performance drop minority class . The default uniform anchor configuration suitable scenario due perspective projection vehicle camera . Therefore propose perspective-aware methodology divide image key region via clustering us evolutionary algorithm optimize base anchor . Furthermore add module enhances precision second-stage header network including spatial information candidate region proposed first stage . We also explore different re-weighting strategy address foreground-foreground class imbalance showing use reduced version focal loss significantly improve detection difficult underrepresented object two-stage detector . Finally design ensemble model combine strength different learning strategy . Our proposal evaluated Waymo Open Dataset extensive diverse date . The result demonstrate average accuracy improvement 6.13 % mAP using best single model 9.69 % mAP ensemble . The proposed modification Faster R-CNN increase computational cost easily extended optimize anchor-based detection framework .
Despite long history studying instant messaging usage know little today 's people participate group chat channel interact others inside real-world organization . In short paper aim update existing knowledge group chat used context today 's organization . The knowledge particularly important new norm remote work COVID-19 pandemic . We privilege collecting two valuable datasets : total 4300 group chat channel Slack R & D department multinational IT company ; total 117 group ' performance data . Through qualitative coding 100 randomly sampled group channel 4300 channel dataset identified reported 9 category Project channel IT-Support channel Event channel . We defined feature metric 21 meta feature ( derived feature ) without looking message content depict group communication style group chat channel successfully trained machine learning model automatically classify given group channel one 9 category . In addition descriptive data analysis illustrated communication metric used analyze team performance . We cross-referenced 117 project team team-based Slack channel identified 57 team appeared datasets built regression model reveal relationship group communication style project team performance . This work contributes updated empirical understanding human-human communication practice within enterprise setting suggests design opportunity future human-AI communication experience .
Machine learning algorithm aim minimizing number false decision increasing accuracy prediction . However high predictive power advanced algorithm come cost transparency . State-of-the-art method neural network ensemble method often result highly complex model offer little transparency . We propose shallow model tree way combine simple highly transparent predictive model higher predictive power without losing transparency original model . We present novel split criterion model tree allows significantly higher predictive power state-of-the-art model tree maintaining level simplicity . This novel approach find split point allow underlying simple model make better prediction corresponding data . In addition introduce multiple mechanism increase transparency resulting tree .
Learning implicit feedback one common case application recommender system . Generally speaking interacted example considered positive negative example sampled uninteracted one . However noisy example prevalent real-world implicit feedback . A noisy positive example could interacted actually lead negative user preference . A noisy negative example uninteracted unawareness user could also denote potential positive user preference . Conventional training method overlook noisy example leading sub-optimal recommendation . In work propose novel framework learn robust recommenders implicit feedback . Through empirical study find different model make relatively similar prediction clean example denote real user preference prediction noisy example vary much across different model . Motivated observation propose denoising cross-model agreement ( DeCA ) aim minimize KL-divergence real user preference distribution parameterized two recommendation model maximizing likelihood data observation . We employ proposed DeCA four state-of-the-art recommendation model conduct experiment four datasets . Experimental result demonstrate DeCA significantly improves recommendation performance compared normal training denoising method . Codes open-sourced .
Robust vision restoration underwater image remains challenge . Owing lack well-matched underwater in-air image unsupervised method based cyclic generative adversarial framework widely investigated recent year . However using end-to-end unsupervised approach unpaired image data mode collapse could occur color correction restored image usually poor . In paper propose data- physics-driven unsupervised architecture perform underwater image restoration unpaired underwater in-air image . For effective color correction quality enhancement underwater image degeneration model must explicitly constructed based optically unambiguous physic law . Thus employ Jaffe-McGlamery degeneration theory design generator use neural network model process underwater visual degeneration . Furthermore impose physical constraint scene depth degeneration factor backscattering estimation avoid vanishing gradient problem training hybrid physical-neural model . Experimental result show proposed method used perform high-quality restoration unconstrained underwater image without supervision . On multiple benchmark proposed method outperforms several state-of-the-art supervised unsupervised approach . We demonstrate method yield encouraging result real-world application .
This paper introduces novel framework named D-LORD ( Double Latent Optimization Representation Disentanglement ) designed motion stylization ( motion style transfer motion retargeting ) . The primary objective framework separate class content information given motion sequence using data-driven latent optimization approach . Here class refers person-specific style particular emotion individual 's identity content relates style-agnostic aspect action walking jumping universally understood concept . The key advantage D-LORD ability perform style transfer without needing paired motion data . Instead utilizes class content label latent optimization process . By disentangling representation framework enables transformation one motion sequence style another 's style using Adaptive Instance Normalization . The proposed D-LORD framework designed focus generalization allowing handle different class content label various application . Additionally generate diverse motion sequence specific class content label provided . The framework 's efficacy demonstrated experimentation three datasets : CMU XIA dataset motion style transfer MHAD dataset RRIS Ability dataset motion retargeting . Notably paper present first generalized framework motion style transfer motion retargeting showcasing potential contribution area .
This paper proposes methodological approach transfer learning scheme plastic waste bottle detection instance segmentation using \textit { mask region proposal convolutional neural network } ( Mask R-CNN ) . Plastic bottle constitute one major pollutant posing serious threat environment ocean land . The automated identification segregation bottle facilitate plastic waste recycling . We prepare custom-made dataset 192 bottle image pixel-by pixel-polygon annotation automatic segmentation task . The proposed transfer learning scheme make use Mask R-CNN model pre-trained Microsoft COCO dataset . We present comprehensive scheme fine-tuning base pre-trained Mask-RCNN model custom dataset . Our final fine-tuned model achieved 59.4 \textit { mean average precision } ( mAP ) corresponds MS COCO metric . The result indicate promising application deep learning detecting waste bottle .
Recent research biometrics focus achieving high success rate authentication addressing concern various spoofing attack . Although hand geometry recognition provides adequate security unauthorized access susceptible presentation attack . This paper present anti-spoofing method toward hand biometrics . A presentation attack detection approach addressed assessing visual quality genuine fake hand image . A threshold-based gradient magnitude similarity quality metric proposed discriminate real spoofed hand sample . The visual hand image 255 subject Bogazici University hand database considered original sample . Correspondingly genuine sample acquire forged image using Canon EOS 700D camera . Such fake hand image natural degradation considered electronic screen display based spoofing attack detection . Furthermore create another fake hand dataset artificial degradation introducing additional Gaussian blur salt pepper speckle noise original image . Ten quality metric measured sample classification original fake hand image . The classification experiment performed using k-nearest neighbor random forest support vector machine classifier well deep convolutional neural network . The proposed gradient similarity-based quality metric achieves 1.5 % average classification er ror using k-nearest neighbor random forest classifier . An average classification error 2.5 % obtained using baseline evaluation MobileNetV2 deep network discriminating original different type fake hand sample .
This paper show problem web service representation crucial analyzes various factor influence . It present traditional representation web service considering traditional textual description based information contained WSDL file . Unfortunately textual web service description dirty need significant cleaning keep useful information . To deal problem introduce rule based text tagging method allows filtering web service description keep significant information . A new representation based filtered data introduced . Many web service empty description . Also consider web service representation based WSDL file structure ( type attribute etc . ) . Alternatively introduce new representation called symbolic reputation computed relationship web service . The impact use representation web service discovery recommendation studied discussed experimentation using real world web service .
After admission emergency department ( ED ) patient critical illness transferred intensive care unit ( ICU ) due unexpected clinical deterioration occurrence . Identifying unplanned ICU transfer urgently needed medical physician achieve two-fold goal : improving critical care quality preventing mortality . A priority task understand crucial rationale behind diagnosis result individual patient stay ED help prepare early transfer ICU . Most existing prediction study based univariate analysis multiple logistic regression provide one-size-fit-all result . However patient condition varying case case may accurately examined judgment . In study present new decision tool using mathematical optimization approach aiming automatically discover rule associating diagnostic feature high-risk outcome ( i.e . unplanned transfer ) different deterioration scenario . We consider four mutually exclusive patient subgroup based principal reason ED visit : infection cardiovascular/respiratory disease gastrointestinal disease neurological/other disease suburban teaching hospital . The analysis result demonstrate significant rule associated unplanned transfer outcome subgroup also show comparable prediction accuracy compared state-of-the-art machine learning method providing easy-to-interpret symptom-outcome information .
Since ML algorithm proven success many different application also big interest privacy preserving ( PP ) ML method building model sensitive data . Moreover increase number data source high computational power required algorithm force individual outsource training and/or inference ML model cloud providing service . To address propose secure 3-party computation framework CECILIA offering PP building block enable complex operation privately . In addition adapted common operation like addition multiplication offer multiplexer significant bit modulus conversion . The first two novel term methodology last one novel term functionality methodology . CECILIA also two complex novel method exact exponential public base raised power secret value inverse square root secret Gram matrix . We use CECILIA realize private inference pre-trained RKNs require complex operation DNNs structural classification protein first study ever accomplishing PP inference RKNs . In addition successful private computation basic building block result demonstrate perform exact fully private exponential computation done approximation literature far . Moreover also show compute exact inverse square root secret Gram matrix certain privacy level addressed literature . We also analyze scalability CECILIA various setting synthetic dataset . The framework show great promise make ML algorithm well computation privately computable building block framework .
Invariances neural network useful necessary many task . However representation invariance neural network model characterized . We propose measure quantify invariance neural network term internal representation . The measure efficient interpretable applied neural network model . They also sensitive invariance previously defined measure . We validate measure property domain affine transformation CIFAR10 MNIST datasets including stability interpretability . Using measure perform first analysis CNN model show internal invariance remarkably stable random weight initialization change dataset transformation . We believe measure enable new avenue research invariance representation .
Background aim : Image registration alignment main limitation augmented reality-based knee replacement surgery . This research aim decrease registration error eliminate outcome trapped local minimum improve alignment problem handle occlusion maximize overlapping part . Methodology : markerless image registration method used Augmented reality-based knee replacement surgery guide visualize surgical operation . While weight least square algorithm used enhance stereo camera-based tracking filling border occlusion right left direction non-border occlusion left right direction . Results : This study improved video precision 0.57 mm~0.61 mm alignment error . Furthermore use bidirectional point example forward backwards directional cloud point iteration image registration decreased . This led improve processing time well . The processing time video frame improved 7.4~11.74 fps . Conclusions : It seems clear proposed system focused overcoming misalignment difficulty caused movement patient enhancing AR visualization knee replacement surgery . The proposed system reliable favorable help eliminating alignment error ascertaining optimal rigid transformation two cloud point removing outlier non-Gaussian noise . The proposed augmented reality system help accurate visualization navigation anatomy knee femur tibia cartilage blood vessel etc .
In short paper neural network able form low dimensional topological hidden representation explained . The neural network trained autoencoder classifier mix produce different low dimensional topological map . When trained autoencoder inherent topological structure data visualized trained classifier topological structure constrained concept example label data hence visualization structural also conceptual . The proposed neural network significantly differ many dimensional reduction model primarily ability execute supervised unsupervised dimensional reduction . The neural network allows multi perspective visualization data thus giving flexibility data analysis . This paper supported preliminary intuitive visualization experiment .
Fuels high-knock resistance enable modern spark-ignition engine achieve high efficiency thus low CO2 emission . Identification molecule desired autoignition property indicated high research octane number high octane sensitivity therefore great practical relevance supported computer-aided molecular design ( CAMD ) . Recent development field graph machine learning ( graph-ML ) provide novel promising tool CAMD . We propose modular graph-ML CAMD framework integrates generative graph-ML model graph neural network optimization enabling design molecule desired ignition property continuous molecular space . In particular explore potential Bayesian optimization genetic algorithm combination generative graph-ML model . The graph-ML CAMD framework successfully identifies well-established high-octane component . It also suggests new candidate one experimentally investigate use illustrate need auto-ignition training data .
Active learning unique abstraction machine learning technique model/algorithm could guide user annotation set data point would beneficial model unlike passive machine learning . The primary advantage active learning framework select data point accelerate learning process model reduce amount data needed achieve full accuracy compared model trained randomly acquired data set . Multiple framework active learning combined deep learning proposed majority dedicated classification task . Herein explore active learning task segmentation medical imaging data set . We investigate proposed framework using two datasets : 1 . ) MRI scan hippocampus 2 . ) CT scan pancreas tumor . This work present query-by-committee approach active learning joint optimizer used committee . At time propose three new strategy active learning : 1 . ) increasing frequency uncertain data bias training data set ; 2 . ) Using mutual information among input image regularizer acquisition ensure diversity training dataset ; 3 . ) adaptation Dice log-likelihood Stein variational gradient descent ( SVGD ) . The result indicate improvement term data reduction achieving full accuracy using 22.69 % 48.85 % available data dataset respectively .
Sense ownership writing confines investment thought time contribution leading attachment output . However using writing assistant introduces mental dilemma content n't directly creation . For instance tend credit Large Language Models ( LLMs ) creative task even though task equal . Additionally may claim complete ownership LLM-generated content freely claim authorship . We conduct short survey examine issue understand underlying cognitive process order gain better knowledge human-computer interaction writing improve writing aid system .
Understanding 3D object structure single image important challenging task computer vision mostly due lack 3D object annotation real image . Previous research tackled problem either searching 3D shape best explains 2D annotation training purely synthetic data ground truth 3D information . In work propose 3D INterpreter Networks ( 3D-INN ) end-to-end trainable framework sequentially estimate 2D keypoint heatmaps 3D object skeleton pose . Our system learns 2D-annotated real image synthetic 3D data . This made possible mainly two technical innovation . First heatmaps 2D keypoints serve intermediate representation connect real synthetic data . 3D-INN trained real image estimate 2D keypoint heatmaps input image ; predicts 3D object structure heatmaps using knowledge learned synthetic 3D shape . By 3D-INN benefit variation abundance synthetic 3D object without suffering domain difference real synthesized image often due imperfect rendering . Second propose Projection Layer mapping estimated 3D structure back 2D . During training ensures 3D-INN predict 3D structure whose projection consistent 2D annotation real image . Experiments show proposed system performs well 2D keypoint estimation 3D structure recovery . We also demonstrate recovered 3D information wide vision application image retrieval .
Since seminal work [ 9 ] Physics-Informed neural network ( PINNs ) many effort conducted towards solving partial differential equation ( PDEs ) Deep Learning model . However challenge remain instance extension model complex three-dimensional geometry study approach could combined classical numerical solver . In work justify use graph neural network problem based similarity architecture mesh used traditional numerical technique solving partial differential equation . After proving issue Physics-Informed framework complex geometry computation PDE residual alternative procedure proposed combining classical numerical solver Physics-Informed framework . Finally propose implementation approach test three-dimensional problem irregular geometry .
We study different aspect active learning deep neural network consistent unified way . ) We investigate incremental cumulative training mode specify newly labeled data used training . ii ) We study active learning w.r.t . model configuration number epoch neuron well choice batch size . iii ) We consider detail behavior query strategy corresponding informativeness measure accordingly propose efficient querying procedure . iv ) We perform statistical analysis e.g . actively learned class test error estimation reveal several insight active learning . v ) We investigate active learning neural network benefit pseudo-labels proxy actual label .
In recent year trend deploying digital system numerous industry hiked . The health sector observed extensive adoption digital system service generate significant medical record . Electronic health record contain valuable information prospective retrospective analysis often entirely exploited complicated dense information storage . The crude purpose condensing health record select information hold characteristic original document based reported disease . These summary may boost diagnosis save doctor 's time saturated workload situation like COVID-19 pandemic . In paper applying multi-head attention-based mechanism perform extractive summarization meaningful phrase clinical note . Our method find major sentence summary correlating token segment positional embeddings sentence clinical note . The model output attention score statistically transformed extract critical phrase visualization heat-mapping tool human use .
In medical imaging accurate diagnosis heavily relies effective image enhancement technique particularly X-ray image . Existing method often suffer various challenge sacrificing global image characteristic local image characteristic vice versa . In paper present novel approach called G-CLAHE ( Global-Contrast Limited Adaptive Histogram Equalization ) perfectly suit medical imaging focus X-rays . This method adapts Global Histogram Equalization ( GHE ) Contrast Limited Adaptive Histogram Equalization ( CLAHE ) take advantage avoid weakness preserve local global characteristic . Experimental result show significantly improve current state-of-the-art algorithm effectively address limitation enhance contrast quality X-ray image diagnostic accuracy .
We connect problem semi-supervised clustering constrained Markov aggregation i.e . task partitioning state space Markov chain . We achieve connection considering every data point dataset element Markov chain 's state space defining transition probability state via similarity corresponding data point incorporating semi-supervision information hard constraint Hartigan-style algorithm . The introduced Constrained Markov Clustering ( CoMaC ) extension recent information-theoretic framework ( unsupervised ) Markov aggregation semi-supervised case . Instantiating CoMaC certain parameter setting generalizes two previous information-theoretic objective unsupervised clustering . Our result indicate CoMaC competitive state-of-the-art .
Memorability measure easily image memorized glancing may contribute designing magazine cover tourism publicity material forth . Recent work shed light visual feature make generic image object image face photograph memorable . However method able effectively predict memorability outdoor natural scene image . To overcome shortcoming previous work paper provide attempt answer : `` exactly make outdoor natural scene memorable `` . To end first establish large-scale outdoor natural scene image memorability ( LNSIM ) database containing 2632 outdoor natural scene image ground truth memorability score multi-label scene category annotation . Then similar previous work mine database investigate low- middle- high-level handcrafted feature affect memorability outdoor natural scene . In particular find high-level feature scene category rather correlated outdoor natural scene memorability deep feature learnt deep neural network ( DNN ) also effective predicting memorability score . Moreover combining deep feature category feature boost performance memorability prediction . Therefore propose end-to-end DNN based outdoor natural scene memorability ( DeepNSM ) predictor take advantage learned category-related feature . Then experimental result validate effectiveness DeepNSM model exceeding state-of-the-art method . Finally try understand reason good performance DeepNSM model also study case DeepNSM model succeeds fails accurately predict memorability outdoor natural scene . Code : github.com/JiaxinLu-home/Natural-Scene-Memorability-Dataset .
We investigate association musical chord lyric analyzing large dataset user-contributed guitar tablature . Motivated idea emotional content chord reflected word used corresponding lyric analyze association lyric chord category . We also examine usage pattern chord lyric different musical genre historical era geographical region . Our overall result confirms previously known association Major chord positive valence . We also report wide variation association across region genre era . Our result suggest possible existence different emotional association type chord .
Understanding textual description generate code seems achieved capability instruction-following Large Language Models ( LLMs ) zero-shot scenario . However severe possibility translation ability may influenced seen target textual description related code . This effect known Data Contamination . In study investigate impact Data Contamination performance GPT-3.5 Text-to-SQL code-generating task . Hence introduce novel method detect Data Contamination GPTs examine GPT-3.5 's Text-to-SQL performance using known Spider Dataset new unfamiliar dataset Termite . Furthermore analyze GPT-3.5 's efficacy database modified information via adversarial table disconnection ( ATD ) approach complicating Text-to-SQL task removing structural piece information database . Our result indicate significant performance drop GPT-3.5 unfamiliar Termite dataset even ATD modification highlighting effect Data Contamination LLMs Text-to-SQL translation task .
Nonlinear phenomenon analyzed via linear technique using operator-theoretic approach . Data-driven method called extended dynamic mode decomposition ( EDMD ) variant approximate Koopman operator associated nonlinear phenomenon rapidly developing incorporating machine learning method . Neural ordinary differential equation ( NODEs ) neural network equipped continuum layer high parameter memory efficiency proposed . In paper propose algorithm perform EDMD using NODEs . NODEs used find parameter-efficient dictionary provides good finite-dimensional approximation Koopman operator . We show superiority parameter efficiency proposed method numerical experiment .
PAC-Bayes recently re-emerged effective theory one derive principled learning algorithm tight performance guarantee . However application PAC-Bayes bandit problem relatively rare great misfortune . Many decision-making problem healthcare finance natural science modelled bandit problem . In many application principled algorithm strong performance guarantee would much appreciated . This survey provides overview PAC-Bayes bound bandit problem experimental comparison bound . On one hand found PAC-Bayes bound useful tool designing offline bandit algorithm performance guarantee . In experiment PAC-Bayesian offline contextual bandit algorithm able learn randomised neural network police competitive expected reward non-vacuous performance guarantee . On hand PAC-Bayesian online bandit algorithm tested loose cumulative regret bound . We conclude discussing topic future work PAC-Bayesian bandit algorithm .
Much experiment designed uncover cause ( ) effect ( ) behind data generating mechanism ( i.e . phenomenon ) happen interested . Uncovering relationship allows u identify true working phenomenon importantly articulate model may enable u explore phenomenon hand and/or allow u predict accurately . Fundamentally model likely derived via causal approach ( opposed observational empirical mean ) . In approach causal discovery required create causal model applied infer influence intervention answer hypothetical question ( i.e . form What ifs ? Etc . ) might . This paper build case causal discovery causal inference contrast traditional machine learning approach ; civil structural engineering perspective . More specifically paper outline key principle causality commonly used algorithm package causal discovery causal inference . Finally paper also present series example case study causal concept adopted domain .
Knowing people look click visual design provide clue design perceived important relevant content lie . The important content visual design used effective summarization facilitate retrieval database . We present automated model predict relative importance different element data visualization graphic design . Our model neural network trained human click importance annotation hundred design . We collected new dataset crowdsourced importance analyzed prediction model respect ground truth importance human eye movement . We demonstrate prediction importance used automatic design retargeting thumbnailing . User study hundred MTurk participant validate limited post-processing importance-driven application par outperform current state-of-the-art method including natural image saliency . We also provide demonstration importance prediction built interactive design tool offer immediate feedback design process .
Semantic parsing i.e . automatic derivation meaning representation instantiated predicate-argument structure sentence play critical role deep processing natural language . Unlike top system semantic dependency parsing rely pipeline framework chain series submodels specialized specific subtask one presented article integrates everything one model hope achieving desirable integrity practicality real application maintaining competitive performance . This integrative approach tackle semantic parsing word pair classification problem using maximum entropy classifier . We leverage adaptive pruning argument candidate large-scale feature selection engineering allow largest feature space ever use far field achieves state-of-the-art performance evaluation data set CoNLL-2008 shared task top one top pipeline system confirming feasibility effectiveness .
The study aim investigate similarity difference brain damage caused Hypoxia-Ischemia ( HI ) Hypoglycemia Epilepsy . Hypoglycemia pose significant challenge improving glycemic regulation insulin-treated patient HI brain disease neonate associated low oxygen level . The study examines possibility using combination medical data Electroencephalography ( EEG ) measurement predict outcome two-year period . The study employ multilevel fusion data feature enhance accuracy prediction . Therefore paper suggests hybridized classification model Hypoxia-Ischemia Hypoglycemia Epilepsy brain injury ( HCM-BI ) . A Support Vector Machine applied clinical detail define Hypoxia-Ischemia outcome infant . The newborn baby assessed every two year know neural development result . A selection four attribute derived Electroencephalography record SVM get conclusion regarding classification disease . The final feature extraction EEG signal optimized Bayesian Neural Network ( BNN ) get clear health condition Hypoglycemia Epilepsy patient . Through monitoring assessing physical effect resulting Electroencephalography The Bayesian Neural Network ( BNN ) used extract test sample log data report hypoglycemia epilepsy Keywords- Hypoxia-Ischemia Hypoglycemia Epilepsy Multilevel Fusion Data Features Bayesian Neural Network ( BNN ) Support Vector Machine ( SVM )
In study investigate degree expert non-experts agree question difficulty crowdsourcing experiment . We ask non-experts ( second language learner Swedish ) two group expert ( teacher Swedish second/foreign language CEFR expert ) rank multi-word expression crowdsourcing experiment . We find resulting ranking three tested group correlate high degree suggests judgment produced comparative setting influenced professional insight Swedish second language .
Analyzing vast textual data summarizing key information electronic health record imposes substantial burden clinician allocate time . Although large language model ( LLMs ) shown promise natural language processing ( NLP ) effectiveness diverse range clinical summarization task remains unproven . In study apply adaptation method eight LLMs spanning four distinct clinical summarization task : radiology report patient question progress note doctor-patient dialogue . Quantitative assessment syntactic semantic conceptual NLP metric reveal trade-off model adaptation method . A clinical reader study ten physician evaluates summary completeness correctness conciseness ; majority case summary best adapted LLMs either equivalent ( 45 % ) superior ( 36 % ) compared summary medical expert . The ensuing safety analysis highlight challenge faced LLMs medical expert connect error potential medical harm categorize type fabricated information . Our research provides evidence LLMs outperforming medical expert clinical text summarization across multiple task . This suggests integrating LLMs clinical workflow could alleviate documentation burden allowing clinician focus patient care .
In spam malware detection attacker exploit randomization obfuscate malicious data increase chance evading detection test time ; e.g . malware code typically obfuscated using random string byte sequence hide known exploit . Interestingly randomization also proposed improve security learning algorithm evasion attack result hiding information classifier attacker . Recent work proposed game-theoretical formulation learn secure classifier simulating different evasion attack modifying classification function accordingly . However classification function simulated data manipulation modeled deterministic manner without accounting form randomization . In work overcome limitation proposing randomized prediction game namely non-cooperative game-theoretic formulation classifier attacker make randomized strategy selection according probability distribution defined respective strategy set . We show approach allows one improve trade-off attack detection false alarm respect state-of-the-art secure classifier even attack different hypothesized design application example including handwritten digit recognition spam malware detection .
The ability detect Out-of-Domain ( OOD ) input critical requirement many real-world NLP application . For example intent classification dialogue system . The reason inclusion unsupported OOD input may lead catastrophic failure system . However remains empirical question whether current method tackle problem reliably realistic scenario zero OOD training data available . In study propose ProtoInfoMax new architecture extends Prototypical Networks simultaneously process in-domain OOD sentence via Mutual Information Maximization ( InfoMax ) objective . Experimental result show proposed method substantially improve performance 20 % OOD detection low resource setting text classification . We also show ProtoInfoMax less prone typical overconfidence error Neural Networks leading reliable prediction result .
Studies evaluating bikeability usually compute spatial indicator shaping cycling condition conflate quantitative index . Much research involves site visit conventional geospatial approach study leveraged street view imagery ( SVI ) conducting virtual audit . These assessed limited range aspect automated using computer vision ( CV ) . Furthermore study yet zeroed gauging usability technology thoroughly . We investigate experiment fine spatial scale across multiple geography ( Singapore Tokyo ) whether use SVI CV assess bikeability comprehensively . Extending related work develop exhaustive index bikeability composed 34 indicator . The result suggest SVI CV adequate evaluate bikeability city comprehensively . As outperformed non-SVI counterpart wide margin SVI indicator also found superior assessing urban bikeability potentially used independently replacing traditional technique . However paper expose limitation suggesting best way forward combining SVI non-SVI approach . The new bikeability index present contribution transportation urban analytics scalable assess cycling appeal widely .
An autoencoder layered neural network whose structure viewed consisting encoder compress input vector dimension $ D $ vector low dimension $ $ decoder transforms low-dimensional vector back original input vector ( one similar ) . In paper explore compressive power autoencoders Boolean threshold network studying number node layer required ensure number node layer required ensure vector given set distinct input binary vector transformed back original . We show set $ n $ distinct vector exists seven-layer autoencoder smallest possible middle layer ( i.e . size logarithmic $ n $ ) set $ n $ vector three-layer autoencoder middle layer size . In addition present kind trade-off : considerably larger middle layer permissible five-layer autoencoder exist . We also study encoding . The result obtain suggest decoding constitutes bottleneck autoencoding . For example always three-layer Boolean threshold encoder compress $ n $ vector dimension reduced twice logarithm $ n $ .
The desire train complex machine learning algorithm increase statistical power association study drive neuroimaging research use ever-larger datasets . The obvious way increase sample size pooling scan independent study . However simple pooling often ill-advised selection measurement confounding bias may creep yield spurious correlation . In work combine 35320 magnetic resonance image brain 17 study examine bias neuroimaging . In first experiment Name That Dataset provide empirical evidence presence bias showing scan correctly assigned respective dataset 71.5 % accuracy . Given evidence take closer look confounding bias often viewed main shortcoming observational study . In practice neither know potential confounders data . Hence model confounders unknown latent variable . Kolmogorov complexity used decide whether confounded causal model provides simplest factorization graphical model . Finally present method dataset harmonization study ability remove bias imaging feature . In particular propose extension recently introduced ComBat algorithm control global variation across image feature inspired adjusting population stratification genetics . Our result demonstrate harmonization reduce dataset-specific information image feature . Further confounding bias reduced even turned causal relationship . However harmonziation also requires caution easily remove relevant subject-specific information . Code available http : //github.com/ai-med/Dataset-Bias .
We introduce dataset studying evolution word constructed WordNet Google Books Ngram Corpus . The dataset track evolution 4000 synonym set ( synset ) containing 9000 English word 1800 AD 2000 AD . We present supervised learning algorithm able predict future leader synset : word synset highest frequency . The algorithm us feature based word 's length character word historical frequency word . It predict change leadership ( including identity new leader ) fifty year future F-score considerably random guessing . Analysis learned model provides insight cause change leader synset . The algorithm confirms observation linguist made trend replace -ise suffix -ize rivalry -ity -ness suffix struggle economy ( shorter word easier remember write ) clarity ( longer word distinctive less likely confused one another ) . The result indicate integration Google Books Ngram Corpus WordNet significant potential improving understanding language evolves .
This paper present novel deep learning-based method learning functional representation mammalian neural image . The method us deep convolutional denoising autoencoder ( CDAE ) generating invariant compact representation situ hybridization ( ISH ) image . While existing method bio-imaging analysis developed handle image highly complex anatomical structure result presented paper show functional representation extracted CDAE help learn feature functional gene ontology category classification highly accurate manner . Using CDAE representation method outperforms previous state-of-the-art classification rate improving average AUC 0.92 0.98 i.e . achieving 75 % reduction error . The method operates input image downsampled significantly respect original one make computationally feasible .
Specialised transformers-based model ( BioBERT BioMegatron ) adapted biomedical domain based publicly available biomedical corpus . As potential encode large-scale biological knowledge . We investigate encoding representation biological knowledge model potential utility support inference cancer precision medicine - namely interpretation clinical significance genomic alteration . We compare performance different transformer baseline ; use probing determine consistency encoding distinct entity ; use clustering method compare contrast internal property embeddings gene variant drug disease . We show model indeed encode biological knowledge although lost fine-tuning specific task . Finally analyse model behave regard bias imbalance dataset .
Parkinson 's disease patient develop different speech impairment affect communication capability . The automatic assessment speech patient allows development computer aided tool support diagnosis evaluation disease severity . This paper introduces methodology classify Parkinson 's disease speech three different language : Spanish German Czech . The proposed approach considers convolutional neural network trained time frequency representation transfer learning strategy among three language . The transfer learning scheme aim improve accuracy model weight neural network initialized utterance different language used test set . The result suggest proposed strategy improves accuracy model 8\ % base model used initialize weight classifier robust enough . In addition result obtained transfer learning case balanced term specificity-sensitivity trained without transfer learning strategy .
Recently ocular biometrics unconstrained environment using image obtained visible wavelength gained researcher ' attention especially image captured mobile device . Periocular recognition demonstrated alternative iris trait available due occlusion low image resolution . However periocular trait high uniqueness presented iris trait . Thus use datasets containing many subject essential assess biometric system ' capacity extract discriminating information periocular region . Also address within-class variability caused lighting attribute periocular region paramount importance use datasets image subject captured distinct session . As datasets available literature present factor work present new periocular dataset containing sample 1122 subject acquired 3 session 196 different mobile device . The image captured unconstrained environment single instruction participant : place eye region interest . We also performed extensive benchmark several Convolutional Neural Network ( CNN ) architecture model employed state-of-the-art approach based Multi-class Classification Multitask Learning Pairwise Filters Network Siamese Network . The result achieved closed- open-world protocol considering identification verification task show area still need research development .
Remotely sensed nighttime light ( NTL ) uniquely capture urban change process important human ecological well-being urbanization socio-political conflict displacement impact disaster holiday change daily human pattern movement . Though several NTL product global extent intrinsic city-specific factor affect lighting development level social economic cultural characteristic unique city making urban process embedded NTL signature difficult characterize limiting scalability urban change analysis . In study propose data-driven approach detect urban change daily satellite-derived NTL data record adaptive across city effective learning city-specific temporal pattern . The proposed method learns forecast NTL signature past data record using neural network allows use large volume unlabeled data eliminating annotation effort . Urban change detected based deviation observed NTL model forecast using anomaly detection approach . Comparing model forecast observed NTL also allows identifying direction change ( positive negative ) monitoring change severity tracking recovery . In operationalizing model consider ten urban area diverse geographic region dynamic NTL time-series demonstrate generalizability approach detecting change process different driver rate occurring within urban area based NTL deviation . This scalable approach monitoring change daily remote sensing observation efficiently utilizes large data volume support continuous monitoring decision making .
Trip destination prediction area increasing importance many application trip planning autonomous driving electric vehicle . Even though problem could naturally addressed online learning paradigm data arriving sequential fashion majority research rather considered offline setting . In paper present unified framework trip destination prediction online setting suitable online training online prediction . For purpose develop two clustering algorithm integrate within two online prediction model problem . We investigate different configuration clustering algorithm prediction model real-world dataset . We demonstrate clustering entire framework yield consistent result compared offline setting . Finally propose novel regret metric evaluating entire online framework comparison offline counterpart . This metric make possible relate source erroneous prediction either clustering prediction model . Using metric show proposed method converge probability distribution resembling true underlying distribution lower regret baseline .
In paper frame homogeneous-feature multi-task learning ( MTL ) hierarchical representation learning problem one task-agnostic multiple task-specific latent representation . Drawing inspiration information bottleneck principle assuming additive independent noise model task-agnostic task-specific latent representation limit information contained task-specific representation . It shown resulting representation yield competitive performance several MTL benchmark . Furthermore certain setup show trained parameter additive noise model closely related similarity different task . This indicates approach yield task-agnostic representation disentangled sense individual dimension may interpretable task-specific perspective .
This paper offer methodological contribution intersection machine learning operation research . Namely propose methodology quickly predict tactical solution given operational problem . In context tactical solution less detailed operational one computed short time imperfect information . The problem importance various application tactical operational planning problem interrelated information operational problem revealed time . This instance case certain capacity planning demand management system . We formulate problem two-stage optimal prediction stochastic program whose solution predict supervised machine learning algorithm . The training data set consists large number deterministic ( second stage ) problem generated controlled probabilistic sampling . The label computed based solution deterministic problem ( solved independently offline ) employing appropriate aggregation subselection method address uncertainty . Results motivating application load planning rail transportation show deep learning algorithm produce highly accurate prediction short computing time ( millisecond less ) . The prediction accuracy comparable solution computed sample average approximation stochastic program .
Computer vision-based damage detection using remote camera unmanned aerial vehicle ( UAVs ) enables efficient low-cost bridge health monitoring reduces labor cost need sensor installation maintenance . By leveraging recent semantic image segmentation approach able find region critical structural component recognize damage pixel level using image input . However existing method perform poorly detecting small damage ( e.g . crack exposed rebars ) thin object limited image sample especially component interest highly imbalanced . To end paper introduces semantic segmentation framework imposes hierarchical semantic relationship component category damage type . For example certain concrete crack present bridge column therefore non-column region masked detecting damage . In way damage detection model could focus learning feature possible damaged region avoid effect irrelevant region . We also utilize multi-scale augmentation provides view different scale preserve contextual information image without losing ability handling small thin object . Furthermore proposed framework employ important sampling repeatedly sample image containing rare component ( e.g . railway sleeper exposed rebars ) provide data sample address imbalanced data challenge .
A novel algorithm uncalibrated stereo image-pair rectification constraint geometric distortion called USR-CGD presented work . Although straightforward define rectifying transformation ( homography ) given epipolar geometry many existing algorithm unwanted geometric distortion side effect . To obtain rectified image reduced geometric distortion maintaining small rectification error parameterize homography considering influence various kind geometric distortion . Next define several geometric measure incorporate new cost function parameter optimization . Finally propose constrained adaptive optimization scheme allow balanced performance rectification error geometric error . Extensive experimental result provided demonstrate superb performance proposed USR-CGD method outperforms existing algorithm significant margin .
We study problem coarse-grained response selection retrieval-based dialogue system . The problem equally important fine-grained response selection less explored existing literature . In paper propose Contextual Fine-to-Coarse ( CFC ) distilled model coarse-grained response selection open-domain conversation . In CFC model dense representation query candidate response corresponding context learned based multi-tower architecture expressive knowledge learned one-tower architecture ( fine-grained ) distilled multi-tower architecture ( coarse-grained ) enhance performance retriever . To evaluate performance proposed model construct two new datasets based Reddit comment dump Twitter corpus . Extensive experimental result two datasets show proposed method achieve significant improvement evaluation metric compared traditional baseline method .
Deep Learning algorithm achieved state-of-the-art performance Image Classification used even security-critical application biometric recognition system self-driving car . However recent work shown algorithm even surpass human capability vulnerable adversarial example . In Computer Vision adversarial example image containing subtle perturbation generated malicious optimization algorithm order fool classifier . As attempt mitigate vulnerability numerous countermeasure constantly proposed literature . Nevertheless devising efficient defense mechanism proven difficult task since many approach already shown ineffective adaptive attacker . Thus self-containing paper aim provide readership review latest research progress Adversarial Machine Learning Image Classification however defender 's perspective . Here novel taxonomy categorizing adversarial attack defense introduced discussion existence adversarial example provided . Further contrast exisiting survey also given relevant guidance taken consideration researcher devising evaluating defense . Finally based reviewed literature discussed promising path future research .
We propose framework configuration operation expensive-to-evaluate advanced manufacturing method based Bayesian optimization . The framework unifies tailored acquisition function parallel acquisition procedure integration process information providing context optimization procedure . \cmtb { The novel acquisition function demonstrated analyzed compared state-of-the-art benchmarking problem . We apply optimization approach atmospheric plasma spraying fused deposition modeling . } Our result demonstrate proposed framework efficiently find input parameter produce desired outcome minimize process cost .
In realm data classification broad learning system ( BLS ) proven potent tool utilizes layer-by-layer feed-forward neural network . However traditional BLS treat sample equally significant make less robust less effective real-world datasets noise outlier . To address issue propose fuzzy broad learning system ( F-BLS ) intuitionistic fuzzy broad learning system ( IF-BLS ) model confront challenge posed noise outlier present dataset enhance overall robustness . Employing fuzzy membership technique proposed F-BLS model embeds sample neighborhood information based proximity class center within inherent feature space BLS framework . Furthermore proposed IF-BLS model introduces intuitionistic fuzzy concept encompassing membership non-membership score value function . IF-BLS strategically considers homogeneity heterogeneity sample neighborhood kernel space . We evaluate performance proposed F-BLS IF-BLS model UCI benchmark datasets without Gaussian noise . As application implement proposed F-BLS IF-BLS model diagnose Alzheimer 's disease ( AD ) . Experimental finding statistical analysis consistently highlight superior generalization capability proposed F-BLS IF-BLS model baseline model across scenario . The proposed model offer promising solution enhance BLS framework 's ability handle noise outlier . The source code link proposed model available http : //github.com/mtanveer1/IF-BLS .
Epidemiologists model dynamic epidemic order propose control strategy based pharmaceutical non-pharmaceutical intervention ( contact limitation lock vaccination etc ) . Hand-designing strategy trivial number possible intervention difficulty predict long-term effect . This task cast optimization problem state-of-the-art machine learning algorithm deep reinforcement learning might bring significant value . However specificity domain -- epidemic modelling solving optimization problem -- requires strong collaboration researcher different field expertise . This introduce EpidemiOptim Python toolbox facilitates collaboration researcher epidemiology optimization . EpidemiOptim turn epidemiological model cost function optimization problem via standard interface commonly used optimization practitioner ( OpenAI Gym ) . Reinforcement learning algorithm based Q-Learning deep neural network ( DQN ) evolutionary algorithm ( NSGA-II ) already implemented . We illustrate use EpidemiOptim find optimal policy dynamical on-off lock-down control optimization death toll economic recess using Susceptible-Exposed-Infectious-Removed ( SEIR ) model COVID-19 . Using EpidemiOptim interactive visualization platform Jupyter notebook epidemiologist optimization practitioner others ( e.g . economist ) easily compare epidemiological model cost function optimization algorithm address important choice made health decision-makers .
The recent research explosion around implicit neural representation NeRF show immense potential implicitly storing high-quality scene lighting information compact neural network . However one major limitation preventing use NeRF real-time rendering application prohibitive computational cost excessive network evaluation along view ray requiring dozen petaFLOPS . In work bring compact neural representation closer practical rendering synthetic content real-time application game virtual reality . We show number sample required view ray significantly reduced sample placed around surface scene without compromising image quality . To end propose depth oracle network predicts ray sample location view ray single network evaluation . We show using classification network around logarithmically discretized spherically warped depth value essential encode surface location rather directly estimating depth . The combination technique lead DONeRF compact dual network design depth oracle network first step locally sampled shading network ray accumulation . With DONeRF reduce inference cost 48x compared NeRF conditioning available ground truth depth information . Compared concurrent acceleration method raymarching-based neural representation DONeRF require additional memory explicit caching acceleration structure render interactively ( 20 frame per second ) single GPU .
Recently meta-learning shown promising way solve few-shot learning . In paper inspired human cognition process utilizes prior-knowledge vision attention learning new knowledge present novel paradigm meta-learning approach three development introduce attention mechanism prior-knowledge meta-learning . In approach prior-knowledge responsible helping meta-learner expressing input data high-level representation space attention mechanism enables meta-learner focusing key feature data representation space . Compared existing meta-learning approach pay little attention prior-knowledge vision attention approach alleviates meta-learner 's few-shot cognition burden . Furthermore Task-Over-Fitting ( TOF ) problem indicates meta-learner poor generalization different K-shot learning task discovered propose Cross-Entropy across Tasks ( CET ) metric model solve TOF problem . Extensive experiment demonstrate improve meta-learner state-of-the-art performance several few-shot learning benchmark time TOF problem also released greatly .
Modeling law search retrieval prediction problem recently emerged predominant approach law intelligence . Focusing law article retrieval task present deep learning framework named LamBERTa designed civil-law code specifically trained Italian civil code . To knowledge first study proposing advanced approach law article prediction Italian legal system based BERT ( Bidirectional Encoder Representations Transformers ) learning framework recently attracted increased attention among deep learning approach showing outstanding effectiveness several natural language processing learning task . We define LamBERTa model fine-tuning Italian pre-trained BERT Italian civil code portion law article retrieval classification task . One key aspect LamBERTa framework conceived address extreme classification scenario characterized high number class few-shot learning problem lack test query benchmark Italian legal prediction task . To solve issue define different method unsupervised labeling law article principle applied law article code system . We provide insight explainability interpretability LamBERTa model present extensive experimental analysis query set different type single-label well multi-label evaluation task . Empirical evidence shown effectiveness LamBERTa also superiority widely used deep-learning text classifier few-shot learner conceived attribute-aware prediction task .
The problem selecting small yet high quality subset pattern larger collection itemsets recently attracted lot research . Here discus approach problem using notion decomposable family itemsets . Such itemset family define probabilistic model data original collection itemsets derived . Furthermore induce special tree structure called junction tree familiar theory Markov Random Fields . The method several advantage . The junction tree provide intuitive representation mining result . From computational point view model provides leverage problem could intractable using entire collection itemsets . We provide efficient algorithm build decomposable itemset family give application example frequency bound querying using model . Empirical result show algorithm yield high quality result .
The design neural network architecture new data set laborious task requires human deep learning expertise . In order make deep learning available broader audience automated method finding neural network architecture vital . Recently proposed method already achieve human expert level performance . However method run time month even year GPU computing time ignoring hardware constraint faced many researcher company . We propose use Monte Carlo planning combination two different UCT ( upper confidence bound applied tree ) derivation search network architecture . We adapt UCT algorithm need network architecture search proposing two way sharing information different branch search tree . In empirical study able demonstrate method able find competitive network MNIST SVHN CIFAR-10 single GPU day . Extending search time five GPU day able outperform human architecture competitor consider type layer .
Today web best medium communication modern business . Many company redefining business strategy improve business output . Business internet provides opportunity customer partner product specific business found . Nowadays online business break barrier time space compared physical office . Big company around world realizing e-commerce buying selling Internet rather improves efficiency compete giant market . For purpose data mining sometimes called knowledge discovery used . Web mining data mining technique applied WWW . There vast quantity information available Internet .
Logographs ( Chinese character ) recursive structure ( i.e . hierarchy sub-units logograph ) contain phonological semantic information developmental psychology literature suggests native speaker leverage structure learn read . Exploiting structure could potentially lead better embeddings benefit many downstream task . We propose building hierarchical logograph ( character ) embeddings logograph recursive structure using treeLSTM recursive neural network . Using recursive neural network imposes prior mapping logograph embeddings since network must read sub-units logograph according order specified recursive structure . Based human behavior language learning reading hypothesize modeling logograph ' structure using recursive neural network beneficial . To verify claim consider two task ( 1 ) predicting logograph ' Cantonese pronunciation logographic structure ( 2 ) language modeling . Empirical result show proposed hierarchical embeddings outperform baseline approach . Diagnostic analysis suggests hierarchical embeddings constructed using treeLSTM less sensitive distractors thus robust especially complex logograph .
Label smoothing effective regularization tool deep neural network ( DNNs ) generates soft label applying weighted average uniform distribution hard label . It often used reduce overfitting problem training DNNs improve classification performance . In paper aim investigate generate reliable soft label . We present Online Label Smoothing ( OLS ) strategy generates soft label based statistic model prediction target category . The proposed OLS construct reasonable probability distribution target category non-target category supervise DNNs . Experiments demonstrate based classification model proposed approach effectively improve classification performance CIFAR-100 ImageNet fine-grained datasets . Additionally proposed method significantly improve robustness DNN model noisy label compared current label smoothing approach .
SpectralNet graph clustering method us neural network find embedding separate data . So far used $ k $ -nn graph usually constructed using distance metric ( e.g . Euclidean distance ) . $ k $ -nn graph restrict point fixed number neighbor regardless local statistic around . We proposed new SpectralNet similarity metric based random projection tree ( rpTrees ) . Our experiment revealed SpectralNet produce better clustering accuracy using rpTree similarity metric compared $ k $ -nn graph distance metric . Also found rpTree parameter affect clustering accuracy . These parameter include leaf size selection projection direction . It computationally efficient keep leaf size order $ \log ( n ) $ project point onto random direction instead trying find direction maximum dispersion .
Deep neural network ( DNNs ) quite successful solving many complex learning problem . However DNNs tend large number learning parameter leading large memory computation requirement . In paper propose model compression framework efficient training inference deep neural network embedded system . Our framework provides data structure kernel OpenCL-based parallel forward backward computation compressed form . In particular method learns sparse representation parameter using $ \ell_1 $ -based sparse coding training storing compressed sparse matrix . Unlike previous work method require pre-trained model input therefore versatile different application environment . Even though use $ \ell_1 $ -based sparse coding model compression new show far effective previously reported use proximal point algorithm technique debiasing . Our experiment show method produce minimal learning model suitable small embedded device .
Plant aliveness proven laboratory experiment special scientific instrument . In paper aim detect degree animation plant based magnification small color change plant 's green leaf using Eulerian video magnification . Capturing video controlled environment e.g . using tripod direct current ( DC ) light source reduces camera movement minimizes light fluctuation ; aim reduce external factor much possible . The acquired video stabilized proposed algorithm used reduce illumination variation . Lastly Euler magnification utilized magnify color change light invariant video . The proposed system require special purpose instrument us digital camera regular frame rate . The result magnified color change natural plastic leaf show live green leaf color change contrast plastic leaf . Hence argue color change leaf due biological operation photosynthesis . To date possibly first work focus interpreting visually biological operation plant without special purpose instrument .
Deep learning revolutionized data science recently popularity grown exponentially amount paper employing deep network . Vision task human pose estimation escape trend . There large number deep model small change network architecture data pre-processing together stochastic nature optimization procedure produce notably different result making extremely difficult sift method significantly outperform others . This situation motivates current study perform systematic evaluation statistical analysis vanilla deep regression i.e . convolutional neural network linear regression top layer . This first comprehensive analysis deep regression technique . We perform experiment four vision problem report confidence interval median performance well statistical significance result . Surprisingly variability due different data pre-processing procedure generally eclipse variability due modification network architecture . Our result reinforce hypothesis according general general-purpose network ( e.g . VGG-16 ResNet-50 ) adequately tuned yield result close state-of-the-art without resort complex ad-hoc regression model .
Change detection ( CD ) fundamental important task monitoring land surface dynamic earth observation field . Existing deep learning-based CD method typically extract bi-temporal image feature using weight-sharing Siamese encoder network identify change region using decoder network . These CD method however still perform far satisfactorily observe 1 ) deep encoder layer focus irrelevant background region 2 ) model ' confidence change region inconsistent different decoder stage . The first problem deep encoder layer effectively learn imbalanced change category using sole output supervision second problem attributed lack explicit semantic consistency preservation . To address issue design novel similarity-aware attention flow network ( SAAN ) . SAAN incorporates similarity-guided attention flow module deeply supervised similarity optimization achieve effective change detection . Specifically counter first issue explicitly guiding deep encoder layer discover semantic relation bi-temporal input image using deeply supervised similarity optimization . The extracted feature optimized semantically similar unchanged region dissimilar changing region . The second drawback alleviated proposed similarity-guided attention flow module incorporates similarity-guided attention module attention flow mechanism guide model focus discriminative channel region . We evaluated effectiveness generalization ability proposed method conducting experiment wide range CD task . The experimental result demonstrate method achieves excellent performance several CD task discriminative feature semantic consistency preserved .
The effectiveness machine learning evaluating creditworthiness loan applicant demonstrated long time . However concern use automated decision-making process may result unequal treatment group individual potentially leading discriminatory outcome . This paper seek address issue evaluating effectiveness 12 leading bias mitigation method across 5 different fairness metric well assessing accuracy potential profitability financial institution . Through analysis identified challenge associated achieving fairness maintaining accuracy profitabiliy highlighted successful least successful mitigation method . Ultimately research serf bridge gap experimental machine learning practical application finance industry .
Detecting recognizing human action video crowded scene challenging problem due complex environment diversity event . Prior work always fail deal problem two aspect : ( 1 ) lacking utilizing information scene ; ( 2 ) lacking training data crowd complex scene . In paper focus improving spatio-temporal action recognition fully-utilizing information scene collecting new data . A top-down strategy used overcome limitation . Specifically adopt strong human detector detect spatial location frame . We apply action recognition model learn spatio-temporal information video frame HIE dataset new data diverse scene internet improve generalization ability model . Besides scene information extracted semantic segmentation model assistant process . As result method achieved average 26.05 wf\_mAP ( ranking 1st place ACM MM grand challenge 2020 : Human Events ) .
Identifying human behavior challenging research problem due complexity variation appearance posture variation camera setting view angle . In paper try address problem human behavior identification introducing novel motion descriptor based statistical feature . The method first divide video N number temporal segment . Then segment compute dense optical flow provides instantaneous velocity information pixel . We compute Histogram Optical Flow ( HOOF ) weighted norm quantized 32 bin . We compute statistical feature obtained HOOF forming descriptor vector 192- dimension . We train non-linear multi-class SVM classify different human behavior accuracy 72.1 % . We evaluate method using publicly available human action data set . Experimental result show proposed method performs state art method .
Parallel sentence relatively scarce extremely useful resource many application including cross-lingual retrieval statistical machine translation . This research explores methodology mining data previously obtained comparable corpus . The task highly practical since non-parallel multilingual data exist far greater quantity parallel corpus parallel sentence much useful resource . Here propose web crawling method building subject-aligned comparable corpus Wikipedia article . We also introduce method extracting truly parallel sentence filtered noisy comparable sentence pair . We describe implementation specialized tool task well training adaption machine translation system supply filter additional information similarity comparable sentence pair .
Sophisticated user interaction automotive industry fast emerging topic . Mid-air gesture speech already numerous application driver-car interaction . Additionally multimodal approach developed leverage use multiple sensor added advantage . In paper propose fast practical multimodal fusion method based machine learning selection various control module automotive vehicle . The modality taken account gaze head pose finger pointing gesture . Speech used trigger fusion . Single modality previously used numerous time recognition user 's pointing direction . We however demonstrate multiple input fused together enhance recognition performance . Furthermore compare different deep neural network architecture conventional Machine Learning method namely Support Vector Regression Random Forests show enhancement pointing direction accuracy using deep learning . The result suggest great potential use multimodal input applied use case vehicle .
Despite recent success multi-task learning pre-finetuning natural language understanding work studied effect task family abstractive text summarization . Task family form task grouping pre-finetuning stage learn common skill reading comprehension . To close gap analyze influence multi-task learning strategy using task family English abstractive text summarization task . We group task one three strategy i.e . sequential simultaneous continual multi-task learning evaluate trained model two downstream task . We find certain combination task family ( e.g . advanced reading comprehension natural language inference ) positively impact downstream performance . Further find choice combination task family influence downstream performance training scheme supporting use task family abstractive text summarization .
We present novel method solving square jigsaw puzzle based global optimization . The method fully automatic assumes prior information handle puzzle known unknown piece orientation . At core optimization process nonlinear relaxation labeling well-founded approach deducing global solution local constraint unlike classical scheme propose multi-phase approach guarantee convergence feasible puzzle solution . Next algorithmic novelty also present new compatibility function quantification affinity adjacent puzzle piece . Competitive result advantage multi-phase approach demonstrated standard datasets .
2D object proposal quickly detected region image likely contain object interest effective approach improving computational efficiency accuracy object detection color image . In work propose novel online method generates 3D object proposal RGB-D video sequence . Our main observation depth image provide important information geometry scene . Diverging traditional goal 2D object proposal provide high recall ( lot 2D bounding box near potential object ) aim precise 3D proposal . We leverage depth information per frame multi-view scene information obtain accurate 3D object proposal . Using efficient robust registration enables u combine multiple frame scene near real time generate 3D bounding box potential 3D region interest . Using standard metric Precision-Recall curve F-measure show proposed approach significantly accurate current state-of-the-art technique . Our online approach integrated SLAM based video processing quick 3D object localization . Our method take less second MATLAB UW-RGBD scene dataset single thread CPU thus potential used low-power chip Unmanned Aerial Vehicles ( UAVs ) quadcopters drone .
Media sharing application Flickr Panoramio contain large amount picture related real life event . For reason development effective method retrieve picture important still challenging task . Recognizing importance improve retrieval effectiveness tag-based event retrieval system propose new method extract set geographical tag feature raw geo-spatial profile user tag . The main idea use feature select best expansion term machine learning-based query expansion approach . Specifically apply rigorous statistical exploratory analysis spatial point pattern extract geo-spatial feature . We use feature summarize spatial characteristic spatial distribution single term determine similarity spatial profile two term -- i.e . term-to-term spatial similarity . To improve approach investigate effect combining geo-spatial feature temporal feature choosing expansion term . To evaluate method perform several experiment including well-known feature analysis . Such analysis show much proposed geo-spatial feature contribute improve overall retrieval performance . The result experiment demonstrate effectiveness viability method .
The crucial role evaluation development information retrieval tool useful evidence improve performance tool quality result return . However classic evaluation approach limitation shortcoming especially regarding user consideration measure adequacy query returned document consideration characteristic specification behavior search tool . Therefore believe exploitation contextual element could good way evaluate search tool . So paper present new approach take account context evaluation process three complementary level . The experiment give end article shown applicability proposed approach real research tool . The test performed popular searching engine ( i.e . Google Bing Yahoo ) selected particular high selectivity . The obtained result revealed ability engine rejecting dead link redundant result parasite page depends strongly query formulated political site offering information present content . The relevance evaluation result provided engine using user 's judgment using automatic manner take account query context also shown general decline perceived relevance according number considered result .
Microblog classification received lot attention recent year . Different classification task investigated focusing classifying microblogs small number class ( five less ) using training set manually annotated tweet . Unfortunately labelling data tedious expensive finding tweet cover class interest always straightforward especially class frequently arise practice . In paper study approach tweet classification based distant supervision whereby automatically transfer label one social medium another single-label multi-class classification task . In particular apply YouTube video class tweet linking video . This provides free virtually unlimited number labelled instance used training data . The classification experiment run show training tweet classifier via automatically labelled data achieves substantially better performance training classifier limited amount manually labelled data ; advantageous given automatically labelled data come cost . Further investigation approach show robustness applied different number class across different language .
Most domain adaptation method consider problem transferring knowledge target domain single source dataset . However practical application typically access multiple source . In paper propose first approach Multi-Source Domain Adaptation ( MSDA ) based Generative Adversarial Networks . Our method inspired observation appearance given image depends three factor : domain style ( characterized term low-level feature variation ) content . For reason propose project image feature onto space dependence content kept re-project invariant representation onto pixel space using target domain style . In way new labeled image generated used train final target classifier . We test approach using common MSDA benchmark showing outperforms state-of-the-art method .
Bottom-up top-down visual cue two type information help visual saliency model . These salient cue spatial distribution feature ( space-based saliency ) contextual / task-dependent feature ( object based saliency ) . Saliency model generally incorporate salient cue either bottom-up top-down norm separately . In work combine bottom-up top-down cue space object based salient feature RGB-D data . In addition also investigated ability various pre-trained convolutional neural network extracting top-down saliency color image based object dependent feature activation . We demonstrate combining salient feature color dept bottom-up top-down method give significant improvement salient object detection space based object based salient cue . RGB-D saliency integration framework yield promising result compared several state-of-the-art-models .
This paper present GoPose 3D skeleton-based human pose estimation system us WiFi device home . Our system leverage WiFi signal reflected human body 3D pose estimation . In contrast prior system need specialized hardware dedicated sensor system require user wear carry sensor reuse WiFi device already exist home environment mass adoption . To realize system leverage 2D AoA spectrum signal reflected human body deep learning technique . In particular 2D AoA spectrum proposed locate different part human body well enable environment-independent pose estimation . Deep learning incorporated model complex relationship 2D AoA spectrum 3D skeleton human body pose tracking . Our evaluation result show GoPose achieves around 4.7cm accuracy various scenario including tracking unseen activity NLoS scenario .
In context cluster analysis graph partitioning many external evaluation measure proposed literature compare two partition set . This make task selecting appropriate measure given situation challenge end user . However issue overlooked literature . Researchers tend follow tradition use standard measure field although often became standard previous researcher started consistently using . In work propose new empirical evaluation framework solve issue help end user selecting appropriate measure application . For collection candidate measure first consists describing behavior computing generated dataset partition obtained applying set predefined parametric partition transformation . Second framework performs regression analysis characterize measure term affected parameter transformation . This allows describing comparing measure . Our approach tied specific measure application applied situation . We illustrate relevance applying selection standard measure show put practice two concrete use case .
Supervised machine learning method geological mapping via remote sensing face limitation due scarcity accurately labelled training data addressed unsupervised learning dimensionality reduction clustering . Dimensionality reduction method potential play crucial role improving accuracy geological map . Although conventional dimensionality reduction method may struggle nonlinear data unsupervised deep learning model autoencoders model non-linear relationship . Stacked autoencoders feature multiple interconnected layer capture hierarchical data representation useful remote sensing data . We present unsupervised machine learning-based framework processing remote sensing data using stacked autoencoders dimensionality reduction k-means clustering mapping geological unit . We use Landsat 8 ASTER Sentinel-2 datasets evaluate framework geological mapping Mutawintji region Western New South Wales Australia . We also compare stacked autoencoders principal component analysis ( PCA ) canonical autoencoders . Our result reveal framework produce accurate interpretable geological map efficiently discriminating rock unit . The result reveal combination stacked autoencoders Sentinel-2 data yield best performance accuracy compared combination . We find stacked autoencoders enable better extraction complex hierarchical representation input data compared canonical autoencoders PCA . We also find generated map align prior geological knowledge study area providing novel insight geological structure .
Non-extractive fish abundance estimation aid visual analysis drawn increasing attention . Unstable illumination ubiquitous noise low frame rate video capturing underwater environment however make conventional tracking method unreliable . In paper present multiple fish tracking system low-contrast low-frame-rate stereo video use trawl-based underwater camera system . An automatic fish segmentation algorithm overcomes low-contrast issue adopting histogram backprojection approach double local-thresholded image ensure accurate segmentation fish shape boundary . Built upon reliable feature-based object matching method multiple-target tracking algorithm via modified Viterbi data association proposed overcome poor motion continuity frequent entrance/exit fish target low-frame-rate scenario . In addition computationally efficient block-matching approach performs successful stereo matching enables automatic fish-body tail compensation greatly reduce segmentation error allows accurate fish length measurement . Experimental result show effective reliable tracking performance multiple live fish underwater stereo camera achieved .
Balancing computational efficiency recognition accuracy one major challenge real-world video-based face recognition . A significant design decision system whether process use possible face detected video frame whether select `` best `` face . This paper present video face recognition system based probabilistic Multi-Region Histograms characterise performance trade-off : ( ) selecting subset face compared using face ( ii ) combining information face via clustering . Three face selection metric evaluated choosing subset : face detection confidence random subset sequential selection . Experiments recently introduced MOBIO dataset indicate usage face clustering always outperformed selecting subset face . The experiment also show face selection metric based face detection confidence generally provides better recognition performance random sequential sampling . Moreover optimal number face varies drastically across selection metric subset MOBIO . Given trade-off computational effort recognition accuracy robustness recommended face feature clustering would advantageous batch processing ( particularly video-based watchlists ) whereas face selection method limited application significant computational restriction .
We study unsupervised multilingual alignment problem finding word-to-word translation multiple language without using parallel data . One popular strategy reduce multilingual alignment much simplified bilingual setting picking one input language pivot language transit . However well-known transiting poorly chosen pivot language ( English ) may severely degrade translation quality since assumed transitive relation among pair language may enforced training process . Instead going rather arbitrarily chosen pivot language propose use Wasserstein barycenter informative `` mean `` language : encapsulates information language minimizes pairwise transportation cost . We evaluate method standard benchmark demonstrate state-of-the-art performance .
This paper describes design implementation initial testing reusable platform creation pervasive game geo-localization service . We concentrate role-playing game built combining several type simpler mini-games three major component : Quests ; Collectables ; Non-player character ( NPC ) . Quests encourage player active physical environment take part collaborative play ; Collectables provide motivation ; NPCs enable player-friendly interaction platform . Each element pose different technical requirement met implementing gaming platform using inTrack pervasive middle-ware developed group . Several sample game implemented tested within urban environment Kyoto Japan using gaming client running mobile phone NTT DoCoMo Japan 's largest mobile provider .
Due popularity availability social medium data may present new way identify individual experiencing mental illness . By analysing blog content study aimed investigate association linguistic feature symptom depression generalised anxiety suicidal ideation . This study utilised longitudinal study design . Individuals blogged invited participate study completed fortnightly mental health questionnaire including PHQ9 GAD7 period 36 week . Linguistic feature extracted blog data using LIWC tool . Bivariate multivariate analysis performed investigate correlation linguistic feature mental health score subject . We used multivariate regression model predict longitudinal change mood within subject . A total 153 participant consented taking part 38 participant completing required number questionnaire blog post study period . Between-subject analysis revealed several linguistic feature including tentativeness non-fluencies significantly associated depression anxiety symptom suicidal thought . Within-subject analysis showed robust correlation linguistic feature change mental health score . This study provides support relationship linguistic feature within social medium data symptom depression anxiety . The lack robust within-subject correlation indicate relationship observed group level may generalise individual change time .
Personalization applied great extend many system . This paper present multi-dimensional user data model application web search . Online Offline activity user tracked creating user model . The main phase identification relevant document representation relevance similarity document . The concept Keywords Topics URLs cluster used implementation . The algorithm profiling grading clustering concept user model algorithm determining personalized search result re-ranking result search bank presented paper . Simple experiment evaluation model result described .
Neural ordinary differential equation ( NODE ) proposed continuous depth generalization popular deep learning model Residual network ( ResNets ) . They provide parameter efficiency automate model selection process deep learning model extent . However lack much-required uncertainty modelling robustness capability crucial use several real-world application autonomous driving healthcare . We propose novel unique approach model uncertainty NODE considering distribution end-time $ T $ ODE solver . The proposed approach latent time NODE ( LT-NODE ) treat $ T $ latent variable apply Bayesian learning obtain posterior distribution $ T $ data . In particular use variational inference learn approximate posterior model parameter . Prediction done considering NODE representation different sample posterior done efficiently using single forward pas . As $ T $ implicitly defines depth NODE posterior distribution $ T $ would also help model selection NODE . We also propose adaptive latent time NODE ( ALT-NODE ) allow data point distinct posterior distribution end-times . ALT-NODE us amortized variational inference learn approximate posterior using inference network . We demonstrate effectiveness proposed approach modelling uncertainty robustness experiment synthetic several real-world image classification data .
Our goal survey provide overview state art deep learning method face generation editing using StyleGAN . The survey cover evolution StyleGAN PGGAN StyleGAN3 explores relevant topic suitable metric training different latent representation GAN inversion latent space StyleGAN face image editing cross-domain face stylization face restoration even Deepfake application . We aim provide entry point field reader basic knowledge field deep learning looking accessible introduction overview .
Video understanding recognize classify different action activity appearing video . A lot previous work video captioning shown promising performance producing general video understanding . However still challenging generate fine-grained description human action interaction using state-of-the-art video captioning technique . The detailed description human action group activity essential information used real-time CCTV video surveillance health care sport video analysis etc . This study proposes video understanding method mainly focused group activity recognition learning pair-wise actor appearance similarity actor position . We propose use Normalized cross-correlation ( NCC ) sum absolute difference ( SAD ) calculate pair-wise appearance similarity build actor relationship graph allow graph convolution network learn classify group activity . We also propose use MobileNet backbone extract feature video frame . A visualization model introduced visualize input video frame predicted bounding box human object predict individual action collective activity .
With proliferation user-generated online video Multimodal Sentiment Analysis ( MSA ) attracted increasing attention recently . Despite significant progress still two major challenge way towards robust MSA : 1 ) inefficiency modeling cross-modal interaction unaligned multimodal data ; 2 ) vulnerability random modality feature missing typically occurs realistic setting . In paper propose generic unified framework address named Efficient Multimodal Transformer Dual-Level Feature Restoration ( EMT-DLFR ) . Concretely EMT employ utterance-level representation modality global multimodal context interact local unimodal feature mutually promote . It avoids quadratic scaling cost previous local-local cross-modal interaction method also lead better performance . To improve model robustness incomplete modality setting one hand DLFR performs low-level feature reconstruction implicitly encourage model learn semantic information incomplete data . On hand innovatively regard complete incomplete data two different view one sample utilizes siamese representation learning explicitly attract high-level representation . Comprehensive experiment three popular datasets demonstrate method achieves superior performance complete incomplete modality setting .
Object detection optical remote sensing image fundamental challenging problem field aerial satellite image analysis play important role wide range application receiving significant attention recent year . While enormous method exist deep review literature concerning generic object detection still lacking . This paper aim provide review recent progress field . Different several previously published survey focus specific object class building road concentrate generic object category including limited road building tree vehicle ship airport urban-area . Covering 270 publication survey 1 ) template matching-based object detection method 2 ) knowledge-based object detection method 3 ) object-based image analysis ( OBIA ) -based object detection method 4 ) machine learning-based object detection method 5 ) five publicly available datasets three standard evaluation metric . We also discus challenge current study propose two promising research direction namely deep learning-based feature representation weakly supervised learning-based geospatial object detection . It hope survey beneficial researcher better understanding research field .
This systematic literature review paper explores use extended reality { ( XR ) } technology smart built environment particularly smart lighting system design . Smart lighting novel concept emerged decade used tested commercial industrial built environment . We used PRISMA methodology review 270 research paper published 1968 2023 . Following discussion historical advance key modeling technique description lighting simulation context extended reality smart built environment given followed discussion current trend challenge .
Bearing fault diagnosis challenge monitoring activity rotating machinery 's receiving attention . The conventional fault diagnosis method usually extract feature waveform spectrum vibration signal order realize fault classification . In paper novel feature form image presented namely spectrum image vibration signal . The spectrum image simply obtained fast Fourier transformation . Such image processed two-dimensional principal component analysis ( 2DPCA ) reduce dimension minimum distance method applied classify fault bearing . The effectiveness proposed method verified experimental data .
Credit card fraud detection challenging problem specific nature transaction data labeling process . The transaction data peculiar obtained streaming fashion strongly imbalanced prone non-stationarity . The labeling outcome active learning process every day human investigator contact small number cardholder ( associated riskiest transaction ) obtain class ( fraud genuine ) related transaction . An adequate selection set cardholder therefore crucial efficient fraud detection process . In paper present number active learning strategy investigate fraud detection accuracy . We compare different criterion ( supervised semi-supervised unsupervised ) query unlabeled transaction . Finally highlight existence exploitation/exploration trade-off active learning context fraud detection far overlooked literature .
We study adaptive anisotropic Huber functional based image restoration scheme . By using combination L2-L1 regularization function adaptive Huber functional based energy minimization model provides denoising edge preservation noisy digital image . We study convergent finite difference scheme based continuous piecewise linear function use variable splitting scheme namely Split Bregman obtain discrete minimizer . Experimental result given image denoising comparison additive operator splitting dual fixed point projected gradient scheme illustrate best convergence rate obtained algorithm .
Skeletonization popular shape analysis technique model object 's interior opposed boundary . Fitting template-based skeletal model time-consuming process requiring much manual parameter tuning . Recently machine learning-based method shown promise generating s-reps object boundary . In work propose new skeletonization method leverage graph convolutional network produce skeletal representation ( s-reps ) dense segmentation mask . The method evaluated synthetic data real hippocampus segmentation achieving promising result fast inference .
This work proposes novel approach us semantic segmentation mask obtain 2D spatial layout segmentation-categories across scene designated segmentation-based semantic feature ( SSFs ) . These feature represent per segmentation-category pixel count well 2D average position respective standard deviation value . Moreover two-branch network GS2F2App exploit CNN-based global feature extracted RGB image segmentation-based feature extracted proposed SSFs also proposed . GS2F2App evaluated two indoor scene benchmark datasets : SUN RGB-D NYU Depth V2 achieving state-of-the-art result datasets .
Chat Generative Pre-trained Transformer ( ChatGPT ) gained significant interest attention since launch November 2022 . It shown impressive performance various domain including passing exam creative writing . However challenge concern related bias trust persist . In work present comprehensive review 100 Scopus-indexed publication ChatGPT aiming provide taxonomy ChatGPT research explore application . We critically analyze existing literature identifying common approach employed study . Additionally investigate diverse application area ChatGPT found utility healthcare marketing financial service software engineering academic scientific writing research education environmental science natural language processing . Through examining application gain valuable insight potential ChatGPT addressing real-world challenge . We also discus crucial issue related ChatGPT including bias trustworthiness emphasizing need research development area . Furthermore identify potential future direction ChatGPT research proposing solution current challenge speculating expected advancement . By fully leveraging capability ChatGPT unlock potential across various domain leading advancement conversational AI transformative impact society .
In paper present general flexible framework learning mapping image action interacting environment . The basic idea introduce feature-based image classifier front reinforcement learning algorithm . The classifier partition visual space according presence absence highly informative local descriptor incrementally selected sequence attempt remove perceptual aliasing . We also address problem fighting overfitting greedy algorithm . Finally show high-level visual feature generated power local descriptor insufficient completely disambiguating aliased state . This done building hierarchy composite feature consist recursive spatial combination visual feature . We demonstrate efficacy algorithm solving three visual navigation task visual version classical Car Hill control problem .
Big data great share success deep learning computer vision . Recent work suggest significant potential increase object detection performance utilizing even bigger datasets . In paper introduce EuroCity Persons dataset provides large number highly diverse accurate detailed annotation pedestrian cyclist rider urban traffic scene . The image dataset collected on-board moving vehicle 31 city 12 European country . With 238200 person instance manually labeled 47300 image EuroCity Persons nearly one order magnitude larger person datasets used previously benchmarking . The dataset furthermore contains large number person orientation annotation ( 211200 ) . We optimize four state-of-the-art deep learning approach ( Faster R-CNN R-FCN SSD YOLOv3 ) serve baseline new object detection benchmark . In experiment previous datasets analyze generalization capability detector trained new dataset . We furthermore study effect training set size dataset diversity ( day- vs. night-time geographical region ) dataset detail ( i.e . availability object orientation information ) annotation quality detector performance . Finally analyze error source discus road ahead .
Nowadays growing interest applying Artificial Intelligence ( AI ) board Earth Observation ( EO ) satellite time-critical application natural disaster response . However unavailability raw satellite data currently hinders research lightweight pre-processing technique limit exploration end-to-end pipeline could offer efficient accurate extraction insight directly source data . To fill gap work present novel methodology automate creation datasets detection target event ( e.g . warm thermal hotspot ) object ( e.g . vessel ) Sentinel-2 raw data multispectral EO pushbroom raw imagery . The presented approach first process raw data applying pipeline consisting spatial band registration georeferencing raw data pixel . Then detects target event leveraging event-specific state-of-the-art algorithm Level-1C product mosaicked cropped georeferenced correspondent raw granule area . The detected event finally re-projected back onto corresponding raw image . We apply proposed methodology realize THRawS ( Thermal Hotspots Raw Sentinel-2 data ) first dataset Sentinel-2 raw data containing warm thermal hotspot . THRawS includes 1090 sample containing wildfire volcanic eruption 33335 event-free acquisition enable thermal hotspot detection general classification application . This dataset associated toolkits provide community immediately useful resource well framework methodology acting template future addition . With work hope pave way research energy-efficient pre-processing algorithm AI-based end-to-end processing system board EO satellite .
Autonomous vision-based spaceborne navigation enabling technology future on-orbit servicing space logistics mission . While computer vision general benefited Machine Learning ( ML ) training validating spaceborne ML model extremely challenging due impracticality acquiring large-scale labeled dataset image intended target space environment . Existing datasets Spacecraft PosE Estimation Dataset ( SPEED ) far mostly relied synthetic image training validation easy mass-produce fail resemble visual feature illumination variability inherent target spaceborne image . In order bridge gap current practice intended application future space mission paper introduces SPEED+ : next generation spacecraft pose estimation dataset specific emphasis domain gap . In addition 60000 synthetic image training SPEED+ includes 9531 hardware-in-the-loop image spacecraft mockup model captured Testbed Rendezvous Optical Navigation ( TRON ) facility . TRON first-of-a-kind robotic testbed capable capturing arbitrary number target image accurate maximally diverse pose label high-fidelity spaceborne illumination condition . SPEED+ used second international Satellite Pose Estimation Challenge co-hosted SLAB Advanced Concepts Team European Space Agency evaluate compare robustness spaceborne ML model trained synthetic image .
Methods fusing document list retrieved response query often utilize retrieval score and/or rank document list . We present novel fusion approach based using addition information induced inter-document similarity . Specifically method let similar document different list provide relevance-status support . We use graph-based method model relevance-status propagation document . The propagation governed inter-document-similarities retrieval score document list . Empirical evaluation demonstrates effectiveness method fusing TREC run . The performance effective method transcends effective fusion method utilize retrieval score rank .
While existing face recognition system based local feature robust issue misalignment exhibit accuracy degradation comparing image differing resolution . This common surveillance environment gallery high resolution mugshot compared low resolution CCTV probe image size given image reliable indicator underlying resolution ( eg . poor optic ) . To alleviate degradation propose compensation framework dynamically chooses appropriate face recognition system given pair image resolution . This framework applies novel resolution detection method rely size input image instead exploit sensitivity local feature resolution using probabilistic multi-region histogram approach . Experiments resolution-modified version `` Labeled Faces Wild `` dataset show proposed resolution detector frontend obtains 99 % average accuracy selecting appropriate face recognition system resulting higher overall face discrimination accuracy ( across several resolution ) compared individual baseline face recognition system .
We propose visualization method understand effect multidimensional projection local subspace using implicit function differentiation . Here understand local subspace multidimensional local neighborhood data point . Existing method focus projection multidimensional data point neighborhood information ignored . Our method able analyze shape directional information local subspace gain insight global structure data perception local structure . Local subspace fitted multidimensional ellipsis spanned basis vector . An accurate efficient vector transformation method proposed based analytical differentiation multidimensional projection formulated implicit function . The result visualized glyph analyzed using full set specifically-designed interaction supported efficient web-based visualization tool . The usefulness method demonstrated using various multi- high-dimensional benchmark datasets . Our implicit differentiation vector transformation evaluated numerical comparison ; overall method evaluated exploration example use case .
Radio-frequency dosimetry important process human safety compliance related product . Recently computational human model generated medical image often used assessment especially consider inter-variability subject . However common procedure develop personalized model time consuming involves excessive segmentation several component represent different biological tissue limit inter-variability assessment radiation safety based personalized dosimetry . Deep learning method shown powerful approach pattern recognition signal analysis . Convolutional neural network deep architecture proven robust feature extraction image mapping several biomedical application . In study develop learning-based approach fast accurate estimation dielectric property density tissue directly magnetic resonance image single shot . The smooth distribution dielectric property head model realized using process without tissue segmentation improves smoothness specific absorption rate ( SAR ) distribution compared commonly used procedure . The estimated SAR distribution well averaged 10-g tissue cubic shape found highly consistent computed using conventional method employ segmentation .
Coronary heart disease ( CHD ) caused hardening artery wall due cholesterol known atherosclerosis responsible large number death world-wide . The disease progression slow asymptomatic may lead sudden cardiac arrest stroke myocardial infraction . Presently imaging technique employed understand molecular metabolic activity atherosclerotic plaque estimate risk . Though imaging method able provide information plaque metabolism lack required resolution sensitivity detection . In paper consider clinical observation habit individual predicting risk factor CHD . The identification risk factor help stratifying patient intensive test nuclear imaging coronary angiography . We present novel approach predicting risk factor atherosclerosis in-built imputation algorithm particle swarm optimization ( PSO ) . We compare performance methodology machine learning technique STULONG dataset based longitudinal study middle aged individual lasting twenty year . Our methodology powered PSO search identified physical inactivity one risk factor onset atherosclerosis addition already known factor . The decision rule extracted methodology able predict risk factor accuracy $ 99.73 % $ higher accuracy obtained application state-of-the-art machine learning technique presently employed identification atherosclerosis risk study .
Shared gaze visualization found enhance collaboration communication outcome diverse HCI scenario including computer supported collaborative work learning context . Given importance gaze surgery operation especially surgeon trainer trainee need coordinate action research use gaze facilitate intra-operative coordination instruction limited show mixed implication . We performed field observation 8 surgery interview study 14 surgeon understand visual need operation informing way leverage augment gaze enhance intra-operative coordination instruction . We found trainee varying need receiving visual guidance often unfulfilled trainer ' instruction . It critical surgeon control timing gaze-based visualization effectively interpret gaze data . We suggest overlay technology e.g . gaze-based summary depth sensing augment raw gaze support surgical coordination instruction .
Multiview learning ( MVL ) seek leverage benefit diverse perspective complement effectively extracting utilizing latent information within dataset . Several twin support vector machine-based MVL ( MvTSVM ) model introduced demonstrated outstanding performance various learning task . However MvTSVM-based model face significant challenge form computational complexity due four matrix inversion need reformulate optimization problem order employ kernel-generated surface handling non-linear case constraint uniform noise assumption training data . Particularly case data possesses heteroscedastic error structure challenge become even pronounced . In view aforementioned challenge propose multiview twin parametric margin support vector machine ( MvTPMSVM ) . MvTPMSVM construct parametric margin hyperplanes corresponding class aiming regulate manage impact heteroscedastic noise structure existing within data . The proposed MvTPMSVM model avoids explicit computation matrix inversion dual formulation leading enhanced computational efficiency . We perform extensive assessment MvTPMSVM model using benchmark datasets UCI KEEL synthetic Animals Attributes ( AwA ) . Our experimental result coupled rigorous statistical analysis confirm superior generalization capability proposed MvTPMSVM model compared baseline model . The source code proposed MvTPMSVM model available \url { http : //github.com/mtanveer1/MvTPMSVM } .
The recently proposed Multi-Layer Convolutional Sparse Coding ( ML-CSC ) model consisting cascade convolutional sparse layer provides new interpretation Convolutional Neural Networks ( CNNs ) . Under framework computation forward pas CNN equivalent pursuit algorithm aiming estimate nested sparse representation vector -- feature map -- given input signal . Despite served pivotal connection CNNs sparse modeling deeper understanding ML-CSC still lacking : pursuit algorithm serve model exactly condition guarantee non-empty model . While one easily obtain signal approximately satisfy ML-CSC constraint remains unclear simply sample model importantly one train convolutional filter real data . In work propose sound pursuit algorithm ML-CSC model adopting projection approach . We provide new improved bound stability solution pursuit analyze different practical alternative implement practice . We show training filter essential allow non-trivial signal model derive online algorithm learn dictionary real data effectively resulting cascaded sparse convolutional layer . Last least demonstrate applicability ML-CSC model several application unsupervised setting providing competitive result . Our work represents bridge matrix factorization sparse dictionary learning sparse auto-encoders analyze connection detail .
In paper discus review combined multi-view imagery satellite street-level benefit scene analysis . Numerous work exist merge information remote sensing image acquired ground task like land cover mapping object detection scene understanding . What make combination overhead street-level image challenging strongly varying viewpoint different scale illumination sensor modality time acquisition . Direct ( dense ) matching image per-pixel basis thus often impossible one resort alternative strategy discussed paper . We review recent work attempt combine image taken ground overhead view purpose like scene registration reconstruction classification . Three method represent wide range potential method application ( change detection image orientation tree cataloging ) described detail . We show cross-fertilization remote sensing computer vision machine learning valuable make best geographic data available Earth Observation sensor ground imagery . Despite challenge believe integrating complementary data source lead major breakthrough Big GeoData .
Fusing satellite imagery acquired different sensor long-standing challenge Earth observation particularly across different modality optical Synthetic Aperture Radar ( SAR ) image . Here explore joint analysis imagery different sensor light representation learning : propose learn joint embedding multiple satellite sensor within deep neural network . Our application problem monitoring lake ice Alpine lake . To reach temporal resolution requirement Swiss Global Climate Observing System ( GCOS ) office combine three image source : Sentinel-1 SAR ( S1-SAR ) Terra MODIS Suomi-NPP VIIRS . The large gap optical SAR domain sensor resolution make challenging instance sensor fusion problem . Our approach classified late fusion learned data-driven manner . The proposed network architecture separate encoding branch image sensor feed single latent embedding . I.e . common feature representation shared input subsequent processing step deliver comparable output irrespective sort input image used . By fusing satellite data map lake ice temporal resolution < 1.5 day . The network produce spatially explicit lake ice map pixel-wise accuracy > 91 % ( respectively mIoU score > 60 % ) generalises well across different lake winter . Moreover set new state-of-the-art determining important ice-on ice-off date target lake many case meeting GCOS requirement .
We formulate practical yet challenging problem : General Partial Label Learning ( GPLL ) . Compared traditional Partial Label Learning ( PLL ) problem GPLL relaxes supervision assumption instance-level -- label set partially label instance -- group-level : 1 ) label set partially label group instance within-group instance-label link annotation missing 2 ) cross-group link allowed -- instance group may partially linked label set another group . Such ambiguous group-level supervision practical real-world scenario additional annotation instance-level longer required e.g . face-naming video group consists face frame labeled name set corresponding caption . In paper propose novel graph convolutional network ( GCN ) called Dual Bipartite Graph Autoencoder ( DB-GAE ) tackle label ambiguity challenge GPLL . First exploit cross-group correlation represent instance group dual bipartite graph : within-group cross-group reciprocally complement resolve linking ambiguity . Second design GCN autoencoder encode decode decoding considered refined result . It worth noting DB-GAE self-supervised transductive us group-level supervision without separate offline training stage . Extensive experiment two real-world datasets demonstrate DB-GAE significantly outperforms best baseline absolute 0.159 F1-score 24.8 % accuracy . We offer analysis various level label ambiguity .
Ground deformation measured Interferometric Synthetic Aperture Radar ( InSAR ) data considered sign volcanic unrest statistically linked volcanic eruption . Recent study shown potential using Sentinel-1 InSAR data supervised deep learning ( DL ) method detection volcanic deformation signal towards global volcanic hazard mitigation . However detection accuracy compromised lack labelled data class imbalance . To overcome synthetic data typically used finetuning DL model pre-trained ImageNet dataset . This approach suffers poor generalisation real InSAR data . This letter proposes use self-supervised contrastive learning learn quality visual representation hidden unlabeled InSAR data . Our approach based SimCLR framework provides solution require specialized architecture large labelled synthetic dataset . We show self-supervised pipeline achieves higher accuracy respect state-of-the-art method show excellent generalisation even out-of-distribution test data . Finally showcase effectiveness approach detecting unrest episode preceding recent Icelandic Fagradalsfjall volcanic eruption .
Generating virtual try-on image in-shop clothing image model person 's snapshot challenging task human body clothes high flexibility shape . In paper develop Virtual Try-on Generative Adversarial Network ( VITON-GAN ) generates virtual try-on image using image in-shop clothing model person . This method enhances quality generated image occlusion present model person 's image ( e.g . arm crossed front clothes ) adding adversarial mechanism training pipeline .
Objective : A variety pattern analysis technique model training brain interface exploit neural feature dimensionality reduction based feature ranking selection heuristic . In light broad evidence demonstrating potential sub-optimality ranking based feature selection criterion propose extend focus information theoretic learning driven feature transformation concept . Methods : We present maximum mutual information linear transformation ( MMI-LinT ) nonlinear transformation ( MMI-NonLinT ) framework derived general definition feature transformation learning problem . Empirical assessment performed based electroencephalographic ( EEG ) data recorded four class motor imagery brain-computer interface ( BCI ) task . Exploiting state-of-the-art method initial feature vector construction compare proposed approach conventional feature selection based dimensionality reduction technique widely used brain interface . Furthermore multi-class problem present exploit hierarchical graphical model based BCI decoding system . Results : Both binary multi-class decoding analysis demonstrate significantly better performance proposed method . Conclusion : Information theoretic feature transformation capable tackling potential confounders conventional approach various setting . Significance : We argue concept provides significant insight extend focus feature selection heuristic broader definition feature transformation learning brain interface .
In work address problem approximating high-dimensional data low-dimensional representation . We make following contribution . We propose inverse regression method exchange role input response low-dimensional variable becomes regressor tractable . We introduce mixture locally-linear probabilistic mapping model start estimating parameter inverse regression follows inferring closed-form solution forward parameter high-dimensional regression problem interest . Moreover introduce partially-latent paradigm vector-valued response variable composed observed latent entry thus able deal data contaminated experimental artifact explained noise model . The proposed probabilistic formulation could viewed latent-variable augmentation regression . We devise expectation-maximization ( EM ) procedure based data augmentation strategy facilitates maximum-likelihood search model parameter . We propose two augmentation scheme describe detail associated EM inference procedure may well viewed generalization number EM regression dimension reduction factor analysis algorithm . The proposed framework validated synthetic real data . We provide experimental evidence method outperforms several existing regression technique .
The performance Collaborative Filtering ( CF ) method based property User-Item Rating Matrix ( URM ) . And property Rating Data Characteristics ( RDC ) URM constantly changing . Recent study significantly explained variation performance CF method resulted due change URM using six RDC . Here found significant proportion variation performance different CF technique accounted two RDC . The two RDC number rating per user Information per User ( IpU ) number rating per item Information per Item ( IpI ) . And performance CF algorithm quadratic IpU ( IpI ) square URM . The finding study based seven well-established CF method three popular public recommender datasets : 1M MovieLens 25M MovieLens Yahoo ! Music Rating datasets
Depth map produced consumer-grade sensor suffer inaccurate measurement missing data either system scene-specific source . Data-driven denoising algorithm mitigate problem . However require vast amount ground truth depth data . Recent research tackled limitation using self-supervised learning technique requires multiple RGB-D sensor . Moreover existing approach focus denoising single isolated depth map specific subject interest highlighting need method effectively denoise depth map real-time dynamic environment . This paper extends state-of-the-art approach depth-denoising commodity depth device proposing SelfReDepth self-supervised deep learning technique depth restoration via denoising hole-filling inpainting full-depth map captured RGB-D sensor . The algorithm target depth data video stream utilizing multiple sequential depth frame coupled color data achieve high-quality depth video temporal coherence . Finally SelfReDepth designed compatible various RGB-D sensor usable real-time scenario pre-processing step applying depth-dependent algorithm . Our result demonstrate approach 's real-time performance real-world datasets . They show outperforms state-of-the-art denoising restoration performance 30fps Commercial Depth Cameras potential benefit augmented mixed-reality application .
In paper developed solution roadside LiDAR object detection using combination two unsupervised learning algorithm . The 3D point cloud firstly converted spherical coordinate filled elevation-azimuth matrix using hash function . After raw LiDAR data rearranged new data structure store information range azimuth intensity . Then Dynamic Mode Decomposition method applied decompose LiDAR data low-rank background sparse foreground based intensity channel pattern recognition . The Coarse Fine Triangle Algorithm ( CFTA ) automatically find dividing value separate moving target static background according range information . After intensity range background subtraction foreground moving object detected using density-based detector encoded state-space model tracking . The output proposed solution includes vehicle trajectory enable many mobility safety application . The method validated path point level outperformed state-of-the-art . In contrast previous method process directly scattered discrete point cloud dynamic classification method establish less sophisticated linear relationship 3D measurement data capture spatial-temporal structure often desire .
With increasingly detailed investigation game play tactic invasive team sport soccer becomes ever important present cause action finding meaningful manner . Visualizations especially augmenting relevant information directly inside video recording match significantly improve simplify soccer match preparation tactic planning . However many visualization technique soccer developed recent year directly applied video-based analysis soccer match . This paper provides comprehensive overview categorization method developed video-based visual analysis soccer match . While identifying advantage disadvantage individual approach identify discus open research question soon enabling analyst develop winning strategy efficiently rapid failure analysis identify weakness opposing team .
Automatic question generation one challenging task Natural Language Processing . It requires `` bidirectional `` language processing : firstly system understand input text ( Natural Language Understanding ) generate question also form text ( Natural Language Generation ) . In article introduce framework generating factual question unstructured text English language . It us combination traditional linguistic approach based sentence pattern several machine learning method . We firstly obtain lexical syntactic semantic information input text construct hierarchical set pattern sentence . The set feature extracted pattern used automated learning new transformation rule . Our learning process totally data-driven transformation rule obtained set initial sentence-question pair . The advantage approach lie simple expansion new transformation rule allows u generate various type question also continuous improvement system reinforcement learning . The framework also includes question evaluation module estimate quality generated question . It serf filter selecting best question eliminating incorrect one duplicate . We performed several experiment evaluate correctness generated question also compared system several state-of-the-art system . Our result indicate quality generated question outperforms state-of-the-art system question also comparable question created human . We also created published interface created datasets evaluated question possible follow work .
Disease detection smartphone data represents open research challenge mobile health ( m-health ) system . COVID-19 respiratory symptom important case study area early detection potential real instrument counteract pandemic situation . The efficacy solution mainly depends performance AI algorithm applied collected data possible implementation directly user ' mobile device . Considering issue limited amount available data paper present experimental evaluation 3 different deep learning model compared also hand-crafted feature two main approach transfer learning considered scenario : feature extraction fine-tuning . Specifically considered VGGish YAMNET L\textsuperscript { 3 } -Net ( including 12 different configuration ) evaluated user-independent experiment 4 different datasets ( 13447 sample total ) . Results clearly show advantage L\textsuperscript { 3 } -Net experimental setting overcomes solution 12.3\ % term Precision-Recall AUC feature extractor 10\ % model fine-tuned . Moreover note fine-tune fully-connected layer pre-trained model generally lead worse performance average drop 6.6\ % respect feature extraction . % highlighting need investigation . Finally evaluate memory footprint different model possible application commercial mobile device .
Histopathological image classification constitutes pivotal task computer-aided diagnostics . The precise identification categorization histopathological image paramount significance early disease detection treatment . In diagnostic process pathologist multi-tiered approach typically employed assess abnormality cell region different magnification . However feature extraction often performed single granularity overlooking multi-granular characteristic cell . To address issue propose Fuzzy-guided Multi-granularity Deep Neural Network ( FMDNN ) . Inspired multi-granular diagnostic approach pathologist perform feature extraction cell structure coarse medium fine granularity enabling model fully harness information histopathological image . We incorporate theory fuzzy logic address challenge redundant key information arising multi-granular feature extraction . Cell feature described different perspective using multiple fuzzy membership function fused create universal fuzzy feature . A fuzzy-guided cross-attention module guide universal fuzzy feature toward multi-granular feature . We propagate feature encoder patch token aiming achieve enhanced classification accuracy robustness . In experiment multiple public datasets model exhibit significant improvement accuracy commonly used classification method histopathological image classification show commendable interpretability .
Deep neural network ( DNNs ) widely used surrogate model geophysical application ; incorporating theoretical guidance DNNs improved generalizability . However approach define loss function based strong form conservation law ( via partial differential equation PDEs ) subject deteriorated accuracy PDE high order derivative solution strong discontinuity . Herein propose weak form theory-guided neural network ( TgNN-wf ) incorporates weak form formulation PDE loss function combined data constraint initial boundary condition regularization tackle aforementioned difficulty . In weak form high order derivative PDE transferred test function performing integration-by-parts reduces computational error . We use domain decomposition locally defined test function capture local discontinuity effectively . Two numerical case demonstrate superiority proposed TgNN-wf strong form TgNN including hydraulic head prediction unsteady-state 2D single-phase flow problem saturation profile prediction 1D two-phase flow problem . Results show TgNN-wf consistently higher accuracy TgNN especially strong discontinuity solution present . TgNN-wf also train faster TgNN number integration subdomains large ( < 10000 ) . Moreover TgNN-wf robust noise . Thus proposed TgNN-wf pave way variety deep learning problem small data regime solved accurately efficiently .
In paper consider task space-time video super-resolution ( ST-VSR ) increase spatial resolution frame rate given video simultaneously . Despite remarkable progress recent method still suffer high computational cost inefficient long-range information usage . To alleviate problem propose Bidirectional Recurrence Network ( BRN ) optical-flow-reuse strategy better use temporal knowledge long-range neighboring frame high-efficiency reconstruction . Specifically efficient memory-saving multi-frame motion utilization strategy proposed reusing intermediate flow adjacent frame considerably reduces computation burden frame alignment compared traditional LSTM-based design . In addition proposed hidden state BRN updated reused optical flow refined Feature Refinement Module ( FRM ) optimization . Moreover utilizing intermediate flow estimation proposed method inference non-linear motion restore detail better . Extensive experiment demonstrate optical-flow-reuse-based bidirectional recurrent network ( OFR-BRN ) superior state-of-the-art method accuracy efficiency .
Deep hashing intensively studied successfully applied large-scale image retrieval system due efficiency effectiveness . Recent study recognized existence adversarial example pose security threat deep hashing model adversarial vulnerability . Notably challenging efficiently distill reliable semantic representative deep hashing guide adversarial learning thereby hinders enhancement adversarial robustness deep hashing-based retrieval model . Moreover current research adversarial training deep hashing hard formalized unified minimax structure . In paper explore Semantic-Aware Adversarial Training ( SAAT ) improving adversarial robustness deep hashing model . Specifically conceive discriminative mainstay feature learning ( DMFL ) scheme construct semantic representative guiding adversarial learning deep hashing . Particularly DMFL strict theoretical guarantee adaptively optimized discriminative learning manner discriminative semantic property jointly considered . Moreover adversarial example fabricated maximizing Hamming distance hash code adversarial sample mainstay feature efficacy validated adversarial attack trial . Further first time formulate formalized adversarial training deep hashing unified minimax optimization guidance generated mainstay code . Extensive experiment benchmark datasets show superb attack performance state-of-the-art algorithm meanwhile proposed adversarial training effectively eliminate adversarial perturbation trustworthy deep hashing-based retrieval . Our code available http : //github.com/xandery-geek/SAAT .
Despite large success deep neural network ( DNN ) recent year neural network still lack mathematical guarantee term stability . For instance DNNs vulnerable small even imperceptible input perturbation called adversarial example cause false prediction . This instability severe consequence application influence health safety human e.g . biomedical imaging autonomous driving . While bounding Lipschitz constant neural network improves stability method rely restricting Lipschitz constant layer give poor bound actual Lipschitz constant . In paper investigate variational regularization method named CLIP controlling Lipschitz constant neural network easily integrated training procedure . We mathematically analyze proposed model particular discussing impact chosen regularization parameter output network . Finally numerically evaluate method nonlinear regression problem MNIST Fashion-MNIST classification database compare result weight regularization approach .
Fingerprint dense registration aim finely align fingerprint pair pixel level thereby reducing intra-class difference caused distortion . Unfortunately traditional method exhibited subpar performance dealing low-quality fingerprint suffering slow inference speed . Although deep learning based approach show significant improvement aspect registration accuracy still unsatisfactory . In paper propose Phase-aggregated Dual-branch Registration Network ( PDRNet ) aggregate advantage type method . A dual-branch structure multi-stage interaction introduced correlation information high resolution texture feature low resolution perceive local fine difference ensuring global stability . Extensive experiment conducted comprehensive database compared previous work . Experimental result demonstrate method reach state-of-the-art registration performance term accuracy robustness maintaining considerable competitiveness efficiency .
Tissue texture known exhibit heterogeneous non-stationary nature therefore using single resolution approach optimum classification might suffice . A clinical decision support system exploit subband textural fractal characteristic best base selection meningioma brain histopathological image classification proposed . Each subband analysed using fractal dimension instead energy advantage less sensitive image intensity abrupt change tissue texture . The significant subband best identifies texture discontinuity chosen decomposition fractal characteristic would represent optimal feature vector classification . The performance tested using support vector machine ( SVM ) Bayesian k-nearest neighbour ( kNN ) classifier leave-one-patient-out method employed validation . Our method outperformed classical energy based selection approach achieving SVM Bayesian kNN classifier overall classification accuracy 94.12 % 92.50 % 79.70 % compared 86.31 % 83.19 % 51.63 % co-occurrence matrix 76.01 % 73.50 % 50.69 % energy texture signature respectively . These result indicate potential usefulness decision support system could complement radiologist diagnostic capability discriminate higher order statistical textural information would otherwise difficult via ordinary human vision .
This paper focus system WOLFIE ( WOrd Learning From Interpreted Examples ) acquires semantic lexicon corpus sentence paired semantic representation . The lexicon learned consists phrase paired meaning representation . WOLFIE part integrated system learns transform sentence representation logical database query . Experimental result presented demonstrating WOLFIE 's ability learn useful lexicon database interface four different natural language . The usefulness lexicon learned WOLFIE compared acquired similar system result favorable WOLFIE . A second set experiment demonstrates WOLFIE 's ability scale larger difficult albeit artificially generated corpus . In natural language acquisition difficult gather annotated data needed supervised learning ; however unannotated data fairly plentiful . Active learning method attempt select annotation training informative example therefore potentially useful natural language application . However result date active learning considered standard classification task . To reduce annotation effort maintaining accuracy apply active learning semantic lexicon . We show active learning significantly reduce number annotated example required achieve given level performance .
Vital sign ( breathing heartbeat ) monitoring essential patient care sleep disease prevention . Most current solution based wearable sensor camera ; however former could affect sleep quality latter often present privacy concern . To address shortcoming propose Wital contactless vital sign monitoring system based low-cost widespread commercial off-the-shelf ( COTS ) Wi-Fi device . There two challenge need overcome . First torso deformation caused breathing/heartbeats weak . How deformation effectively captured ? Second movement turning affect accuracy vital sign monitoring . How detrimental effect avoided ? For former propose non-line-of-sight ( NLOS ) sensing model modeling relationship energy ratio line-of-sight ( LOS ) NLOS signal vital sign monitoring capability using Ricean K theory use model guide system construction better capture deformation caused breathing/heartbeats . For latter propose motion segmentation method based motion regularity detection accurately distinguishes respiration motion remove period include movement turning eliminate detrimental effect . We implemented validated Wital low-cost COTS device . The experimental result demonstrate effectiveness Wital monitoring vital sign .
We introduce novel framework continuous facial motion deblurring restores continuous sharp moment latent single motion-blurred face image via moment control factor . Although motion-blurred image accumulated signal continuous sharp moment exposure time existing single image deblurring approach aim restore fixed number frame using multiple network training stage . To address problem propose continuous facial motion deblurring network based GAN ( CFMD-GAN ) novel framework restoring continuous moment latent single motion-blurred face image single network single training stage . To stabilize network training train generator restore continuous moment order determined facial motion-based reordering process ( FMR ) utilizing domain-specific knowledge face . Moreover propose auxiliary regressor help generator produce accurate image estimating continuous sharp moment . Furthermore introduce control-adaptive ( ContAda ) block performs spatially deformable convolution channel-wise attention function control factor . Extensive experiment 300VW datasets demonstrate proposed framework generates various number continuous output frame varying moment control factor . Compared recent single-to-single image deblurring network trained 300VW training set proposed method show superior performance restoring central sharp frame term perceptual metric including LPIPS FID Arcface identity distance . The proposed method outperforms existing single-to-video deblurring method qualitative quantitative comparison .
Self-supervised contrastive learning ( SSCL ) achieved significant milestone remote sensing image ( RSI ) understanding . Its essence lie designing unsupervised instance discrimination pretext task extract image feature large number unlabeled image beneficial downstream task . However existing instance discrimination based SSCL suffer two limitation applied RSI semantic segmentation task : 1 ) Positive sample confounding issue ; 2 ) Feature adaptation bias . It introduces feature adaptation bias applied semantic segmentation task require pixel-level object-level feature . In study We observed discrimination information mapped specific region RSI gradient unsupervised contrastive loss specific region tend contain singular ground object . Based propose contrastive learning Gradient guided Sampling Strategy ( GraSS ) RSI semantic segmentation . GraSS consists two stage : Instance Discrimination warm-up ( ID warm-up ) Gradient guided Sampling contrastive training ( GS training ) . The ID warm-up aim provide initial discrimination information contrastive loss gradient . The GS training stage aim utilize discrimination information contained contrastive loss gradient adaptively select region RSI patch contain singular ground object order construct new positive negative sample . Experimental result three open datasets demonstrate GraSS effectively enhances performance SSCL high-resolution RSI semantic segmentation . Compared seven baseline method five different type SSCL GraSS achieves average improvement 1.57\ % maximum improvement 3.58\ % term mean intersection union . The source code available http : //github.com/GeoX-Lab/GraSS
Research content-based image retrieval ( CBIR ) development decade numerous method competing extract discriminative feature improved representation image content . Recently deep learning method gained attention computer vision including CBIR . In paper present comparative investigation different feature including low-level high-level feature CBIR . We compare performance CBIR system using different deep feature state-of-the-art low-level feature SIFT SURF HOG LBP LTP using different dictionary coefficient learning technique . Furthermore conduct comparison set primitive popular feature used field including colour histogram Gabor feature . We also investigate discriminative power deep feature using certain similarity measure different validation approach . Furthermore investigate effect dimensionality reduction deep feature performance CBIR system using principal component analysis discrete wavelet transform discrete cosine transform . Unprecedentedly experimental result demonstrate high ( 95\ % 93\ % ) mean average precision using VGG-16 FC7 deep feature Corel-1000 Coil-20 datasets 10-D 20-D K-SVD respectively .
Learning-based analysis image commonly used field mobility robotics safe environmental motion interaction . This requires object recognition also assignment certain property . With help information causally related action adapted different circumstance . Such logical interaction optimized recognizing object-assigned property . Density physical property offer possibility recognize heavy object material made force work consequently influence environment . Our approach introduces AI-based concept assigning physical property object use associated image . Based synthesized data derive specific pattern 2D image using neural network extract information volume material density . Accordingly discus possibility property-based feature extraction improve causally related logic .
The model low-dimensional manifold sparse representation two well-known concise model suggest data described characteristic . Manifold learning usually investigated dimension reduction preserving expected local geometric structure original space low-dimensional one . The structure generally determined using pairwise distance e.g . Euclidean distance . Alternatively sparse representation denotes data point linear combination point subspace . In practical application however nearby point term pairwise distance may belong subspace vice versa . Consequently interesting important explore get better representation integrating two model together . To end paper proposes novel coding algorithm called Locality-Constrained Collaborative Representation ( LCCR ) improves robustness discrimination data representation introducing kind local consistency . The locality term derives biologic observation similar input similar code . The objective function LCCR analytical solution involve local minimum . The empirical study based four public facial database ORL AR Extended Yale B Multiple PIE show LCCR promising recognizing human face frontal view varying expression illumination well various corruption occlusion .
Although widely discussed video surveillance background subtraction still open problem context complex scenario e.g . dynamic background illumination variation indistinct foreground object . To address challenge propose effective background subtraction method learning maintaining array dynamic texture model within spatio-temporal representation . At location scene extract sequence regular video brick i.e . video volume spanning spatial temporal domain . The background modeling thus posed pursuing subspace within video brick adapting scene variation . For sequence video brick pursue subspace employing ARMA ( Auto Regressive Moving Average ) Model jointly characterizes appearance consistency temporal coherence observation . During online processing incrementally update subspace cope disturbance foreground object scene change . In experiment validate proposed method several complex scenario show superior performance state-of-the-art approach background subtraction . The empirical study parameter setting component analysis presented well .
In paper propose novel method transforming data low-dimensional space optimized one-class classification . The proposed method iteratively transforms data new subspace optimized ellipsoidal encapsulation target class data . We provide linear non-linear formulation proposed method . The method take account covariance data subspace ; hence yield generalized solution compared Subspace Support Vector Data Description hypersphere . We propose different regularization term expressing class variance projected space . We compare result classic recently proposed one-class classification method achieve better result majority case . The proposed method also noticed converge much faster recently proposed Subspace Support Vector Data Description .
We propose active learning approach image segmentation exploit geometric prior speed streamline annotation process . It applied background-foreground multi-class segmentation task 2D image 3D image volume . Our approach combine geometric smoothness prior image space traditional uncertainty measure estimate pixel voxels informative thus annotated next . For multi-class setting additionally introduce two novel criterion uncertainty . In 3D case use resulting uncertainty measure select voxels lying planar patch make batch annotation much convenient end user compared setting voxels randomly distributed volume . The planar patch found using branch-and-bound algorithm look 2D patch 3D volume informative instance located . We evaluate approach Electron Microscopy Magnetic Resonance image volume well regular image horse face . We demonstrate substantial performance increase approach thanks use geometric prior .
A recent proposal data dependent similarity called Isolation Kernel/Similarity enabled SVM produce better classification accuracy . We identify shortcoming using tree method implement Isolation Similarity ; propose nearest neighbour method instead . We formally prove characteristic Isolation Similarity use proposed method . The impact Isolation Similarity density-based clustering studied . We show first time clustering performance classic density-based clustering algorithm DBSCAN significantly uplifted surpass recent density-peak clustering algorithm DP . This achieved simply replacing distance measure proposed nearest-neighbour-induced Isolation Similarity DBSCAN leaving rest procedure unchanged . A new type cluster called mass-connected cluster formally defined . We show DBSCAN detects density-connected cluster becomes one detects mass-connected cluster distance measure replaced proposed similarity . We also provide condition mass-connected cluster detected density-connected cluster .
To investigate neural network parameter easier study distribution parameter study parameter neuron . The ridgelet transform pseudo-inverse operator map given function $ f $ parameter distribution $ \gamma $ network $ \mathtt { NN } [ \gamma ] $ reproduces $ f $ i.e . $ \mathtt { NN } [ \gamma ] =f $ . For depth-2 fully-connected network Euclidean space ridgelet transform discovered closed-form expression thus could describe parameter distributed . However variety modern neural network architecture closed-form expression known . In paper explain systematic method using Fourier expression derive ridgelet transforms variety modern network network finite field $ \mathbb { F } _p $ group convolutional network abstract Hilbert space $ \mathcal { H } $ fully-connected network noncompact symmetric space $ G/K $ pooling layer $ $ -plane ridgelet transform .
Session-based recommendation ( SBR ) aim predict next item certain time point based anonymous user behavior sequence . Existing method typically model session representation based simple item transition information . However since session-based data consists limited user ' short-term interaction modeling session representation capturing fixed item transition information single dimension suffers data sparsity . In paper propose novel contrastive multi-level graph neural network ( CM-GNN ) better exploit complex high-order item transition information . Specifically CM-GNN applies local-level graph convolutional network ( L-GCN ) global-level network ( G-GCN ) current session session respectively effectively capture pairwise relation session aggregation strategy . Meanwhile CM-GNN applies hyper-level graph convolutional network ( H-GCN ) capture high-order information among item transition . CM-GNN introduces attention-based fusion module learn pairwise relation-based session representation fusing item representation generated L-GCN G-GCN . CM-GNN average item representation obtained H-GCN obtain high-order relation-based session representation . Moreover convert high-order item transition information pairwise relation-based session representation CM-GNN maximizes mutual information representation derived fusion module average pool layer contrastive learning paradigm . We conduct extensive experiment multiple widely used benchmark datasets validate efficacy proposed method . The encouraging result demonstrate proposed method outperforms state-of-the-art SBR technique .
Affective computing field great interest many computer vision application including video surveillance behaviour analysis human-robot interaction . Most existing literature addressed field analysing different set face feature . However last decade several study shown body movement play key role even emotion recognition . The majority experiment body performed trained actor whose aim simulate emotional reaction . These unnatural expression differ challenging genuine emotion thus invalidating obtained result . In paper solution basic non-acted emotion recognition based 3D skeleton Deep Neural Networks ( DNNs ) provided . The proposed work introduces three major contribution . First unlike current state-of-the-art non-acted body affect recognition static global body feature considered work also temporal local movement performed subject frame examined . Second original set global time-dependent feature body movement description provided . Third best knowledge first attempt use deep learning method non-acted body affect recognition . Due novelty topic UCLIC dataset currently considered benchmark comparative test . On latter proposed method outperforms competitor .
Recognizing emotional state people basic challenging task video understanding . In paper propose new task field named Pairwise Emotional Relationship Recognition ( PERR ) . This task aim recognize emotional relationship two interactive character given video clip . It different traditional emotion social relation recognition task . Varieties information consisting character appearance behavior facial emotion dialogue background music well subtitle contribute differently final result make task challenging meaningful developing advanced multi-modal model . To facilitate task develop new dataset called Emotional RelAtionship inTeractiOn ( ERATO ) based drama movie . ERATO large-scale multi-modal dataset PERR task 31182 video clip lasting 203 video hour . Different existing datasets ERATO contains interaction-centric video multi-shots varied video length multiple modality including visual audio text . As minor contribution propose baseline model composed Synchronous Modal-Temporal Attention ( SMTA ) unit fuse multi-modal information PERR task . In contrast prevailing attention mechanism proposed SMTA steadily improve performance 1\ % . We expect ERATO well proposed SMTA open new way PERR task video understanding improve research multi-modal fusion methodology .
Analysis spatial multivariate data i.e . measurement irregularly-spaced location challenging topic visualization statistic alike . Such data integral many domain e.g . indicator valuable mineral measured mine prospecting . Popular analysis method like PCA often design account spatial nature data . Thus together spatial variant must employed carefully . Clearly preferable use method specifically designed data like spatial blind source separation ( SBSS ) . However SBSS requires two tuning parameter complex spatial object . Setting parameter involves navigating two large interdependent parameter space also taking account prior knowledge physical reality represented data . To support analyst process developed visual analytics prototype . We evaluated expert visualization SBSS geochemistry . Our evaluation show interactive prototype allows define complex realistic parameter setting efficiently far impractical . Settings identified non-expert led remarkable surprising insight domain expert . Therefore paper present important first step enable use promising analysis method spatial multivariate data .
Deep neural network ( DNNs ) increasingly applied safety-critical domain self-driving car unmanned aircraft medical diagnosis . It fundamental importance certify safety DNNs i.e . comply formal safety specification . While safety certification tool exactly answer question help debugging unsafe DNNs requiring developer iteratively verify modify DNN safety eventually achieved . Hence repair technique need developed produce safe DNN automatically . To address need present SpecRepair tool efficiently eliminates counter-examples DNN produce provably safe DNN without harming classification accuracy . SpecRepair combine specification-based counter-example search resume training DNN penalizing counter-examples certifying resulting DNN . We evaluate SpecRepair 's effectiveness ACAS Xu benchmark DNN-based controller unmanned aircraft two image classification benchmark . The result show SpecRepair successful producing safe DNNs comparable method shorter runtime produce safe DNNs preserving classification accuracy .
Knowledge base ( KBs ) notable entity property important asset application search question answering dialogue . All popular KBs capture virtually positive statement abstain taking stance statement stored KB . This paper make case explicitly stating salient statement hold . Negative statement useful overcome limitation question answering system mainly geared positive question ; also contribute informative summary entity . Due abundance invalid statement effort compile need address ranking saliency . We present statisticalinference method compiling ranking negative statement based expectation positive statement related entity peer group . Experimental result variety datasets show method effectively discover notable negative statement extrinsic study underline usefulness entity summarization . Datasets code released resource research .
A smart vehicle able understand human behavior predict action avoid hazardous situation . Specific trait human behavior automatically predicted help vehicle make decision increasing safety . One important aspect pertaining driving task driver 's visual attention . Predicting driver 's visual attention help vehicle understand awareness state driver providing important contextual information . While estimating exact gaze direction difficult car environment coarse estimation visual attention obtained tracking position orientation head . Since relation head pose gaze direction one-to-one paper proposes formulation based probabilistic model create salient region describing visual attention driver . The area predicted region small model high confidence prediction directly learned data . We use Gaussian process regression ( GPR ) implement framework comparing performance different regression formulation linear regression neural network based method . We evaluate framework studying tradeoff spatial resolution accuracy probability map using naturalistic recording collected UTDrive platform . We observe GPR method produce best result creating accurate prediction localized salient region . For example 95 % confidence region defined area cover 3.77 % region sphere surrounding driver .
