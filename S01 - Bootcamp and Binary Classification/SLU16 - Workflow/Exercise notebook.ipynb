{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba84fc3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b4d3733f6cccd6be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# SLU16 - Workflow: Exercise Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ef698a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2f7d8358f51a95c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import hashlib # just for grading purposes\n",
    "import json # just for grading purposes\n",
    "\n",
    "from utils import workflow_steps, data_analysis_steps\n",
    "from utils import get_dataset\n",
    "from utils import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0379fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-017c07341b261351",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    A <b>data science workflow</b> defines the phases (or steps) in a data science project. Using a well-defined data science workflow is useful not only to you, but also to your teammates as it provides a simple way to clearly structure and organize a data science project. Across this specialization we've been covering the different steps in this workflow, but how well are you familiarised with them?\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4842c68b-b2cb-4ad2-a5d8-361334d80265",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cab312b59a379771",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1: Workflow\n",
    "\n",
    "### Exercise 1.1 - Overall workflow steps\n",
    "\n",
    "What are the basic workflow steps?\n",
    "\n",
    "You probably know them already, but we want you to really internalize them. We've given you a list of steps in `workflow_steps`, but it appears that, not only does it have too many steps, some are _probably_ wrong, as well.\n",
    "\n",
    "Listed below are several steps that might be part of a machine learning workflow. Some of these steps are essential, some are substeps of broader categories, and others are not relevant at all. Your task is to filter out the irrelevant steps, identify which are major/principal steps and arrange them in a logical order.\n",
    "\n",
    "The answer should be a list of the workflow names as shown below.\n",
    "```python\n",
    "workflow_steps_answer_EXAMPLE = ['Google Hackathon solutions',  'Train model', 'Watch Netflix','Iterate']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae1b06d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c5101e47a4828368",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Workflow steps:\")\n",
    "for i in range(len(workflow_steps)):\n",
    "    print(i+1, ': ', workflow_steps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e8f62",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-eb636145aa25eef4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 1.1. Filter and sort the names of the steps in the workflow_steps list\n",
    "# workflow_steps_answer = [...]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2728e0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8c9ae302d2c9c48c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert hashlib.sha256(json.dumps(str(len(workflow_steps_answer))).encode()).hexdigest() == \\\n",
    "'d10a4bc9e0c1fa4e8f3d7ce2512b8756e47ca5fa451f373c39a1431bb88db49f', \"your workflow size doesn't look right! Don't forget to remove steps that shouldn't be there\"\n",
    "assert hashlib.sha256(json.dumps(''.join(workflow_steps_answer)).encode()).hexdigest() == \\\n",
    "'f52fdbe9d46026f357ca8077b5b522e2ff03d1d6406bcbcded01e51cbb1c7407', \"Your workflow order doesn't look right! Some steps might be out of place.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e463f97f-e92d-4443-adb2-015fec949e21",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f258575f6c7a6dc6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.2: Data Analysis and Preparation\n",
    "\n",
    "There are way too many substeps in the **Data Analysis and Preparation** step to group them all under a single category. We've given you another list of steps: `data_analysis_steps`.\n",
    "\n",
    "Aside from being shuffled it should be fine, but keep an eye out. You never know what to expect..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397e0bfa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28be987a3be96809",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Data Analysis and Preparation steps:\")\n",
    "for i in range(len(data_analysis_steps)):\n",
    "    print(i+1, ': ', data_analysis_steps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4116241",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2dab17640925e0d9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Exercise 1.2. Filter and sort the names of the steps in the data_analysis_steps list\n",
    "# data_analysis_steps_answer = [...]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b060a6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6d6087c6110d2371",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert hashlib.sha256(json.dumps(str(len(data_analysis_steps_answer))).encode()).hexdigest() == \\\n",
    "'2bf175f9655e7bb7357b9f0a7c6051465a5ae701104ffe741b98e852c0e4d460', \\\n",
    "\"Your workflow size doesn't look right! Don't forget to remove steps that shouldn't be there\"\n",
    "assert hashlib.sha256(json.dumps(''.join(data_analysis_steps_answer)).encode()).hexdigest() == \\\n",
    "'c13423bcff9996a81603cf2b46eca48bcea7ed4449781ca7b2b7349acc15da58', \\\n",
    "\"Your workflow order doesn't look right! Some steps might be out of place.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23109fc9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-010003b31ea0fd27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"media/spanish_inquisition.gif\" width=\"400\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99aede2b-a9c0-44e2-b48a-9c042ef7c9de",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ba6650bcf67a8fa3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2 - Walking down the yellow (workflow) path\n",
    "\n",
    "There is no template for solving a data science problem. The roadmap changes with every new dataset and new problem. But we do see similar steps in many different projects. Regardless, some steps are fairly common in any process. Let's go through them one by one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e95bd11d-d0de-44b9-b5e8-e0d3d7ed8c86",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bb496988687ae3d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.1 - Objective\n",
    "\n",
    "Every DS analysis should start with one question: **What is the problem you are trying to solve?** Clearly stating your problem is the first step to solving it and without a clear problem, you could find yourself down a data-science rabbit-hole.\n",
    "\n",
    "For this workflow, we are going to analyze a **randomly generated dataset**. The objective? \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    Build a model to predict the <b>value of y</b> given a set of features.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5369123f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-91bc71f2573aaaaf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Exercise 2.1.1 - Objective\n",
    "Let's start by importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18917a09",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a7a6a16a20aec456",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df, y = get_dataset()  # preloaded dataset\n",
    "df['y'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1bee47",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8c90322f33f668bd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "⚠️ Is the objective clear to you?\n",
    "This is just a yes or no question, no need for code here! :P \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5a2f49",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7bac9e5a5b30e333",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer_2_1_1=False\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d55c39b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-dad9e0e457bf29a1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert answer_2_1_1, \"Don't make the panda sad!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332cb222",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-58ea5ecaae02df01",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Exercise 2.1.2 - Clasifying the problem\n",
    "Now that we have our data imported into Pandas and we've checked out the first few rows of our dataframe, there's a few questions we need to answer before we move on:\n",
    "\n",
    "- *A*: Is this **supervised learning** or **unsupervised learning**? \n",
    "- *B*: Is this a **classification problem** or is it a **regression problem**? \n",
    "- *C*: Is this a **prediction problem** or an **inference problem**?\n",
    "\n",
    "Keeping our **objective in mind** how would you classify this problem?\n",
    "\n",
    "Save, in `answer_2_1_2`, the values from **A, B and C** that apply to our problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6af8f33",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-26745fdc9dca03d8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remove from the string what doesn't apply to our problem (including the '/')\n",
    "#answer_2_1_2 = [\"supervised/unsupervised learning\",\"classification/regression problem\", \"prediction/inference problem\"]\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df5101",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-80d1e9191be2cad6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert hashlib.sha256(json.dumps(str(len(answer_2_1_2))).encode()).hexdigest() == \\\n",
    "'a4aab3f1f08004e907d2357fafe74cab56359bcb32e23f52e7eb1d3a9c0a2ad3', \"Your answer doesn't have the correct size. I've asked you to pick the correct option for three questions.\"\n",
    "assert hashlib.sha256(json.dumps(''.join(answer_2_1_2)).encode()).hexdigest() == \\\n",
    "'daf0671c4703f89c723f13ef493b7e91314f3e681dc18d4f0b3b15807738913c', \"One or more of your answers are incorrect.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61edfcab-d498-45cf-8b3b-940b5ba4c011",
   "metadata": {
    "deletable": false,
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8b336c0b944c04c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.2 - Data Exploration and Data Cleaning\n",
    "\n",
    "Back to our data! Let’s determine which variable is our target and which features we think are important.\n",
    "Our target is the column titled **y** and our features are the columns not containing the words **arm** or **leg** (assume we got this information from our boss or client). Remove all of the columns we don’t need for this analysis from the dataframe. Order the columns lexicographically by column name.\n",
    "\n",
    "<div class=\"alert alert-warning\"> \n",
    "⚠️ <b>NOTE: </b>lexicographic sorting means basically that the language treats the variables as strings and compares character by character (\"200\" is greater than \"19999\" because '2' is greater than '1').\n",
    "</div>\n",
    "    \n",
    "Save the resulting dataframe in `df_clean`. \n",
    "\n",
    "Remember, in this case we're telling you what columns are to be kept, but this decision is something that is part of your workflow process. **A good data exploration and data cleaning is a key factor in the outcome of your model!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f580ee",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-138aa6edcbd29190",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#df_clean = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2460fe8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-797514f689b49b52",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df_clean, pd.DataFrame), \"Should be a dataframe\"\n",
    "assert df_clean.shape == (100, 21), \"The shape of the dataframe is different than expected. Have you dropped the uncessessary columns?\"\n",
    "assert hashlib.sha256(json.dumps(''.join([step.lower() for step in df_clean.columns])).encode()).hexdigest() == \\\n",
    "'20881c4cd7cacd9965a7a43119651d0a2b116c79196cf7f93958a7b75b7d4929', \"One or more of your column headers is incorrect.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "110b99d1-5ea3-41f7-a60f-27eceede1f88",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0febe6071b3fff48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.3 - EDA\n",
    "\n",
    "Exploratory data analysis (EDA) gives the data scientist an opportunity to really learn about the data they are working with. \n",
    "\n",
    "Throughout the EDA process, I clean the data. Data from the real world is *very messy*. As I work through the EDA process and learn about the data, I take notes on things I need to fix in order to conduct my analysis. Most times, **Data cleaning and EDA go hand in hand for me**.\n",
    "\n",
    "The first things I check are data types. Getting all of the values in the correct format is important. This can involve stripping characters from strings, converting integers to floats, or many other things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac25c74d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c1df6eb16892c268",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "What is the data type of our features? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9a4d86",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4dfbeeaad55f42af",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer_2_3 = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27647936",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-e82bcea511e8aa79",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert hashlib.sha256(json.dumps(answer_2_3).encode()).hexdigest() == \\\n",
    "'570f5a17338b199b7bd32e4bc5fe0cdf0b58d3f6cb8ef982ddb5c69f53520e3a', \"Not correct.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08897511",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c44cf8d3b12a8ec6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2.4 - Impute missing values\n",
    "Finding missing values is quite common. Just replace them in our clean dataframe with the mean of the corresponding column/feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c6d756",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc4703b89bf0d85b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#df_clean = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14446f9b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8443173a170a44d8",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df_clean, pd.DataFrame), \"Should be a dataframe\"\n",
    "assert df_clean.isna().sum().sum() == 0, \"Missing values are still present\"\n",
    "assert df_clean.shape == (100, 21), \"The shape of the dataframe is different than expected. Have you dropped the rows with missing data?\"\n",
    "np.testing.assert_almost_equal(df_clean.values.sum(), 127.5116, decimal=4,\n",
    "                               err_msg=\"Are you replacing the missing values by the mean of each column?\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b8a99",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ddc782874c5a987a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Uff! That took quite some time, but now we have a clean and tidy dataframe to work with!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6c87933-6b16-4f21-a4c2-47efcbcd505c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b3cceed7311b4e1f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 3 - Baseline modeling\n",
    "\n",
    "As a data scientist, you will build a lot of models. You will use a variety of algorithms to perform a wide variety of tasks. You will need to use intuition and experience to decide when certain models are appropriate! \n",
    "\n",
    "But when constructing your baseline model, the simpler, the better! \n",
    "\n",
    "Let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a454a96",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5cb59cec192c4d69",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3.1 - Separate your target value \n",
    "\n",
    "Separate into `X` and `y` your features and your target. Keep the lexicographical order of columns in `X` as in exercise 2.2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e099a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c1c072726b679fe8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#X = ...\n",
    "#y = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30212e96",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d02011f7f3426b07",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert  hashlib.sha256(json.dumps(''.join(y.astype(str))).encode()).hexdigest() == \\\n",
    "'29d0b7d8313fdfca4a5d4215caca67fc45cd0497eafa274912e59e1599da5b00', \"Have you picked the right column as the target?\"\n",
    "assert X.shape == (100, 20), \"The shape of X is different than expected. Have you dropped the target?\"\n",
    "assert  hashlib.sha256(json.dumps(''.join(sorted(X.columns))).encode()).hexdigest() == \\\n",
    "'258dfdcebee87cef91291a45e5020f6bb7abe504edb66a1f68b5cb853068bb0a', \"Have you included the right columns in X?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc49702",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7ad60c0b0b46ef11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3.2 - Split data\n",
    "\n",
    "Split your dataset into test and train data, using `test_size=0.2` and `random_state=42` on your `train_test_split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bdd29d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0a59ceb29b6e7a7b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876dc7d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-eda4965289c315c6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (X_train.shape, X_test.shape, y_train.shape, y_test.shape) == ((80, 20), (20, 20), (80,), (20,)),\\\n",
    "\"Have you split the data correctly? Test size should be 0.2.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12f74a3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cbbe2d32e51c944c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3.3 - Scale your data\n",
    "As we are not sure whether the features are on the same scale, you should scale your X_train and X_test. Use the `MinMaxScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab4a81",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fe58c296cca28681",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# scaler = ...\n",
    "# X_train_scaled = ...\n",
    "# X_test_scaled = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632e4395",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cc5e79e6d94f3521",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(sum(X_train_scaled[:,1]), 42.147, decimal=3, err_msg=\"Have you used the correct scaler?\")\n",
    "np.testing.assert_almost_equal(sum(X_test_scaled[:,4]), 13.565, decimal=3, err_msg=\"Have you used the correct scaler?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a406d6aa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-46502ca5406d2e19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3.4 - Finally! The model!\n",
    "\n",
    "We can finally make our predictions with a simple Random Forest Classifier! Fit this classifier with default settings and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd43740",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6423f554ffdba88d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#model = ...\n",
    "#predictions = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d54b964",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-408ce12cfa728ad1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert predictions.size == 20\n",
    "assert hashlib.sha256(json.dumps(model.get_params()).encode()).hexdigest() == \\\n",
    "'92f8858316e0ad22d4eaa3f686a7bd9f171c7d2a48c2e17144bbf4c73bf0123d', 'Have you fitted the correct model?'\n",
    "plot_confusion_matrix(y_test, predictions)\n",
    "\n",
    "print ('Accuracy score:', accuracy_score(y_test, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13696d98",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-92d7a5fdbef2f1a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Our model is not performing bad at all! If you want to improve it, you should make **small alterations**, **one at a time**! Keeping track of your changes is crucial to know exactly what change is helping or hurting your model! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9ec9b60-d2c1-4e2d-85a8-9514c70d4957",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-953febcd52772794",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 4 - Pipelines!!!!! \n",
    "\n",
    "We've already loaded and splitted a dataset for the following exercises. They're stored in the `new_X_train`, `new_X_test`, `new_y_train` and `new_y_test` variables.\n",
    "\n",
    "In a perfect world, where you have all your data clean and ready-to-go, you can create your pipeline with just Scikit-learn's Transformers. However, in the real world, that's not the case, and you'll need to create custom Transformers to get the job done. Take a look at the data set, what do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00bf12a-9a85-4636-8ab3-6e7779cc2cc0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8e88cbc3e3064083",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "new_X, new_y = get_dataset()  # preloaded dataset\n",
    "new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(new_X, new_y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce38ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to explore the data\n",
    "# do you notice something interesting in the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f926376c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bab71226281048e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see, it's the exact same dataset from the previous exercises! The same issues have returned:\n",
    "\n",
    "- There are 4 columns whose name starts with either arm or leg which are all filled with gibberish.\n",
    "- There are some missing values in some columns.\n",
    "\n",
    "So, first things first, let's get rid of those columns with gibberish through a **Custom Transformer**, so we can plug it in a Scikit Pipeline after."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e89ddb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c111570451988ca9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 4.1 - Custom Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376cfb92",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dc3fa4786483541e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a pipeline step called RemoveLimbs that removes any\n",
    "# column whose name starts with the string 'arm' or ´leg´\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68742df",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b91664f72233c2c7",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "new_X, new_y = get_dataset()  # preloaded dataset\n",
    "new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(new_X, new_y, test_size=0.33)\n",
    "assert issubclass(RemoveLimbs, TransformerMixin)\n",
    "assert hashlib.sha256(json.dumps(''.join(sorted(RemoveLimbs().fit_transform(new_X).columns))).encode()).hexdigest() == \\\n",
    "'258dfdcebee87cef91291a45e5020f6bb7abe504edb66a1f68b5cb853068bb0a', 'The transformer does not work as expected.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d6b7a6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57a63eb58da3b85b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 4.2 - Pipelines are the best!\n",
    "\n",
    "Now that we have our Custom Transformer in place, we can design our pipeline! \n",
    "\n",
    "Create a pipeline with the following steps:\n",
    "\n",
    "1. Removes limbs columns\n",
    "2. Imputes missing values with the mean\n",
    "3. Has a Random Forest Classifier as the last step\n",
    "\n",
    "Use `make_pipeline` to create your pipeline with as many steps as you want as long as the first two are the Custom Transformer you developed previously, a `SimpleImputer` as the second step, and a `RandomForestClassifier` as the last step. Save your pipeline into a variable named `pipeline`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2502c2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-178a0f61ec49c4ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# pipeline = make_pipeline(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f575fe8-6c55-45e2-8b97-baf1762a45fa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b83147bac13bafad",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert hashlib.sha256(json.dumps(pipeline.steps[0][0]).encode()).hexdigest() == \\\n",
    "'617c9c17cb0d8631f14cbb249c4a1bf179e2a914fe58e2fb9bdb7f66767ec388', 'The first pipeline step is not correct.'\n",
    "assert hashlib.sha256(json.dumps(pipeline.steps[1][0]).encode()).hexdigest() == \\\n",
    "'78f213811c43cb005d721596ad15f98a02e57c6db473e2a80b3904837b3a998a', 'The second pipeline step is not correct.'\n",
    "assert hashlib.sha256(json.dumps(pipeline.steps[-1][0]).encode()).hexdigest() == \\\n",
    "'8be548c26fc993261b503615ee03e07c5a6054dfa558b41c5e1fd836fceb155c', 'The last pipeline step is not correct.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64ba237",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b813e89a08b2880e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Does it work? Let's check it out on our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ecbaec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aa9293b40285d113",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pipeline.fit(new_X_train, new_y_train)\n",
    "new_y_pred = pipeline.predict(new_X_test)\n",
    "accuracy_score(new_y_test, new_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9341e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-20bc44001d7869f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "It doesn't get much simpler that this, does it?\n",
    "\n",
    "For an extra challenge, go back to exercises 2 and 3 and follow our workflow but with a Pipeline! For each special processing we've done, you can create a custom transformer for that column.\n",
    "\n",
    "Dominating pipelines and custom transformers can be a huge time saver! And there's the hackathon ahead...\n",
    "\n",
    "**Good luck!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
