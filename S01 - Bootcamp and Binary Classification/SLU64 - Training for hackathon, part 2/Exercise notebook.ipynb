{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c8eb4b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fe6ee765726b9073",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# SLU64 - Training for the hackathon, part 2\n",
    "Welcome to the second part of the hackathon training. Hopefully, after going through part 1, you now know your data set in and out and have constructed your first model.\n",
    "\n",
    "In this SLU, you will deal with the imbalance, try out other models, engineer new features, and finally optimize your model and its hyperparameters. We are providing hints to guide you through the workflow. It's on you to fill in all the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all you need in this cell - we already did some imports for you\n",
    "# basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "#sklearn libraries\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, RobustScaler\n",
    "from sklearn.preprocessing import KBinsDiscretizer, Binarizer, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,roc_curve,classification_report,auc\n",
    "# imbalanced datasets\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler\n",
    "from imblearn.under_sampling import TomekLinks,RandomUnderSampler\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, SelectFromModel\n",
    "# model selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# pipelines\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "\n",
    "#other libraries\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30037655",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8a2c0317ea21724e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Import the dataset and do the train-test split\n",
    "Here we make a step back. The first step in the model set up is the division of the dataset into a train and test dataset. Hide your test dataset into a virtual drawer and take it out when it's time for testing. Prepare your preprocessing workflow with the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset and do the train-test split.\n",
    "# Take into account the imbalance of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00ce1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your preprocessing pipeline using the train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7300e8f2",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "The dataset contains numerical and categorical features. Basic feature engineering such as dealing with the categorical features is an obligatory part of the preprocessing. Engineering new features is an optional step that can be done as part of model optimization.\n",
    "\n",
    "Can you encode the categorical features in a form that is more advantageous for the model? Can you engineer new features from the existing one?  Look especially at the `anonymous` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98095f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the categorical features and see if you can encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff92416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, explore the anonymous column and see if you can extract more information from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02de966e",
   "metadata": {},
   "source": [
    "### Preprocess the test data\n",
    "Repeat the exact same preprocessing as for the train data. Apply the transformations that you have fitted before with the train data. Do not fit the transformers again!\n",
    "\n",
    "The easiest way to do this is using a pipeline, but you can do this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1145a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all the transformation that you did with the train dataset to the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9474b37f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef5d5e954409e874",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Test more models\n",
    "Here you can test all the models that you know and see which one performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef4c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all the models you know.\n",
    "# Use the default model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48f360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the predictions for the train and test data and choose your best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc2f2cf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05403a72454a58c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Feature selection\n",
    "Feature selection is part of model optimization. Use common sense first, then the automatic tools and always check if their output is sensible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a58ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Think about which features are likely to have or not have influence on the model outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24327f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at feature importance for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4d086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if the automatic feature selection tools help you out. Critically evaluate their output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae81ffa4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9447088a54b1ed54",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Model optimization\n",
    "You can further refine your best performing models with hyperparameter optimization. This methods can take some time to run. If you don't have much computing power, consider running your notebooks on Kaggle or Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ad838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross validation to test models or model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca2d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300c9d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the hyperparameter search schemes to find the best hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e371c4",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "Now is the time to turn your workflow into a pipeline! Usually, you'd use a pipeline from the start because it makes everything easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your pipeline.\n",
    "# You run your train data through it first, then your test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e481eec4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6d886d52117f2ba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Calculate the score with the test data\n",
    "In this section, we will test the model predictions for the test data (the one with the unknown labels, not the data from your train-test split). In a real hackathon, you will generate these predictions, then submit them to the portal. The portal will compare your prediction with the real labels and give you a score.\n",
    "\n",
    "Here, you have the test predictions in the `portal` directory, together with the code to calculate the score. Run the following cells to calculate your score (you need to uncomment some parts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd89c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the code to calculate the score.\n",
    "from portal.score import load, validate, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the true labels and your prediction.\n",
    "# Uncomment and run the code.\n",
    "#y_true = load(\"portal/data\")\n",
    "#y_pred = load(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f79f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function just validates if the prediction has the correct format.\n",
    "# Uncomment and run it.\n",
    "#validate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e150642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the auc-roc score for your test prediction.\n",
    "# Uncomment and run the code.\n",
    "#score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1a4816",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f280ee0ade08e13c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Presentation\n",
    "Add the model optimization part to your presentation. Remember to justify the decisions you made. You will need to use tables or visualizations to support your claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8522dd7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-96f8b599abd52e9f",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"I have completed the hackathon training part 2, I'm a star!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
