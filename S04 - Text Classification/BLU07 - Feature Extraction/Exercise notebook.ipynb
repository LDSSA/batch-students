{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-12bea12324c032d8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import hashlib # for grading\n",
    "import json\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "\n",
    "# NLTK imports\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# SKLearn related imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-da97614b7076e26a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1 - Price of cars (regex)\n",
    "For the first question, you will be using regex to extract information from the `cars.txt` dataset. In this dataset, you'll find a list of cars that have been sold, as well as their brand, model and selling price.\n",
    "\n",
    "Start by loading the data into a list. The list items are the lines of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2e5273236adf54e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "path = \"data/cars.txt\"\n",
    "cars = []\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    cars = [l.strip() for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2b06a7ac18252021",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cars[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-32879d17b087c102",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the first item, for example, `FORD` is the brand name, `Focus` is the model, and `19757` is the price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-999bbbabdecd84cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.1 - Find Toyota cars\n",
    "\n",
    "First, we want to see which `TOYOTA` models have been sold. Find the items in the `cars` list which correspond to cars of the `TOYOTA` brand. Put these items into a list called `ans_1_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d7292940dd0f0b2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# ans_1_1 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9d5ce92d78b9b815",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(ans_1_1,list)\n",
    "assert len(ans_1_1) == 111\n",
    "assert hashlib.sha256(json.dumps(''.join(sorted(ans_1_1))).encode()).hexdigest() == \\\n",
    "'292f64bf78d500d2bb5dc13ca282edb571f1589b47ce0353f030de70c630608c', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9eeeb76b6d1ab67c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.2 - Find models with numbers\n",
    "\n",
    "Next, find the items in the `cars` list whose model is a set of numbers instead of characters. For example, `'BMW -- 535 -- 23521'`. Store these items in the list called `ans_1_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8dccb1f349ce02a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# ans_1_2 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-98c96bad0127da20",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(ans_1_2,list)\n",
    "assert len(ans_1_2) == 73\n",
    "assert hashlib.sha256(json.dumps(''.join(sorted(ans_1_2))).encode()).hexdigest() == \\\n",
    "'cdee14b87d092c0510a1cb9af05e8b9e96fc6a1c81489f7fd235e4a24e6b9119', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fcd2e99fd51f7864",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1.3 - Selling price bellow 1000\n",
    "\n",
    "Finally, get the car brands and models whose selling price is below 1000.\n",
    "\n",
    "Save the results in the list `ans_1_3`. Each element in this list should be in the format `BRAND -- MODEL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b8146ce9f0ba50df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# ans_1_3 = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b746057a51e92a5d",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(ans_1_3) == 77\n",
    "assert hashlib.sha256(json.dumps(''.join(sorted(ans_1_3))).encode()).hexdigest() == \\\n",
    "'4d1ef7339260bc7b24f98c0ea6031b4a6fff0f7a9e0100dfde1e17dbbe1308f9', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7271784ba90d3ce9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2 - Job postings\n",
    "The challenge of this exercise notebook is to classify job postings as 'Fake' or 'Real'. In this exercise, we'll be preprocessing the data.\n",
    "\n",
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c69e26f590ef0c78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/job_postings.csv', index_col=0).convert_dtypes()\n",
    "\n",
    "X = df['description']\n",
    "y = df['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-254c128c0c743d4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's look at an example of a job description and its corresponding label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad805151accfbdc9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[10]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cf38bca6e1a69176",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[10]['fraudulent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dbdc0548dd699460",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's check the data size and distribution of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-622a8322d87daf24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_data_stats(X, y):\n",
    "    print(f\"Size of dataset: {len(X)}\")\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"Distribution of classes: {dict(zip(unique, counts))}\")\n",
    "\n",
    "get_data_stats(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-808b90ccd21d360d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The classes are evenly distributed. We'll use a dev and test set to be able to identify overfitting and check the performance on unseen data.\n",
    "\n",
    "**Note**: So far you've used the `train`/`val`/`test` nomenclature for naming variables related to training, validation and test sets, respectively. `dev` is short for \"development\" and is just another typical identifier for the validation set, and we'll use it throughout this notebook instead of `val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a524119b37972d48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train dev test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.3, random_state=42, stratify=y_temp)\n",
    "print(f\"Train size: {len(X_train)}\\nDev size: {len(X_dev)}\\nTest size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e93f9088c1da685e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The first step in the workflow is preprocessing which we'll do in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-addc0c904c359402",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2.1 - Tokenization\n",
    "\n",
    "Implement the function `apply_tokenizer`. The function should receive a pandas series of text data like `X_train` and an NLTK-style tokenizer. It should return the series with the tokenized text. The tokens of each item in the series should be joined into one string with spaces in between like in the example in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a8b7930a61806e32",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_tokenizer(data, tokenizer):\n",
    "    \"\"\"\n",
    "    Tokenizes text data in the provided series using the provided tokenizer.\n",
    "    \n",
    "    E.g. for text data  \"This is a test! No, it can't be\"\n",
    "         it returns \"This is a test ! No , it can ' t be\"\n",
    "    \n",
    "    Args:\n",
    "    data - pd.Series with text data\n",
    "    tokenizer - nltk tokenizer\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f829c5a222c54690",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "X_train_tok = apply_tokenizer(X_train, tokenizer)\n",
    "\n",
    "assert isinstance(X_train_tok, pd.Series), 'The function should return a pandas series.'\n",
    "assert len(X_train_tok) == 1530, 'The length of the series is not correct.'\n",
    "assert isinstance(X_train_tok.iloc[0],str), 'The items of the series should be strings.'\n",
    "assert hashlib.sha256(json.dumps(''.join([i for i in X_train_tok])).encode()).hexdigest() == \\\n",
    "'0e4a3d7fdab35e43079953d4d1328450b8b36454083f28966e3026e813eb3e3f', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b76d100b971a777f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2.2 - Lowercasing\n",
    "\n",
    "In the second step, implement a function that will lowercase the data.  It should take and return a pandas series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ee47fb5a45fbd622",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_lowercase(data):\n",
    "    \"\"\"\n",
    "    Lowercases the text data in the provided pandas series.\n",
    "    \n",
    "    Args:\n",
    "    data - pd.Series\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7979e12840663ea2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_tok_lc = apply_lowercase(X_train_tok)\n",
    "\n",
    "assert isinstance(X_train_tok_lc, pd.Series), 'The output should be a pandas series.'\n",
    "assert len(X_train_tok_lc) == 1530, 'The length of the output is not correct.'\n",
    "assert isinstance(X_train_tok_lc.iloc[0],str), 'The items of the series should be strings.'\n",
    "assert hashlib.sha256(json.dumps(''.join([i for i in X_train_tok_lc])).encode()).hexdigest() == \\\n",
    "'bd90f00143ed79470e7c4000aa5a800a0c0f68fe0e661eb5ee126fc0d2bb38ac', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8044c14c20583cf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2.3 - Stopwords\n",
    "\n",
    "Now implement a function that filters the stopwords from the text data. The function should take and return a pandas series. We will use NLTK's built-in English stopword list shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3f0dea2c5108c93a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42ecb29c8fe117f1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_filter_stopwords(data, stopword_list):\n",
    "    \"\"\"\n",
    "    Removes stopwords from the provided pandas series with text data.\n",
    "    \n",
    "    Args:\n",
    "    data - pd.Series\n",
    "    stopword_list - list of stopwords to filter out\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f70da0255ea6e291",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_tok_lc_nosw = apply_filter_stopwords(X_train_tok_lc, stopword_list)\n",
    "\n",
    "assert isinstance (X_train_tok_lc_nosw, pd.Series), 'The output should be a pandas series.'\n",
    "assert len(X_train_tok_lc_nosw) == 1530, 'The length of the output is not correct.'\n",
    "assert isinstance(X_train_tok_lc_nosw.iloc[0],str), 'The items of the series should be strings.'\n",
    "assert hashlib.sha256(json.dumps(''.join([i for i in X_train_tok_lc_nosw])).encode()).hexdigest() == \\\n",
    "'13a80f1f4d7740b20cd3e2993ab73d37563212a8b208d3f554646a5783234e87', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8d0cb317596faa2f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2.4 - Punctuation\n",
    "\n",
    "After filtering the stopwords, we want to remove punctuation from the text. Consider only the punctuation characters in `string.punctuation`. Make sure to remove all punctuation and not only tokens that are single punctuation characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a0cd3cf5cc97a8f2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_filter_punct(data):\n",
    "    \"\"\"\n",
    "    Removes punctuation from the provided pandas series with text data.\n",
    "    \n",
    "    Args:\n",
    "    data - pandas series with text data\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-31c9a6a65413aef8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_tok_lc_nosw_nopunct = apply_filter_punct(X_train_tok_lc_nosw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-925e418acc339a2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Normalize whitespaces**\n",
    "\n",
    "Run the following function on `X_train_tok_lc_nosw_nopunct` before checking your answers to remove extra white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-67539c50de422305",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize_whitespace(text):\n",
    "    return re.sub(r\"^\\s+|\\s+$|(?<=\\s)\\s*\", \"\", text)\n",
    "\n",
    "X_train_tok_lc_nosw_nopunct_norm = X_train_tok_lc_nosw_nopunct.apply(normalize_whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-650a677a3a01d1bf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance (X_train_tok_lc_nosw_nopunct_norm, pd.Series), 'The output should be a pandas series.'\n",
    "assert len(X_train_tok_lc_nosw_nopunct_norm) == 1530, 'The length of the output is not correct.'\n",
    "assert isinstance(X_train_tok_lc_nosw_nopunct_norm.iloc[0],str), 'The items of the series should be strings.'\n",
    "assert hashlib.sha256(json.dumps(''.join([i for i in X_train_tok_lc_nosw_nopunct_norm])).encode()).hexdigest() == \\\n",
    "'a8273b9bae9dfb421af75eacc22bfd1b9c809ff36526060d756ffcbbed35dce9', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-38d66dd89731e114",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2.5 - Stemming\n",
    "\n",
    "The last preprocessing step that you are going to implement is stemming. Implement the function below to receive an NLTK-style stemmer and a pandas series with text data and return the series with the stemmed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a831ba989f3e50e6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_stemmer(data, stemmer):\n",
    "    \"\"\"\n",
    "    Stems the text data in the provided pandas series.\n",
    "    \n",
    "    Args:\n",
    "    data - pd.Series\n",
    "    stemmer - NLTK-style stemmer\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3596a6510ebbda3d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "X_train_tok_lc_nosw_nopunct_norm_stem = apply_stemmer(X_train_tok_lc_nosw_nopunct_norm, stemmer)\n",
    "\n",
    "assert isinstance (X_train_tok_lc_nosw_nopunct_norm_stem, pd.Series), 'The output should be a pandas series.'\n",
    "assert len(X_train_tok_lc_nosw_nopunct_norm_stem) == 1530, 'The length of the output is not correct.'\n",
    "assert isinstance(X_train_tok_lc_nosw_nopunct_norm_stem.iloc[0],str), 'The items of the series should be strings.'\n",
    "assert hashlib.sha256(json.dumps(''.join([i for i in X_train_tok_lc_nosw_nopunct_norm_stem])).encode()).hexdigest() == \\\n",
    "'fb150190fd6957d636e470fb703db7a353e4d53fcdff4ef131431dac6461a895', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2bfe5aed6ebdbb26",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2.6 - Everything together\n",
    "\n",
    "Finally, join all the preprocessing steps from above into a transformer that applies the steps in the following order:\n",
    "* tokenization\n",
    "* lowercasing\n",
    "* filtering stopwords\n",
    "* filtering punctuation\n",
    "* normalizing whitespace\n",
    "* stemming.\n",
    "\n",
    "Make use of the functions you designed above and don't forget to initialize all the necessary parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ea5b2305431c20dd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class TextCleanerTransformer(TransformerMixin, BaseEstimator):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0a4c1aa16cea2ffb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "text_cleaner = TextCleanerTransformer(\n",
    "    WordPunctTokenizer(),\n",
    "    stopwords=stopwords.words('english'),\n",
    "    stemmer=SnowballStemmer(\"english\"),\n",
    ")\n",
    "\n",
    "X_train_pre = text_cleaner.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4a87d0c9b1f20f7e",
     "locked": true,
     "points": 2.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(X_train_pre, pd.Series), 'The output should be a pandas series.'\n",
    "assert len(X_train_pre) == 1530, 'The length of the output is not correct.'\n",
    "assert isinstance(X_train_pre.iloc[0],str), 'The items of the series should be strings.'\n",
    "assert hashlib.sha256(json.dumps(''.join([i for i in X_train_pre])).encode()).hexdigest() == \\\n",
    "'fb150190fd6957d636e470fb703db7a353e4d53fcdff4ef131431dac6461a895', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f48abbdab8acc3d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Exercise 3 - Text classification\n",
    "\n",
    "We will now classify the job postings as fake or real. Let's first load the preprocessed data and check the balance of the classes.\n",
    "\n",
    "We are loading the preprocessed csv file here. This way you won't be penalized if you did not finish exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6cfef332c9bd3d0f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(file_name):\n",
    "    \"\"\"\n",
    "    Loads a csv file and returns two pandas series, one\n",
    "    the text and one containing the labels\n",
    "    \n",
    "    Args:\n",
    "    file_name: path to input file\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_name, index_col = 0)\n",
    "\n",
    "    return df['description'], df['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-99de6cc5a4a3ff52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_pre, y_train = load_dataset('data/job_postings_train_preprocessed.csv')\n",
    "X_dev_pre, y_dev = load_dataset('data/job_postings_dev_preprocessed.csv')\n",
    "X_test_pre, y_test = load_dataset('data/job_postings_test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dfca3c5348fd2262",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "get_data_stats(X_train_pre, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-aaf6fbf5dbc51f95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "get_data_stats(X_dev_pre, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e5147de37fa0351",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So we should be aiming for much better than 45% accuracy, which is what we would get if we naively predicted `1` (fake) for everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a844631e7326ff6d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3.1 - Top N-grams in the BoW vectorization\n",
    "\n",
    "First, we'll look at the top X N-grams in each category to see if anything is interesting. Implement a function that returns the most common N-grams and their count for the given label in the dataset. Use the `CountVectorizer` to create the N-grams. The function should return a list of tuples of the form `(N-gram, count)`, sorted by the `count` in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-36567f8f392a4836",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def top_ngrams_for_category(data, labels, filter_label, top_n=10, ngram_size=1):\n",
    "    \"\"\"\n",
    "    Finds the top_n N-grams in the BoW for the given class label.\n",
    "    \n",
    "    Args:\n",
    "    data: pd.Series with text data\n",
    "    labels: class labels for the data\n",
    "    filter_label: the label to filter the data on before getting ngrams\n",
    "    top_n: top n N-grams to return\n",
    "    ngram_size: the \"N\" in N-gram (e.g. if ngram_size=2, return only bigrams)\n",
    "    \n",
    "    Returns: list of tuples (N-gram, count)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cca0190cfba4ad83",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "top_10_unigrams_real = top_ngrams_for_category(X_train_pre, y_train, 0, top_n=10, ngram_size=1)\n",
    "assert top_10_unigrams_real == [('nan', 3199),\n",
    "                                ('work', 2689),\n",
    "                                ('experi', 1966),\n",
    "                                ('manag', 1854),\n",
    "                                ('team', 1830),\n",
    "                                ('servic', 1773),\n",
    "                                ('develop', 1706),\n",
    "                                ('custom', 1624),\n",
    "                                ('compani', 1430),\n",
    "                                ('time', 1428)]\n",
    "top_6_unigrams_fake = top_ngrams_for_category(X_train_pre, y_train, 1, top_n=6, ngram_size=1)\n",
    "assert top_6_unigrams_fake == [('nan', 3318),\n",
    "                               ('work', 1828),\n",
    "                               ('manag', 1303),\n",
    "                               ('experi', 1287),\n",
    "                               ('time', 1221),\n",
    "                               ('servic', 1187)]\n",
    "top_5_bigrams_real = top_ngrams_for_category(X_train_pre, y_train, 0, top_n=5, ngram_size=2)\n",
    "assert top_5_bigrams_real == [('nan nan', 1349),\n",
    "                              ('full time', 745),\n",
    "                              ('custom servic', 398),\n",
    "                              ('bachelor degre', 308),\n",
    "                              ('year experi', 211)]\n",
    "top_10_trigrams_fake = top_ngrams_for_category(X_train_pre, y_train, 1, top_n=10, ngram_size=3)\n",
    "assert top_10_trigrams_fake == [('nan nan nan', 851),\n",
    "                                ('nan full time', 165),\n",
    "                                ('time nan nan', 138),\n",
    "                                ('high school equival', 134),\n",
    "                                ('full time nan', 131),\n",
    "                                ('oil gas industri', 123),\n",
    "                                ('time entri level', 116),\n",
    "                                ('full time entri', 104),\n",
    "                                ('level high school', 92),\n",
    "                                ('mid senior level', 89)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05f81b8870270b19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Looking at the top ngrams for each category, it doesn't seem like a BoW model will be very interesting, but let's try anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1a096ee6776427b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3.2 - Modeling pipeline on BoW\n",
    "Let's streamline our pipeline in a nice function. The function should set up the pipeline, fit the pipeline with the train data and predict on the dev data. It should also calculate the accuracy of the prediction and print the classification report.\n",
    "\n",
    "The pipeline should have two steps, vectorization with sklearn `CountVectorizer` and classification with the `LogisticRegression`. Name the pipeline steps `vect` and `clf`. The `CountVectorizer` should take the given `ngram_range` and `max_features` parameter values.\n",
    "\n",
    "The function should return the fitted pipeline, the prediction, and the accuracy of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af90809e6c74e780",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_validate(X_train, X_dev, y_train, y_dev, ngram_range=(1,1), max_features=None):\n",
    "    \"\"\"\n",
    "    Train a model using sklearn's pipeline and return it along with the predictions and the\n",
    "    accuracy in the validation set. Print the classification report as well.\n",
    "    \n",
    "    Args:\n",
    "    X_train - preprocessed training data\n",
    "    X_dev - preprocessed dev data\n",
    "    y_train - labels of training data\n",
    "    y_dev - labels of dev data\n",
    "    ngram_range - ngram range to use in CountVectorizer (tuple)\n",
    "    max_features - max number of features to use in CountVectorizer (int)\n",
    "    \n",
    "    Returns:\n",
    "    text_clf - fitted pipeline\n",
    "    y_dev_pred - prediction on the dev data (np.array)\n",
    "    acc - accuracy of the prediction (float)\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    print(classification_report(y_dev, y_dev_pred))\n",
    "    return text_clf, y_dev_pred, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-97ba1cceed5a53f9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "clf, y_dev_pred, acc = train_and_validate(X_train_pre, X_dev_pre, y_train, y_dev)\n",
    "assert isinstance(clf['vect'], CountVectorizer), 'The pipeline steps are not correct.'\n",
    "assert isinstance(clf['clf'], LogisticRegression), 'The pipeline steps are not correct.'\n",
    "assert hashlib.sha256(json.dumps(''.join([str(i) for i in y_dev_pred])).encode()).hexdigest() == \\\n",
    "'36720a1e3d54d5a2d740cfe8cff6370341459fb18ecfbbddc04e5978ea0e7a7e', 'The prediction is not correct.'\n",
    "np.testing.assert_almost_equal(acc, 0.906, decimal=3, err_msg=\"The accuracy is not correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should look at some misclassified examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d7678b7610a7200f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for text, pred, true in zip(X_dev_pre[:70], y_dev_pred[:70], y_dev[:70]):\n",
    "    if pred != true:\n",
    "        print(f\"Job posting: {text}\")\n",
    "        print(f\"Predicted: {pred}, Actual: {true}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c7cbbc0c3275557",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So just with the simplest BoW model we already get an accuracy of 0.9! But let's see if we can do even better... In the misclassified examples, the last one even contains an application url but classified as 'fake'. That's suspicious..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4fd66e62c165a4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3.3 - Tune hyperparameters\n",
    "Run the function from the previous exercise for different N-gram ranges and/or with different values for max_features. Try to achieve an accuracy higher or equal to 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e75ac8652cc7e741",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# clf_tuned, y_dev_pred_tuned, acc_tuned = train_and_validate(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-722d1b4ff466bdd7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert(acc_tuned >= 0.90)\n",
    "print(acc_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76675b1b36125145",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now evaluate your model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dcb6e703b4c8ed64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-711b6cc0145d445c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Great! We were able to improve the model a little on the dev set and the performance on the test set is pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28921443e50007c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 4 - TF-IDF\n",
    "\n",
    "We will now work with the TF-IDF vectorization of the preprocessed job postings data.\n",
    "\n",
    "### Exercise 4.1 - Manual TF-IDF\n",
    "\n",
    "First, implement a function that manually calculates the TF-IDF vectorization from a dataframe with a Bag of Words vectorization. Here is a reminder of the TF-IDF formula:\n",
    "\n",
    "$$ tf\\text{-}idf(t,d) = tf(t,d) \\times idf(t) = \\frac{n_{td}}{n_d} \\times (log{(\\frac{n+1}{df_t+1})} + 1 )$$\n",
    "\n",
    "where $t$ is the term (word) for which we are calculating the weight, $d$ is the document containing the term, $n_{td}$ is the word count of the term $t$ in document $d$, $n_d$ is the number of words in document $d$, $n$ is the number of documents, and $df_t$ is the number of documents where the term appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5b15b82e46b905ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# We'll start you off with the BoW representation, in pandas dataframe format\n",
    "vec = CountVectorizer()\n",
    "bow_train = vec.fit_transform(X_train_pre)\n",
    "bow_train_df = pd.DataFrame(bow_train.todense())\n",
    "vocab = vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b915bab713aba13",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_tfidf(bow_df):\n",
    "    \"\"\"\n",
    "    Calculates the tfidf vectorization from a BoW vectorization.\n",
    "\n",
    "    Args:\n",
    "    bow_df - dataframe with document word counts (Bag of Words)\n",
    "\n",
    "    Returns:\n",
    "    tfidf - dataframe with the calculated tfidf\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-86090d8867691e1a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tfidf_df = calculate_tfidf(bow_train_df)\n",
    "assert tfidf_df.shape==bow_train_df.shape, 'The shape of the tfidf dataframe is not correct.'\n",
    "assert ((tfidf_df>0).sum()==(bow_train_df>0).sum()).sum()==bow_train_df.shape[1], ''\n",
    "assert hashlib.sha256(json.dumps(''.join([str(round(i,3)) for i in tfidf_df[(tfidf_df>0)].sum().to_numpy()])).encode()).hexdigest() \\\n",
    "== 'cdeee674f9f9449ffb7a1cec047e75a0318af7836d0b94fe3948ce81e1ae4559', 'Not correct, try again.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c9d199071250b72d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 4.2 - Top words in the TF-IDF vectorization\n",
    "\n",
    "Implement a function which returns the top N most important words for the given class in the TF-IDF vectorization, i.e. the words with the highest sum of weights. The function takes the dataframe with the TF-IDF weights calculated in the previous exercise and a vocabulary of words and feature indices from the CountVectorizer and returns a list of the top N most important words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-00f14b79ff68d32e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def top_words_for_category_tfidf(data, labels, filter_label, vocab, top_n=10):\n",
    "    \"\"\"\n",
    "    Finds the top_n words in the TF-IDF for the given class label.\n",
    "    \n",
    "    Args:\n",
    "    data: pd.Series with text data\n",
    "    labels: class labels for the data\n",
    "    filter_label: the label to filter the data on before getting ngrams\n",
    "    vocab: vocabulary of words and feature indices\n",
    "    top_n: top n ngrams to return\n",
    "    \n",
    "    Returns: list of top-n words\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3b51198b450763c2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "top_15_fake = top_words_for_category_tfidf(tfidf_df, y_train, 1, vocab, top_n=15)\n",
    "assert top_15_fake == ['nan',\n",
    "                       'work',\n",
    "                       'time',\n",
    "                       'servic',\n",
    "                       'entri',\n",
    "                       'custom',\n",
    "                       'posit',\n",
    "                       'skill',\n",
    "                       'amp',\n",
    "                       'experi',\n",
    "                       'home',\n",
    "                       'manag',\n",
    "                       'requir',\n",
    "                       'administr',\n",
    "                       'data']\n",
    "top_20_real = top_words_for_category_tfidf(tfidf_df, y_train, 0, vocab, top_n=20)\n",
    "assert top_20_real == ['nan',\n",
    "                       'work',\n",
    "                       'develop',\n",
    "                       'manag',\n",
    "                       'experi',\n",
    "                       'custom',\n",
    "                       'sale',\n",
    "                       'team',\n",
    "                       'servic',\n",
    "                       'product',\n",
    "                       'job',\n",
    "                       'market',\n",
    "                       'client',\n",
    "                       'busi',\n",
    "                       'design',\n",
    "                       'compani',\n",
    "                       'time',\n",
    "                       'technolog',\n",
    "                       'us',\n",
    "                       'engin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2672054e4024a51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 4.3 - Modeling pipeline on TF-IDF\n",
    "Let's include the TF-IDF features into the pipeline. The function should set up the pipeline, fit the pipeline with the train data and predict on the dev data. It should also calculate the accuracy of the prediction and print the classification report.\n",
    "\n",
    "The pipeline should have three steps: vectorization with sklearn `CountVectorizer`, transformation with sklearn `TfidfTransformer`, and classification with the `LogisticRegression`. Name the pipeline steps `vect`, `tfidf`, and `clf`. The `CountVectorizer` should take the given `ngram_range`, `max_features`, `max_df`, and `min_df` parameter values.\n",
    "\n",
    "The function should return the fitted pipeline, the prediction, and the accuracy of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-02453bb681cd33b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_and_validate_with_tfidf(X_train, X_dev, y_train, y_dev, ngram_range=(1,1),\n",
    "                                  max_features=None, max_df=1.0, min_df=1):\n",
    "    \"\"\"\n",
    "    Train a model using sklearn's pipeline and return it along with the predictions and the\n",
    "    accuracy in the validation set. Print the classification report as well.\n",
    "    \n",
    "    Args:\n",
    "    X_train - preprocessed training data\n",
    "    X_dev - preprocessed dev data\n",
    "    y_train - labels of training data\n",
    "    y_dev - labels of dev data\n",
    "    ngram_range - ngram range to use in CountVectorizer (tuple)\n",
    "    max_features - max number of features to use in CountVectorizer (int)\n",
    "    max_df - minimum threshold for document frequency to use in CountVectorizer (int or float)\n",
    "    min_df - maximum threshold for document frequency to use in CountVectorizer (int or float)\n",
    "    \n",
    "    Returns:\n",
    "    text_clf - fitted pipeline\n",
    "    y_dev_pred - prediction on the dev data (np.array)\n",
    "    acc - accuracy of the prediction (float)\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    print(classification_report(y_dev, y_dev_pred))\n",
    "    return text_clf, y_dev_pred, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ee1c189fe642928a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "clf_tfidf, y_dev_pred_tfidf, acc_tfidf = train_and_validate_with_tfidf(X_train_pre, X_dev_pre, y_train, y_dev)\n",
    "assert isinstance(clf_tfidf['vect'], CountVectorizer), 'The pipeline steps are not correct.'\n",
    "assert isinstance(clf_tfidf['tfidf'], TfidfTransformer), 'The pipeline steps are not correct.'\n",
    "assert isinstance(clf_tfidf['clf'], LogisticRegression), 'The pipeline steps are not correct.'\n",
    "assert hashlib.sha256(json.dumps(''.join([str(i) for i in y_dev_pred_tfidf])).encode()).hexdigest() == \\\n",
    "'475ecac8a2c6e2dea9aa06f0105f19aa20ead066339a6398af8d797bfeafbd0a', 'The prediction is not correct.'\n",
    "np.testing.assert_almost_equal(acc_tfidf, 0.906, decimal=3, err_msg=\"The accuracy is not correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we should also look at some misclassified examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-87d3359e8827355d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for text, pred, true in zip(X_dev_pre[:70], y_dev_pred_tfidf[:70], y_dev[:70]):\n",
    "    if pred != true:\n",
    "        print(f\"Job posting: {text}\")\n",
    "        print(f\"Predicted: {pred}, Actual: {true}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-26ada9070ceb8872",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Unfortunately, we're still not able to correctly classify those job postings. Let's keep going and see if we can do even better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab54cc6297c36ee2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Exercise 4.4 - Tune hyperparameters again\n",
    "\n",
    "Use the `train_and_validate_with_tfidf` function you created before to train with different hyperparameters and get an accuracy score above 92% on the validation dataset. (This threshold is the same as what we got for the plain CountVectorizer pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-07b6f3694941ac8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# clf_tfidf_tuned, y_dev_pred_tfidf_tuned, acc_tfidf_tuned = train_and_validate_with_tfidf(...)\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-07b6f3694941ac81",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert(acc_tfidf_tuned > 0.92)\n",
    "print(acc_tfidf_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-123f82e6058cdcdc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now evaluate your model on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a5352a2d0b2f2903",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred = clf_tfidf_tuned.predict(X_test)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the performace on the test set improve against the pure BoW pipeline? If not, the pipeline might require more tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations to mastering the first NLP unit! This was no easy task, be proud of yourself!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
