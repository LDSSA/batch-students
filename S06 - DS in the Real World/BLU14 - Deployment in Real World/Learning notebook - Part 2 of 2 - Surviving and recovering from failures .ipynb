{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLU14 - Learning notebook - Part 2 of 2 - Surviving and recovering from failures \n",
    "\n",
    "It's time to deploy and manage our model! Now that your client is happy with your work, we'll pick up from BLU13 and provide them with a small app to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "from uuid import uuid4\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time to deploy! \n",
    "\n",
    "If you're reacting more or less like this, do not panic.\n",
    "\n",
    "<img src=\"media/model-deploy-unknown.png\" width=300 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you still haven't really internalized the last BLU, we provide you with the template code to deploy the model that we created in part 1, which you can also reuse as a starting point for the exercises. This code handles:\n",
    "\n",
    "* deserialization of our model\n",
    "* serving predictions \n",
    "* storage of observations\n",
    "* update of observations\n",
    "\n",
    "In the previous BLU you've learned how to deploy in railway, and you will want to do that to serve your app. However, for the following topics, we will focus on testing locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Deploying locally\n",
    "\n",
    "What does this mean?\n",
    "\n",
    "Well, it means we'll launch a server in our own machine, making it available to test it there, but not available to the world. This server will be accessible to you by the URLs `127.0.0.1` or `localhost`. These are reserved so that in every machine the traffic that you send to these is looped back to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/localhost-ben.png\" width=450 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by running the server we provide under `server.py`. Open a terminal, go to the BLU folder, and activate the virtual environment. Once you're there, run the following to start up the template server.\n",
    "\n",
    "```sh\n",
    "python3.12 server.py\n",
    "```\n",
    "\n",
    "You should see something like this if everything went well:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/flask-server-log.png\" width=\"100%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, even with that scary red warning this is fine, you're ready to continue. The next thing we will do is to send some requests to our server. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Sending some observations\n",
    "\n",
    "If you remember correctly we used the following columns:\n",
    "\n",
    "* SubjectRaceCode\n",
    "* SubjectSexCode\n",
    "* SubjectEthnicityCode\n",
    "* StatuteReason\n",
    "* InterventionReasonCode\n",
    "* ResidentIndicator\n",
    "* SearchAuthorizationCode\n",
    "* SubjectAge\n",
    "* hour\n",
    "* day_of_week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the way we need to communicate to our server is by sending a json object such as:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"your-observation-id\",\n",
    "  \"observation\": {\n",
    "     \"SubjectRaceCode\": \"W\",\n",
    "     \"SubjectSexCode\": \"F\",\n",
    "     \"SubjectEthnicityCode\": \"H\",\n",
    "     \"StatuteReason\": \"Stop sign\", \n",
    "     \"InterventionReasonCode\": \"V\", \n",
    "     \"ResidentIndicator\": False, \n",
    "     \"SearchAuthorizationCode\": \"N\",\n",
    "     \"SubjectAge\": 20,\n",
    "     \"hour\": 20,\n",
    "     \"day_of_week\": \"Tuesday\",\n",
    "   }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do this in 2 ways:\n",
    "\n",
    "* by using `cURL` requests in the terminal, which you used in the previous BLU\n",
    "* by using the `requests` library from Python and sending requests from this notebook\n",
    "\n",
    "We'll start by creating our dummy observation as JSON so we can use it in curl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": \"fake-observation-3c9bfe03-97ff-439b-8342-ae26bee1f681\", \"observation\": {\"SubjectRaceCode\": \"B\", \"SubjectSexCode\": \"M\", \"SubjectEthnicityCode\": \"N\", \"StatuteReason\": \"Stop sign\", \"InterventionReasonCode\": \"V\", \"ResidentIndicator\": false, \"SearchAuthorizationCode\": \"N\", \"SubjectAge\": 20, \"hour\": 20, \"day_of_week\": \"Tuesday\"}}\n"
     ]
    }
   ],
   "source": [
    "observation = {\n",
    "  \"id\": \"fake-observation-{}\".format(uuid4()),\n",
    "  \"observation\": {\n",
    "      \"SubjectRaceCode\": \"B\",\n",
    "      \"SubjectSexCode\": \"M\",\n",
    "      \"SubjectEthnicityCode\": \"N\",\n",
    "      \"StatuteReason\": \"Stop sign\", \n",
    "      \"InterventionReasonCode\": \"V\", \n",
    "      \"ResidentIndicator\": False, \n",
    "      \"SearchAuthorizationCode\": \"N\",\n",
    "      \"SubjectAge\": 20,\n",
    "      \"hour\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "}\n",
    "\n",
    "print(json.dumps(observation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's copy this and prepare our curl request:\n",
    "\n",
    "```sh\n",
    "curl -X POST http://localhost:5000/predict -d '{\"id\": \"fake-observation-1bc5145b-d7b5-2688-95e8-21a378204133\", \"observation\": {\"SubjectRaceCode\": \"B\", \"SubjectSexCode\": \"M\", \"SubjectEthnicityCode\": \"N\", \"StatuteReason\": \"Stop sign\", \"InterventionReasonCode\": \"V\", \"ResidentIndicator\": false, \"SearchAuthorizationCode\": \"N\", \"SubjectAge\": 20, \"hour\": 20, \"day_of_week\": \"Tuesday\"}}'  -H \"Content-Type:application/json\"\n",
    "```\n",
    "\n",
    "Note that every time you run the previous cell, a different ID will be generated. You can also choose to change your id if you want to perform the request again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you sent the request through cURL, re-run the observation cell and let's run the same request through the requests library as we would to when sending it to a remote webserver (except we still use the local server). This should give you the exact same probability and prediction as the curl request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\"prediction\":true,\"proba\":8118.720467213626}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "observation = {\n",
    "  \"id\": \"fake-observation-{}\".format(uuid4()),\n",
    "  \"observation\": {\n",
    "      \"SubjectRaceCode\": \"B\",\n",
    "      \"SubjectSexCode\": \"M\",\n",
    "      \"SubjectEthnicityCode\": \"N\",\n",
    "      \"StatuteReason\": \"Stop sign\",\n",
    "      \"InterventionReasonCode\": \"V\", \n",
    "      \"ResidentIndicator\": False, \n",
    "      \"SearchAuthorizationCode\": \"N\",\n",
    "      \"SubjectAge\": 20,\n",
    "      \"hour\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "url=\"http://127.0.0.1:5000/predict\"\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "r = requests.post(url, data=json.dumps(observation), headers=headers)\n",
    "\n",
    "print(r.status_code)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty simple, right? Try out a few more requests and play around with both commands.\n",
    "\n",
    "You should get a status 200 and a proper response here. If not, make sure you run the server as explained before and that you did so with the virtual environment activated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dealing with unexpected formats\n",
    "But what happens if we send a weird observation? \n",
    "\n",
    "Let's start by changing our dictionary so that the `observation` is now `my_observation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "<!doctype html>\n",
      "<html lang=en>\n",
      "<title>500 Internal Server Error</title>\n",
      "<h1>Internal Server Error</h1>\n",
      "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bad format\n",
    "\n",
    "observation = {\n",
    "  \"id\": \"fake-observation-{}\".format(uuid4()),\n",
    "  \"my_observation\": {\n",
    "      \"SubjectRaceCode\": \"B\",\n",
    "      \"SubjectSexCode\": None,\n",
    "      \"SubjectEthnicityCode\": \"N\",\n",
    "      \"StatuteReason\": \"Stop sign\", \n",
    "      \"InterventionReasonCode\": \"V\", \n",
    "      \"ResidentIndicator\": False, \n",
    "      \"SearchAuthorizationCode\": \"N\",\n",
    "      \"SubjectAge\": 20,\n",
    "      \"hour\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "url=\"http://127.0.0.1:5000/predict\"\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "r = requests.post(url, data=json.dumps(observation), headers=headers)\n",
    "\n",
    "print(r.status_code)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/michael-surprised.jpg\" width=500 />\n",
    "\n",
    "\n",
    "Ok ok, your users know what they should send.\n",
    "\n",
    "But what about if they are missing some columns?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\"prediction\":true,\"proba\":8902.466495135466}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Missing columns\n",
    "\n",
    "observation = {\n",
    "  \"id\": \"fake-observation-{}\".format(uuid4()),\n",
    "  \"observation\": {\n",
    "      \"SubjectAge\": 20,\n",
    "      \"hour\": 20\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "url=\"http://127.0.0.1:5000/predict\"\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "r = requests.post(url, data=json.dumps(observation), headers=headers)\n",
    "\n",
    "print(r.status_code)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"media/michael-nope.jpg\" width=500 />\n",
    "\n",
    "We got a 200 but in reality our model had almost no information about the observation, how do we know how to interpret this information? \n",
    "\n",
    "Maybe it is useful to see what happens if we send just complete nonsense? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\"prediction\":true,\"proba\":8206.84314096996}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non sense values that don't break the request\n",
    "\n",
    "observation = {\n",
    "  \"id\": \"fake-observation-{}\".format(uuid4()),\n",
    "  \"observation\": {\n",
    "      \"SubjectRaceCode\": \"A\",\n",
    "      \"SubjectSexCode\": \"B\",\n",
    "      \"SubjectEthnicityCode\": \"C\",\n",
    "      \"StatuteReason\": \"D\", \n",
    "      \"InterventionReasonCode\": \"E\", \n",
    "      \"ResidentIndicator\": \"F\", \n",
    "      \"SearchAuthorizationCode\": \"F\",\n",
    "      \"SubjectAge\": 1,\n",
    "      \"hour\": 90,\n",
    "      \"day_of_week\": \"potato\",\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "url=\"http://127.0.0.1:5000/predict\"\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "r = requests.post(url, data=json.dumps(observation), headers=headers)\n",
    "\n",
    "print(r.status_code)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/michael-cringe.png\" width=500 />\n",
    "\n",
    "Getting a 200 is not always good. In fact, if someone just sends completely random values and gets a probability and a prediction, not only are they misled, but since our system is also storing these observations, we will get polluted data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silent errors are the worst. You're better off having explicit ones** \n",
    "\n",
    "Let's do one more just so you get the full picture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "<!doctype html>\n",
      "<html lang=en>\n",
      "<title>500 Internal Server Error</title>\n",
      "<h1>Internal Server Error</h1>\n",
      "<p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# More non sense values that break the request\n",
    "\n",
    "observation = {\n",
    "  \"id\": \"fake-observation-{}\".format(uuid4()),\n",
    "  \"observation\": {\n",
    "      \"SubjectRaceCode\": \"B\",\n",
    "      \"SubjectSexCode\": \"M\",\n",
    "      \"SubjectEthnicityCode\": \"N\",\n",
    "      \"StatuteReason\": \"Stop sign\", \n",
    "      \"InterventionReasonCode\": \"V\", \n",
    "      \"ResidentIndicator\": False, \n",
    "      \"SearchAuthorizationCode\": \"N\",\n",
    "      \"SubjectAge\": \"twenty\",\n",
    "      \"hour\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "url=\"http://127.0.0.1:5000/predict\"\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "r = requests.post(url, data=json.dumps(observation), headers=headers)\n",
    "\n",
    "print(r.status_code)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/michael-tired.jpg\" width=500 />\n",
    "\n",
    "Alright, alright, I'll stop. By this point, you should have an idea of the different ways input data can be bad. So what do we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Handling input \n",
    "\n",
    "We protect the code. On one hand, we obviously don't want to send obscure errors to our client. On the other hand, we don't want to store data that doesn't make sense. So neither of the errors above are acceptable.\n",
    "\n",
    "Let's retrieve the map with the valid values from the last unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_categories = {\n",
    "    \"InterventionReasonCode\": {\"values\": [\"V\", \"E\", \"I\"], \"default\": None},\n",
    "    \"SubjectRaceCode\": {\"values\": [\"W\", \"B\", \"A\", \"I\"], \"default\": None},\n",
    "    \"SubjectSexCode\": {\"values\": [\"M\", \"F\"], \"default\": None},\n",
    "    \"SubjectEthnicityCode\": {\"values\": [\"H\", \"M\", \"N\"], \"default\": \"N\"},\n",
    "    \"SearchAuthorizationCode\": {\"values\": [\"O\", \"I\", \"C\", \"N\"], \"default\": \"N\"},\n",
    "    # We can use it also for booleans!\n",
    "    \"TownResidentIndicator\": {\"values\": [True, False]}, \n",
    "    \"ResidentIndicator\": {\"values\": [True, False]},\n",
    "    \"VehicleSearchedIndicator\": {\"values\": [True, False]},\n",
    "    \"ContrabandIndicator\": {\"values\": [True, False]},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to do some slight modifications. Since we ended up using only a subset of our features and we actually augmented it with some others, we'll change the map to reflect this. Additionally, we'll keep only the allowed values and forget about any defaults for now.\n",
    "\n",
    "Notice that we are not handling numeric values, only categorical (including boolean) values in this map. We'll go back to the numerical values later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_categories = {\n",
    "    \"InterventionReasonCode\": [\"V\", \"E\", \"I\"],\n",
    "    \"SubjectRaceCode\": [\"W\", \"B\", \"A\", \"I\"],\n",
    "    \"SubjectSexCode\": [\"M\", \"F\"],\n",
    "    \"SubjectEthnicityCode\": [\"H\", \"M\", \"N\"],\n",
    "    \"SearchAuthorizationCode\": [\"O\", \"I\", \"C\", \"N\"],\n",
    "    \"ResidentIndicator\": {\"values\": [True, False]},\n",
    "    \"StatuteReason\": [\n",
    "        'Stop Sign', 'Other', 'Speed Related', 'Cell Phone', 'Traffic Control Signal', 'Defective Lights', \n",
    "        'Moving Violation', 'Registration', 'Display of Plates', 'Equipment Violation', 'Window Tint', \n",
    "        'Suspended License', 'Seatbelt', 'Other/Error', 'STC Violation', 'Administrative Offense', 'Unlicensed Operation'], \n",
    "    \"day_of_week\": [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we want to do is verify, when we receive the input, that it is:\n",
    "\n",
    "1. a valid input, with an `id` and an `observation`\n",
    "2. valid columns under the observation\n",
    "3. if categorical, a valid category within its column\n",
    "\n",
    "We can build three small functions to do that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_request(request):\n",
    "    \"\"\"\n",
    "        Validates that our request is well formatted\n",
    "        \n",
    "        Returns:\n",
    "        - assertion value: True if request is ok, False otherwise\n",
    "        - error message: empty if request is ok, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    if \"id\" not in request:\n",
    "        error = \"Field `id` missing from request: {}\".format(request)\n",
    "        return False, error\n",
    "    \n",
    "    if \"observation\" not in request:\n",
    "        error = \"Field `observation` missing from request: {}\".format(request)\n",
    "        return False, error\n",
    "    \n",
    "    return True, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_valid_column(observation):\n",
    "    \"\"\"\n",
    "        Validates that our observation only has valid columns\n",
    "        \n",
    "        Returns:\n",
    "        - assertion value: True if all provided columns are valid, False otherwise\n",
    "        - error message: empty if all provided columns are valid, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    valid_columns = {\n",
    "      \"SubjectRaceCode\",\n",
    "      \"SubjectSexCode\",\n",
    "      \"SubjectEthnicityCode\",\n",
    "      \"StatuteReason\", \n",
    "      \"InterventionReasonCode\", \n",
    "      \"ResidentIndicator\", \n",
    "      \"SearchAuthorizationCode\",\n",
    "      \"SubjectAge\",\n",
    "      \"hour\",\n",
    "      \"day_of_week\",\n",
    "    }\n",
    "    \n",
    "    keys = set(observation.keys())\n",
    "    \n",
    "    if len(valid_columns - keys) > 0: \n",
    "        missing = valid_columns - keys\n",
    "        error = \"Missing columns: {}\".format(missing)\n",
    "        return False, error\n",
    "    \n",
    "    if len(keys - valid_columns) > 0: \n",
    "        extra = keys - valid_columns\n",
    "        error = \"Unrecognized columns provided: {}\".format(extra)\n",
    "        return False, error    \n",
    "\n",
    "    return True, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_categorical_values(observation):\n",
    "    \"\"\"\n",
    "        Validates that all categorical fields are in the observation and values are valid\n",
    "        \n",
    "        Returns:\n",
    "        - assertion value: True if all provided categorical columns contain valid values, \n",
    "                           False otherwise\n",
    "        - error message: empty if all provided columns are valid, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    valid_category_map = {\n",
    "        \"InterventionReasonCode\": [\"V\", \"E\", \"I\"],\n",
    "        \"SubjectRaceCode\": [\"W\", \"B\", \"A\", \"I\"],\n",
    "        \"SubjectSexCode\": [\"M\", \"F\"],\n",
    "        \"SubjectEthnicityCode\": [\"H\", \"M\", \"N\"],\n",
    "        \"SearchAuthorizationCode\": [\"O\", \"I\", \"C\", \"N\"],\n",
    "        \"ResidentIndicator\": [True, False],\n",
    "        \"StatuteReason\": [\n",
    "            'Stop Sign', 'Other', 'Speed Related', 'Cell Phone', 'Traffic Control Signal', 'Defective Lights', \n",
    "            'Moving Violation', 'Registration', 'Display of Plates', 'Equipment Violation', 'Window Tint', \n",
    "            'Suspended License', 'Seatbelt', 'Other/Error', 'STC Violation', 'Administrative Offense', 'Unlicensed Operation'], \n",
    "        \"day_of_week\": [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    }\n",
    "    \n",
    "    for key, valid_categories in valid_category_map.items():\n",
    "        if key in observation:\n",
    "            value = observation[key]\n",
    "            if value not in valid_categories:\n",
    "                error = \"Invalid value provided for {}: {}. Allowed values are: {}\".format(\n",
    "                    key, value, \",\".join([\"'{}'\".format(v) for v in valid_categories]))\n",
    "                return False, error\n",
    "        else:\n",
    "            error = \"Categorical field {} missing\"\n",
    "            return False, error\n",
    "\n",
    "    return True, \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out our functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1.Check request structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, '')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_request({\"id\": \"fake-id\", \"observation\": \"fake-obs\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " \"Field `id` missing from request: {'bad_id': 'fake-id', 'observation': 'fake-obs'}\")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_request({\"bad_id\": \"fake-id\", \"observation\": \"fake-obs\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Check observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, '')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = {\n",
    "      \"SubjectRaceCode\": \"B\",\n",
    "      \"SubjectSexCode\": \"M\",\n",
    "      \"SubjectEthnicityCode\": \"N\",\n",
    "      \"StatuteReason\": \"Stop sign\", \n",
    "      \"InterventionReasonCode\": \"V\", \n",
    "      \"ResidentIndicator\": False, \n",
    "      \"SearchAuthorizationCode\": \"N\",\n",
    "      \"SubjectAge\": 20,\n",
    "      \"hour\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "\n",
    "check_valid_column(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, \"Missing columns: {'SearchAuthorizationCode'}\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = {\n",
    "      \"SubjectRaceCode\": \"B\",\n",
    "      \"SubjectSexCode\": \"M\",\n",
    "      \"SubjectEthnicityCode\": \"N\",\n",
    "      \"StatuteReason\": \"Stop sign\", \n",
    "      \"InterventionReasonCode\": \"V\", \n",
    "      \"ResidentIndicator\": False, \n",
    "      \"SubjectAge\": 20,\n",
    "      \"hour\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "\n",
    "check_valid_column(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, \"Unrecognized columns provided: {'SomeRandomColumn'}\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = {\n",
    "      \"SubjectRaceCode\": \"B\",\n",
    "      \"SubjectSexCode\": \"M\",\n",
    "      \"SubjectEthnicityCode\": \"N\",\n",
    "      \"StatuteReason\": \"Stop sign\", \n",
    "      \"InterventionReasonCode\": \"V\", \n",
    "      \"ResidentIndicator\": False, \n",
    "      \"SearchAuthorizationCode\": \"N\",\n",
    "      \"SomeRandomColumn\": \"N\",\n",
    "      \"SubjectAge\": 20,\n",
    "      \"hour\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "\n",
    "check_valid_column(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Check categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, '')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = {\n",
    "      \"SubjectRaceCode\": \"B\",\n",
    "      \"SubjectSexCode\": \"M\",\n",
    "      \"SubjectEthnicityCode\": \"N\",\n",
    "      \"StatuteReason\": \"Stop Sign\", \n",
    "      \"InterventionReasonCode\": \"V\", \n",
    "      \"ResidentIndicator\": False, \n",
    "      \"SearchAuthorizationCode\": \"N\",\n",
    "      \"SomeRandomColumn\": \"N\",\n",
    "      \"SubjectAge\": 20,\n",
    "      \"hour\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "\n",
    "check_categorical_values(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " \"Invalid value provided for SubjectRaceCode: t. Allowed values are: 'W','B','A','I'\")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = {\n",
    "      \"SubjectRaceCode\": \"t\",\n",
    "      \"SubjectSexCode\": \"M\",\n",
    "      \"SubjectEthnicityCode\": \"N\",\n",
    "      \"StatuteReason\": \"Stop sign\", \n",
    "      \"InterventionReasonCode\": \"V\", \n",
    "      \"ResidentIndicator\": False, \n",
    "      \"SearchAuthorizationCode\": \"N\",\n",
    "      \"SomeRandomColumn\": \"N\",\n",
    "      \"SubjectAge\": 20,\n",
    "      \"hour\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "\n",
    "check_categorical_values(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " \"Invalid value provided for ResidentIndicator: COUCH POTATO. Allowed values are: 'True','False'\")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = {\n",
    "      \"SubjectRaceCode\": \"B\",\n",
    "      \"SubjectSexCode\": \"M\",\n",
    "      \"SubjectEthnicityCode\": \"N\",\n",
    "      \"StatuteReason\": \"Stop sign\", \n",
    "      \"InterventionReasonCode\": \"V\", \n",
    "      \"ResidentIndicator\": \"COUCH POTATO\", \n",
    "      \"SearchAuthorizationCode\": \"N\",\n",
    "      \"SomeRandomColumn\": \"N\",\n",
    "      \"SubjectAge\": 20,\n",
    "      \"hour\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "\n",
    "check_categorical_values(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 Numerical values\n",
    "\n",
    "What about the numeric values - `hour` and `SubjectAge`. Well, each has a particular set of conditions that make sense to apply, so let's create the functions to perform the verifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hour(observation):\n",
    "    \"\"\"\n",
    "        Validates that observation contains valid hour value \n",
    "        \n",
    "        Returns:\n",
    "        - assertion value: True if hour is valid, False otherwise\n",
    "        - error message: empty if hour is valid, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    hour = observation.get(\"hour\")\n",
    "        \n",
    "    if not hour:\n",
    "        error = \"Field `hour` missing\"\n",
    "        return False, error\n",
    "\n",
    "    if not isinstance(hour, int):\n",
    "        error = \"Field `hour` is not an integer\"\n",
    "        return False, error\n",
    "    \n",
    "    if hour < 0 or hour > 24:\n",
    "        error = \"Field `hour` is not between 0 and 24\"\n",
    "        return False, error\n",
    "\n",
    "    return True, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_age(observation):\n",
    "    \"\"\"\n",
    "        Validates that observation contains valid hour value \n",
    "        \n",
    "        Returns:\n",
    "        - assertion value: True if hour is valid, False otherwise\n",
    "        - error message: empty if hour is valid, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    age = observation.get(\"SubjectAge\")\n",
    "        \n",
    "    if not age: \n",
    "        error = \"Field `SubjectAge` missing\"\n",
    "        return False, error\n",
    "\n",
    "    if not isinstance(age, int):\n",
    "        error = \"Field `SubjectAge` is not an integer\"\n",
    "        return False, error\n",
    "    \n",
    "    if age < 10 or age > 100:\n",
    "        error = \"Field `SubjectAge` is not between 10 and 100\"\n",
    "        return False, error\n",
    "\n",
    "    return True, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, '')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = {\n",
    "      \"hour\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "\n",
    "check_hour(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 'Field `hour` is not between 0 and 24')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = {\n",
    "      \"hour\": 100,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "\n",
    "check_hour(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, '')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation = {\n",
    "      \"SubjectAge\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "\n",
    "check_age(observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Putting it all together\n",
    "\n",
    "Now we can run our server with these functions. \n",
    "\n",
    "Run the code under `protected_server.py`:\n",
    "\n",
    "```sh\n",
    "python3.12 protected_server.py\n",
    "```\n",
    "\n",
    "And try out the same examples as before to see what the server returns to us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":\"Field `observation` missing from request: {'id': 'fake-observation-a2d4832a-b616-459f-9e1f-9a1e4c175fad', 'my_observation': {'SubjectRaceCode': 'B', 'SubjectSexCode': None, 'SubjectEthnicityCode': 'N', 'StatuteReason': 'Stop sign', 'InterventionReasonCode': 'V', 'ResidentIndicator': False, 'SearchAuthorizationCode': 'N', 'SubjectAge': 20, 'hour': 20, 'day_of_week': 'Tuesday'}}\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bad format\n",
    "\n",
    "observation = {\n",
    "  \"id\": \"fake-observation-{}\".format(uuid4()),\n",
    "  \"my_observation\": {\n",
    "      \"SubjectRaceCode\": \"B\",\n",
    "      \"SubjectSexCode\": None,\n",
    "      \"SubjectEthnicityCode\": \"N\",\n",
    "      \"StatuteReason\": \"Stop sign\", \n",
    "      \"InterventionReasonCode\": \"V\", \n",
    "      \"ResidentIndicator\": False, \n",
    "      \"SearchAuthorizationCode\": \"N\",\n",
    "      \"SubjectAge\": 20,\n",
    "      \"hour\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "url=\"http://127.0.0.1:5000/predict\"\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "r = requests.post(url, data=json.dumps(observation), headers=headers)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":\"Missing columns: {'SubjectEthnicityCode', 'SubjectSexCode'}\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Missing columns\n",
    "\n",
    "observation = {\n",
    "  \"id\": \"fake-observation-{}\".format(uuid4()),\n",
    "  \"observation\": {\n",
    "      \"SubjectRaceCode\": \"B\",\n",
    "      \"StatuteReason\": \"Stop sign\", \n",
    "      \"InterventionReasonCode\": \"V\", \n",
    "      \"ResidentIndicator\": False, \n",
    "      \"SearchAuthorizationCode\": \"N\",\n",
    "      \"SubjectAge\": 20,\n",
    "      \"hour\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "url=\"http://127.0.0.1:5000/predict\"\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "r = requests.post(url, data=json.dumps(observation), headers=headers)\n",
    "\n",
    "print(r.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\"error\":\"Invalid value provided for SubjectSexCode: B. Allowed values are: 'M','F'\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non sense values that don't break the request\n",
    "\n",
    "observation = {\n",
    "  \"id\": \"fake-observation-{}\".format(uuid4()),\n",
    "  \"observation\": {\n",
    "      \"SubjectRaceCode\": \"A\",\n",
    "      \"SubjectSexCode\": \"B\",\n",
    "      \"SubjectEthnicityCode\": \"C\",\n",
    "      \"StatuteReason\": \"D\", \n",
    "      \"InterventionReasonCode\": \"E\", \n",
    "      \"ResidentIndicator\": \"F\", \n",
    "      \"SearchAuthorizationCode\": \"F\",\n",
    "      \"SubjectAge\": 1,\n",
    "      \"hour\": 90,\n",
    "      \"day_of_week\": \"potato\",\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "url=\"http://127.0.0.1:5000/predict\"\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "r = requests.post(url, data=json.dumps(observation), headers=headers)\n",
    "\n",
    "print(r.status_code)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\"error\":\"Field `SubjectAge` is not an integer\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Non sense values that break the request\n",
    "\n",
    "observation = {\n",
    "  \"id\": \"fake-observation-{}\".format(uuid4()),\n",
    "  \"observation\": {\n",
    "      \"SubjectRaceCode\": \"B\",\n",
    "      \"SubjectSexCode\": \"M\",\n",
    "      \"SubjectEthnicityCode\": \"N\",\n",
    "      \"StatuteReason\": \"Stop Sign\", \n",
    "      \"InterventionReasonCode\": \"V\", \n",
    "      \"ResidentIndicator\": False, \n",
    "      \"SearchAuthorizationCode\": \"N\",\n",
    "      \"SubjectAge\": \"twenty\",\n",
    "      \"hour\": 20,\n",
    "      \"day_of_week\": \"Tuesday\",\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "url=\"http://127.0.0.1:5000/predict\"\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "r = requests.post(url, data=json.dumps(observation), headers=headers)\n",
    "\n",
    "print(r.status_code)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/great_success.jpg\" width=400 />\n",
    "\n",
    "Now we have a bit more robust server. Try out other examples to see if you can break the server!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 A final note\n",
    "\n",
    "When designing APIs there are actually proper error codes to apply for each type of error. For example here the correct code might be 422 (`Unprocessable Entity`) while for the previously seen error with repeated ids we may want to return a 409 (`Conflict`). However, you don't need to know these for now.\n",
    "\n",
    "<a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/418\"><img src=\"media/418_teapot.jpeg\" width=400 /></a>\n",
    "\n",
    "_Who said programmers are no fun?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Monitoring and maintaining the system\n",
    "\n",
    "So you've deployed your model, you made sure to protect it from bad input, you even found a bunch of other potential sources of issues and protected against them. \n",
    "\n",
    "What next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Uptime and surviving failures\n",
    "\n",
    "Even when you are 100% sure all you did was right, things can go wrong. After all, just because your model is deployed on the \"cloud\", it doesn't mean that you can forget about the underlying system and resources. All of those, even though you don't manage them directly, can be the cause of problems with your service. \n",
    "\n",
    "<img src=\"media/cloud-what-if-i-told-you.png\" width=450 />\n",
    "\n",
    "So, how does the average developer handle all of this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Logging, metrics, monitoring and alerting\n",
    "\n",
    "#### 3.2.1 Logging\n",
    "\n",
    "One way of better understanding what is happening to your system is by creating logs. Logs are just textual\n",
    "pieces of information that show what the app is doing. They can be emitted from different points in your code and \n",
    "typically exist in the underlying libraries you use. \n",
    "\n",
    "When you create an app in Python, errors and their tracebacks (where the error came from) will be exposed in the STDERR (in this case of a local app in the terminal where you run it). You can consider that one type of logging. However, these are not enough and we typically create more logs in important parts of our applications. You will learn more about this in BLU15.\n",
    "\n",
    "At the simplest level, it's important to learn where to check for your logs, so you can debug quickly when your app is not working. For example, let's say we deploy an app but pass the wrong paths to the necessary model elements (like `columns.json`, `pipeline.pickle`, etc). When we deploy the app it will crash. By accessing the logs we would be able to check why that is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 System metrics \n",
    "\n",
    "Metrics represent the raw measurements you can expose and collect in your system. They can be generated at many levels, from the operating system where you are running your service to the application that you are running. At the system level, for example, you can measure most resource-related metrics: \n",
    "\n",
    "* how many CPUs you are using\n",
    "* how much memory you are using\n",
    "* how much disk space you are using\n",
    "\n",
    "Another example of a dependency in your system that can be a problem is the database, where you can measure different aspects:\n",
    "\n",
    "* how many connections to the database are open\n",
    "* size of the dabase, i.e. the amount of disk space it is using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you may want to measure particular aspects of the application, for example related to the requests your server is receiving. In this group you could measure the following:\n",
    "\n",
    "* how much time each request took - also known as request latency\n",
    "* how many requests were done to the server\n",
    "* how many requests resulted in 200 codes (OK)\n",
    "* how many requests resulted in error codes\n",
    "\n",
    "Finally, for each problem, there will be a number of \"business level\" metrics, and these can overlap with some of the ones mentioned or be completely different. For example, part of our requirements can be that the server should respond in less than 20 milliseconds, which overlaps with the request latency mentioned in the points above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Model Metrics \n",
    "\n",
    "When serving machine learning models it is interesting to measure also model metrics. This depends a lot on the models you are using and on your input, but you could expose as metrics things such as:\n",
    "\n",
    "* the feature distribution for each feature - hour, sex, age, and so on... \n",
    "* the prediction distribution of your model\n",
    "* the probability distribution of your model\n",
    "\n",
    "These can help you be quick to identify data shifts or problems with your model.\n",
    "\n",
    "Overall, emitting or exposing these metrics is known as instrumenting your services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Monitoring\n",
    "\n",
    "Once you are outputting your metrics, you still need a way to crunch them into meaningful insights. Obviously you are not going to go through, or manually curate, thousands and thousands of measurements.\n",
    "\n",
    "The process of collecting and aggregating these measures, while potentially providing some sort of analytics on them, is called monitoring. The tools that provide this functionality are called dashboards. They give you a place to store the aggregated metrics and create visualizations. They can also provide you the ability to set up thresholds or other conditions that, when met, trigger some sort of response.\n",
    "\n",
    "In more complex applications, the monitoring might even have its own specific systems that need to be monitored. But for now, think of it just as a side system that can provide you with a view over the things you want to measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/monitoring-monitors.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.5 Alerting\n",
    "\n",
    "Finally, the last step in tracking the health of your app is alerting. As mentioned before some tools for monitoring already allow integrated alerting functionality, and you can set up certain conditions to alert a responsible person.\n",
    "\n",
    "While you may want certain responses to be even more automated and have a specific programmatic action to happen, the main purpose of alerting is really to bring a person's attention to the status of the system. Usually, alerts have information that allows the watcher to either take the proper action to fix the problem or at least gives them a starting point to investigate what the problem is.\n",
    "\n",
    "An example of a potential dashboard you could set up for monitoring and alerting is shown below. There, the red lines represent thresholds that when passed would trigger alerts. For example, if the response time goes above a given number, then we want to be notified and potentially investigate the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/monitor-metrics-example.png\" width=1000 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these things together allow you to have an overview over your system and make sure it's healthy, but obviously with each error or problem, you are the one who needs to improve the code and make it more reliable. Which brings us to our final section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Testing\n",
    "\n",
    "If you write a program, even when you are super careful and think you did everything 100% right, usually you try to run it and something is wrong. This is true even just locally, without accounting for all the system components and potentially bad input.\n",
    "\n",
    "> Anything that can go wrong, will go wrong\n",
    "\n",
    "(this is called Murphy's law)\n",
    "\n",
    "That's why we usually perform some sort of testing on our server and model before we share it with the client. This usually happens before you deploy the model to what is called the production environment - this is, the same environment where your app is available to the client. It even happens before you try to run your server locally.\n",
    "\n",
    "There are several layers of testing that you can apply, and quality assessment is a whole discipline by itself, but here we want to introduce you to the most common one: unit testing.\n",
    "\n",
    "#### 3.3.1 Unit tests\n",
    "\n",
    "Unit tests focus on a small part of your code, usually a well isolated one. Let's take one of our functions from a previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_success_rate_above(y_true, y_pred, min_success_rate=0.5):\n",
    "    \"\"\"\n",
    "    Verifies the success rate on a test set is above a provided minimum\n",
    "    \"\"\"\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, pos_label=True)\n",
    "    is_satisfied = (precision >= min_success_rate)\n",
    "    \n",
    "    return is_satisfied, precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function description is `Verifies the success rate on a test set is above a provided minimum`. So how would we go about defining our tests for it? \n",
    "\n",
    "We can think of potential scenarios that we know should be verified as success and scenarios that shouldn't. For example, if I have a vector where all my predictions are right, and my minimum success rate is 0.5, then my function should inform me that the condition is satisfied and return a precision of 1. On the other hand, if I pass an array that is completely wrong, I should get the opposite - my condition is not satisfied and the precision should be 0.\n",
    "\n",
    "We could also decide on more fine-grained cases for which we know what precision values and outcome we should get.\n",
    "\n",
    "For example, we could write the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_verify_success_rate_above():\n",
    "    \n",
    "    # Test correct vector returns success and 1 precision\n",
    "    y = np.array([1.0, 1.0, 0.0, 0.0])\n",
    "    is_satisfied, precision = verify_success_rate_above(y, y)\n",
    "    assert is_satisfied == True\n",
    "    assert precision == 1.0\n",
    "    \n",
    "    # Test wrong vector returns unsuccessful and 0 precision\n",
    "    y_true = np.array([1.0, 1.0, 0.0, 0.0])\n",
    "    y_pred = np.array([0.0, 0.0, 1.0, 1.0])\n",
    "    is_satisfied, precision = verify_success_rate_above(y_true, y_pred)\n",
    "    assert is_satisfied == False\n",
    "    assert precision == 0.0\n",
    "    \n",
    "    # Test 3/4 of positive labels correct\n",
    "    y_true = np.array([0.0, 1.0, 1.0, 1.0, 0.0])\n",
    "    y_pred = np.array([0.0, 1.0, 1.0, 1.0, 1.0])\n",
    "    is_satisfied, precision = verify_success_rate_above(y_true, y_pred)\n",
    "    assert is_satisfied == True\n",
    "    assert precision == 0.75\n",
    "\n",
    "\n",
    "test_verify_success_rate_above()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how would this help us catch a problem? Let's say we wrote our tests after a lot of thinking and then went on to write the function. But for some reason, we got confused and picked the wrong metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m is_satisfied \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m precision \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.75\u001b[39m\n\u001b[0;32m---> 37\u001b[0m \u001b[43mtest_verify_success_rate_above\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[32], line 34\u001b[0m, in \u001b[0;36mtest_verify_success_rate_above\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m is_satisfied, precision \u001b[38;5;241m=\u001b[39m verify_wrong_success_rate_above(y_true, y_pred)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m is_satisfied \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m precision \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.75\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function with \"bug\"\n",
    "def verify_wrong_success_rate_above(y_true, y_pred, min_success_rate=0.5):\n",
    "    \"\"\"\n",
    "    Verifies the success rate on a test set is above a provided minimum\n",
    "    \"\"\"\n",
    "\n",
    "    precision = recall_score(y_true, y_pred, pos_label=True)\n",
    "    is_satisfied = (precision >= min_success_rate)\n",
    "    \n",
    "    return is_satisfied, precision\n",
    "\n",
    "\n",
    "# Tests\n",
    "def test_verify_success_rate_above():\n",
    "    \n",
    "    # Test correct vector returns success and 1 precision\n",
    "    y = np.array([1.0, 1.0, 0.0, 0.0])\n",
    "    is_satisfied, precision = verify_wrong_success_rate_above(y, y)\n",
    "    assert is_satisfied == True\n",
    "    assert precision == 1.0\n",
    "    \n",
    "    # Test wrong vector returns unsuccessful and 0 precision\n",
    "    y_true = np.array([1.0, 1.0, 0.0, 0.0])\n",
    "    y_pred = np.array([0.0, 0.0, 1.0, 1.0])\n",
    "    is_satisfied, precision = verify_wrong_success_rate_above(y_true, y_pred)\n",
    "    assert is_satisfied == False\n",
    "    assert precision == 0.0\n",
    "    \n",
    "    # Test 3/4 of positive labels correct\n",
    "    y_true = np.array([0.0, 1.0, 1.0, 1.0, 0.0])\n",
    "    y_pred = np.array([0.0, 1.0, 1.0, 1.0, 1.0])\n",
    "    is_satisfied, precision = verify_wrong_success_rate_above(y_true, y_pred)\n",
    "    assert is_satisfied == True\n",
    "    assert precision == 0.75\n",
    "\n",
    "\n",
    "test_verify_success_rate_above()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your tests would actually break. \n",
    "\n",
    "Writing tests forces you to think about the different scenarios that may happen, and usually when done before writing the code it leads you to better understand what code you should actually write - writing tests before the code is called test driven development. For each piece of code you are writing, there is an intended behavior. And this behavior can be put into tests.\n",
    "\n",
    "If you actually think about it, a lot of the assertions the instructors write to test your code in the exercise notebooks could actually be packed into unit tests. They basically describe the expected behavior of your function and enforce it by breaking if the behavior is wrong. \n",
    "\n",
    "Unit tests help you a lot to make sure your server is robust, but of course you should also try to test the end-to-end behavior and try out your app locally before you deploy it. The difference is, unit tests can be easily automated and will prevent changes from breaking previously defined behaviors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it. We will not dive too deep into these topics, but keep in mind that they are important for any real-life app that you may work on. So if you take something out of this: monitor your servers, and always, always, test your code before you ship it to production.\n",
    "\n",
    "<img src=\"media/testing-in-production.png\" width=400 />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
