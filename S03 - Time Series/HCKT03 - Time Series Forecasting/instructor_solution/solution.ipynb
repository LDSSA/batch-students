{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922103c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import timedelta\n",
    "import sys\n",
    "import os\n",
    "import utils\n",
    "\n",
    "for item in ['../utils', '../portal']:\n",
    "    module_path = os.path.abspath(item)\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "    \n",
    "plt.rcParams['figure.figsize'] = [16, 4]\n",
    "\n",
    "path_data = \"../data\"\n",
    "path_portal = \"../portal\"\n",
    "year = 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee1c20",
   "metadata": {},
   "source": [
    "# HCKT03 - Time Series Forecasting\n",
    "\n",
    "## 1. Data Cleaning\n",
    "- Impute missing values using interpolation or statistical methods.\n",
    "- Remove invalid PM2.5 values exceeding 165 µg/m³.\n",
    "- Aggregate data spatially across sites to address gaps and inconsistencies.\n",
    "\n",
    "## 2. Data Exploration\n",
    "- Visualize PM2.5 and NOx readings for each site. Highlight trends, outliers, and missing values.\n",
    "- Analyze daily and hourly patterns for both variables to identify recurring peaks or anomalies.\n",
    "- Examine cross-correlations between PM2.5 and NOx to uncover lagged and lead relationships.\n",
    "- Apply seasonal decomposition to separate trend, seasonal, and residual components in the PM2.5 data.\n",
    "- Compare PM2.5 patterns between early November and December to determine if levels are improving or worsening as the year progresses.\n",
    "\n",
    "\n",
    "## 3. Feature Engineering\n",
    "- Create lagged features for PM2.5 and NOx to capture temporal dependencies (e.g., 1-hour, 6-hour, and 1-day lags).\n",
    "- Add time-based features, such as hour of the day and day of the week, to model seasonal trends.\n",
    "- Spatially aggregate NOx as a single exogenous variable for modeling.\n",
    "- Test the predictive power of real NOx data versus forecasted NOx.\n",
    "\n",
    "## 4. Modeling\n",
    "- **Baseline Models**: Build Linear Regression and Gradient Boosting models incorporating NOx as an exogenous variable.\n",
    "- **Improved Models**: Test SARIMAX models with NOx as an exogenous variable. Perform stationarity checks (e.g., ADF test) and apply differencing if needed.\n",
    "- **Advanced Models**: Experiment with Random Forest and XGBoost for multivariate regression, combining PM2.5 and NOx features.\n",
    "- Evaluate model performance using metrics such as Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Akaike Information Criterion (AIC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a241ad10",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87b912",
   "metadata": {},
   "source": [
    "### Fetch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad6734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref = pd.read_csv(f'{path_data}/train.csv')\n",
    "df_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ff9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ref.copy()\n",
    "df.datetime = pd.to_datetime(df.datetime)\n",
    "df = df.set_index(['datetime','site_id'], drop=True).sort_index()\n",
    "\n",
    "sites = df.index.get_level_values('site_id').unique()\n",
    "sensors = df.columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exog = pd.read_csv(f'{path_data}/nox_forecast.csv')\n",
    "df_exog.datetime = pd.to_datetime(df_exog.datetime)\n",
    "df_exog = df_exog.set_index('datetime', drop=True).sort_index()\n",
    "df_exog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c705e8ec",
   "metadata": {},
   "source": [
    "### Handle extreme values\n",
    "\n",
    "Valid values for `pm25` values range from `0` to `165`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d5ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().loc[['min','max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7cafbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_threshold = 165\n",
    "selected = df[df.pm25 > upper_threshold]\n",
    "idx_selected = selected.index\n",
    "iloc_selected = [df.index.get_loc(idx) for idx in idx_selected]\n",
    "\n",
    "for idx in iloc_selected:\n",
    "    df.iloc[idx, df.columns.get_loc('pm25')] = df.iloc[idx-1, df.columns.get_loc('pm25')]\n",
    "    \n",
    "df.describe().loc[['min','max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e98e34e",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b753688",
   "metadata": {},
   "source": [
    "### Generate surrogate data for daily analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spatial = df.groupby('datetime').mean()\n",
    "df_spatial = df_spatial.resample('h').mean()\n",
    "df_spatial = df_spatial.interpolate(method='linear')\n",
    "df_spatial = df_spatial.dropna()\n",
    "\n",
    "df_exog = df_exog.resample('h').mean()\n",
    "\n",
    "df_spatial_d = df_spatial.resample('d').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba97f70",
   "metadata": {},
   "source": [
    "### Visualize Dataset\n",
    "\n",
    "- **Seasonal Decomposition**: Reveals expected weekly and seasonal patterns in the data.  \n",
    "- **Splitting the Dataset**: Splitting the data between mid-October and early November ensures stationarity within each segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75f0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'pm25'\n",
    "data = df_spatial[sensor]\n",
    "decomposition = seasonal_decompose(data, model='additive')\n",
    "\n",
    "fig = decomposition.plot()\n",
    "fig.axes[0].set_ylabel('Original')\n",
    "fig.axes[3].lines[0].set_markersize(3)\n",
    "fig.axes[3].set_xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e293fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_spatial_d[sensor]\n",
    "decomposition_d = seasonal_decompose(data, model='additive')\n",
    "\n",
    "fig = decomposition_d.plot()\n",
    "fig.axes[0].set_ylabel('Original')\n",
    "fig.axes[3].lines[0].set_markersize(3)\n",
    "fig.axes[3].set_xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8045a24",
   "metadata": {},
   "source": [
    "### Winter summer split to regain stationarity\n",
    "After a few tries, we settle for splitting on 1st November."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d23f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = '2023-11-01'\n",
    "\n",
    "df_spatial_summer = df_spatial.loc[:day]\n",
    "df_spatial_winter = df_spatial.loc[day:]\n",
    "\n",
    "df_spatial_d_summer = df_spatial_d.loc[:day]\n",
    "df_spatial_d_winter = df_spatial_d.loc[day:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f87b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'pm25'\n",
    "data = df_spatial_d_summer[sensor]\n",
    "decomposition_d_summer = seasonal_decompose(data, model='additive')\n",
    "\n",
    "fig = decomposition_d_summer.plot()\n",
    "fig.axes[0].set_ylabel('Original')\n",
    "fig.axes[3].lines[0].set_markersize(3)\n",
    "fig.axes[3].set_xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5617349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'pm25'\n",
    "data = df_spatial_d_winter[sensor]\n",
    "decomposition_d_winter = seasonal_decompose(data, model='additive')\n",
    "\n",
    "fig = decomposition_d_winter.plot()\n",
    "fig.axes[0].set_ylabel('Original')\n",
    "fig.axes[3].lines[0].set_markersize(3)\n",
    "fig.axes[3].set_xlabel('Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42e96be",
   "metadata": {},
   "source": [
    "### Out of Curiosity - Residual Distribution Plots\n",
    "\n",
    "To visually estimate the normality of residuals, plot histograms of residuals:\n",
    "\n",
    "- **Daily Data**: Insufficient data points for a reliable estimation.  \n",
    "- **Hourly Data**: Residuals suggest normality, but as a **multiplicative process** — applying a logarithmic transformation (**logged data**) may improve modeling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28524f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'pm25'\n",
    "resid_d = decomposition_d.resid\n",
    "resid_d_summer = decomposition_d_summer.resid\n",
    "resid_d_winter = decomposition_d_winter.resid\n",
    "\n",
    "resid_d_n = (resid_d-resid_d.mean())/resid_d.std()\n",
    "resid_d_summer_n = (resid_d_summer-resid_d_summer.mean())/resid_d_summer.std()\n",
    "resid_d_winter_n = (resid_d_winter-resid_d_winter.mean())/resid_d_winter.std()\n",
    "\n",
    "bins = np.linspace(-3,3, num=16)\n",
    "plt.hist(resid_d_n, bins=bins, density=True, alpha=0.5, label='all')\n",
    "plt.hist(resid_d_summer_n, bins=bins, density=True, alpha=0.5, label='summer')\n",
    "plt.hist(resid_d_winter_n, bins=bins, density=True, alpha=0.5, label='winter')\n",
    "plt.title(f'Histogram of residuals {sensor}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e9719",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'pm25'\n",
    "resid = seasonal_decompose(df_spatial[sensor], model='additive').resid\n",
    "resid_summer = seasonal_decompose(df_spatial_summer[sensor], model='additive').resid\n",
    "resid_winter = seasonal_decompose(df_spatial_winter[sensor], model='additive').resid\n",
    "\n",
    "resid_n = (resid-resid.mean())/resid.std()\n",
    "resid_summer_n = (resid_summer-resid_summer.mean())/resid_summer.std()\n",
    "resid_winter_n = (resid_winter-resid_winter.mean())/resid_winter.std()\n",
    "\n",
    "x = np.linspace(-3, 3, num=1000)\n",
    "y = sp.stats.norm.pdf(x)\n",
    "\n",
    "bins = np.linspace(-3,3, num=26)\n",
    "\n",
    "plt.hist(resid_n, bins=bins, alpha=0.3, density=True, label='all')\n",
    "plt.hist(resid_summer_n, bins=bins, alpha=0.3, density=True, label='summer')\n",
    "plt.hist(resid_winter_n, bins=bins, alpha=0.3, density=True, label='winter')\n",
    "plt.plot(x, y, color='red', linewidth=2)\n",
    "plt.title(f'Histogram of residuals (additive) {sensor}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03291dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-6\n",
    "sensor = 'pm25'\n",
    "resid = seasonal_decompose(df_spatial[sensor]+eps, model='multiplicative').resid\n",
    "resid_summer = seasonal_decompose(df_spatial_summer[sensor]+eps, model='multiplicative').resid\n",
    "resid_winter = seasonal_decompose(df_spatial_winter[sensor]+eps, model='multiplicative').resid\n",
    "\n",
    "resid_n = (resid-resid.mean())/resid.std()\n",
    "resid_summer_n = (resid_summer-resid_summer.mean())/resid_summer.std()\n",
    "resid_winter_n = (resid_winter-resid_winter.mean())/resid_winter.std()\n",
    "\n",
    "x = np.linspace(-3, 3, num=1000)\n",
    "y = sp.stats.norm.pdf(x)\n",
    "\n",
    "bins = np.linspace(-3,3, num=26)\n",
    "\n",
    "plt.hist(resid_n, bins=bins, alpha=0.3, density=True, label='all')\n",
    "plt.hist(resid_summer_n, bins=bins, alpha=0.3, density=True, label='summer')\n",
    "plt.hist(resid_winter_n, bins=bins, alpha=0.3, density=True, label='winter')\n",
    "plt.plot(x, y, color='red', linewidth=2)\n",
    "plt.title(f'Histogram of residuals (multiplicative) {sensor}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06875f3",
   "metadata": {},
   "source": [
    "### Plot partial autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pacf_top(data, n=5):\n",
    "    values = pacf(data)\n",
    "    idx_sort = np.argsort(np.abs(values))[::-1]\n",
    "    for idx in idx_sort[1:n+1]:\n",
    "        print(f'{idx}\\t{values[idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6d07cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'pm25'\n",
    "lags = range(1, 48)\n",
    "data = df_spatial[sensor]\n",
    "\n",
    "plot_pacf(data, lags=lags)\n",
    "plt.xlabel('Lag (h)')\n",
    "plt.ylabel('Partial Autocorrelation')\n",
    "plt.title(f'Partial Autocorrelation of {sensor}')\n",
    "plt.ylim([-0.25,1])\n",
    "plt.show()\n",
    "\n",
    "pacf_top(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2928c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'pm25'\n",
    "lags = range(1, 48)\n",
    "data = df_spatial_summer[sensor]\n",
    "\n",
    "plot_pacf(data, lags=lags)\n",
    "plt.xlabel('Lag (h)')\n",
    "plt.ylabel('Partial Autocorrelation')\n",
    "plt.title(f'Partial Autocorrelation of {sensor}  - Summer')\n",
    "plt.ylim([-0.25,1])\n",
    "plt.show()\n",
    "\n",
    "pacf_top(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'pm25'\n",
    "lags = range(1, 48)\n",
    "data = df_spatial_winter[sensor]\n",
    "\n",
    "plot_pacf(data, lags=lags)\n",
    "plt.xlabel('Lag (h)')\n",
    "plt.ylabel('Partial Autocorrelation')\n",
    "plt.title(f'Partial Autocorrelation of {sensor} - Winter')\n",
    "plt.ylim([-0.25,1])\n",
    "plt.show()\n",
    "\n",
    "pacf_top(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f35e7c",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dd4f94",
   "metadata": {},
   "source": [
    "### Regaining Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0a8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = df_spatial_winter\n",
    "\n",
    "df_train_val = my_df.iloc[:-24*10]\n",
    "df_test = my_df.iloc[-24*10:]\n",
    "df_train = df_train_val.iloc[:-24*10]\n",
    "df_val = df_train_val.iloc[-24*10:]\n",
    "\n",
    "print(df_train_val.index.min(), df_train_val.index.max())\n",
    "print(df_train.index.min(), df_train.index.max())\n",
    "print(df_val.index.min(), df_val.index.max())\n",
    "print(df_test.index.min(), df_test.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660246a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor = 'pm25'\n",
    "lags = range(1, 48)\n",
    "data = df_train[sensor]\n",
    "\n",
    "plot_pacf(data, lags=lags)\n",
    "plt.xlabel('Lag (h)')\n",
    "plt.ylabel('Partial Autocorrelation')\n",
    "plt.title(f'Partial Autocorrelation of {sensor} - Winter')\n",
    "plt.ylim([-0.25,1])\n",
    "plt.show()\n",
    "\n",
    "pacf_top(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb066a",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909899fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test.pm25\n",
    "train_val = df_train_val.pm25\n",
    "train = df_train.pm25\n",
    "val = df_val.pm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66575c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'model': [LinearRegression(), GradientBoostingRegressor(n_estimators=20, random_state=10)], \n",
    "    'num_lags': [0,1,2,3],\n",
    "    'num_diffs': [0,1,2],\n",
    "    'weekday':[True],\n",
    "    'month':[False],\n",
    "    'holidays': [False],\n",
    "    'rolling' : [[]],\n",
    "}\n",
    "\n",
    "grid = ParameterGrid(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee660d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "def wrap_model_selection(params): \n",
    "    predictions = utils.multistep_forecast(\n",
    "        original=train, \n",
    "        model=params['model'], \n",
    "        num_lags=params['num_lags'],\n",
    "        num_diffs=params['num_diffs'],\n",
    "        weekday=params['weekday'],\n",
    "        month=params['month'],\n",
    "        rolling=params['rolling'],\n",
    "        holidays=params['holidays'],\n",
    "        num_periods_ahead=len(val), \n",
    "    )\n",
    "    return params,mean_absolute_error(val, predictions)\n",
    "\n",
    "grid_search_result = Parallel(n_jobs=-1)(\n",
    "    delayed(wrap_model_selection)(params=params) \n",
    "    for params in tqdm(grid)\n",
    ")\n",
    "\n",
    "df_cv = pd.DataFrame(grid_search_result, columns=['params','mae']).sort_values('mae')\n",
    "\n",
    "best_params = df_cv.iloc[0].params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98227b12",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411e09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_params = best_params\n",
    "forecast_multi_step = utils.multistep_forecast(\n",
    "     original=train_val,\n",
    "     model=my_params['model'], \n",
    "     num_lags=my_params['num_lags'],\n",
    "     num_diffs=my_params['num_diffs'],\n",
    "     weekday=my_params['weekday'],\n",
    "     month=my_params['month'],\n",
    "     rolling=my_params['rolling'],\n",
    "     holidays=my_params['holidays'],\n",
    "     num_periods_ahead=len(test)\n",
    ")\n",
    "\n",
    "mae_multi_step = mean_absolute_error(test, forecast_multi_step)\n",
    "mae_multi_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ce2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test, label='original')\n",
    "plt.plot(pd.Series(forecast_multi_step,index=test.index), label='multi-step forecast')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(sensor)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8304b4d",
   "metadata": {},
   "source": [
    "### Introducing `exog` forecast - same timestep signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c78b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = df_exog.exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22abb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "param_grid_exog = dict(param_grid)\n",
    "param_grid_exog['exog'] = [exog]\n",
    "grid_exog = ParameterGrid(param_grid_exog)\n",
    "\n",
    "def wrap_model_selection(params): \n",
    "    predictions = utils.multistep_forecast(\n",
    "        original=train, \n",
    "        model=params['model'], \n",
    "        num_lags=params['num_lags'],\n",
    "        num_diffs=params['num_diffs'],\n",
    "        weekday=params['weekday'],\n",
    "        month=params['month'],\n",
    "        rolling=params['rolling'],\n",
    "        holidays=params['holidays'],\n",
    "        num_periods_ahead=len(val),\n",
    "        exog=params['exog'],\n",
    "    )\n",
    "    return params, mean_absolute_error(val, predictions)\n",
    "\n",
    "grid_search_result_exog = Parallel(n_jobs=-1)(\n",
    "    delayed(wrap_model_selection)(params=params)\n",
    "    for params in tqdm(grid_exog)\n",
    ")\n",
    "\n",
    "df_cv_exog = pd.DataFrame(grid_search_result_exog, columns=['params','mae']).sort_values('mae')\n",
    "\n",
    "best_params_exog = df_cv_exog.iloc[0].params\n",
    "\n",
    "{key:value for key, value in best_params_exog.items() if key!='exog'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da15e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_params = best_params_exog\n",
    "\n",
    "forecast_multi_step_exog = utils.multistep_forecast(\n",
    "     original=train_val,\n",
    "     model=my_params['model'], \n",
    "     num_lags=my_params['num_lags'],\n",
    "     num_diffs=my_params['num_diffs'],\n",
    "     weekday=my_params['weekday'],\n",
    "     month=my_params['month'],\n",
    "     rolling=my_params['rolling'],\n",
    "     holidays=my_params['holidays'],\n",
    "     num_periods_ahead=len(test),\n",
    "     exog=my_params['exog'],\n",
    ")\n",
    "\n",
    "mae_multi_step = mean_absolute_error(test, forecast_multi_step_exog)\n",
    "mae_multi_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e162bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.Series(forecast_multi_step_exog, index=test.index), label='multi-step forecast')\n",
    "plt.plot(test, label='original')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(sensor)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be743835",
   "metadata": {},
   "source": [
    "### What has the model learned vs exog signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df4def",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(forecast_multi_step_exog, index=test.index)\n",
    "data = (data-data.mean())/data.std()\n",
    "data_ref = exog.loc[data.index]\n",
    "data_ref = (data_ref-data_ref.mean())/data_ref.std()\n",
    "\n",
    "plt.plot(data, label='multi-step forecast')\n",
    "plt.plot(data_ref, label='exog')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(sensor)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97616f27",
   "metadata": {},
   "source": [
    "### Introducing `exog leads` - multiple steps into the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045e56ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_params = dict(best_params_exog)\n",
    "my_params['num_lags'] = 24\n",
    "my_params['num_diffs'] = 24\n",
    "my_params['num_exog_leads'] = len(test)\n",
    "\n",
    "forecast_multi_step_exog = utils.multistep_forecast(\n",
    "    original=train_val,\n",
    "    model=my_params['model'], \n",
    "    num_lags=my_params['num_lags'],\n",
    "    num_diffs=my_params['num_diffs'],\n",
    "    weekday=my_params['weekday'],\n",
    "    month=my_params['month'],\n",
    "    rolling=my_params['rolling'],\n",
    "    holidays=my_params['holidays'],\n",
    "    num_periods_ahead=len(test),\n",
    "    exog=my_params['exog'],\n",
    "    num_exog_leads=my_params['num_exog_leads'],\n",
    ")\n",
    "\n",
    "mae_multi_step = mean_absolute_error(test, forecast_multi_step_exog)\n",
    "mae_multi_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.Series(forecast_multi_step_exog, index=test.index), label='multi-step forecast')\n",
    "plt.plot(test, label='original')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(sensor)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c868c604",
   "metadata": {},
   "source": [
    "### What has the model learned vs exog signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccff42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(forecast_multi_step_exog, index=test.index)\n",
    "data = (data-data.mean())/data.std()\n",
    "data_ref = exog.loc[data.index]\n",
    "data_ref = (data_ref-data_ref.mean())/data_ref.std()\n",
    "\n",
    "plt.plot(data, label='multi-step forecast')\n",
    "plt.plot(data_ref, label='exog')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel(sensor)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
